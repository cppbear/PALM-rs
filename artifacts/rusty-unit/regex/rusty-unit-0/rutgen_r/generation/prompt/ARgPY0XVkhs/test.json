{
  "system_pt": "As a software testing expert, please generate Rust test functions based on the following guidelines:\n1. Provide the code in plain text format, without explanations or Markdown.\n2. If the method under test belongs to a trait, construct appropriate structs within the test function, but avoid method overrides. If the method under test uses generics, instantiate them with suitable types based on the context.\n3. Generate test code with minimal scope: avoid creating external structures or implementations. Instead, define any necessary helper structures or implementations directly within the test function when required.\n4. Whenever possible, initialize the corresponding data structures using the initialization methods provided in the context if exist.\n5. Ensure the generated function is fully implemented and can be compiled and executed directly without any missing parts.\n6. Create a minimal yet complete set of test functions, ensuring they adhere to all provided preconditions and cover boundary conditions.\n7. Do not create a test module, but include intrinsic attributes like #[test] or #[should_panic] where necessary.\n",
  "static_pt": "// src/literal/mod.rs\n// crate name is regex\nThe function to be tested is presented as follows:\nfn new(lits: &Literals, sset: SingleByteSet) -> Self {\n    if lits.literals().is_empty() {\n        return Matcher::Empty;\n    }\n    if sset.dense.len() >= 26 {\n        // Avoid trying to match a large number of single bytes.\n        // This is *very* sensitive to a frequency analysis comparison\n        // between the bytes in sset and the composition of the haystack.\n        // No matter the size of sset, if its members all are rare in the\n        // haystack, then it'd be worth using it. How to tune this... IDK.\n        // ---AG\n        return Matcher::Empty;\n    }\n    if sset.complete {\n        return Matcher::Bytes(sset);\n    }\n    if lits.literals().len() == 1 {\n        let lit = lits.literals()[0].to_vec();\n        if BoyerMooreSearch::should_use(lit.as_slice()) {\n            return Matcher::BoyerMoore(BoyerMooreSearch::new(lit));\n        } else {\n            return Matcher::FreqyPacked(FreqyPacked::new(lit));\n        }\n    }\n    let is_aho_corasick_fast = sset.dense.len() == 1 && sset.all_ascii;\n    if TeddyAVX2::available() && !is_aho_corasick_fast {\n        const MAX_TEDDY_LITERALS: usize = 32;\n        if lits.literals().len() <= MAX_TEDDY_LITERALS {\n            if let Some(ted) = TeddyAVX2::new(lits) {\n                return Matcher::TeddyAVX2(ted);\n            }\n        }\n    }\n    if TeddySSSE3::available() && !is_aho_corasick_fast {\n        // Only try Teddy if Aho-Corasick can't use memchr on an ASCII\n        // byte. Also, in its current form, Teddy doesn't scale well to\n        // lots of literals.\n        //\n        // We impose the ASCII restriction since an alternation of\n        // non-ASCII string literals in the same language is likely to all\n        // start with the same byte. Even worse, the corpus being searched\n        // probably has a similar composition, which ends up completely\n        // negating the benefit of memchr.\n        const MAX_TEDDY_LITERALS: usize = 32;\n        if lits.literals().len() <= MAX_TEDDY_LITERALS {\n            if let Some(ted) = TeddySSSE3::new(lits) {\n                return Matcher::TeddySSSE3(ted);\n            }\n        }\n        // Fallthrough to ol' reliable Aho-Corasick...\n    }\n    let pats = lits.literals().to_owned();\n    Matcher::AC(AcAutomaton::new(pats).into_full())\n}\nGiven the following constraints, potential panic-triggering statements, and expected return values/types (all extracted from the function under test).\nGenerate test inputs that maximize the function's runtime satisfaction of all constraints and expected outputs while considering panic conditions:\n",
  "depend_pt": ""
}