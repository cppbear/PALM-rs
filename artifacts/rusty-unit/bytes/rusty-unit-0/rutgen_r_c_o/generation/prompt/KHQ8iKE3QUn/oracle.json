{
  "system_pt": "As a software testing expert, please generate accurate test oracles code based on the provided information. Follow these guidelines:\n1. Generate executable test oracle codes in plain text format, one per line. Do not output complete test functions, do not repeat provided test prefixes, avoid additional explanations, and do not use Markdown.\n2. Generate necessary test oracles solely for the provided test prefixes.\n3. Each test oracle's assertions are independent and have no dependencies between them.\n4. Group all non-assertion statements first, followed by all assertion statements.\n5. Generate test oracles by interpreting the behavior of the test function through the provided test prefixes, context, and documentation.\n",
  "static_pt": "The context for the focal function is as follows:\n// src/buf/buf_mut.rs\n// crate name is bytes\nuse crate::buf::{limit, Chain, Limit, UninitSlice};\n#[cfg(feature = \"std\")]\nuse crate::buf::{writer, Writer};\nuse crate::{panic_advance, panic_does_not_fit, TryGetError};\nuse core::{mem, ptr, usize};\nuse alloc::{boxed::Box, vec::Vec};\nmacro_rules! deref_forward_bufmut {\n    () => {\n        #[inline] fn remaining_mut(& self) -> usize { (** self).remaining_mut() }\n        #[inline] fn chunk_mut(& mut self) -> & mut UninitSlice { (** self).chunk_mut() }\n        #[inline] unsafe fn advance_mut(& mut self, cnt : usize) { (** self)\n        .advance_mut(cnt) } #[inline] fn put_slice(& mut self, src : & [u8]) { (** self)\n        .put_slice(src) } #[inline] fn put_u8(& mut self, n : u8) { (** self).put_u8(n) }\n        #[inline] fn put_i8(& mut self, n : i8) { (** self).put_i8(n) } #[inline] fn\n        put_u16(& mut self, n : u16) { (** self).put_u16(n) } #[inline] fn put_u16_le(&\n        mut self, n : u16) { (** self).put_u16_le(n) } #[inline] fn put_u16_ne(& mut\n        self, n : u16) { (** self).put_u16_ne(n) } #[inline] fn put_i16(& mut self, n :\n        i16) { (** self).put_i16(n) } #[inline] fn put_i16_le(& mut self, n : i16) { (**\n        self).put_i16_le(n) } #[inline] fn put_i16_ne(& mut self, n : i16) { (** self)\n        .put_i16_ne(n) } #[inline] fn put_u32(& mut self, n : u32) { (** self).put_u32(n)\n        } #[inline] fn put_u32_le(& mut self, n : u32) { (** self).put_u32_le(n) }\n        #[inline] fn put_u32_ne(& mut self, n : u32) { (** self).put_u32_ne(n) }\n        #[inline] fn put_i32(& mut self, n : i32) { (** self).put_i32(n) } #[inline] fn\n        put_i32_le(& mut self, n : i32) { (** self).put_i32_le(n) } #[inline] fn\n        put_i32_ne(& mut self, n : i32) { (** self).put_i32_ne(n) } #[inline] fn\n        put_u64(& mut self, n : u64) { (** self).put_u64(n) } #[inline] fn put_u64_le(&\n        mut self, n : u64) { (** self).put_u64_le(n) } #[inline] fn put_u64_ne(& mut\n        self, n : u64) { (** self).put_u64_ne(n) } #[inline] fn put_i64(& mut self, n :\n        i64) { (** self).put_i64(n) } #[inline] fn put_i64_le(& mut self, n : i64) { (**\n        self).put_i64_le(n) } #[inline] fn put_i64_ne(& mut self, n : i64) { (** self)\n        .put_i64_ne(n) }\n    };\n}\npub unsafe trait BufMut {\n    fn remaining_mut(&self) -> usize;\n    unsafe fn advance_mut(&mut self, cnt: usize);\n    #[inline]\n    fn has_remaining_mut(&self) -> bool {\n        self.remaining_mut() > 0\n    }\n    #[cfg_attr(docsrs, doc(alias = \"bytes_mut\"))]\n    fn chunk_mut(&mut self) -> &mut UninitSlice;\n    #[inline]\n    fn put<T: super::Buf>(&mut self, mut src: T)\n    where\n        Self: Sized,\n    {\n        if self.remaining_mut() < src.remaining() {\n            panic_advance(\n                &TryGetError {\n                    requested: src.remaining(),\n                    available: self.remaining_mut(),\n                },\n            );\n        }\n        while src.has_remaining() {\n            let s = src.chunk();\n            let d = self.chunk_mut();\n            let cnt = usize::min(s.len(), d.len());\n            d[..cnt].copy_from_slice(&s[..cnt]);\n            unsafe { self.advance_mut(cnt) };\n            src.advance(cnt);\n        }\n    }\n    #[inline]\n    fn put_slice(&mut self, mut src: &[u8]) {\n        if self.remaining_mut() < src.len() {\n            panic_advance(\n                &TryGetError {\n                    requested: src.len(),\n                    available: self.remaining_mut(),\n                },\n            );\n        }\n        while !src.is_empty() {\n            let dst = self.chunk_mut();\n            let cnt = usize::min(src.len(), dst.len());\n            dst[..cnt].copy_from_slice(&src[..cnt]);\n            src = &src[cnt..];\n            unsafe { self.advance_mut(cnt) };\n        }\n    }\n    #[inline]\n    fn put_bytes(&mut self, val: u8, mut cnt: usize) {\n        if self.remaining_mut() < cnt {\n            panic_advance(\n                &TryGetError {\n                    requested: cnt,\n                    available: self.remaining_mut(),\n                },\n            )\n        }\n        while cnt > 0 {\n            let dst = self.chunk_mut();\n            let dst_len = usize::min(dst.len(), cnt);\n            unsafe { core::ptr::write_bytes(dst.as_mut_ptr(), val, dst_len) };\n            unsafe { self.advance_mut(dst_len) };\n            cnt -= dst_len;\n        }\n    }\n    #[inline]\n    fn put_u8(&mut self, n: u8) {\n        let src = [n];\n        self.put_slice(&src);\n    }\n    #[inline]\n    fn put_i8(&mut self, n: i8) {\n        let src = [n as u8];\n        self.put_slice(&src)\n    }\n    #[inline]\n    fn put_u16(&mut self, n: u16) {\n        self.put_slice(&n.to_be_bytes())\n    }\n    #[inline]\n    fn put_u16_le(&mut self, n: u16) {\n        self.put_slice(&n.to_le_bytes())\n    }\n    #[inline]\n    fn put_u16_ne(&mut self, n: u16) {\n        self.put_slice(&n.to_ne_bytes())\n    }\n    #[inline]\n    fn put_i16(&mut self, n: i16) {\n        self.put_slice(&n.to_be_bytes())\n    }\n    #[inline]\n    fn put_i16_le(&mut self, n: i16) {\n        self.put_slice(&n.to_le_bytes())\n    }\n    #[inline]\n    fn put_i16_ne(&mut self, n: i16) {\n        self.put_slice(&n.to_ne_bytes())\n    }\n    #[inline]\n    fn put_u32(&mut self, n: u32) {\n        self.put_slice(&n.to_be_bytes())\n    }\n    #[inline]\n    fn put_u32_le(&mut self, n: u32) {\n        self.put_slice(&n.to_le_bytes())\n    }\n    #[inline]\n    fn put_u32_ne(&mut self, n: u32) {\n        self.put_slice(&n.to_ne_bytes())\n    }\n    #[inline]\n    fn put_i32(&mut self, n: i32) {\n        self.put_slice(&n.to_be_bytes())\n    }\n    #[inline]\n    fn put_i32_le(&mut self, n: i32) {\n        self.put_slice(&n.to_le_bytes())\n    }\n    #[inline]\n    fn put_i32_ne(&mut self, n: i32) {\n        self.put_slice(&n.to_ne_bytes())\n    }\n    #[inline]\n    fn put_u64(&mut self, n: u64) {\n        self.put_slice(&n.to_be_bytes())\n    }\n    #[inline]\n    fn put_u64_le(&mut self, n: u64) {\n        self.put_slice(&n.to_le_bytes())\n    }\n    #[inline]\n    fn put_u64_ne(&mut self, n: u64) {\n        self.put_slice(&n.to_ne_bytes())\n    }\n    #[inline]\n    fn put_i64(&mut self, n: i64) {\n        self.put_slice(&n.to_be_bytes())\n    }\n    #[inline]\n    fn put_i64_le(&mut self, n: i64) {\n        self.put_slice(&n.to_le_bytes())\n    }\n    #[inline]\n    fn put_i64_ne(&mut self, n: i64) {\n        self.put_slice(&n.to_ne_bytes())\n    }\n    #[inline]\n    fn put_u128(&mut self, n: u128) {\n        self.put_slice(&n.to_be_bytes())\n    }\n    #[inline]\n    fn put_u128_le(&mut self, n: u128) {\n        self.put_slice(&n.to_le_bytes())\n    }\n    #[inline]\n    fn put_u128_ne(&mut self, n: u128) {\n        self.put_slice(&n.to_ne_bytes())\n    }\n    #[inline]\n    fn put_i128(&mut self, n: i128) {\n        self.put_slice(&n.to_be_bytes())\n    }\n    #[inline]\n    fn put_i128_le(&mut self, n: i128) {\n        self.put_slice(&n.to_le_bytes())\n    }\n    #[inline]\n    fn put_i128_ne(&mut self, n: i128) {\n        self.put_slice(&n.to_ne_bytes())\n    }\n    #[inline]\n    fn put_uint(&mut self, n: u64, nbytes: usize) {\n        let start = match mem::size_of_val(&n).checked_sub(nbytes) {\n            Some(start) => start,\n            None => panic_does_not_fit(nbytes, mem::size_of_val(&n)),\n        };\n        self.put_slice(&n.to_be_bytes()[start..]);\n    }\n    #[inline]\n    fn put_uint_le(&mut self, n: u64, nbytes: usize) {\n        let slice = n.to_le_bytes();\n        let slice = match slice.get(..nbytes) {\n            Some(slice) => slice,\n            None => panic_does_not_fit(nbytes, slice.len()),\n        };\n        self.put_slice(slice);\n    }\n    #[inline]\n    fn put_uint_ne(&mut self, n: u64, nbytes: usize) {\n        if cfg!(target_endian = \"big\") {\n            self.put_uint(n, nbytes)\n        } else {\n            self.put_uint_le(n, nbytes)\n        }\n    }\n    #[inline]\n    fn put_int(&mut self, n: i64, nbytes: usize) {\n        let start = match mem::size_of_val(&n).checked_sub(nbytes) {\n            Some(start) => start,\n            None => panic_does_not_fit(nbytes, mem::size_of_val(&n)),\n        };\n        self.put_slice(&n.to_be_bytes()[start..]);\n    }\n    #[inline]\n    fn put_int_le(&mut self, n: i64, nbytes: usize) {\n        let slice = n.to_le_bytes();\n        let slice = match slice.get(..nbytes) {\n            Some(slice) => slice,\n            None => panic_does_not_fit(nbytes, slice.len()),\n        };\n        self.put_slice(slice);\n    }\n    #[inline]\n    fn put_int_ne(&mut self, n: i64, nbytes: usize) {\n        if cfg!(target_endian = \"big\") {\n            self.put_int(n, nbytes)\n        } else {\n            self.put_int_le(n, nbytes)\n        }\n    }\n    #[inline]\n    fn put_f32(&mut self, n: f32) {\n        self.put_u32(n.to_bits());\n    }\n    #[inline]\n    fn put_f32_le(&mut self, n: f32) {\n        self.put_u32_le(n.to_bits());\n    }\n    #[inline]\n    fn put_f32_ne(&mut self, n: f32) {\n        self.put_u32_ne(n.to_bits());\n    }\n    #[inline]\n    fn put_f64(&mut self, n: f64) {\n        self.put_u64(n.to_bits());\n    }\n    #[inline]\n    fn put_f64_le(&mut self, n: f64) {\n        self.put_u64_le(n.to_bits());\n    }\n    #[inline]\n    fn put_f64_ne(&mut self, n: f64) {\n        self.put_u64_ne(n.to_bits());\n    }\n    #[inline]\n    fn limit(self, limit: usize) -> Limit<Self>\n    where\n        Self: Sized,\n    {\n        limit::new(self, limit)\n    }\n    #[cfg(feature = \"std\")]\n    #[cfg_attr(docsrs, doc(cfg(feature = \"std\")))]\n    #[inline]\n    fn writer(self) -> Writer<Self>\n    where\n        Self: Sized,\n    {\n        writer::new(self)\n    }\n    #[inline]\n    fn chain_mut<U: BufMut>(self, next: U) -> Chain<Self, U>\n    where\n        Self: Sized,\n    {\n        Chain::new(self, next)\n    }\n}\nunsafe impl BufMut for Vec<u8> {\n    #[inline]\n    fn remaining_mut(&self) -> usize {}\n    #[inline]\n    unsafe fn advance_mut(&mut self, cnt: usize) {}\n    #[inline]\n    fn chunk_mut(&mut self) -> &mut UninitSlice {}\n    #[inline]\n    fn put<T: super::Buf>(&mut self, mut src: T)\n    where\n        Self: Sized,\n    {}\n    #[inline]\n    fn put_slice(&mut self, src: &[u8]) {\n        self.extend_from_slice(src);\n    }\n    #[inline]\n    fn put_bytes(&mut self, val: u8, cnt: usize) {}\n}\n\nThe function to be tested is presented as follows:\nfn put_slice(&mut self, src: &[u8]) {\n    self.extend_from_slice(src);\n}\n",
  "depend_pt": ""
}