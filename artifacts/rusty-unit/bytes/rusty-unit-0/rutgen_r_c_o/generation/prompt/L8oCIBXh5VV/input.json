{
  "system_pt": "As a software testing expert, infer the test input ranges based on the provided information. Follow these guidelines:\n1. Provide test input ranges in one line in plain text only, without additional explanations or Markdown formatting.\n2. The inferred test input ranges should only satisfy all provided constraints simultaneously.\n3. Ensure the test input ranges cover boundary cases and edge scenarios.\n",
  "static_pt": "The context for the focal function is as follows:\n// src/buf/buf_mut.rs\n// crate name is bytes\nuse crate::buf::{limit, Chain, Limit, UninitSlice};\n#[cfg(feature = \"std\")]\nuse crate::buf::{writer, Writer};\nuse crate::{panic_advance, panic_does_not_fit, TryGetError};\nuse core::{mem, ptr, usize};\nuse alloc::{boxed::Box, vec::Vec};\nmacro_rules! deref_forward_bufmut {\n    () => {\n        #[inline] fn remaining_mut(& self) -> usize { (** self).remaining_mut() }\n        #[inline] fn chunk_mut(& mut self) -> & mut UninitSlice { (** self).chunk_mut() }\n        #[inline] unsafe fn advance_mut(& mut self, cnt : usize) { (** self)\n        .advance_mut(cnt) } #[inline] fn put_slice(& mut self, src : & [u8]) { (** self)\n        .put_slice(src) } #[inline] fn put_u8(& mut self, n : u8) { (** self).put_u8(n) }\n        #[inline] fn put_i8(& mut self, n : i8) { (** self).put_i8(n) } #[inline] fn\n        put_u16(& mut self, n : u16) { (** self).put_u16(n) } #[inline] fn put_u16_le(&\n        mut self, n : u16) { (** self).put_u16_le(n) } #[inline] fn put_u16_ne(& mut\n        self, n : u16) { (** self).put_u16_ne(n) } #[inline] fn put_i16(& mut self, n :\n        i16) { (** self).put_i16(n) } #[inline] fn put_i16_le(& mut self, n : i16) { (**\n        self).put_i16_le(n) } #[inline] fn put_i16_ne(& mut self, n : i16) { (** self)\n        .put_i16_ne(n) } #[inline] fn put_u32(& mut self, n : u32) { (** self).put_u32(n)\n        } #[inline] fn put_u32_le(& mut self, n : u32) { (** self).put_u32_le(n) }\n        #[inline] fn put_u32_ne(& mut self, n : u32) { (** self).put_u32_ne(n) }\n        #[inline] fn put_i32(& mut self, n : i32) { (** self).put_i32(n) } #[inline] fn\n        put_i32_le(& mut self, n : i32) { (** self).put_i32_le(n) } #[inline] fn\n        put_i32_ne(& mut self, n : i32) { (** self).put_i32_ne(n) } #[inline] fn\n        put_u64(& mut self, n : u64) { (** self).put_u64(n) } #[inline] fn put_u64_le(&\n        mut self, n : u64) { (** self).put_u64_le(n) } #[inline] fn put_u64_ne(& mut\n        self, n : u64) { (** self).put_u64_ne(n) } #[inline] fn put_i64(& mut self, n :\n        i64) { (** self).put_i64(n) } #[inline] fn put_i64_le(& mut self, n : i64) { (**\n        self).put_i64_le(n) } #[inline] fn put_i64_ne(& mut self, n : i64) { (** self)\n        .put_i64_ne(n) }\n    };\n}\npub unsafe trait BufMut {\n    fn remaining_mut(&self) -> usize;\n    unsafe fn advance_mut(&mut self, cnt: usize);\n    #[inline]\n    fn has_remaining_mut(&self) -> bool {\n        self.remaining_mut() > 0\n    }\n    #[cfg_attr(docsrs, doc(alias = \"bytes_mut\"))]\n    fn chunk_mut(&mut self) -> &mut UninitSlice;\n    #[inline]\n    fn put<T: super::Buf>(&mut self, mut src: T)\n    where\n        Self: Sized,\n    {\n        if self.remaining_mut() < src.remaining() {\n            panic_advance(\n                &TryGetError {\n                    requested: src.remaining(),\n                    available: self.remaining_mut(),\n                },\n            );\n        }\n        while src.has_remaining() {\n            let s = src.chunk();\n            let d = self.chunk_mut();\n            let cnt = usize::min(s.len(), d.len());\n            d[..cnt].copy_from_slice(&s[..cnt]);\n            unsafe { self.advance_mut(cnt) };\n            src.advance(cnt);\n        }\n    }\n    #[inline]\n    fn put_slice(&mut self, mut src: &[u8]) {\n        if self.remaining_mut() < src.len() {\n            panic_advance(\n                &TryGetError {\n                    requested: src.len(),\n                    available: self.remaining_mut(),\n                },\n            );\n        }\n        while !src.is_empty() {\n            let dst = self.chunk_mut();\n            let cnt = usize::min(src.len(), dst.len());\n            dst[..cnt].copy_from_slice(&src[..cnt]);\n            src = &src[cnt..];\n            unsafe { self.advance_mut(cnt) };\n        }\n    }\n    #[inline]\n    fn put_bytes(&mut self, val: u8, mut cnt: usize) {\n        if self.remaining_mut() < cnt {\n            panic_advance(\n                &TryGetError {\n                    requested: cnt,\n                    available: self.remaining_mut(),\n                },\n            )\n        }\n        while cnt > 0 {\n            let dst = self.chunk_mut();\n            let dst_len = usize::min(dst.len(), cnt);\n            unsafe { core::ptr::write_bytes(dst.as_mut_ptr(), val, dst_len) };\n            unsafe { self.advance_mut(dst_len) };\n            cnt -= dst_len;\n        }\n    }\n    #[inline]\n    fn put_u8(&mut self, n: u8) {\n        let src = [n];\n        self.put_slice(&src);\n    }\n    #[inline]\n    fn put_i8(&mut self, n: i8) {\n        let src = [n as u8];\n        self.put_slice(&src)\n    }\n    #[inline]\n    fn put_u16(&mut self, n: u16) {\n        self.put_slice(&n.to_be_bytes())\n    }\n    #[inline]\n    fn put_u16_le(&mut self, n: u16) {\n        self.put_slice(&n.to_le_bytes())\n    }\n    #[inline]\n    fn put_u16_ne(&mut self, n: u16) {\n        self.put_slice(&n.to_ne_bytes())\n    }\n    #[inline]\n    fn put_i16(&mut self, n: i16) {\n        self.put_slice(&n.to_be_bytes())\n    }\n    #[inline]\n    fn put_i16_le(&mut self, n: i16) {\n        self.put_slice(&n.to_le_bytes())\n    }\n    #[inline]\n    fn put_i16_ne(&mut self, n: i16) {\n        self.put_slice(&n.to_ne_bytes())\n    }\n    #[inline]\n    fn put_u32(&mut self, n: u32) {\n        self.put_slice(&n.to_be_bytes())\n    }\n    #[inline]\n    fn put_u32_le(&mut self, n: u32) {\n        self.put_slice(&n.to_le_bytes())\n    }\n    #[inline]\n    fn put_u32_ne(&mut self, n: u32) {\n        self.put_slice(&n.to_ne_bytes())\n    }\n    #[inline]\n    fn put_i32(&mut self, n: i32) {\n        self.put_slice(&n.to_be_bytes())\n    }\n    #[inline]\n    fn put_i32_le(&mut self, n: i32) {\n        self.put_slice(&n.to_le_bytes())\n    }\n    #[inline]\n    fn put_i32_ne(&mut self, n: i32) {\n        self.put_slice(&n.to_ne_bytes())\n    }\n    #[inline]\n    fn put_u64(&mut self, n: u64) {\n        self.put_slice(&n.to_be_bytes())\n    }\n    #[inline]\n    fn put_u64_le(&mut self, n: u64) {\n        self.put_slice(&n.to_le_bytes())\n    }\n    #[inline]\n    fn put_u64_ne(&mut self, n: u64) {\n        self.put_slice(&n.to_ne_bytes())\n    }\n    #[inline]\n    fn put_i64(&mut self, n: i64) {\n        self.put_slice(&n.to_be_bytes())\n    }\n    #[inline]\n    fn put_i64_le(&mut self, n: i64) {\n        self.put_slice(&n.to_le_bytes())\n    }\n    #[inline]\n    fn put_i64_ne(&mut self, n: i64) {\n        self.put_slice(&n.to_ne_bytes())\n    }\n    #[inline]\n    fn put_u128(&mut self, n: u128) {\n        self.put_slice(&n.to_be_bytes())\n    }\n    #[inline]\n    fn put_u128_le(&mut self, n: u128) {\n        self.put_slice(&n.to_le_bytes())\n    }\n    #[inline]\n    fn put_u128_ne(&mut self, n: u128) {\n        self.put_slice(&n.to_ne_bytes())\n    }\n    #[inline]\n    fn put_i128(&mut self, n: i128) {\n        self.put_slice(&n.to_be_bytes())\n    }\n    #[inline]\n    fn put_i128_le(&mut self, n: i128) {\n        self.put_slice(&n.to_le_bytes())\n    }\n    #[inline]\n    fn put_i128_ne(&mut self, n: i128) {\n        self.put_slice(&n.to_ne_bytes())\n    }\n    #[inline]\n    fn put_uint(&mut self, n: u64, nbytes: usize) {\n        let start = match mem::size_of_val(&n).checked_sub(nbytes) {\n            Some(start) => start,\n            None => panic_does_not_fit(nbytes, mem::size_of_val(&n)),\n        };\n        self.put_slice(&n.to_be_bytes()[start..]);\n    }\n    #[inline]\n    fn put_uint_le(&mut self, n: u64, nbytes: usize) {\n        let slice = n.to_le_bytes();\n        let slice = match slice.get(..nbytes) {\n            Some(slice) => slice,\n            None => panic_does_not_fit(nbytes, slice.len()),\n        };\n        self.put_slice(slice);\n    }\n    #[inline]\n    fn put_uint_ne(&mut self, n: u64, nbytes: usize) {\n        if cfg!(target_endian = \"big\") {\n            self.put_uint(n, nbytes)\n        } else {\n            self.put_uint_le(n, nbytes)\n        }\n    }\n    #[inline]\n    fn put_int(&mut self, n: i64, nbytes: usize) {\n        let start = match mem::size_of_val(&n).checked_sub(nbytes) {\n            Some(start) => start,\n            None => panic_does_not_fit(nbytes, mem::size_of_val(&n)),\n        };\n        self.put_slice(&n.to_be_bytes()[start..]);\n    }\n    #[inline]\n    fn put_int_le(&mut self, n: i64, nbytes: usize) {\n        let slice = n.to_le_bytes();\n        let slice = match slice.get(..nbytes) {\n            Some(slice) => slice,\n            None => panic_does_not_fit(nbytes, slice.len()),\n        };\n        self.put_slice(slice);\n    }\n    #[inline]\n    fn put_int_ne(&mut self, n: i64, nbytes: usize) {\n        if cfg!(target_endian = \"big\") {\n            self.put_int(n, nbytes)\n        } else {\n            self.put_int_le(n, nbytes)\n        }\n    }\n    #[inline]\n    fn put_f32(&mut self, n: f32) {\n        self.put_u32(n.to_bits());\n    }\n    #[inline]\n    fn put_f32_le(&mut self, n: f32) {\n        self.put_u32_le(n.to_bits());\n    }\n    #[inline]\n    fn put_f32_ne(&mut self, n: f32) {\n        self.put_u32_ne(n.to_bits());\n    }\n    #[inline]\n    fn put_f64(&mut self, n: f64) {\n        self.put_u64(n.to_bits());\n    }\n    #[inline]\n    fn put_f64_le(&mut self, n: f64) {\n        self.put_u64_le(n.to_bits());\n    }\n    #[inline]\n    fn put_f64_ne(&mut self, n: f64) {\n        self.put_u64_ne(n.to_bits());\n    }\n    #[inline]\n    fn limit(self, limit: usize) -> Limit<Self>\n    where\n        Self: Sized,\n    {\n        limit::new(self, limit)\n    }\n    #[cfg(feature = \"std\")]\n    #[cfg_attr(docsrs, doc(cfg(feature = \"std\")))]\n    #[inline]\n    fn writer(self) -> Writer<Self>\n    where\n        Self: Sized,\n    {\n        writer::new(self)\n    }\n    #[inline]\n    fn chain_mut<U: BufMut>(self, next: U) -> Chain<Self, U>\n    where\n        Self: Sized,\n    {\n        Chain::new(self, next)\n    }\n}\npub trait Buf {\n    fn remaining(&self) -> usize;\n    #[cfg_attr(docsrs, doc(alias = \"bytes\"))]\n    fn chunk(&self) -> &[u8];\n    #[cfg(feature = \"std\")]\n    #[cfg_attr(docsrs, doc(cfg(feature = \"std\")))]\n    fn chunks_vectored<'a>(&'a self, dst: &mut [IoSlice<'a>]) -> usize;\n    fn advance(&mut self, cnt: usize);\n    fn has_remaining(&self) -> bool;\n    fn copy_to_slice(&mut self, dst: &mut [u8]);\n    fn get_u8(&mut self) -> u8;\n    fn get_i8(&mut self) -> i8;\n    fn get_u16(&mut self) -> u16;\n    fn get_u16_le(&mut self) -> u16;\n    fn get_u16_ne(&mut self) -> u16;\n    fn get_i16(&mut self) -> i16;\n    fn get_i16_le(&mut self) -> i16;\n    fn get_i16_ne(&mut self) -> i16;\n    fn get_u32(&mut self) -> u32;\n    fn get_u32_le(&mut self) -> u32;\n    fn get_u32_ne(&mut self) -> u32;\n    fn get_i32(&mut self) -> i32;\n    fn get_i32_le(&mut self) -> i32;\n    fn get_i32_ne(&mut self) -> i32;\n    fn get_u64(&mut self) -> u64;\n    fn get_u64_le(&mut self) -> u64;\n    fn get_u64_ne(&mut self) -> u64;\n    fn get_i64(&mut self) -> i64;\n    fn get_i64_le(&mut self) -> i64;\n    fn get_i64_ne(&mut self) -> i64;\n    fn get_u128(&mut self) -> u128;\n    fn get_u128_le(&mut self) -> u128;\n    fn get_u128_ne(&mut self) -> u128;\n    fn get_i128(&mut self) -> i128;\n    fn get_i128_le(&mut self) -> i128;\n    fn get_i128_ne(&mut self) -> i128;\n    fn get_uint(&mut self, nbytes: usize) -> u64;\n    fn get_uint_le(&mut self, nbytes: usize) -> u64;\n    fn get_uint_ne(&mut self, nbytes: usize) -> u64;\n    fn get_int(&mut self, nbytes: usize) -> i64;\n    fn get_int_le(&mut self, nbytes: usize) -> i64;\n    fn get_int_ne(&mut self, nbytes: usize) -> i64;\n    fn get_f32(&mut self) -> f32;\n    fn get_f32_le(&mut self) -> f32;\n    fn get_f32_ne(&mut self) -> f32;\n    fn get_f64(&mut self) -> f64;\n    fn get_f64_le(&mut self) -> f64;\n    fn get_f64_ne(&mut self) -> f64;\n    fn try_copy_to_slice(&mut self, mut dst: &mut [u8]) -> Result<(), TryGetError>;\n    fn try_get_u8(&mut self) -> Result<u8, TryGetError>;\n    fn try_get_i8(&mut self) -> Result<i8, TryGetError>;\n    fn try_get_u16(&mut self) -> Result<u16, TryGetError>;\n    fn try_get_u16_le(&mut self) -> Result<u16, TryGetError>;\n    fn try_get_u16_ne(&mut self) -> Result<u16, TryGetError>;\n    fn try_get_i16(&mut self) -> Result<i16, TryGetError>;\n    fn try_get_i16_le(&mut self) -> Result<i16, TryGetError>;\n    fn try_get_i16_ne(&mut self) -> Result<i16, TryGetError>;\n    fn try_get_u32(&mut self) -> Result<u32, TryGetError>;\n    fn try_get_u32_le(&mut self) -> Result<u32, TryGetError>;\n    fn try_get_u32_ne(&mut self) -> Result<u32, TryGetError>;\n    fn try_get_i32(&mut self) -> Result<i32, TryGetError>;\n    fn try_get_i32_le(&mut self) -> Result<i32, TryGetError>;\n    fn try_get_i32_ne(&mut self) -> Result<i32, TryGetError>;\n    fn try_get_u64(&mut self) -> Result<u64, TryGetError>;\n    fn try_get_u64_le(&mut self) -> Result<u64, TryGetError>;\n    fn try_get_u64_ne(&mut self) -> Result<u64, TryGetError>;\n    fn try_get_i64(&mut self) -> Result<i64, TryGetError>;\n    fn try_get_i64_le(&mut self) -> Result<i64, TryGetError>;\n    fn try_get_i64_ne(&mut self) -> Result<i64, TryGetError>;\n    fn try_get_u128(&mut self) -> Result<u128, TryGetError>;\n    fn try_get_u128_le(&mut self) -> Result<u128, TryGetError>;\n    fn try_get_u128_ne(&mut self) -> Result<u128, TryGetError>;\n    fn try_get_i128(&mut self) -> Result<i128, TryGetError>;\n    fn try_get_i128_le(&mut self) -> Result<i128, TryGetError>;\n    fn try_get_i128_ne(&mut self) -> Result<i128, TryGetError>;\n    fn try_get_uint(&mut self, nbytes: usize) -> Result<u64, TryGetError>;\n    fn try_get_uint_le(&mut self, nbytes: usize) -> Result<u64, TryGetError>;\n    fn try_get_uint_ne(&mut self, nbytes: usize) -> Result<u64, TryGetError>;\n    fn try_get_int(&mut self, nbytes: usize) -> Result<i64, TryGetError>;\n    fn try_get_int_le(&mut self, nbytes: usize) -> Result<i64, TryGetError>;\n    fn try_get_int_ne(&mut self, nbytes: usize) -> Result<i64, TryGetError>;\n    fn try_get_f32(&mut self) -> Result<f32, TryGetError>;\n    fn try_get_f32_le(&mut self) -> Result<f32, TryGetError>;\n    fn try_get_f32_ne(&mut self) -> Result<f32, TryGetError>;\n    fn try_get_f64(&mut self) -> Result<f64, TryGetError>;\n    fn try_get_f64_le(&mut self) -> Result<f64, TryGetError>;\n    fn try_get_f64_ne(&mut self) -> Result<f64, TryGetError>;\n    fn copy_to_bytes(&mut self, len: usize) -> crate::Bytes;\n    fn take(self, limit: usize) -> Take<Self>\n    where\n        Self: Sized,\n    {\n        take::new(self, limit)\n    }\n    fn chain<U: Buf>(self, next: U) -> Chain<Self, U>\n    where\n        Self: Sized,\n    {\n        Chain::new(self, next)\n    }\n    #[cfg(feature = \"std\")]\n    #[cfg_attr(docsrs, doc(cfg(feature = \"std\")))]\n    fn reader(self) -> Reader<Self>\n    where\n        Self: Sized,\n    {\n        reader::new(self)\n    }\n}\n#[repr(transparent)]\npub struct UninitSlice([MaybeUninit<u8>]);\n#[derive(Debug, PartialEq, Eq)]\npub struct TryGetError {\n    /// The number of bytes necessary to get the value\n    pub requested: usize,\n    /// The number of bytes available in the buffer\n    pub available: usize,\n}\nunsafe impl BufMut for &mut [core::mem::MaybeUninit<u8>] {\n    #[inline]\n    fn remaining_mut(&self) -> usize {}\n    #[inline]\n    fn chunk_mut(&mut self) -> &mut UninitSlice {}\n    #[inline]\n    unsafe fn advance_mut(&mut self, cnt: usize) {}\n    #[inline]\n    fn put_slice(&mut self, src: &[u8]) {}\n    #[inline]\n    fn put_bytes(&mut self, val: u8, cnt: usize) {\n        if self.len() < cnt {\n            panic_advance(\n                &TryGetError {\n                    requested: cnt,\n                    available: self.len(),\n                },\n            );\n        }\n        unsafe {\n            ptr::write_bytes(self.as_mut_ptr() as *mut u8, val, cnt);\n            self.advance_mut(cnt);\n        }\n    }\n}\nimpl UninitSlice {\n    #[inline]\n    pub fn new(slice: &mut [u8]) -> &mut UninitSlice {}\n    #[inline]\n    pub fn uninit(slice: &mut [MaybeUninit<u8>]) -> &mut UninitSlice {}\n    fn uninit_ref(slice: &[MaybeUninit<u8>]) -> &UninitSlice {}\n    #[inline]\n    pub unsafe fn from_raw_parts_mut<'a>(\n        ptr: *mut u8,\n        len: usize,\n    ) -> &'a mut UninitSlice {}\n    #[inline]\n    pub fn write_byte(&mut self, index: usize, byte: u8) {}\n    #[inline]\n    pub fn copy_from_slice(&mut self, src: &[u8]) {}\n    #[inline]\n    pub fn as_mut_ptr(&mut self) -> *mut u8 {\n        self.0.as_mut_ptr() as *mut _\n    }\n    #[inline]\n    pub unsafe fn as_uninit_slice_mut(&mut self) -> &mut [MaybeUninit<u8>] {}\n    #[inline]\n    pub fn len(&self) -> usize {\n        self.0.len()\n    }\n}\n#[cold]\nfn panic_advance(error_info: &TryGetError) -> ! {\n    panic!(\n        \"advance out of bounds: the len is {} but advancing by {}\", error_info.available,\n        error_info.requested\n    );\n}\n\nThe function to be tested is presented as follows:\n/// Put `cnt` bytes `val` into `self`.\n///\n/// Logically equivalent to calling `self.put_u8(val)` `cnt` times, but may work faster.\n///\n/// `self` must have at least `cnt` remaining capacity.\n///\n/// ```\n/// use bytes::BufMut;\n///\n/// let mut dst = [0; 6];\n///\n/// {\n///     let mut buf = &mut dst[..];\n///     buf.put_bytes(b'a', 4);\n///\n///     assert_eq!(2, buf.remaining_mut());\n/// }\n///\n/// assert_eq!(b\"aaaa\\0\\0\", &dst);\n/// ```\n///\n/// # Panics\n///\n/// This function panics if there is not enough remaining capacity in\n/// `self`.\nfn put_bytes(&mut self, val: u8, mut cnt: usize) {\n    if self.remaining_mut() < cnt {\n        panic_advance(&TryGetError {\n            requested: cnt,\n            available: self.remaining_mut(),\n        })\n    }\n\n    while cnt > 0 {\n        let dst = self.chunk_mut();\n        let dst_len = usize::min(dst.len(), cnt);\n        // SAFETY: The pointer is valid for `dst_len <= dst.len()` bytes.\n        unsafe { core::ptr::write_bytes(dst.as_mut_ptr(), val, dst_len) };\n        // SAFETY: We just initialized `dst_len` bytes in `self`.\n        unsafe { self.advance_mut(dst_len) };\n        cnt -= dst_len;\n    }\n}\nGiven the following constraints, potential panic-triggering statements, and expected return values/types (all extracted from the function under test).\nGenerate test inputs that maximize the function's runtime satisfaction of all constraints and expected outputs while considering panic conditions:\n",
  "depend_pt": ""
}