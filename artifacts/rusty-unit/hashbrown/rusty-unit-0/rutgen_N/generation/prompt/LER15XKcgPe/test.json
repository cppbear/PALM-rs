{
  "system_pt": "As a software testing expert, please generate Rust test functions based on the following guidelines:\n1. Provide the code in plain text format, without explanations or Markdown.\n2. If the method under test belongs to a trait, construct appropriate structs within the test function, but avoid method overrides. If the method under test uses generics, instantiate them with suitable types based on the context.\n3. Generate test code with minimal scope: avoid creating external structures or implementations. Instead, define any necessary helper structures or implementations directly within the test function when required.\n4. Whenever possible, initialize the corresponding data structures using the initialization methods provided in the context if exist.\n5. Ensure the generated function is fully implemented and can be compiled and executed directly without any missing parts.\n6. Create a minimal yet complete set of test functions, ensuring they adhere to all provided preconditions and cover boundary conditions.\n7. Do not create a test module, but include intrinsic attributes like #[test] or #[should_panic] where necessary.\n",
  "static_pt": "// src/raw/mod.rs\n// crate name is hashbrown\nThe function to be tested is presented as follows:\n/// Prepares for rehashing data in place (that is, without allocating new memory).\n/// Converts all full index `control bytes` to `Tag::DELETED` and all `Tag::DELETED` control\n/// bytes to `Tag::EMPTY`, i.e. performs the following conversion:\n///\n/// - `Tag::EMPTY` control bytes   -> `Tag::EMPTY`;\n/// - `Tag::DELETED` control bytes -> `Tag::EMPTY`;\n/// - `FULL` control bytes    -> `Tag::DELETED`.\n///\n/// This function does not make any changes to the `data` parts of the table,\n/// or any changes to the `items` or `growth_left` field of the table.\n///\n/// # Safety\n///\n/// You must observe the following safety rules when calling this function:\n///\n/// * The [`RawTableInner`] has already been allocated;\n///\n/// * The caller of this function must convert the `Tag::DELETED` bytes back to `FULL`\n///   bytes when re-inserting them into their ideal position (which was impossible\n///   to do during the first insert due to tombstones). If the caller does not do\n///   this, then calling this function may result in a memory leak.\n///\n/// * The [`RawTableInner`] must have properly initialized control bytes otherwise\n///   calling this function results in [`undefined behavior`].\n///\n/// Calling this function on a table that has not been allocated results in\n/// [`undefined behavior`].\n///\n/// See also [`Bucket::as_ptr`] method, for more information about of properly removing\n/// or saving `data element` from / into the [`RawTable`] / [`RawTableInner`].\n///\n/// [`Bucket::as_ptr`]: Bucket::as_ptr\n/// [`undefined behavior`]: https://doc.rust-lang.org/reference/behavior-considered-undefined.html\nunsafe fn prepare_rehash_in_place(&mut self) {\n    // Bulk convert all full control bytes to DELETED, and all DELETED control bytes to EMPTY.\n    // This effectively frees up all buckets containing a DELETED entry.\n    //\n    // SAFETY:\n    // 1. `i` is guaranteed to be within bounds since we are iterating from zero to `buckets - 1`;\n    // 2. Even if `i` will be `i == self.bucket_mask`, it is safe to call `Group::load_aligned`\n    //    due to the extended control bytes range, which is `self.bucket_mask + 1 + Group::WIDTH`;\n    // 3. The caller of this function guarantees that [`RawTableInner`] has already been allocated;\n    // 4. We can use `Group::load_aligned` and `Group::store_aligned` here since we start from 0\n    //    and go to the end with a step equal to `Group::WIDTH` (see TableLayout::calculate_layout_for).\n    for i in (0..self.buckets()).step_by(Group::WIDTH) {\n        let group = Group::load_aligned(self.ctrl(i));\n        let group = group.convert_special_to_empty_and_full_to_deleted();\n        group.store_aligned(self.ctrl(i));\n    }\n\n    // Fix up the trailing control bytes. See the comments in set_ctrl\n    // for the handling of tables smaller than the group width.\n    //\n    // SAFETY: The caller of this function guarantees that [`RawTableInner`]\n    // has already been allocated\n    if unlikely(self.buckets() < Group::WIDTH) {\n        // SAFETY: We have `self.bucket_mask + 1 + Group::WIDTH` number of control bytes,\n        // so copying `self.buckets() == self.bucket_mask + 1` bytes with offset equal to\n        // `Group::WIDTH` is safe\n        self.ctrl(0)\n            .copy_to(self.ctrl(Group::WIDTH), self.buckets());\n    } else {\n        // SAFETY: We have `self.bucket_mask + 1 + Group::WIDTH` number of\n        // control bytes,so copying `Group::WIDTH` bytes with offset equal\n        // to `self.buckets() == self.bucket_mask + 1` is safe\n        self.ctrl(0)\n            .copy_to(self.ctrl(self.buckets()), Group::WIDTH);\n    }\n}\n",
  "depend_pt": ""
}