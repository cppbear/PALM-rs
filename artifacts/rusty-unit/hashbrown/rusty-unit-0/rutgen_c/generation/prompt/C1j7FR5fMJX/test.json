{
  "system_pt": "As a software testing expert, please generate Rust test functions based on the following guidelines:\n1. Provide the code in plain text format, without explanations or Markdown.\n2. If the method under test belongs to a trait, construct appropriate structs within the test function, but avoid method overrides. If the method under test uses generics, instantiate them with suitable types based on the context.\n3. Generate test code with minimal scope: avoid creating external structures or implementations. Instead, define any necessary helper structures or implementations directly within the test function when required.\n4. Whenever possible, initialize the corresponding data structures using the initialization methods provided in the context if exist.\n5. Ensure the generated function is fully implemented and can be compiled and executed directly without any missing parts.\n6. Create a minimal yet complete set of test functions, ensuring they adhere to all provided preconditions and cover boundary conditions.\n7. Do not create a test module, but include intrinsic attributes like #[test] or #[should_panic] where necessary.\n",
  "static_pt": "The context for the focal function is as follows:\n// src/raw/mod.rs\n// crate name is hashbrown\nuse crate::alloc::alloc::{handle_alloc_error, Layout};\nuse crate::scopeguard::{guard, ScopeGuard};\nuse crate::TryReserveError;\nuse core::array;\nuse core::iter::FusedIterator;\nuse core::marker::PhantomData;\nuse core::mem;\nuse core::ptr::NonNull;\nuse core::{hint, ptr};\npub(crate) use self::alloc::{do_alloc, Allocator, Global};\nuse self::bitmask::BitMaskIter;\nuse self::imp::Group;\n#[cfg(not(feature = \"nightly\"))]\nuse core::convert::{identity as likely, identity as unlikely};\n#[cfg(feature = \"nightly\")]\nuse core::intrinsics::{likely, unlikely};\ncfg_if! {\n    if #[cfg(all(target_feature = \"sse2\", any(target_arch = \"x86\", target_arch =\n    \"x86_64\"), not(miri),))] { mod sse2; use sse2 as imp; } else if #[cfg(all(target_arch\n    = \"aarch64\", target_feature = \"neon\", target_endian = \"little\", not(miri),))] { mod\n    neon; use neon as imp; } else { mod generic; use generic as imp; }\n}\ntrait RawTableClone {\n    unsafe fn clone_from_spec(&mut self, source: &Self);\n}\n#[allow(clippy::missing_safety_doc)]\npub unsafe trait Allocator {\n    fn allocate(&self, layout: Layout) -> Result<NonNull<u8>, ()>;\n    unsafe fn deallocate(&self, ptr: NonNull<u8>, layout: Layout);\n}\npub struct RawTable<T, A: Allocator = Global> {\n    table: RawTableInner,\n    alloc: A,\n    marker: PhantomData<T>,\n}\npub struct Bucket<T> {\n    ptr: NonNull<T>,\n}\nstruct RawTableInner {\n    bucket_mask: usize,\n    ctrl: NonNull<u8>,\n    growth_left: usize,\n    items: usize,\n}\n#[derive(Copy, Clone)]\nstruct TableLayout {\n    size: usize,\n    ctrl_align: usize,\n}\nimpl<T, A: Allocator> RawTable<T, A> {\n    const TABLE_LAYOUT: TableLayout = TableLayout::new::<T>();\n    #[inline]\n    pub const fn new_in(alloc: A) -> Self {\n        Self {\n            table: RawTableInner::NEW,\n            alloc,\n            marker: PhantomData,\n        }\n    }\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    unsafe fn new_uninitialized(\n        alloc: A,\n        buckets: usize,\n        fallibility: Fallibility,\n    ) -> Result<Self, TryReserveError> {\n        debug_assert!(buckets.is_power_of_two());\n        Ok(Self {\n            table: RawTableInner::new_uninitialized(\n                &alloc,\n                Self::TABLE_LAYOUT,\n                buckets,\n                fallibility,\n            )?,\n            alloc,\n            marker: PhantomData,\n        })\n    }\n    pub fn with_capacity_in(capacity: usize, alloc: A) -> Self {\n        Self {\n            table: RawTableInner::with_capacity(&alloc, Self::TABLE_LAYOUT, capacity),\n            alloc,\n            marker: PhantomData,\n        }\n    }\n    #[inline]\n    pub fn allocator(&self) -> &A {}\n    #[inline]\n    pub fn data_end(&self) -> NonNull<T> {\n        self.table.ctrl.cast()\n    }\n    #[inline]\n    #[cfg(feature = \"nightly\")]\n    pub unsafe fn data_start(&self) -> NonNull<T> {}\n    #[inline]\n    pub fn allocation_size(&self) -> usize {}\n    #[inline]\n    pub unsafe fn bucket_index(&self, bucket: &Bucket<T>) -> usize {}\n    #[inline]\n    pub unsafe fn bucket(&self, index: usize) -> Bucket<T> {\n        debug_assert_ne!(self.table.bucket_mask, 0);\n        debug_assert!(index < self.buckets());\n        Bucket::from_base_index(self.data_end(), index)\n    }\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    unsafe fn erase_no_drop(&mut self, item: &Bucket<T>) {}\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    #[allow(clippy::needless_pass_by_value)]\n    pub unsafe fn erase(&mut self, item: Bucket<T>) {}\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    #[allow(clippy::needless_pass_by_value)]\n    pub unsafe fn remove(&mut self, item: Bucket<T>) -> (T, InsertSlot) {}\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn remove_entry(&mut self, hash: u64, eq: impl FnMut(&T) -> bool) -> Option<T> {}\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn clear_no_drop(&mut self) {}\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn clear(&mut self) {}\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn shrink_to(&mut self, min_size: usize, hasher: impl Fn(&T) -> u64) {}\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn reserve(&mut self, additional: usize, hasher: impl Fn(&T) -> u64) {}\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn try_reserve(\n        &mut self,\n        additional: usize,\n        hasher: impl Fn(&T) -> u64,\n    ) -> Result<(), TryReserveError> {}\n    #[cold]\n    #[inline(never)]\n    unsafe fn reserve_rehash(\n        &mut self,\n        additional: usize,\n        hasher: impl Fn(&T) -> u64,\n        fallibility: Fallibility,\n    ) -> Result<(), TryReserveError> {}\n    unsafe fn resize(\n        &mut self,\n        capacity: usize,\n        hasher: impl Fn(&T) -> u64,\n        fallibility: Fallibility,\n    ) -> Result<(), TryReserveError> {}\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn insert(\n        &mut self,\n        hash: u64,\n        value: T,\n        hasher: impl Fn(&T) -> u64,\n    ) -> Bucket<T> {}\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn insert_entry(\n        &mut self,\n        hash: u64,\n        value: T,\n        hasher: impl Fn(&T) -> u64,\n    ) -> &mut T {}\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    #[cfg(feature = \"rustc-internal-api\")]\n    pub unsafe fn insert_no_grow(&mut self, hash: u64, value: T) -> Bucket<T> {}\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub unsafe fn replace_bucket_with<F>(&mut self, bucket: Bucket<T>, f: F) -> bool\n    where\n        F: FnOnce(T) -> Option<T>,\n    {}\n    #[inline]\n    pub fn find_or_find_insert_slot(\n        &mut self,\n        hash: u64,\n        mut eq: impl FnMut(&T) -> bool,\n        hasher: impl Fn(&T) -> u64,\n    ) -> Result<Bucket<T>, InsertSlot> {}\n    #[inline]\n    pub unsafe fn insert_in_slot(\n        &mut self,\n        hash: u64,\n        slot: InsertSlot,\n        value: T,\n    ) -> Bucket<T> {}\n    #[inline]\n    pub fn find(&self, hash: u64, mut eq: impl FnMut(&T) -> bool) -> Option<Bucket<T>> {}\n    #[inline]\n    pub fn get(&self, hash: u64, eq: impl FnMut(&T) -> bool) -> Option<&T> {}\n    #[inline]\n    pub fn get_mut(&mut self, hash: u64, eq: impl FnMut(&T) -> bool) -> Option<&mut T> {}\n    pub fn get_many_mut<const N: usize>(\n        &mut self,\n        hashes: [u64; N],\n        eq: impl FnMut(usize, &T) -> bool,\n    ) -> [Option<&'_ mut T>; N] {}\n    pub unsafe fn get_many_unchecked_mut<const N: usize>(\n        &mut self,\n        hashes: [u64; N],\n        eq: impl FnMut(usize, &T) -> bool,\n    ) -> [Option<&'_ mut T>; N] {}\n    unsafe fn get_many_mut_pointers<const N: usize>(\n        &mut self,\n        hashes: [u64; N],\n        mut eq: impl FnMut(usize, &T) -> bool,\n    ) -> [Option<NonNull<T>>; N] {}\n    #[inline]\n    pub fn capacity(&self) -> usize {}\n    #[inline]\n    pub fn len(&self) -> usize {}\n    #[inline]\n    pub fn is_empty(&self) -> bool {}\n    #[inline]\n    pub fn buckets(&self) -> usize {\n        self.table.bucket_mask + 1\n    }\n    #[inline]\n    pub unsafe fn is_bucket_full(&self, index: usize) -> bool {}\n    #[inline]\n    pub unsafe fn iter(&self) -> RawIter<T> {}\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub unsafe fn iter_hash(&self, hash: u64) -> RawIterHash<T> {}\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn drain(&mut self) -> RawDrain<'_, T, A> {}\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub unsafe fn drain_iter_from(&mut self, iter: RawIter<T>) -> RawDrain<'_, T, A> {}\n    pub unsafe fn into_iter_from(self, iter: RawIter<T>) -> RawIntoIter<T, A> {}\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub(crate) fn into_allocation(self) -> Option<(NonNull<u8>, Layout, A)> {}\n}\nimpl<T> Bucket<T> {\n    #[inline]\n    unsafe fn from_base_index(base: NonNull<T>, index: usize) -> Self {\n        let ptr = if T::IS_ZERO_SIZED {\n            invalid_mut(index + 1)\n        } else {\n            base.as_ptr().sub(index)\n        };\n        Self {\n            ptr: NonNull::new_unchecked(ptr),\n        }\n    }\n    #[inline]\n    unsafe fn to_base_index(&self, base: NonNull<T>) -> usize {}\n    #[inline]\n    pub fn as_ptr(&self) -> *mut T {}\n    #[inline]\n    fn as_non_null(&self) -> NonNull<T> {}\n    #[inline]\n    unsafe fn next_n(&self, offset: usize) -> Self {\n        let ptr = if T::IS_ZERO_SIZED {\n            invalid_mut(self.ptr.as_ptr() as usize + offset)\n        } else {\n            self.ptr.as_ptr().sub(offset)\n        };\n        Self {\n            ptr: NonNull::new_unchecked(ptr),\n        }\n    }\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub(crate) unsafe fn drop(&self) {}\n    #[inline]\n    pub(crate) unsafe fn read(&self) -> T {}\n    #[inline]\n    pub(crate) unsafe fn write(&self, val: T) {}\n    #[inline]\n    pub unsafe fn as_ref<'a>(&self) -> &'a T {}\n    #[inline]\n    pub unsafe fn as_mut<'a>(&self) -> &'a mut T {}\n}\n\nThe function to be tested is presented as follows:\n/// Returns a pointer to an element in the table.\n///\n/// The caller must ensure that the `RawTable` outlives the returned [`Bucket<T>`],\n/// otherwise using it may result in [`undefined behavior`].\n///\n/// # Safety\n///\n/// If `mem::size_of::<T>() != 0`, then the caller of this function must observe the\n/// following safety rules:\n///\n/// * The table must already be allocated;\n///\n/// * The `index` must not be greater than the number returned by the [`RawTable::buckets`]\n///   function, i.e. `(index + 1) <= self.buckets()`.\n///\n/// It is safe to call this function with index of zero (`index == 0`) on a table that has\n/// not been allocated, but using the returned [`Bucket`] results in [`undefined behavior`].\n///\n/// If `mem::size_of::<T>() == 0`, then the only requirement is that the `index` must\n/// not be greater than the number returned by the [`RawTable::buckets`] function, i.e.\n/// `(index + 1) <= self.buckets()`.\n///\n/// [`RawTable::buckets`]: RawTable::buckets\n/// [`undefined behavior`]: https://doc.rust-lang.org/reference/behavior-considered-undefined.html\npub unsafe fn bucket(&self, index: usize) -> Bucket<T> {\n    // If mem::size_of::<T>() != 0 then return a pointer to the `element` in the `data part` of the table\n    // (we start counting from \"0\", so that in the expression T[n], the \"n\" index actually one less than\n    // the \"buckets\" number of our `RawTable`, i.e. \"n = RawTable::buckets() - 1\"):\n    //\n    //           `table.bucket(3).as_ptr()` returns a pointer that points here in the `data`\n    //           part of the `RawTable`, i.e. to the start of T3 (see `Bucket::as_ptr`)\n    //                  |\n    //                  |               `base = self.data_end()` points here\n    //                  |               (to the start of CT0 or to the end of T0)\n    //                  v                 v\n    // [Pad], T_n, ..., |T3|, T2, T1, T0, |CT0, CT1, CT2, CT3, ..., CT_n, CTa_0, CTa_1, ..., CTa_m\n    //                     ^                                              \\__________  __________/\n    //        `table.bucket(3)` returns a pointer that points                        \\/\n    //         here in the `data` part of the `RawTable` (to              additional control bytes\n    //         the end of T3)                                              `m = Group::WIDTH - 1`\n    //\n    // where: T0...T_n  - our stored data;\n    //        CT0...CT_n - control bytes or metadata for `data`;\n    //        CTa_0...CTa_m - additional control bytes (so that the search with loading `Group` bytes from\n    //                        the heap works properly, even if the result of `h1(hash) & self.table.bucket_mask`\n    //                        is equal to `self.table.bucket_mask`). See also `RawTableInner::set_ctrl` function.\n    //\n    // P.S. `h1(hash) & self.table.bucket_mask` is the same as `hash as usize % self.buckets()` because the number\n    // of buckets is a power of two, and `self.table.bucket_mask = self.buckets() - 1`.\n    debug_assert_ne!(self.table.bucket_mask, 0);\n    debug_assert!(index < self.buckets());\n    Bucket::from_base_index(self.data_end(), index)\n}\n",
  "depend_pt": ""
}