{"dependencies":{"<R as TryRngCore>::try_fill_bytes":["core::marker::Sized","core::result::Result"],"<R as TryRngCore>::try_next_u32":["core::marker::Sized","core::result::Result"],"<R as TryRngCore>::try_next_u64":["core::marker::Sized","core::result::Result"],"<T as RngCore>::fill_bytes":[],"<T as RngCore>::next_u32":[],"<T as RngCore>::next_u64":[],"<UnwrapErr<R> as RngCore>::fill_bytes":["<R as TryRngCore>::R","TryRngCore","UnwrapErr","core::marker::Sized"],"<UnwrapErr<R> as RngCore>::next_u32":["<R as TryRngCore>::R","TryRngCore","UnwrapErr","core::marker::Sized"],"<UnwrapErr<R> as RngCore>::next_u64":["<R as TryRngCore>::R","TryRngCore","UnwrapErr","core::marker::Sized"],"<UnwrapErr<R> as core::clone::Clone>::clone":["<R as TryRngCore>::R","TryRngCore","UnwrapErr","core::marker::Sized"],"<UnwrapErr<R> as core::cmp::Eq>::assert_receiver_is_total_eq":["<R as TryRngCore>::R","TryRngCore","UnwrapErr","core::marker::Sized"],"<UnwrapErr<R> as core::cmp::PartialEq>::eq":["<R as TryRngCore>::R","TryRngCore","UnwrapErr","core::marker::Sized"],"<UnwrapErr<R> as core::default::Default>::default":["<R as TryRngCore>::R","TryRngCore","UnwrapErr","core::marker::Sized"],"<UnwrapErr<R> as core::fmt::Debug>::fmt":["<R as TryRngCore>::R","TryRngCore","UnwrapErr","core::fmt::Formatter","core::marker::Sized","core::result::Result"],"<UnwrapErr<R> as core::hash::Hash>::hash":["<R as TryRngCore>::R","TryRngCore","UnwrapErr","core::hash::Hasher","core::marker::Sized"],"<UnwrapMut<'_, R> as RngCore>::fill_bytes":["<R as TryRngCore>::R","TryRngCore","UnwrapMut"],"<UnwrapMut<'_, R> as RngCore>::next_u32":["<R as TryRngCore>::R","TryRngCore","UnwrapMut"],"<UnwrapMut<'_, R> as RngCore>::next_u64":["<R as TryRngCore>::R","TryRngCore","UnwrapMut"],"<UnwrapMut<'r, R> as core::cmp::Eq>::assert_receiver_is_total_eq":["<R as TryRngCore>::R","TryRngCore","UnwrapMut"],"<UnwrapMut<'r, R> as core::cmp::PartialEq>::eq":["<R as TryRngCore>::R","TryRngCore","UnwrapMut"],"<UnwrapMut<'r, R> as core::fmt::Debug>::fmt":["<R as TryRngCore>::R","TryRngCore","UnwrapMut","core::fmt::Formatter","core::marker::Sized","core::result::Result"],"<UnwrapMut<'r, R> as core::hash::Hash>::hash":["<R as TryRngCore>::R","TryRngCore","UnwrapMut","core::hash::Hasher","core::marker::Sized"],"<block::BlockRng64<R> as RngCore>::fill_bytes":["block::BlockRng64","block::BlockRngCore"],"<block::BlockRng64<R> as RngCore>::next_u32":["block::BlockRng64","block::BlockRngCore"],"<block::BlockRng64<R> as RngCore>::next_u64":["block::BlockRng64","block::BlockRngCore"],"<block::BlockRng64<R> as SeedableRng>::from_rng":["<T as RngCore>::T","RngCore","block::BlockRng64","block::BlockRngCore","core::marker::Sized"],"<block::BlockRng64<R> as SeedableRng>::from_seed":["block::BlockRng64","block::BlockRngCore"],"<block::BlockRng64<R> as SeedableRng>::seed_from_u64":["block::BlockRng64","block::BlockRngCore"],"<block::BlockRng64<R> as SeedableRng>::try_from_rng":["<R as TryRngCore>::R","TryRngCore","core::marker::Sized","core::result::Result"],"<block::BlockRng64<R> as core::clone::Clone>::clone":["block::BlockRng64","block::BlockRngCore"],"<block::BlockRng64<R> as core::fmt::Debug>::fmt":["block::BlockRng64","block::BlockRngCore","core::fmt::Formatter","core::marker::Sized","core::result::Result"],"<block::BlockRng<R> as RngCore>::fill_bytes":["block::BlockRng","block::BlockRngCore","core::marker::Sized"],"<block::BlockRng<R> as RngCore>::next_u32":["block::BlockRng","block::BlockRngCore","core::marker::Sized"],"<block::BlockRng<R> as RngCore>::next_u64":["block::BlockRng","block::BlockRngCore","core::marker::Sized"],"<block::BlockRng<R> as SeedableRng>::from_rng":["<T as RngCore>::T","RngCore","block::BlockRng","block::BlockRngCore","core::marker::Sized"],"<block::BlockRng<R> as SeedableRng>::from_seed":["block::BlockRng","block::BlockRngCore","core::marker::Sized"],"<block::BlockRng<R> as SeedableRng>::seed_from_u64":["block::BlockRng","block::BlockRngCore","core::marker::Sized"],"<block::BlockRng<R> as SeedableRng>::try_from_rng":["<R as TryRngCore>::R","TryRngCore","core::marker::Sized","core::result::Result"],"<block::BlockRng<R> as core::clone::Clone>::clone":["block::BlockRng","block::BlockRngCore","core::marker::Sized"],"<block::BlockRng<R> as core::fmt::Debug>::fmt":["block::BlockRng","block::BlockRngCore","core::fmt::Formatter","core::marker::Sized","core::result::Result"],"<u32 as impls::Observable>::to_le_bytes":[],"<u64 as impls::Observable>::to_le_bytes":[],"RngCore::fill_bytes":[],"RngCore::next_u32":[],"RngCore::next_u64":[],"SeedableRng::from_rng":["<T as RngCore>::T","RngCore","core::marker::Sized"],"SeedableRng::from_seed":[],"SeedableRng::seed_from_u64":[],"SeedableRng::seed_from_u64::pcg32":[],"SeedableRng::try_from_rng":["<R as TryRngCore>::R","TryRngCore","core::marker::Sized","core::result::Result"],"TryRngCore::try_fill_bytes":["core::marker::Sized","core::result::Result"],"TryRngCore::try_next_u32":["core::marker::Sized","core::result::Result"],"TryRngCore::try_next_u64":["core::marker::Sized","core::result::Result"],"TryRngCore::unwrap_err":["<R as TryRngCore>::R","TryRngCore","UnwrapErr","core::marker::Sized"],"TryRngCore::unwrap_mut":["<R as TryRngCore>::R","TryRngCore","UnwrapMut"],"UnwrapErr":["<R as TryRngCore>::R","TryRngCore","UnwrapErr","core::marker::Sized"],"UnwrapMut":["<R as TryRngCore>::R","TryRngCore","UnwrapMut"],"UnwrapMut::<'r, R>::re":["<R as TryRngCore>::R","TryRngCore","UnwrapMut"],"block::BlockRng":["block::BlockRng","block::BlockRngCore","core::marker::Sized"],"block::BlockRng64":["block::BlockRng64","block::BlockRngCore"],"block::BlockRng64::<R>::generate_and_set":["block::BlockRng64","block::BlockRngCore"],"block::BlockRng64::<R>::index":["block::BlockRng64","block::BlockRngCore"],"block::BlockRng64::<R>::new":["block::BlockRng64","block::BlockRngCore"],"block::BlockRng64::<R>::reset":["block::BlockRng64","block::BlockRngCore"],"block::BlockRng::<R>::generate_and_set":["block::BlockRng","block::BlockRngCore","core::marker::Sized"],"block::BlockRng::<R>::index":["block::BlockRng","block::BlockRngCore","core::marker::Sized"],"block::BlockRng::<R>::new":["block::BlockRng","block::BlockRngCore","core::marker::Sized"],"block::BlockRng::<R>::reset":["block::BlockRng","block::BlockRngCore","core::marker::Sized"],"block::BlockRngCore::generate":[],"impls::Observable::to_le_bytes":[],"impls::fill_bytes_via_next":["<T as RngCore>::T","RngCore"],"impls::fill_via_chunks":["core::marker::Sized","impls::Observable"],"impls::fill_via_u32_chunks":[],"impls::fill_via_u64_chunks":[],"impls::next_u32_via_fill":["<T as RngCore>::T","RngCore"],"impls::next_u64_via_fill":["<T as RngCore>::T","RngCore"],"impls::next_u64_via_u32":["<T as RngCore>::T","RngCore"],"le::read_u32_into":[],"le::read_u64_into":[]},"glob_path_import":{},"self_to_fn":{"<R as TryCryptoRng>::R":["impl<R: CryptoRng + ?Sized> TryCryptoRng for R {}"],"<R as TryRngCore>::R":["impl<R: RngCore + ?Sized> TryRngCore for R {\n    type Error = core::convert::Infallible;\n\n    #[inline]\n    fn try_next_u32(&mut self) -> Result<u32, Self::Error> {\n        Ok(self.next_u32())\n    }\n\n    #[inline]\n    fn try_next_u64(&mut self) -> Result<u64, Self::Error> {\n        Ok(self.next_u64())\n    }\n\n    #[inline]\n    fn try_fill_bytes(&mut self, dst: &mut [u8]) -> Result<(), Self::Error> {\n        self.fill_bytes(dst);\n        Ok(())\n    }\n}"],"<T as CryptoRng>::T":["impl<T: DerefMut> CryptoRng for T where T::Target: CryptoRng {}"],"<T as RngCore>::T":["impl<T: DerefMut> RngCore for T\nwhere\n    T::Target: RngCore,\n{\n    #[inline]\n    fn next_u32(&mut self) -> u32 {\n        self.deref_mut().next_u32()\n    }\n\n    #[inline]\n    fn next_u64(&mut self) -> u64 {\n        self.deref_mut().next_u64()\n    }\n\n    #[inline]\n    fn fill_bytes(&mut self, dst: &mut [u8]) {\n        self.deref_mut().fill_bytes(dst);\n    }\n}"],"UnwrapErr":["Clone","Copy","Debug","Default","Eq","Hash","PartialEq","impl<R: TryCryptoRng> CryptoRng for UnwrapErr<R> {}","impl<R: TryRngCore> RngCore for UnwrapErr<R> {\n    #[inline]\n    fn next_u32(&mut self) -> u32 {\n        self.0.try_next_u32().unwrap()\n    }\n\n    #[inline]\n    fn next_u64(&mut self) -> u64 {\n        self.0.try_next_u64().unwrap()\n    }\n\n    #[inline]\n    fn fill_bytes(&mut self, dst: &mut [u8]) {\n        self.0.try_fill_bytes(dst).unwrap()\n    }\n}"],"UnwrapMut":["Debug","Eq","Hash","PartialEq","impl<'r, R: TryRngCore + ?Sized> UnwrapMut<'r, R> {\n    /// Reborrow with a new lifetime\n    ///\n    /// Rust allows references like `&T` or `&mut T` to be \"reborrowed\" through\n    /// coercion: essentially, the pointer is copied under a new, shorter, lifetime.\n    /// Until rfcs#1403 lands, reborrows on user types require a method call.\n    #[inline(always)]\n    pub fn re<'b>(&'b mut self) -> UnwrapMut<'b, R>\n    where\n        'r: 'b,\n    {\n        UnwrapMut(self.0)\n    }\n}","impl<R: TryCryptoRng + ?Sized> CryptoRng for UnwrapMut<'_, R> {}","impl<R: TryRngCore + ?Sized> RngCore for UnwrapMut<'_, R> {\n    #[inline]\n    fn next_u32(&mut self) -> u32 {\n        self.0.try_next_u32().unwrap()\n    }\n\n    #[inline]\n    fn next_u64(&mut self) -> u64 {\n        self.0.try_next_u64().unwrap()\n    }\n\n    #[inline]\n    fn fill_bytes(&mut self, dst: &mut [u8]) {\n        self.0.try_fill_bytes(dst).unwrap()\n    }\n}"],"block::BlockRng":["Clone","impl<R: BlockRngCore + SeedableRng> SeedableRng for BlockRng<R> {\n    type Seed = R::Seed;\n\n    #[inline(always)]\n    fn from_seed(seed: Self::Seed) -> Self {\n        Self::new(R::from_seed(seed))\n    }\n\n    #[inline(always)]\n    fn seed_from_u64(seed: u64) -> Self {\n        Self::new(R::seed_from_u64(seed))\n    }\n\n    #[inline(always)]\n    fn from_rng(rng: &mut impl RngCore) -> Self {\n        Self::new(R::from_rng(rng))\n    }\n\n    #[inline(always)]\n    fn try_from_rng<S: TryRngCore>(rng: &mut S) -> Result<Self, S::Error> {\n        R::try_from_rng(rng).map(Self::new)\n    }\n}","impl<R: BlockRngCore + fmt::Debug> fmt::Debug for BlockRng<R> {\n    fn fmt(&self, fmt: &mut fmt::Formatter) -> fmt::Result {\n        fmt.debug_struct(\"BlockRng\")\n            .field(\"core\", &self.core)\n            .field(\"result_len\", &self.results.as_ref().len())\n            .field(\"index\", &self.index)\n            .finish()\n    }\n}","impl<R: BlockRngCore<Item = u32>> RngCore for BlockRng<R> {\n    #[inline]\n    fn next_u32(&mut self) -> u32 {\n        if self.index >= self.results.as_ref().len() {\n            self.generate_and_set(0);\n        }\n\n        let value = self.results.as_ref()[self.index];\n        self.index += 1;\n        value\n    }\n\n    #[inline]\n    fn next_u64(&mut self) -> u64 {\n        let read_u64 = |results: &[u32], index| {\n            let data = &results[index..=index + 1];\n            (u64::from(data[1]) << 32) | u64::from(data[0])\n        };\n\n        let len = self.results.as_ref().len();\n\n        let index = self.index;\n        if index < len - 1 {\n            self.index += 2;\n            // Read an u64 from the current index\n            read_u64(self.results.as_ref(), index)\n        } else if index >= len {\n            self.generate_and_set(2);\n            read_u64(self.results.as_ref(), 0)\n        } else {\n            let x = u64::from(self.results.as_ref()[len - 1]);\n            self.generate_and_set(1);\n            let y = u64::from(self.results.as_ref()[0]);\n            (y << 32) | x\n        }\n    }\n\n    #[inline]\n    fn fill_bytes(&mut self, dest: &mut [u8]) {\n        let mut read_len = 0;\n        while read_len < dest.len() {\n            if self.index >= self.results.as_ref().len() {\n                self.generate_and_set(0);\n            }\n            let (consumed_u32, filled_u8) =\n                fill_via_chunks(&self.results.as_mut()[self.index..], &mut dest[read_len..]);\n\n            self.index += consumed_u32;\n            read_len += filled_u8;\n        }\n    }\n}","impl<R: BlockRngCore> BlockRng<R> {\n    /// Create a new `BlockRng` from an existing RNG implementing\n    /// `BlockRngCore`. Results will be generated on first use.\n    #[inline]\n    pub fn new(core: R) -> BlockRng<R> {\n        let results_empty = R::Results::default();\n        BlockRng {\n            core,\n            index: results_empty.as_ref().len(),\n            results: results_empty,\n        }\n    }\n\n    /// Get the index into the result buffer.\n    ///\n    /// If this is equal to or larger than the size of the result buffer then\n    /// the buffer is \"empty\" and `generate()` must be called to produce new\n    /// results.\n    #[inline(always)]\n    pub fn index(&self) -> usize {\n        self.index\n    }\n\n    /// Reset the number of available results.\n    /// This will force a new set of results to be generated on next use.\n    #[inline]\n    pub fn reset(&mut self) {\n        self.index = self.results.as_ref().len();\n    }\n\n    /// Generate a new set of results immediately, setting the index to the\n    /// given value.\n    #[inline]\n    pub fn generate_and_set(&mut self, index: usize) {\n        assert!(index < self.results.as_ref().len());\n        self.core.generate(&mut self.results);\n        self.index = index;\n    }\n}","impl<R: CryptoBlockRng + BlockRngCore<Item = u32>> CryptoRng for BlockRng<R> {}"],"block::BlockRng64":["Clone","impl<R: BlockRngCore + SeedableRng> SeedableRng for BlockRng64<R> {\n    type Seed = R::Seed;\n\n    #[inline(always)]\n    fn from_seed(seed: Self::Seed) -> Self {\n        Self::new(R::from_seed(seed))\n    }\n\n    #[inline(always)]\n    fn seed_from_u64(seed: u64) -> Self {\n        Self::new(R::seed_from_u64(seed))\n    }\n\n    #[inline(always)]\n    fn from_rng(rng: &mut impl RngCore) -> Self {\n        Self::new(R::from_rng(rng))\n    }\n\n    #[inline(always)]\n    fn try_from_rng<S: TryRngCore>(rng: &mut S) -> Result<Self, S::Error> {\n        R::try_from_rng(rng).map(Self::new)\n    }\n}","impl<R: BlockRngCore + fmt::Debug> fmt::Debug for BlockRng64<R> {\n    fn fmt(&self, fmt: &mut fmt::Formatter) -> fmt::Result {\n        fmt.debug_struct(\"BlockRng64\")\n            .field(\"core\", &self.core)\n            .field(\"result_len\", &self.results.as_ref().len())\n            .field(\"index\", &self.index)\n            .field(\"half_used\", &self.half_used)\n            .finish()\n    }\n}","impl<R: BlockRngCore<Item = u64>> RngCore for BlockRng64<R> {\n    #[inline]\n    fn next_u32(&mut self) -> u32 {\n        let mut index = self.index - self.half_used as usize;\n        if index >= self.results.as_ref().len() {\n            self.core.generate(&mut self.results);\n            self.index = 0;\n            index = 0;\n            // `self.half_used` is by definition `false`\n            self.half_used = false;\n        }\n\n        let shift = 32 * (self.half_used as usize);\n\n        self.half_used = !self.half_used;\n        self.index += self.half_used as usize;\n\n        (self.results.as_ref()[index] >> shift) as u32\n    }\n\n    #[inline]\n    fn next_u64(&mut self) -> u64 {\n        if self.index >= self.results.as_ref().len() {\n            self.core.generate(&mut self.results);\n            self.index = 0;\n        }\n\n        let value = self.results.as_ref()[self.index];\n        self.index += 1;\n        self.half_used = false;\n        value\n    }\n\n    #[inline]\n    fn fill_bytes(&mut self, dest: &mut [u8]) {\n        let mut read_len = 0;\n        self.half_used = false;\n        while read_len < dest.len() {\n            if self.index >= self.results.as_ref().len() {\n                self.core.generate(&mut self.results);\n                self.index = 0;\n            }\n\n            let (consumed_u64, filled_u8) =\n                fill_via_chunks(&self.results.as_mut()[self.index..], &mut dest[read_len..]);\n\n            self.index += consumed_u64;\n            read_len += filled_u8;\n        }\n    }\n}","impl<R: BlockRngCore> BlockRng64<R> {\n    /// Create a new `BlockRng` from an existing RNG implementing\n    /// `BlockRngCore`. Results will be generated on first use.\n    #[inline]\n    pub fn new(core: R) -> BlockRng64<R> {\n        let results_empty = R::Results::default();\n        BlockRng64 {\n            core,\n            index: results_empty.as_ref().len(),\n            half_used: false,\n            results: results_empty,\n        }\n    }\n\n    /// Get the index into the result buffer.\n    ///\n    /// If this is equal to or larger than the size of the result buffer then\n    /// the buffer is \"empty\" and `generate()` must be called to produce new\n    /// results.\n    #[inline(always)]\n    pub fn index(&self) -> usize {\n        self.index\n    }\n\n    /// Reset the number of available results.\n    /// This will force a new set of results to be generated on next use.\n    #[inline]\n    pub fn reset(&mut self) {\n        self.index = self.results.as_ref().len();\n        self.half_used = false;\n    }\n\n    /// Generate a new set of results immediately, setting the index to the\n    /// given value.\n    #[inline]\n    pub fn generate_and_set(&mut self, index: usize) {\n        assert!(index < self.results.as_ref().len());\n        self.core.generate(&mut self.results);\n        self.index = index;\n        self.half_used = false;\n    }\n}","impl<R: CryptoBlockRng + BlockRngCore<Item = u64>> CryptoRng for BlockRng64<R> {}"]},"single_path_import":{},"srcs":{"<R as TryRngCore>::try_fill_bytes":["#[inline]\nfn try_fill_bytes(&mut self, dst: &mut [u8]) -> Result<(), Self::Error>{\n        self.fill_bytes(dst);\n        Ok(())\n    }","Real(LocalPath(\"rand_core/src/lib.rs\"))"],"<R as TryRngCore>::try_next_u32":["#[inline]\nfn try_next_u32(&mut self) -> Result<u32, Self::Error>{\n        Ok(self.next_u32())\n    }","Real(LocalPath(\"rand_core/src/lib.rs\"))"],"<R as TryRngCore>::try_next_u64":["#[inline]\nfn try_next_u64(&mut self) -> Result<u64, Self::Error>{\n        Ok(self.next_u64())\n    }","Real(LocalPath(\"rand_core/src/lib.rs\"))"],"<T as RngCore>::fill_bytes":["#[inline]\nfn fill_bytes(&mut self, dst: &mut [u8]){\n        self.deref_mut().fill_bytes(dst);\n    }","Real(LocalPath(\"rand_core/src/lib.rs\"))"],"<T as RngCore>::next_u32":["#[inline]\nfn next_u32(&mut self) -> u32{\n        self.deref_mut().next_u32()\n    }","Real(LocalPath(\"rand_core/src/lib.rs\"))"],"<T as RngCore>::next_u64":["#[inline]\nfn next_u64(&mut self) -> u64{\n        self.deref_mut().next_u64()\n    }","Real(LocalPath(\"rand_core/src/lib.rs\"))"],"<UnwrapErr<R> as RngCore>::fill_bytes":["#[inline]\nfn fill_bytes(&mut self, dst: &mut [u8]){\n        self.0.try_fill_bytes(dst).unwrap()\n    }","Real(LocalPath(\"rand_core/src/lib.rs\"))"],"<UnwrapErr<R> as RngCore>::next_u32":["#[inline]\nfn next_u32(&mut self) -> u32{\n        self.0.try_next_u32().unwrap()\n    }","Real(LocalPath(\"rand_core/src/lib.rs\"))"],"<UnwrapErr<R> as RngCore>::next_u64":["#[inline]\nfn next_u64(&mut self) -> u64{\n        self.0.try_next_u64().unwrap()\n    }","Real(LocalPath(\"rand_core/src/lib.rs\"))"],"<UnwrapMut<'_, R> as RngCore>::fill_bytes":["#[inline]\nfn fill_bytes(&mut self, dst: &mut [u8]){\n        self.0.try_fill_bytes(dst).unwrap()\n    }","Real(LocalPath(\"rand_core/src/lib.rs\"))"],"<UnwrapMut<'_, R> as RngCore>::next_u32":["#[inline]\nfn next_u32(&mut self) -> u32{\n        self.0.try_next_u32().unwrap()\n    }","Real(LocalPath(\"rand_core/src/lib.rs\"))"],"<UnwrapMut<'_, R> as RngCore>::next_u64":["#[inline]\nfn next_u64(&mut self) -> u64{\n        self.0.try_next_u64().unwrap()\n    }","Real(LocalPath(\"rand_core/src/lib.rs\"))"],"<block::BlockRng64<R> as RngCore>::fill_bytes":["#[inline]\nfn fill_bytes(&mut self, dest: &mut [u8]){\n        let mut read_len = 0;\n        self.half_used = false;\n        while read_len < dest.len() {\n            if self.index >= self.results.as_ref().len() {\n                self.core.generate(&mut self.results);\n                self.index = 0;\n            }\n\n            let (consumed_u64, filled_u8) =\n                fill_via_chunks(&self.results.as_mut()[self.index..], &mut dest[read_len..]);\n\n            self.index += consumed_u64;\n            read_len += filled_u8;\n        }\n    }","Real(LocalPath(\"rand_core/src/block.rs\"))"],"<block::BlockRng64<R> as RngCore>::next_u32":["#[inline]\nfn next_u32(&mut self) -> u32{\n        let mut index = self.index - self.half_used as usize;\n        if index >= self.results.as_ref().len() {\n            self.core.generate(&mut self.results);\n            self.index = 0;\n            index = 0;\n            // `self.half_used` is by definition `false`\n            self.half_used = false;\n        }\n\n        let shift = 32 * (self.half_used as usize);\n\n        self.half_used = !self.half_used;\n        self.index += self.half_used as usize;\n\n        (self.results.as_ref()[index] >> shift) as u32\n    }","Real(LocalPath(\"rand_core/src/block.rs\"))"],"<block::BlockRng64<R> as RngCore>::next_u64":["#[inline]\nfn next_u64(&mut self) -> u64{\n        if self.index >= self.results.as_ref().len() {\n            self.core.generate(&mut self.results);\n            self.index = 0;\n        }\n\n        let value = self.results.as_ref()[self.index];\n        self.index += 1;\n        self.half_used = false;\n        value\n    }","Real(LocalPath(\"rand_core/src/block.rs\"))"],"<block::BlockRng64<R> as SeedableRng>::from_rng":["#[inline(always)]\nfn from_rng(rng: &mut impl RngCore) -> Self{\n        Self::new(R::from_rng(rng))\n    }","Real(LocalPath(\"rand_core/src/block.rs\"))"],"<block::BlockRng64<R> as SeedableRng>::from_seed":["#[inline(always)]\nfn from_seed(seed: Self::Seed) -> Self{\n        Self::new(R::from_seed(seed))\n    }","Real(LocalPath(\"rand_core/src/block.rs\"))"],"<block::BlockRng64<R> as SeedableRng>::seed_from_u64":["#[inline(always)]\nfn seed_from_u64(seed: u64) -> Self{\n        Self::new(R::seed_from_u64(seed))\n    }","Real(LocalPath(\"rand_core/src/block.rs\"))"],"<block::BlockRng64<R> as SeedableRng>::try_from_rng":["#[inline(always)]\nfn try_from_rng<S: TryRngCore>(rng: &mut S) -> Result<Self, S::Error>{\n        R::try_from_rng(rng).map(Self::new)\n    }","Real(LocalPath(\"rand_core/src/block.rs\"))"],"<block::BlockRng64<R> as core::fmt::Debug>::fmt":["fn fmt(&self, fmt: &mut fmt::Formatter) -> fmt::Result{\n        fmt.debug_struct(\"BlockRng64\")\n            .field(\"core\", &self.core)\n            .field(\"result_len\", &self.results.as_ref().len())\n            .field(\"index\", &self.index)\n            .field(\"half_used\", &self.half_used)\n            .finish()\n    }","Real(LocalPath(\"rand_core/src/block.rs\"))"],"<block::BlockRng<R> as RngCore>::fill_bytes":["#[inline]\nfn fill_bytes(&mut self, dest: &mut [u8]){\n        let mut read_len = 0;\n        while read_len < dest.len() {\n            if self.index >= self.results.as_ref().len() {\n                self.generate_and_set(0);\n            }\n            let (consumed_u32, filled_u8) =\n                fill_via_chunks(&self.results.as_mut()[self.index..], &mut dest[read_len..]);\n\n            self.index += consumed_u32;\n            read_len += filled_u8;\n        }\n    }","Real(LocalPath(\"rand_core/src/block.rs\"))"],"<block::BlockRng<R> as RngCore>::next_u32":["#[inline]\nfn next_u32(&mut self) -> u32{\n        if self.index >= self.results.as_ref().len() {\n            self.generate_and_set(0);\n        }\n\n        let value = self.results.as_ref()[self.index];\n        self.index += 1;\n        value\n    }","Real(LocalPath(\"rand_core/src/block.rs\"))"],"<block::BlockRng<R> as RngCore>::next_u64":["#[inline]\nfn next_u64(&mut self) -> u64{\n        let read_u64 = |results: &[u32], index| {\n            let data = &results[index..=index + 1];\n            (u64::from(data[1]) << 32) | u64::from(data[0])\n        };\n\n        let len = self.results.as_ref().len();\n\n        let index = self.index;\n        if index < len - 1 {\n            self.index += 2;\n            // Read an u64 from the current index\n            read_u64(self.results.as_ref(), index)\n        } else if index >= len {\n            self.generate_and_set(2);\n            read_u64(self.results.as_ref(), 0)\n        } else {\n            let x = u64::from(self.results.as_ref()[len - 1]);\n            self.generate_and_set(1);\n            let y = u64::from(self.results.as_ref()[0]);\n            (y << 32) | x\n        }\n    }","Real(LocalPath(\"rand_core/src/block.rs\"))"],"<block::BlockRng<R> as SeedableRng>::from_rng":["#[inline(always)]\nfn from_rng(rng: &mut impl RngCore) -> Self{\n        Self::new(R::from_rng(rng))\n    }","Real(LocalPath(\"rand_core/src/block.rs\"))"],"<block::BlockRng<R> as SeedableRng>::from_seed":["#[inline(always)]\nfn from_seed(seed: Self::Seed) -> Self{\n        Self::new(R::from_seed(seed))\n    }","Real(LocalPath(\"rand_core/src/block.rs\"))"],"<block::BlockRng<R> as SeedableRng>::seed_from_u64":["#[inline(always)]\nfn seed_from_u64(seed: u64) -> Self{\n        Self::new(R::seed_from_u64(seed))\n    }","Real(LocalPath(\"rand_core/src/block.rs\"))"],"<block::BlockRng<R> as SeedableRng>::try_from_rng":["#[inline(always)]\nfn try_from_rng<S: TryRngCore>(rng: &mut S) -> Result<Self, S::Error>{\n        R::try_from_rng(rng).map(Self::new)\n    }","Real(LocalPath(\"rand_core/src/block.rs\"))"],"<block::BlockRng<R> as core::fmt::Debug>::fmt":["fn fmt(&self, fmt: &mut fmt::Formatter) -> fmt::Result{\n        fmt.debug_struct(\"BlockRng\")\n            .field(\"core\", &self.core)\n            .field(\"result_len\", &self.results.as_ref().len())\n            .field(\"index\", &self.index)\n            .finish()\n    }","Real(LocalPath(\"rand_core/src/block.rs\"))"],"<u32 as impls::Observable>::to_le_bytes":["fn to_le_bytes(self) -> Self::Bytes{\n        Self::to_le_bytes(self)\n    }","Real(LocalPath(\"rand_core/src/impls.rs\"))"],"<u64 as impls::Observable>::to_le_bytes":["fn to_le_bytes(self) -> Self::Bytes{\n        Self::to_le_bytes(self)\n    }","Real(LocalPath(\"rand_core/src/impls.rs\"))"],"CryptoRng":["/// A marker trait over [`RngCore`] for securely unpredictable RNGs\n///\n/// This marker trait indicates that the implementing generator is intended,\n/// when correctly seeded and protected from side-channel attacks such as a\n/// leaking of state, to be a cryptographically secure generator. This trait is\n/// provided as a tool to aid review of cryptographic code, but does not by\n/// itself guarantee suitability for cryptographic applications.\n///\n/// Implementors of `CryptoRng` automatically implement the [`TryCryptoRng`]\n/// trait.\n///\n/// Implementors of `CryptoRng` should only implement [`Default`] if the\n/// `default()` instances are themselves secure generators: for example if the\n/// implementing type is a stateless interface over a secure external generator\n/// (like [`OsRng`]) or if the `default()` instance uses a strong, fresh seed.\n///\n/// Formally, a CSPRNG (Cryptographically Secure Pseudo-Random Number Generator)\n/// should satisfy an additional property over other generators: assuming that\n/// the generator has been appropriately seeded and has unknown state, then\n/// given the first *k* bits of an algorithm's output\n/// sequence, it should not be possible using polynomial-time algorithms to\n/// predict the next bit with probability significantly greater than 50%.\n///\n/// An optional property of CSPRNGs is backtracking resistance: if the CSPRNG's\n/// state is revealed, it will not be computationally-feasible to reconstruct\n/// prior output values. This property is not required by `CryptoRng`.\npub trait CryptoRng: RngCore {}","Real(LocalPath(\"rand_core/src/lib.rs\"))"],"RngCore":["/// Implementation-level interface for RNGs\n///\n/// This trait encapsulates the low-level functionality common to all\n/// generators, and is the \"back end\", to be implemented by generators.\n/// End users should normally use the [`rand::Rng`] trait\n/// which is automatically implemented for every type implementing `RngCore`.\n///\n/// Three different methods for generating random data are provided since the\n/// optimal implementation of each is dependent on the type of generator. There\n/// is no required relationship between the output of each; e.g. many\n/// implementations of [`fill_bytes`] consume a whole number of `u32` or `u64`\n/// values and drop any remaining unused bytes. The same can happen with the\n/// [`next_u32`] and [`next_u64`] methods, implementations may discard some\n/// random bits for efficiency.\n///\n/// Implementers should produce bits uniformly. Pathological RNGs (e.g. always\n/// returning the same value, or never setting certain bits) can break rejection\n/// sampling used by random distributions, and also break other RNGs when\n/// seeding them via [`SeedableRng::from_rng`].\n///\n/// Algorithmic generators implementing [`SeedableRng`] should normally have\n/// *portable, reproducible* output, i.e. fix Endianness when converting values\n/// to avoid platform differences, and avoid making any changes which affect\n/// output (except by communicating that the release has breaking changes).\n///\n/// Typically an RNG will implement only one of the methods available\n/// in this trait directly, then use the helper functions from the\n/// [`impls`] module to implement the other methods.\n///\n/// Note that implementors of [`RngCore`] also automatically implement\n/// the [`TryRngCore`] trait with the `Error` associated type being\n/// equal to [`Infallible`].\n///\n/// It is recommended that implementations also implement:\n///\n/// - `Debug` with a custom implementation which *does not* print any internal\n///   state (at least, [`CryptoRng`]s should not risk leaking state through\n///   `Debug`).\n/// - `Serialize` and `Deserialize` (from Serde), preferably making Serde\n///   support optional at the crate level in PRNG libs.\n/// - `Clone`, if possible.\n/// - *never* implement `Copy` (accidental copies may cause repeated values).\n/// - *do not* implement `Default` for pseudorandom generators, but instead\n///   implement [`SeedableRng`], to guide users towards proper seeding.\n///   External / hardware RNGs can choose to implement `Default`.\n/// - `Eq` and `PartialEq` could be implemented, but are probably not useful.\n///\n/// # Example\n///\n/// A simple example, obviously not generating very *random* output:\n///\n/// ```\n/// #![allow(dead_code)]\n/// use rand_core::{RngCore, impls};\n///\n/// struct CountingRng(u64);\n///\n/// impl RngCore for CountingRng {\n///     fn next_u32(&mut self) -> u32 {\n///         self.next_u64() as u32\n///     }\n///\n///     fn next_u64(&mut self) -> u64 {\n///         self.0 += 1;\n///         self.0\n///     }\n///\n///     fn fill_bytes(&mut self, dst: &mut [u8]) {\n///         impls::fill_bytes_via_next(self, dst)\n///     }\n/// }\n/// ```\n///\n/// [`rand::Rng`]: https://docs.rs/rand/latest/rand/trait.Rng.html\n/// [`fill_bytes`]: RngCore::fill_bytes\n/// [`next_u32`]: RngCore::next_u32\n/// [`next_u64`]: RngCore::next_u64\n/// [`Infallible`]: core::convert::Infallible\npub trait RngCore {\n    /// Return the next random `u32`.\n    ///\n    /// RNGs must implement at least one method from this trait directly. In\n    /// the case this method is not implemented directly, it can be implemented\n    /// using `self.next_u64() as u32` or via [`impls::next_u32_via_fill`].\n    fn next_u32(&mut self) -> u32;\n\n    /// Return the next random `u64`.\n    ///\n    /// RNGs must implement at least one method from this trait directly. In\n    /// the case this method is not implemented directly, it can be implemented\n    /// via [`impls::next_u64_via_u32`] or via [`impls::next_u64_via_fill`].\n    fn next_u64(&mut self) -> u64;\n\n    /// Fill `dest` with random data.\n    ///\n    /// RNGs must implement at least one method from this trait directly. In\n    /// the case this method is not implemented directly, it can be implemented\n    /// via [`impls::fill_bytes_via_next`].\n    ///\n    /// This method should guarantee that `dest` is entirely filled\n    /// with new data, and may panic if this is impossible\n    /// (e.g. reading past the end of a file that is being used as the\n    /// source of randomness).\n    fn fill_bytes(&mut self, dst: &mut [u8]);\n}","Real(LocalPath(\"rand_core/src/lib.rs\"))"],"SeedableRng":["/// A random number generator that can be explicitly seeded.\n///\n/// This trait encapsulates the low-level functionality common to all\n/// pseudo-random number generators (PRNGs, or algorithmic generators).\n///\n/// A generator implementing `SeedableRng` will usually be deterministic, but\n/// beware that portability and reproducibility of results **is not implied**.\n/// Refer to documentation of the generator, noting that generators named after\n/// a specific algorithm are usually tested for reproducibility against a\n/// reference vector, while `SmallRng` and `StdRng` specifically opt out of\n/// reproducibility guarantees.\n///\n/// [`rand`]: https://docs.rs/rand\npub trait SeedableRng: Sized {\n    /// Seed type, which is restricted to types mutably-dereferenceable as `u8`\n    /// arrays (we recommend `[u8; N]` for some `N`).\n    ///\n    /// It is recommended to seed PRNGs with a seed of at least circa 100 bits,\n    /// which means an array of `[u8; 12]` or greater to avoid picking RNGs with\n    /// partially overlapping periods.\n    ///\n    /// For cryptographic RNG's a seed of 256 bits is recommended, `[u8; 32]`.\n    ///\n    ///\n    /// # Implementing `SeedableRng` for RNGs with large seeds\n    ///\n    /// Note that [`Default`] is not implemented for large arrays `[u8; N]` with\n    /// `N` > 32. To be able to implement the traits required by `SeedableRng`\n    /// for RNGs with such large seeds, the newtype pattern can be used:\n    ///\n    /// ```\n    /// use rand_core::SeedableRng;\n    ///\n    /// const N: usize = 64;\n    /// #[derive(Clone)]\n    /// pub struct MyRngSeed(pub [u8; N]);\n    /// # #[allow(dead_code)]\n    /// pub struct MyRng(MyRngSeed);\n    ///\n    /// impl Default for MyRngSeed {\n    ///     fn default() -> MyRngSeed {\n    ///         MyRngSeed([0; N])\n    ///     }\n    /// }\n    ///\n    /// impl AsRef<[u8]> for MyRngSeed {\n    ///     fn as_ref(&self) -> &[u8] {\n    ///         &self.0\n    ///     }\n    /// }\n    ///\n    /// impl AsMut<[u8]> for MyRngSeed {\n    ///     fn as_mut(&mut self) -> &mut [u8] {\n    ///         &mut self.0\n    ///     }\n    /// }\n    ///\n    /// impl SeedableRng for MyRng {\n    ///     type Seed = MyRngSeed;\n    ///\n    ///     fn from_seed(seed: MyRngSeed) -> MyRng {\n    ///         MyRng(seed)\n    ///     }\n    /// }\n    /// ```\n    type Seed: Clone + Default + AsRef<[u8]> + AsMut<[u8]>;\n\n    /// Create a new PRNG using the given seed.\n    ///\n    /// PRNG implementations are allowed to assume that bits in the seed are\n    /// well distributed. That means usually that the number of one and zero\n    /// bits are roughly equal, and values like 0, 1 and (size - 1) are unlikely.\n    /// Note that many non-cryptographic PRNGs will show poor quality output\n    /// if this is not adhered to. If you wish to seed from simple numbers, use\n    /// `seed_from_u64` instead.\n    ///\n    /// All PRNG implementations should be reproducible unless otherwise noted:\n    /// given a fixed `seed`, the same sequence of output should be produced\n    /// on all runs, library versions and architectures (e.g. check endianness).\n    /// Any \"value-breaking\" changes to the generator should require bumping at\n    /// least the minor version and documentation of the change.\n    ///\n    /// It is not required that this function yield the same state as a\n    /// reference implementation of the PRNG given equivalent seed; if necessary\n    /// another constructor replicating behaviour from a reference\n    /// implementation can be added.\n    ///\n    /// PRNG implementations should make sure `from_seed` never panics. In the\n    /// case that some special values (like an all zero seed) are not viable\n    /// seeds it is preferable to map these to alternative constant value(s),\n    /// for example `0xBAD5EEDu32` or `0x0DDB1A5E5BAD5EEDu64` (\"odd biases? bad\n    /// seed\"). This is assuming only a small number of values must be rejected.\n    fn from_seed(seed: Self::Seed) -> Self;\n\n    /// Create a new PRNG using a `u64` seed.\n    ///\n    /// This is a convenience-wrapper around `from_seed` to allow construction\n    /// of any `SeedableRng` from a simple `u64` value. It is designed such that\n    /// low Hamming Weight numbers like 0 and 1 can be used and should still\n    /// result in good, independent seeds to the PRNG which is returned.\n    ///\n    /// This **is not suitable for cryptography**, as should be clear given that\n    /// the input size is only 64 bits.\n    ///\n    /// Implementations for PRNGs *may* provide their own implementations of\n    /// this function, but the default implementation should be good enough for\n    /// all purposes. *Changing* the implementation of this function should be\n    /// considered a value-breaking change.\n    fn seed_from_u64(mut state: u64) -> Self {\n        // We use PCG32 to generate a u32 sequence, and copy to the seed\n        fn pcg32(state: &mut u64) -> [u8; 4] {\n            const MUL: u64 = 6364136223846793005;\n            const INC: u64 = 11634580027462260723;\n\n            // We advance the state first (to get away from the input value,\n            // in case it has low Hamming Weight).\n            *state = state.wrapping_mul(MUL).wrapping_add(INC);\n            let state = *state;\n\n            // Use PCG output function with to_le to generate x:\n            let xorshifted = (((state >> 18) ^ state) >> 27) as u32;\n            let rot = (state >> 59) as u32;\n            let x = xorshifted.rotate_right(rot);\n            x.to_le_bytes()\n        }\n\n        let mut seed = Self::Seed::default();\n        let mut iter = seed.as_mut().chunks_exact_mut(4);\n        for chunk in &mut iter {\n            chunk.copy_from_slice(&pcg32(&mut state));\n        }\n        let rem = iter.into_remainder();\n        if !rem.is_empty() {\n            rem.copy_from_slice(&pcg32(&mut state)[..rem.len()]);\n        }\n\n        Self::from_seed(seed)\n    }\n\n    /// Create a new PRNG seeded from an infallible `Rng`.\n    ///\n    /// This may be useful when needing to rapidly seed many PRNGs from a master\n    /// PRNG, and to allow forking of PRNGs. It may be considered deterministic.\n    ///\n    /// The master PRNG should be at least as high quality as the child PRNGs.\n    /// When seeding non-cryptographic child PRNGs, we recommend using a\n    /// different algorithm for the master PRNG (ideally a CSPRNG) to avoid\n    /// correlations between the child PRNGs. If this is not possible (e.g.\n    /// forking using small non-crypto PRNGs) ensure that your PRNG has a good\n    /// mixing function on the output or consider use of a hash function with\n    /// `from_seed`.\n    ///\n    /// Note that seeding `XorShiftRng` from another `XorShiftRng` provides an\n    /// extreme example of what can go wrong: the new PRNG will be a clone\n    /// of the parent.\n    ///\n    /// PRNG implementations are allowed to assume that a good RNG is provided\n    /// for seeding, and that it is cryptographically secure when appropriate.\n    /// As of `rand` 0.7 / `rand_core` 0.5, implementations overriding this\n    /// method should ensure the implementation satisfies reproducibility\n    /// (in prior versions this was not required).\n    ///\n    /// [`rand`]: https://docs.rs/rand\n    fn from_rng(rng: &mut impl RngCore) -> Self {\n        let mut seed = Self::Seed::default();\n        rng.fill_bytes(seed.as_mut());\n        Self::from_seed(seed)\n    }\n\n    /// Create a new PRNG seeded from a potentially fallible `Rng`.\n    ///\n    /// See [`from_rng`][SeedableRng::from_rng] docs for more information.\n    fn try_from_rng<R: TryRngCore>(rng: &mut R) -> Result<Self, R::Error> {\n        let mut seed = Self::Seed::default();\n        rng.try_fill_bytes(seed.as_mut())?;\n        Ok(Self::from_seed(seed))\n    }\n\n    /// Creates a new instance of the RNG seeded via [`getrandom`].\n    ///\n    /// This method is the recommended way to construct non-deterministic PRNGs\n    /// since it is convenient and secure.\n    ///\n    /// Note that this method may panic on (extremely unlikely) [`getrandom`] errors.\n    /// If it's not desirable, use the [`try_from_os_rng`] method instead.\n    ///\n    /// In case the overhead of using [`getrandom`] to seed *many* PRNGs is an\n    /// issue, one may prefer to seed from a local PRNG, e.g.\n    /// `from_rng(rand::rng()).unwrap()`.\n    ///\n    /// # Panics\n    ///\n    /// If [`getrandom`] is unable to provide secure entropy this method will panic.\n    ///\n    /// [`getrandom`]: https://docs.rs/getrandom\n    /// [`try_from_os_rng`]: SeedableRng::try_from_os_rng\n    #[cfg(feature = \"os_rng\")]\n    fn from_os_rng() -> Self {\n        match Self::try_from_os_rng() {\n            Ok(res) => res,\n            Err(err) => panic!(\"from_os_rng failed: {}\", err),\n        }\n    }\n\n    /// Creates a new instance of the RNG seeded via [`getrandom`] without unwrapping\n    /// potential [`getrandom`] errors.\n    ///\n    /// In case the overhead of using [`getrandom`] to seed *many* PRNGs is an\n    /// issue, one may prefer to seed from a local PRNG, e.g.\n    /// `from_rng(&mut rand::rng()).unwrap()`.\n    ///\n    /// [`getrandom`]: https://docs.rs/getrandom\n    #[cfg(feature = \"os_rng\")]\n    fn try_from_os_rng() -> Result<Self, getrandom::Error> {\n        let mut seed = Self::Seed::default();\n        getrandom::fill(seed.as_mut())?;\n        let res = Self::from_seed(seed);\n        Ok(res)\n    }\n}","Real(LocalPath(\"rand_core/src/lib.rs\"))"],"SeedableRng::from_rng":["/// Create a new PRNG seeded from an infallible `Rng`.\n///\n/// This may be useful when needing to rapidly seed many PRNGs from a master\n/// PRNG, and to allow forking of PRNGs. It may be considered deterministic.\n///\n/// The master PRNG should be at least as high quality as the child PRNGs.\n/// When seeding non-cryptographic child PRNGs, we recommend using a\n/// different algorithm for the master PRNG (ideally a CSPRNG) to avoid\n/// correlations between the child PRNGs. If this is not possible (e.g.\n/// forking using small non-crypto PRNGs) ensure that your PRNG has a good\n/// mixing function on the output or consider use of a hash function with\n/// `from_seed`.\n///\n/// Note that seeding `XorShiftRng` from another `XorShiftRng` provides an\n/// extreme example of what can go wrong: the new PRNG will be a clone\n/// of the parent.\n///\n/// PRNG implementations are allowed to assume that a good RNG is provided\n/// for seeding, and that it is cryptographically secure when appropriate.\n/// As of `rand` 0.7 / `rand_core` 0.5, implementations overriding this\n/// method should ensure the implementation satisfies reproducibility\n/// (in prior versions this was not required).\n///\n/// [`rand`]: https://docs.rs/rand\nfn from_rng(rng: &mut impl RngCore) -> Self{\n        let mut seed = Self::Seed::default();\n        rng.fill_bytes(seed.as_mut());\n        Self::from_seed(seed)\n    }","Real(LocalPath(\"rand_core/src/lib.rs\"))"],"SeedableRng::seed_from_u64":["/// Create a new PRNG using a `u64` seed.\n///\n/// This is a convenience-wrapper around `from_seed` to allow construction\n/// of any `SeedableRng` from a simple `u64` value. It is designed such that\n/// low Hamming Weight numbers like 0 and 1 can be used and should still\n/// result in good, independent seeds to the PRNG which is returned.\n///\n/// This **is not suitable for cryptography**, as should be clear given that\n/// the input size is only 64 bits.\n///\n/// Implementations for PRNGs *may* provide their own implementations of\n/// this function, but the default implementation should be good enough for\n/// all purposes. *Changing* the implementation of this function should be\n/// considered a value-breaking change.\nfn seed_from_u64(mut state: u64) -> Self{\n        // We use PCG32 to generate a u32 sequence, and copy to the seed\n        fn pcg32(state: &mut u64) -> [u8; 4] {\n            const MUL: u64 = 6364136223846793005;\n            const INC: u64 = 11634580027462260723;\n\n            // We advance the state first (to get away from the input value,\n            // in case it has low Hamming Weight).\n            *state = state.wrapping_mul(MUL).wrapping_add(INC);\n            let state = *state;\n\n            // Use PCG output function with to_le to generate x:\n            let xorshifted = (((state >> 18) ^ state) >> 27) as u32;\n            let rot = (state >> 59) as u32;\n            let x = xorshifted.rotate_right(rot);\n            x.to_le_bytes()\n        }\n\n        let mut seed = Self::Seed::default();\n        let mut iter = seed.as_mut().chunks_exact_mut(4);\n        for chunk in &mut iter {\n            chunk.copy_from_slice(&pcg32(&mut state));\n        }\n        let rem = iter.into_remainder();\n        if !rem.is_empty() {\n            rem.copy_from_slice(&pcg32(&mut state)[..rem.len()]);\n        }\n\n        Self::from_seed(seed)\n    }","Real(LocalPath(\"rand_core/src/lib.rs\"))"],"SeedableRng::seed_from_u64::pcg32":["fn pcg32(state: &mut u64) -> [u8; 4]{\n            const MUL: u64 = 6364136223846793005;\n            const INC: u64 = 11634580027462260723;\n\n            // We advance the state first (to get away from the input value,\n            // in case it has low Hamming Weight).\n            *state = state.wrapping_mul(MUL).wrapping_add(INC);\n            let state = *state;\n\n            // Use PCG output function with to_le to generate x:\n            let xorshifted = (((state >> 18) ^ state) >> 27) as u32;\n            let rot = (state >> 59) as u32;\n            let x = xorshifted.rotate_right(rot);\n            x.to_le_bytes()\n        }","Real(LocalPath(\"rand_core/src/lib.rs\"))"],"SeedableRng::try_from_rng":["/// Create a new PRNG seeded from a potentially fallible `Rng`.\n///\n/// See [`from_rng`][SeedableRng::from_rng] docs for more information.\nfn try_from_rng<R: TryRngCore>(rng: &mut R) -> Result<Self, R::Error>{\n        let mut seed = Self::Seed::default();\n        rng.try_fill_bytes(seed.as_mut())?;\n        Ok(Self::from_seed(seed))\n    }","Real(LocalPath(\"rand_core/src/lib.rs\"))"],"TryCryptoRng":["/// A marker trait over [`TryRngCore`] for securely unpredictable RNGs\n///\n/// This trait is like [`CryptoRng`] but for the trait [`TryRngCore`].\n///\n/// This marker trait indicates that the implementing generator is intended,\n/// when correctly seeded and protected from side-channel attacks such as a\n/// leaking of state, to be a cryptographically secure generator. This trait is\n/// provided as a tool to aid review of cryptographic code, but does not by\n/// itself guarantee suitability for cryptographic applications.\n///\n/// Implementors of `TryCryptoRng` should only implement [`Default`] if the\n/// `default()` instances are themselves secure generators: for example if the\n/// implementing type is a stateless interface over a secure external generator\n/// (like [`OsRng`]) or if the `default()` instance uses a strong, fresh seed.\npub trait TryCryptoRng: TryRngCore {}","Real(LocalPath(\"rand_core/src/lib.rs\"))"],"TryRngCore":["/// A potentially fallible variant of [`RngCore`]\n///\n/// This trait is a generalization of [`RngCore`] to support potentially-\n/// fallible IO-based generators such as [`OsRng`].\n///\n/// All implementations of [`RngCore`] automatically support this `TryRngCore`\n/// trait, using [`Infallible`][core::convert::Infallible] as the associated\n/// `Error` type.\n///\n/// An implementation of this trait may be made compatible with code requiring\n/// an [`RngCore`] through [`TryRngCore::unwrap_err`]. The resulting RNG will\n/// panic in case the underlying fallible RNG yields an error.\npub trait TryRngCore {\n    /// The type returned in the event of a RNG error.\n    type Error: fmt::Debug + fmt::Display;\n\n    /// Return the next random `u32`.\n    fn try_next_u32(&mut self) -> Result<u32, Self::Error>;\n    /// Return the next random `u64`.\n    fn try_next_u64(&mut self) -> Result<u64, Self::Error>;\n    /// Fill `dest` entirely with random data.\n    fn try_fill_bytes(&mut self, dst: &mut [u8]) -> Result<(), Self::Error>;\n\n    /// Wrap RNG with the [`UnwrapErr`] wrapper.\n    fn unwrap_err(self) -> UnwrapErr<Self>\n    where\n        Self: Sized,\n    {\n        UnwrapErr(self)\n    }\n\n    /// Wrap RNG with the [`UnwrapMut`] wrapper.\n    fn unwrap_mut(&mut self) -> UnwrapMut<'_, Self> {\n        UnwrapMut(self)\n    }\n\n    /// Convert an [`RngCore`] to a [`RngReadAdapter`].\n    #[cfg(feature = \"std\")]\n    fn read_adapter(&mut self) -> RngReadAdapter<'_, Self>\n    where\n        Self: Sized,\n    {\n        RngReadAdapter { inner: self }\n    }\n}","Real(LocalPath(\"rand_core/src/lib.rs\"))"],"TryRngCore::unwrap_err":["/// Wrap RNG with the [`UnwrapErr`] wrapper.\nfn unwrap_err(self) -> UnwrapErr<Self>\n    where\n        Self: Sized,{\n        UnwrapErr(self)\n    }","Real(LocalPath(\"rand_core/src/lib.rs\"))"],"TryRngCore::unwrap_mut":["/// Wrap RNG with the [`UnwrapMut`] wrapper.\nfn unwrap_mut(&mut self) -> UnwrapMut<'_, Self>{\n        UnwrapMut(self)\n    }","Real(LocalPath(\"rand_core/src/lib.rs\"))"],"UnwrapErr":["/// Wrapper around [`TryRngCore`] implementation which implements [`RngCore`]\n/// by panicking on potential errors.\npub struct UnwrapErr<R: TryRngCore>(pub R);","Real(LocalPath(\"rand_core/src/lib.rs\"))"],"UnwrapMut":["/// Wrapper around [`TryRngCore`] implementation which implements [`RngCore`]\n/// by panicking on potential errors.\npub struct UnwrapMut<'r, R: TryRngCore + ?Sized>(pub &'r mut R);","Real(LocalPath(\"rand_core/src/lib.rs\"))"],"UnwrapMut::<'r, R>::re":["/// Reborrow with a new lifetime\n///\n/// Rust allows references like `&T` or `&mut T` to be \"reborrowed\" through\n/// coercion: essentially, the pointer is copied under a new, shorter, lifetime.\n/// Until rfcs#1403 lands, reborrows on user types require a method call.\n#[inline(always)]\npub fn re<'b>(&'b mut self) -> UnwrapMut<'b, R>\n    where\n        'r: 'b,{\n        UnwrapMut(self.0)\n    }","Real(LocalPath(\"rand_core/src/lib.rs\"))"],"block::BlockRng":["/// A wrapper type implementing [`RngCore`] for some type implementing\n/// [`BlockRngCore`] with `u32` array buffer; i.e. this can be used to implement\n/// a full RNG from just a `generate` function.\n///\n/// The `core` field may be accessed directly but the results buffer may not.\n/// PRNG implementations can simply use a type alias\n/// (`pub type MyRng = BlockRng<MyRngCore>;`) but might prefer to use a\n/// wrapper type (`pub struct MyRng(BlockRng<MyRngCore>);`); the latter must\n/// re-implement `RngCore` but hides the implementation details and allows\n/// extra functionality to be defined on the RNG\n/// (e.g. `impl MyRng { fn set_stream(...){...} }`).\n///\n/// `BlockRng` has heavily optimized implementations of the [`RngCore`] methods\n/// reading values from the results buffer, as well as\n/// calling [`BlockRngCore::generate`] directly on the output array when\n/// [`fill_bytes`] is called on a large array. These methods also handle\n/// the bookkeeping of when to generate a new batch of values.\n///\n/// No whole generated `u32` values are thrown away and all values are consumed\n/// in-order. [`next_u32`] simply takes the next available `u32` value.\n/// [`next_u64`] is implemented by combining two `u32` values, least\n/// significant first. [`fill_bytes`] consume a whole number of `u32` values,\n/// converting each `u32` to a byte slice in little-endian order. If the requested byte\n/// length is not a multiple of 4, some bytes will be discarded.\n///\n/// See also [`BlockRng64`] which uses `u64` array buffers. Currently there is\n/// no direct support for other buffer types.\n///\n/// For easy initialization `BlockRng` also implements [`SeedableRng`].\n///\n/// [`next_u32`]: RngCore::next_u32\n/// [`next_u64`]: RngCore::next_u64\n/// [`fill_bytes`]: RngCore::fill_bytes\npub struct BlockRng<R: BlockRngCore> {\n    results: R::Results,\n    index: usize,\n    /// The *core* part of the RNG, implementing the `generate` function.\n    pub core: R,\n}","Real(LocalPath(\"rand_core/src/block.rs\"))"],"block::BlockRng64":["/// A wrapper type implementing [`RngCore`] for some type implementing\n/// [`BlockRngCore`] with `u64` array buffer; i.e. this can be used to implement\n/// a full RNG from just a `generate` function.\n///\n/// This is similar to [`BlockRng`], but specialized for algorithms that operate\n/// on `u64` values.\n///\n/// No whole generated `u64` values are thrown away and all values are consumed\n/// in-order. [`next_u64`] simply takes the next available `u64` value.\n/// [`next_u32`] is however a bit special: half of a `u64` is consumed, leaving\n/// the other half in the buffer. If the next function called is [`next_u32`]\n/// then the other half is then consumed, however both [`next_u64`] and\n/// [`fill_bytes`] discard the rest of any half-consumed `u64`s when called.\n///\n/// [`fill_bytes`] consumes a whole number of `u64` values. If the requested length\n/// is not a multiple of 8, some bytes will be discarded.\n///\n/// [`next_u32`]: RngCore::next_u32\n/// [`next_u64`]: RngCore::next_u64\n/// [`fill_bytes`]: RngCore::fill_bytes\npub struct BlockRng64<R: BlockRngCore + ?Sized> {\n    results: R::Results,\n    index: usize,\n    half_used: bool, // true if only half of the previous result is used\n    /// The *core* part of the RNG, implementing the `generate` function.\n    pub core: R,\n}","Real(LocalPath(\"rand_core/src/block.rs\"))"],"block::BlockRng64::<R>::generate_and_set":["/// Generate a new set of results immediately, setting the index to the\n/// given value.\n#[inline]\npub fn generate_and_set(&mut self, index: usize){\n        assert!(index < self.results.as_ref().len());\n        self.core.generate(&mut self.results);\n        self.index = index;\n        self.half_used = false;\n    }","Real(LocalPath(\"rand_core/src/block.rs\"))"],"block::BlockRng64::<R>::index":["/// Get the index into the result buffer.\n///\n/// If this is equal to or larger than the size of the result buffer then\n/// the buffer is \"empty\" and `generate()` must be called to produce new\n/// results.\n#[inline(always)]\npub fn index(&self) -> usize{\n        self.index\n    }","Real(LocalPath(\"rand_core/src/block.rs\"))"],"block::BlockRng64::<R>::new":["/// Create a new `BlockRng` from an existing RNG implementing\n/// `BlockRngCore`. Results will be generated on first use.\n#[inline]\npub fn new(core: R) -> BlockRng64<R>{\n        let results_empty = R::Results::default();\n        BlockRng64 {\n            core,\n            index: results_empty.as_ref().len(),\n            half_used: false,\n            results: results_empty,\n        }\n    }","Real(LocalPath(\"rand_core/src/block.rs\"))"],"block::BlockRng64::<R>::reset":["/// Reset the number of available results.\n/// This will force a new set of results to be generated on next use.\n#[inline]\npub fn reset(&mut self){\n        self.index = self.results.as_ref().len();\n        self.half_used = false;\n    }","Real(LocalPath(\"rand_core/src/block.rs\"))"],"block::BlockRng::<R>::generate_and_set":["/// Generate a new set of results immediately, setting the index to the\n/// given value.\n#[inline]\npub fn generate_and_set(&mut self, index: usize){\n        assert!(index < self.results.as_ref().len());\n        self.core.generate(&mut self.results);\n        self.index = index;\n    }","Real(LocalPath(\"rand_core/src/block.rs\"))"],"block::BlockRng::<R>::index":["/// Get the index into the result buffer.\n///\n/// If this is equal to or larger than the size of the result buffer then\n/// the buffer is \"empty\" and `generate()` must be called to produce new\n/// results.\n#[inline(always)]\npub fn index(&self) -> usize{\n        self.index\n    }","Real(LocalPath(\"rand_core/src/block.rs\"))"],"block::BlockRng::<R>::new":["/// Create a new `BlockRng` from an existing RNG implementing\n/// `BlockRngCore`. Results will be generated on first use.\n#[inline]\npub fn new(core: R) -> BlockRng<R>{\n        let results_empty = R::Results::default();\n        BlockRng {\n            core,\n            index: results_empty.as_ref().len(),\n            results: results_empty,\n        }\n    }","Real(LocalPath(\"rand_core/src/block.rs\"))"],"block::BlockRng::<R>::reset":["/// Reset the number of available results.\n/// This will force a new set of results to be generated on next use.\n#[inline]\npub fn reset(&mut self){\n        self.index = self.results.as_ref().len();\n    }","Real(LocalPath(\"rand_core/src/block.rs\"))"],"block::BlockRngCore":["/// A trait for RNGs which do not generate random numbers individually, but in\n/// blocks (typically `[u32; N]`). This technique is commonly used by\n/// cryptographic RNGs to improve performance.\n///\n/// See the [module][crate::block] documentation for details.\npub trait BlockRngCore {\n    /// Results element type, e.g. `u32`.\n    type Item;\n\n    /// Results type. This is the 'block' an RNG implementing `BlockRngCore`\n    /// generates, which will usually be an array like `[u32; 16]`.\n    type Results: AsRef<[Self::Item]> + AsMut<[Self::Item]> + Default;\n\n    /// Generate a new block of results.\n    fn generate(&mut self, results: &mut Self::Results);\n}","Real(LocalPath(\"rand_core/src/block.rs\"))"],"block::CryptoBlockRng":["/// A marker trait used to indicate that an [`RngCore`] implementation is\n/// supposed to be cryptographically secure.\n///\n/// See [`CryptoRng`] docs for more information.\npub trait CryptoBlockRng: BlockRngCore {}","Real(LocalPath(\"rand_core/src/block.rs\"))"],"impls::Observable":["pub(crate) trait Observable: Copy {\n    type Bytes: Sized + AsRef<[u8]>;\n    fn to_le_bytes(self) -> Self::Bytes;\n}","Real(LocalPath(\"rand_core/src/impls.rs\"))"],"impls::fill_bytes_via_next":["/// Implement `fill_bytes` via `next_u64` and `next_u32`, little-endian order.\n///\n/// The fastest way to fill a slice is usually to work as long as possible with\n/// integers. That is why this method mostly uses `next_u64`, and only when\n/// there are 4 or less bytes remaining at the end of the slice it uses\n/// `next_u32` once.\npub fn fill_bytes_via_next<R: RngCore + ?Sized>(rng: &mut R, dest: &mut [u8]){\n    let mut left = dest;\n    while left.len() >= 8 {\n        let (l, r) = { left }.split_at_mut(8);\n        left = r;\n        let chunk: [u8; 8] = rng.next_u64().to_le_bytes();\n        l.copy_from_slice(&chunk);\n    }\n    let n = left.len();\n    if n > 4 {\n        let chunk: [u8; 8] = rng.next_u64().to_le_bytes();\n        left.copy_from_slice(&chunk[..n]);\n    } else if n > 0 {\n        let chunk: [u8; 4] = rng.next_u32().to_le_bytes();\n        left.copy_from_slice(&chunk[..n]);\n    }\n}","Real(LocalPath(\"rand_core/src/impls.rs\"))"],"impls::fill_via_chunks":["/// Fill dest from src\n///\n/// Returns `(n, byte_len)`. `src[..n]` is consumed,\n/// `dest[..byte_len]` is filled. `src[n..]` and `dest[byte_len..]` are left\n/// unaltered.\npub(crate) fn fill_via_chunks<T: Observable>(src: &[T], dest: &mut [u8]) -> (usize, usize){\n    let size = core::mem::size_of::<T>();\n\n    // Always use little endian for portability of results.\n\n    let mut dest = dest.chunks_exact_mut(size);\n    let mut src = src.iter();\n\n    let zipped = dest.by_ref().zip(src.by_ref());\n    let num_chunks = zipped.len();\n    zipped.for_each(|(dest, src)| dest.copy_from_slice(src.to_le_bytes().as_ref()));\n\n    let byte_len = num_chunks * size;\n    if let Some(src) = src.next() {\n        // We have consumed all full chunks of dest, but not src.\n        let dest = dest.into_remainder();\n        let n = dest.len();\n        if n > 0 {\n            dest.copy_from_slice(&src.to_le_bytes().as_ref()[..n]);\n            return (num_chunks + 1, byte_len + n);\n        }\n    }\n    (num_chunks, byte_len)\n}","Real(LocalPath(\"rand_core/src/impls.rs\"))"],"impls::fill_via_u32_chunks":["/// Implement `fill_bytes` by reading chunks from the output buffer of a block\n/// based RNG.\n///\n/// The return values are `(consumed_u32, filled_u8)`.\n///\n/// `src` is not modified; it is taken as a `&mut` reference for backward\n/// compatibility with previous versions that did change it.\n///\n/// `filled_u8` is the number of filled bytes in `dest`, which may be less than\n/// the length of `dest`.\n/// `consumed_u32` is the number of words consumed from `src`, which is the same\n/// as `filled_u8 / 4` rounded up.\n///\n/// # Example\n/// (from `IsaacRng`)\n///\n/// ```ignore\n/// fn fill_bytes(&mut self, dest: &mut [u8]) {\n///     let mut read_len = 0;\n///     while read_len < dest.len() {\n///         if self.index >= self.rsl.len() {\n///             self.isaac();\n///         }\n///\n///         let (consumed_u32, filled_u8) =\n///             impls::fill_via_u32_chunks(&mut self.rsl[self.index..],\n///                                        &mut dest[read_len..]);\n///\n///         self.index += consumed_u32;\n///         read_len += filled_u8;\n///     }\n/// }\n/// ```\n#[deprecated(since = \"0.9.3\", note = \"use BlockRng instead\")]\npub fn fill_via_u32_chunks(src: &mut [u32], dest: &mut [u8]) -> (usize, usize){\n    fill_via_chunks(src, dest)\n}","Real(LocalPath(\"rand_core/src/impls.rs\"))"],"impls::fill_via_u64_chunks":["/// Implement `fill_bytes` by reading chunks from the output buffer of a block\n/// based RNG.\n///\n/// The return values are `(consumed_u64, filled_u8)`.\n///\n/// `src` is not modified; it is taken as a `&mut` reference for backward\n/// compatibility with previous versions that did change it.\n///\n/// `filled_u8` is the number of filled bytes in `dest`, which may be less than\n/// the length of `dest`.\n/// `consumed_u64` is the number of words consumed from `src`, which is the same\n/// as `filled_u8 / 8` rounded up.\n///\n/// See `fill_via_u32_chunks` for an example.\n#[deprecated(since = \"0.9.3\", note = \"use BlockRng64 instead\")]\npub fn fill_via_u64_chunks(src: &mut [u64], dest: &mut [u8]) -> (usize, usize){\n    fill_via_chunks(src, dest)\n}","Real(LocalPath(\"rand_core/src/impls.rs\"))"],"impls::next_u32_via_fill":["/// Implement `next_u32` via `fill_bytes`, little-endian order.\npub fn next_u32_via_fill<R: RngCore + ?Sized>(rng: &mut R) -> u32{\n    let mut buf = [0; 4];\n    rng.fill_bytes(&mut buf);\n    u32::from_le_bytes(buf)\n}","Real(LocalPath(\"rand_core/src/impls.rs\"))"],"impls::next_u64_via_fill":["/// Implement `next_u64` via `fill_bytes`, little-endian order.\npub fn next_u64_via_fill<R: RngCore + ?Sized>(rng: &mut R) -> u64{\n    let mut buf = [0; 8];\n    rng.fill_bytes(&mut buf);\n    u64::from_le_bytes(buf)\n}","Real(LocalPath(\"rand_core/src/impls.rs\"))"],"impls::next_u64_via_u32":["/// Implement `next_u64` via `next_u32`, little-endian order.\npub fn next_u64_via_u32<R: RngCore + ?Sized>(rng: &mut R) -> u64{\n    // Use LE; we explicitly generate one value before the next.\n    let x = u64::from(rng.next_u32());\n    let y = u64::from(rng.next_u32());\n    (y << 32) | x\n}","Real(LocalPath(\"rand_core/src/impls.rs\"))"],"le::read_u32_into":["/// Fills `dst: &mut [u32]` from `src`\n///\n/// Reads use Little-Endian byte order, allowing portable reproduction of `dst`\n/// from a byte slice.\n///\n/// # Panics\n///\n/// If `src` has insufficient length (if `src.len() < 4*dst.len()`).\n#[inline]\n#[track_caller]\npub fn read_u32_into(src: &[u8], dst: &mut [u32]){\n    assert!(src.len() >= 4 * dst.len());\n    for (out, chunk) in dst.iter_mut().zip(src.chunks_exact(4)) {\n        *out = u32::from_le_bytes(chunk.try_into().unwrap());\n    }\n}","Real(LocalPath(\"rand_core/src/le.rs\"))"],"le::read_u64_into":["/// Fills `dst: &mut [u64]` from `src`\n///\n/// # Panics\n///\n/// If `src` has insufficient length (if `src.len() < 8*dst.len()`).\n#[inline]\n#[track_caller]\npub fn read_u64_into(src: &[u8], dst: &mut [u64]){\n    assert!(src.len() >= 8 * dst.len());\n    for (out, chunk) in dst.iter_mut().zip(src.chunks_exact(8)) {\n        *out = u64::from_le_bytes(chunk.try_into().unwrap());\n    }\n}","Real(LocalPath(\"rand_core/src/le.rs\"))"]},"struct_constructor":{"(usize, usize)":["fill_via_chunks","fill_via_u32_chunks","fill_via_u64_chunks"],"Alias(Projection, AliasTy { args: [Self/#0], def_id: DefId(0:79 ~ rand_core[1228]::impls::Observable::Bytes) })":["to_le_bytes"],"Alias(Projection, AliasTy { args: [u32], def_id: DefId(0:79 ~ rand_core[1228]::impls::Observable::Bytes) })":["to_le_bytes"],"Alias(Projection, AliasTy { args: [u64], def_id: DefId(0:79 ~ rand_core[1228]::impls::Observable::Bytes) })":["to_le_bytes"],"UnwrapErr":["clone","default","unwrap_err"],"UnwrapMut":["re","unwrap_mut"],"[u8; 4_usize]":["pcg32"],"block::BlockRng":["clone","from_rng","from_seed","new","seed_from_u64"],"block::BlockRng64":["clone","from_rng","from_seed","new","seed_from_u64"],"bool":["eq"],"core::result::Result":["fmt","try_fill_bytes","try_from_rng","try_next_u32","try_next_u64"],"u32":["next_u32","next_u32_via_fill"],"u64":["next_u64","next_u64_via_fill","next_u64_via_u32"],"usize":["index"]},"struct_to_trait":{"<R as TryCryptoRng>::R":["TryCryptoRng"],"<R as TryRngCore>::R":["TryRngCore"],"<T as CryptoRng>::T":["CryptoRng"],"<T as RngCore>::T":["RngCore"],"UnwrapErr":["CryptoRng","RngCore","core::clone::Clone","core::cmp::Eq","core::cmp::PartialEq","core::default::Default","core::fmt::Debug","core::hash::Hash","core::marker::Copy","core::marker::StructuralPartialEq"],"UnwrapMut":["CryptoRng","RngCore","core::cmp::Eq","core::cmp::PartialEq","core::fmt::Debug","core::hash::Hash","core::marker::StructuralPartialEq"],"block::BlockRng":["CryptoRng","RngCore","SeedableRng","core::clone::Clone","core::fmt::Debug"],"block::BlockRng64":["CryptoRng","RngCore","SeedableRng","core::clone::Clone","core::fmt::Debug"]},"targets":{"<R as TryRngCore>::try_fill_bytes":["try_fill_bytes","Real(LocalPath(\"rand_core/src/lib.rs\"))","TryRngCore"],"<R as TryRngCore>::try_next_u32":["try_next_u32","Real(LocalPath(\"rand_core/src/lib.rs\"))","TryRngCore"],"<R as TryRngCore>::try_next_u64":["try_next_u64","Real(LocalPath(\"rand_core/src/lib.rs\"))","TryRngCore"],"<T as RngCore>::fill_bytes":["fill_bytes","Real(LocalPath(\"rand_core/src/lib.rs\"))","RngCore"],"<T as RngCore>::next_u32":["next_u32","Real(LocalPath(\"rand_core/src/lib.rs\"))","RngCore"],"<T as RngCore>::next_u64":["next_u64","Real(LocalPath(\"rand_core/src/lib.rs\"))","RngCore"],"<UnwrapErr<R> as RngCore>::fill_bytes":["fill_bytes","Real(LocalPath(\"rand_core/src/lib.rs\"))","RngCore"],"<UnwrapErr<R> as RngCore>::next_u32":["next_u32","Real(LocalPath(\"rand_core/src/lib.rs\"))","RngCore"],"<UnwrapErr<R> as RngCore>::next_u64":["next_u64","Real(LocalPath(\"rand_core/src/lib.rs\"))","RngCore"],"<UnwrapMut<'_, R> as RngCore>::fill_bytes":["fill_bytes","Real(LocalPath(\"rand_core/src/lib.rs\"))","RngCore"],"<UnwrapMut<'_, R> as RngCore>::next_u32":["next_u32","Real(LocalPath(\"rand_core/src/lib.rs\"))","RngCore"],"<UnwrapMut<'_, R> as RngCore>::next_u64":["next_u64","Real(LocalPath(\"rand_core/src/lib.rs\"))","RngCore"],"<block::BlockRng64<R> as RngCore>::fill_bytes":["fill_bytes","Real(LocalPath(\"rand_core/src/block.rs\"))","RngCore"],"<block::BlockRng64<R> as RngCore>::next_u32":["next_u32","Real(LocalPath(\"rand_core/src/block.rs\"))","RngCore"],"<block::BlockRng64<R> as RngCore>::next_u64":["next_u64","Real(LocalPath(\"rand_core/src/block.rs\"))","RngCore"],"<block::BlockRng64<R> as SeedableRng>::from_rng":["from_rng","Real(LocalPath(\"rand_core/src/block.rs\"))","SeedableRng"],"<block::BlockRng64<R> as SeedableRng>::from_seed":["from_seed","Real(LocalPath(\"rand_core/src/block.rs\"))","SeedableRng"],"<block::BlockRng64<R> as SeedableRng>::seed_from_u64":["seed_from_u64","Real(LocalPath(\"rand_core/src/block.rs\"))","SeedableRng"],"<block::BlockRng64<R> as SeedableRng>::try_from_rng":["try_from_rng","Real(LocalPath(\"rand_core/src/block.rs\"))","SeedableRng"],"<block::BlockRng64<R> as core::fmt::Debug>::fmt":["fmt","Real(LocalPath(\"rand_core/src/block.rs\"))","core::fmt::Debug"],"<block::BlockRng<R> as RngCore>::fill_bytes":["fill_bytes","Real(LocalPath(\"rand_core/src/block.rs\"))","RngCore"],"<block::BlockRng<R> as RngCore>::next_u32":["next_u32","Real(LocalPath(\"rand_core/src/block.rs\"))","RngCore"],"<block::BlockRng<R> as RngCore>::next_u64":["next_u64","Real(LocalPath(\"rand_core/src/block.rs\"))","RngCore"],"<block::BlockRng<R> as SeedableRng>::from_rng":["from_rng","Real(LocalPath(\"rand_core/src/block.rs\"))","SeedableRng"],"<block::BlockRng<R> as SeedableRng>::from_seed":["from_seed","Real(LocalPath(\"rand_core/src/block.rs\"))","SeedableRng"],"<block::BlockRng<R> as SeedableRng>::seed_from_u64":["seed_from_u64","Real(LocalPath(\"rand_core/src/block.rs\"))","SeedableRng"],"<block::BlockRng<R> as SeedableRng>::try_from_rng":["try_from_rng","Real(LocalPath(\"rand_core/src/block.rs\"))","SeedableRng"],"<block::BlockRng<R> as core::fmt::Debug>::fmt":["fmt","Real(LocalPath(\"rand_core/src/block.rs\"))","core::fmt::Debug"],"<u32 as impls::Observable>::to_le_bytes":["to_le_bytes","Real(LocalPath(\"rand_core/src/impls.rs\"))","impls::Observable"],"<u64 as impls::Observable>::to_le_bytes":["to_le_bytes","Real(LocalPath(\"rand_core/src/impls.rs\"))","impls::Observable"],"SeedableRng::from_rng":["from_rng","Real(LocalPath(\"rand_core/src/lib.rs\"))",""],"SeedableRng::seed_from_u64":["seed_from_u64","Real(LocalPath(\"rand_core/src/lib.rs\"))",""],"SeedableRng::seed_from_u64::pcg32":["pcg32","Real(LocalPath(\"rand_core/src/lib.rs\"))",""],"SeedableRng::try_from_rng":["try_from_rng","Real(LocalPath(\"rand_core/src/lib.rs\"))",""],"TryRngCore::unwrap_err":["unwrap_err","Real(LocalPath(\"rand_core/src/lib.rs\"))",""],"TryRngCore::unwrap_mut":["unwrap_mut","Real(LocalPath(\"rand_core/src/lib.rs\"))",""],"UnwrapMut::<'r, R>::re":["re","Real(LocalPath(\"rand_core/src/lib.rs\"))",""],"block::BlockRng64::<R>::generate_and_set":["generate_and_set","Real(LocalPath(\"rand_core/src/block.rs\"))",""],"block::BlockRng64::<R>::index":["index","Real(LocalPath(\"rand_core/src/block.rs\"))",""],"block::BlockRng64::<R>::new":["new","Real(LocalPath(\"rand_core/src/block.rs\"))",""],"block::BlockRng64::<R>::reset":["reset","Real(LocalPath(\"rand_core/src/block.rs\"))",""],"block::BlockRng::<R>::generate_and_set":["generate_and_set","Real(LocalPath(\"rand_core/src/block.rs\"))",""],"block::BlockRng::<R>::index":["index","Real(LocalPath(\"rand_core/src/block.rs\"))",""],"block::BlockRng::<R>::new":["new","Real(LocalPath(\"rand_core/src/block.rs\"))",""],"block::BlockRng::<R>::reset":["reset","Real(LocalPath(\"rand_core/src/block.rs\"))",""],"impls::fill_bytes_via_next":["fill_bytes_via_next","Real(LocalPath(\"rand_core/src/impls.rs\"))",""],"impls::fill_via_chunks":["fill_via_chunks","Real(LocalPath(\"rand_core/src/impls.rs\"))",""],"impls::fill_via_u32_chunks":["fill_via_u32_chunks","Real(LocalPath(\"rand_core/src/impls.rs\"))",""],"impls::fill_via_u64_chunks":["fill_via_u64_chunks","Real(LocalPath(\"rand_core/src/impls.rs\"))",""],"impls::next_u32_via_fill":["next_u32_via_fill","Real(LocalPath(\"rand_core/src/impls.rs\"))",""],"impls::next_u64_via_fill":["next_u64_via_fill","Real(LocalPath(\"rand_core/src/impls.rs\"))",""],"impls::next_u64_via_u32":["next_u64_via_u32","Real(LocalPath(\"rand_core/src/impls.rs\"))",""],"le::read_u32_into":["read_u32_into","Real(LocalPath(\"rand_core/src/le.rs\"))",""],"le::read_u64_into":["read_u64_into","Real(LocalPath(\"rand_core/src/le.rs\"))",""]},"trait_to_struct":{"CryptoRng":["<T as CryptoRng>::T","UnwrapErr","UnwrapMut","block::BlockRng","block::BlockRng64"],"RngCore":["<T as RngCore>::T","UnwrapErr","UnwrapMut","block::BlockRng","block::BlockRng64"],"SeedableRng":["block::BlockRng","block::BlockRng64"],"TryCryptoRng":["<R as TryCryptoRng>::R"],"TryRngCore":["<R as TryRngCore>::R"],"core::clone::Clone":["UnwrapErr","block::BlockRng","block::BlockRng64"],"core::cmp::Eq":["UnwrapErr","UnwrapMut"],"core::cmp::PartialEq":["UnwrapErr","UnwrapMut"],"core::default::Default":["UnwrapErr"],"core::fmt::Debug":["UnwrapErr","UnwrapMut","block::BlockRng","block::BlockRng64"],"core::hash::Hash":["UnwrapErr","UnwrapMut"],"core::marker::Copy":["UnwrapErr"],"core::marker::StructuralPartialEq":["UnwrapErr","UnwrapMut"]},"type_to_def_path":{"UnwrapErr<R>":"UnwrapErr","UnwrapMut<'r, R>":"UnwrapMut","block::BlockRng64<R>":"block::BlockRng64","block::BlockRng<R>":"block::BlockRng"}}