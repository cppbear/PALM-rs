{
    "dependencies": {
        "<&'a map::HashMap<K, V, S, A> as core::iter::IntoIterator>::into_iter": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "map::Iter",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "<&'a mut map::HashMap<K, V, S, A> as core::iter::IntoIterator>::into_iter": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "map::IterMut",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "<&'a mut table::HashTable<T, A> as core::iter::IntoIterator>::into_iter": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTable",
            "raw::RawTableInner",
            "table::HashTable",
            "table::IterMut"
        ],
        "<&'a set::HashSet<T, S, A> as core::iter::IntoIterator>::into_iter": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "map::Iter",
            "map::Keys",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::HashSet",
            "set::Iter"
        ],
        "<&'a table::HashTable<T, A> as core::iter::IntoIterator>::into_iter": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTable",
            "raw::RawTableInner",
            "table::HashTable",
            "table::Iter"
        ],
        "<&set::HashSet<T, S, A> as core::ops::BitAnd<&set::HashSet<T, S, A>>>::bitand": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::HashSet"
        ],
        "<&set::HashSet<T, S, A> as core::ops::BitOr<&set::HashSet<T, S, A>>>::bitor": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::HashSet"
        ],
        "<&set::HashSet<T, S, A> as core::ops::BitXor<&set::HashSet<T, S, A>>>::bitxor": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::HashSet"
        ],
        "<&set::HashSet<T, S, A> as core::ops::Sub<&set::HashSet<T, S, A>>>::sub": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::HashSet"
        ],
        "<TryReserveError as core::clone::Clone>::clone": [
            "TryReserveError",
            "core::alloc::Layout"
        ],
        "<TryReserveError as core::cmp::Eq>::assert_receiver_is_total_eq": [
            "TryReserveError",
            "core::alloc::Layout"
        ],
        "<TryReserveError as core::cmp::PartialEq>::eq": [
            "TryReserveError",
            "core::alloc::Layout"
        ],
        "<TryReserveError as core::fmt::Debug>::fmt": [
            "TryReserveError",
            "core::alloc::Layout",
            "core::fmt::Formatter",
            "core::marker::Sized",
            "core::result::Result"
        ],
        "<[control::tag::Tag] as control::tag::TagSliceExt>::fill_tag": [
            "control::tag::Tag"
        ],
        "<control::bitmask::BitMask as core::clone::Clone>::clone": [
            "control::bitmask::BitMask"
        ],
        "<control::bitmask::BitMask as core::iter::IntoIterator>::into_iter": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter"
        ],
        "<control::bitmask::BitMaskIter as core::clone::Clone>::clone": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter"
        ],
        "<control::bitmask::BitMaskIter as core::iter::Iterator>::next": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::Sized",
            "core::option::Option"
        ],
        "<control::group::sse2::Group as core::clone::Clone>::clone": [
            "control::group::sse2::Group",
            "core::arch::x86_64::__m128i"
        ],
        "<control::tag::Tag as core::clone::Clone>::clone": [
            "control::tag::Tag"
        ],
        "<control::tag::Tag as core::cmp::Eq>::assert_receiver_is_total_eq": [
            "control::tag::Tag"
        ],
        "<control::tag::Tag as core::cmp::PartialEq>::eq": [
            "control::tag::Tag"
        ],
        "<control::tag::Tag as core::fmt::Debug>::fmt": [
            "control::tag::Tag",
            "core::fmt::Formatter",
            "core::marker::Sized",
            "core::result::Result"
        ],
        "<map::Drain<'_, K, V, A> as core::fmt::Debug>::fmt": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::fmt::Formatter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "core::result::Result",
            "map::Drain",
            "raw::Bucket",
            "raw::RawDrain",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTableInner"
        ],
        "<map::Drain<'_, K, V, A> as core::iter::ExactSizeIterator>::len": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::Drain",
            "raw::Bucket",
            "raw::RawDrain",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTableInner"
        ],
        "<map::Drain<'_, K, V, A> as core::iter::Iterator>::fold": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ops::FnMut",
            "core::ptr::NonNull",
            "map::Drain",
            "raw::Bucket",
            "raw::RawDrain",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTableInner"
        ],
        "<map::Drain<'_, K, V, A> as core::iter::Iterator>::next": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "map::Drain",
            "raw::Bucket",
            "raw::RawDrain",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTableInner"
        ],
        "<map::Drain<'_, K, V, A> as core::iter::Iterator>::size_hint": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "map::Drain",
            "raw::Bucket",
            "raw::RawDrain",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTableInner"
        ],
        "<map::Entry<'_, K, V, S, A> as core::fmt::Debug>::fmt": [
            "allocator_api2::alloc::Allocator",
            "core::fmt::Formatter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "core::result::Result",
            "map::Entry",
            "map::HashMap",
            "map::OccupiedEntry",
            "map::VacantEntry",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "<map::EntryRef<'_, '_, K, Q, V, S, A> as core::fmt::Debug>::fmt": [
            "allocator_api2::alloc::Allocator",
            "core::fmt::Formatter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "core::result::Result",
            "map::EntryRef",
            "map::HashMap",
            "map::OccupiedEntry",
            "map::VacantEntryRef",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "<map::ExtractIf<'_, K, V, F, A> as core::iter::Iterator>::next": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "map::ExtractIf",
            "raw::Bucket",
            "raw::RawExtractIf",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "<map::ExtractIf<'_, K, V, F, A> as core::iter::Iterator>::size_hint": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "map::ExtractIf",
            "raw::Bucket",
            "raw::RawExtractIf",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "<map::HashMap<K, V, S, A> as core::clone::Clone>::clone": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "<map::HashMap<K, V, S, A> as core::clone::Clone>::clone_from": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "<map::HashMap<K, V, S, A> as core::cmp::PartialEq>::eq": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "<map::HashMap<K, V, S, A> as core::default::Default>::default": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "<map::HashMap<K, V, S, A> as core::fmt::Debug>::fmt": [
            "allocator_api2::alloc::Allocator",
            "core::fmt::Formatter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "core::result::Result",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "<map::HashMap<K, V, S, A> as core::iter::Extend<&'a (K, V)>>::extend": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "core::iter::IntoIterator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "<map::HashMap<K, V, S, A> as core::iter::Extend<(&'a K, &'a V)>>::extend": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "core::iter::IntoIterator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "<map::HashMap<K, V, S, A> as core::iter::Extend<(K, V)>>::extend": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "core::iter::IntoIterator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "<map::HashMap<K, V, S, A> as core::iter::FromIterator<(K, V)>>::from_iter": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "core::iter::IntoIterator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "<map::HashMap<K, V, S, A> as core::iter::IntoIterator>::into_iter": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "map::HashMap",
            "map::IntoIter",
            "raw::Bucket",
            "raw::RawIntoIter",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "<map::HashMap<K, V, S, A> as core::ops::Index<&Q>>::index": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "<map::HashMap<K, V, foldhash::fast::RandomState, A> as core::convert::From<[(K, V); N]>>::from": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "<map::IntoIter<K, V, A> as core::default::Default>::default": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "map::IntoIter",
            "raw::Bucket",
            "raw::RawIntoIter",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "<map::IntoIter<K, V, A> as core::fmt::Debug>::fmt": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::fmt::Formatter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "core::result::Result",
            "map::IntoIter",
            "raw::Bucket",
            "raw::RawIntoIter",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "<map::IntoIter<K, V, A> as core::iter::ExactSizeIterator>::len": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "map::IntoIter",
            "raw::Bucket",
            "raw::RawIntoIter",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "<map::IntoIter<K, V, A> as core::iter::Iterator>::fold": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ops::FnMut",
            "core::option::Option",
            "core::ptr::NonNull",
            "map::IntoIter",
            "raw::Bucket",
            "raw::RawIntoIter",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "<map::IntoIter<K, V, A> as core::iter::Iterator>::next": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "map::IntoIter",
            "raw::Bucket",
            "raw::RawIntoIter",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "<map::IntoIter<K, V, A> as core::iter::Iterator>::size_hint": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "map::IntoIter",
            "raw::Bucket",
            "raw::RawIntoIter",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "<map::IntoKeys<K, V, A> as core::default::Default>::default": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "map::IntoIter",
            "map::IntoKeys",
            "raw::Bucket",
            "raw::RawIntoIter",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "<map::IntoKeys<K, V, A> as core::fmt::Debug>::fmt": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::fmt::Formatter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "core::result::Result",
            "map::IntoIter",
            "map::IntoKeys",
            "raw::Bucket",
            "raw::RawIntoIter",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "<map::IntoKeys<K, V, A> as core::iter::ExactSizeIterator>::len": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "map::IntoIter",
            "map::IntoKeys",
            "raw::Bucket",
            "raw::RawIntoIter",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "<map::IntoKeys<K, V, A> as core::iter::Iterator>::fold": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ops::FnMut",
            "core::option::Option",
            "core::ptr::NonNull",
            "map::IntoIter",
            "map::IntoKeys",
            "raw::Bucket",
            "raw::RawIntoIter",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "<map::IntoKeys<K, V, A> as core::iter::Iterator>::next": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "map::IntoIter",
            "map::IntoKeys",
            "raw::Bucket",
            "raw::RawIntoIter",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "<map::IntoKeys<K, V, A> as core::iter::Iterator>::size_hint": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "map::IntoIter",
            "map::IntoKeys",
            "raw::Bucket",
            "raw::RawIntoIter",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "<map::IntoValues<K, V, A> as core::default::Default>::default": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "map::IntoIter",
            "map::IntoValues",
            "raw::Bucket",
            "raw::RawIntoIter",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "<map::IntoValues<K, V, A> as core::fmt::Debug>::fmt": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::fmt::Formatter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "core::result::Result",
            "map::IntoIter",
            "map::IntoValues",
            "raw::Bucket",
            "raw::RawIntoIter",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "<map::IntoValues<K, V, A> as core::iter::ExactSizeIterator>::len": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "map::IntoIter",
            "map::IntoValues",
            "raw::Bucket",
            "raw::RawIntoIter",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "<map::IntoValues<K, V, A> as core::iter::Iterator>::fold": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ops::FnMut",
            "core::option::Option",
            "core::ptr::NonNull",
            "map::IntoIter",
            "map::IntoValues",
            "raw::Bucket",
            "raw::RawIntoIter",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "<map::IntoValues<K, V, A> as core::iter::Iterator>::next": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "map::IntoIter",
            "map::IntoValues",
            "raw::Bucket",
            "raw::RawIntoIter",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "<map::IntoValues<K, V, A> as core::iter::Iterator>::size_hint": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "map::IntoIter",
            "map::IntoValues",
            "raw::Bucket",
            "raw::RawIntoIter",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "<map::Iter<'_, K, V> as core::clone::Clone>::clone": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::Iter",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "<map::Iter<'_, K, V> as core::default::Default>::default": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::Iter",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "<map::Iter<'_, K, V> as core::fmt::Debug>::fmt": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::fmt::Formatter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "core::result::Result",
            "map::Iter",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "<map::Iter<'_, K, V> as core::iter::ExactSizeIterator>::len": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::Iter",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "<map::Iter<'a, K, V> as core::iter::Iterator>::fold": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ops::FnMut",
            "core::ptr::NonNull",
            "map::Iter",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "<map::Iter<'a, K, V> as core::iter::Iterator>::next": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "map::Iter",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "<map::Iter<'a, K, V> as core::iter::Iterator>::size_hint": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "map::Iter",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "<map::IterMut<'_, K, V> as core::default::Default>::default": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::IterMut",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "<map::IterMut<'_, K, V> as core::fmt::Debug>::fmt": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::fmt::Formatter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "core::result::Result",
            "map::IterMut",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "<map::IterMut<'_, K, V> as core::iter::ExactSizeIterator>::len": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::IterMut",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "<map::IterMut<'a, K, V> as core::iter::Iterator>::fold": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ops::FnMut",
            "core::ptr::NonNull",
            "map::IterMut",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "<map::IterMut<'a, K, V> as core::iter::Iterator>::next": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "map::IterMut",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "<map::IterMut<'a, K, V> as core::iter::Iterator>::size_hint": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "map::IterMut",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "<map::Keys<'_, K, V> as core::clone::Clone>::clone": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::Iter",
            "map::Keys",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "<map::Keys<'_, K, V> as core::default::Default>::default": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::Iter",
            "map::Keys",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "<map::Keys<'_, K, V> as core::fmt::Debug>::fmt": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::fmt::Formatter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "core::result::Result",
            "map::Iter",
            "map::Keys",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "<map::Keys<'_, K, V> as core::iter::ExactSizeIterator>::len": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::Iter",
            "map::Keys",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "<map::Keys<'a, K, V> as core::iter::Iterator>::fold": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ops::FnMut",
            "core::ptr::NonNull",
            "map::Iter",
            "map::Keys",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "<map::Keys<'a, K, V> as core::iter::Iterator>::next": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "map::Iter",
            "map::Keys",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "<map::Keys<'a, K, V> as core::iter::Iterator>::size_hint": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "map::Iter",
            "map::Keys",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "<map::OccupiedEntry<'_, K, V, S, A> as core::fmt::Debug>::fmt": [
            "allocator_api2::alloc::Allocator",
            "core::fmt::Formatter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "core::result::Result",
            "map::HashMap",
            "map::OccupiedEntry",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "<map::OccupiedError<'_, K, V, S, A> as core::fmt::Debug>::fmt": [
            "allocator_api2::alloc::Allocator",
            "core::fmt::Formatter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "core::result::Result",
            "map::HashMap",
            "map::OccupiedEntry",
            "map::OccupiedError",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "<map::OccupiedError<'_, K, V, S, A> as core::fmt::Display>::fmt": [
            "allocator_api2::alloc::Allocator",
            "core::fmt::Formatter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "core::result::Result",
            "map::HashMap",
            "map::OccupiedEntry",
            "map::OccupiedError",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "<map::VacantEntry<'_, K, V, S, A> as core::fmt::Debug>::fmt": [
            "allocator_api2::alloc::Allocator",
            "core::fmt::Formatter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "core::result::Result",
            "map::HashMap",
            "map::VacantEntry",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "<map::VacantEntryRef<'_, '_, K, Q, V, S, A> as core::fmt::Debug>::fmt": [
            "allocator_api2::alloc::Allocator",
            "core::fmt::Formatter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "core::result::Result",
            "map::HashMap",
            "map::VacantEntryRef",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "<map::Values<'_, K, V> as core::clone::Clone>::clone": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::Iter",
            "map::Values",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "<map::Values<'_, K, V> as core::default::Default>::default": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::Iter",
            "map::Values",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "<map::Values<'_, K, V> as core::fmt::Debug>::fmt": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::fmt::Formatter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "core::result::Result",
            "map::Iter",
            "map::Values",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "<map::Values<'_, K, V> as core::iter::ExactSizeIterator>::len": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::Iter",
            "map::Values",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "<map::Values<'a, K, V> as core::iter::Iterator>::fold": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ops::FnMut",
            "core::ptr::NonNull",
            "map::Iter",
            "map::Values",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "<map::Values<'a, K, V> as core::iter::Iterator>::next": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "map::Iter",
            "map::Values",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "<map::Values<'a, K, V> as core::iter::Iterator>::size_hint": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "map::Iter",
            "map::Values",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "<map::ValuesMut<'_, K, V> as core::default::Default>::default": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::IterMut",
            "map::ValuesMut",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "<map::ValuesMut<'_, K, V> as core::fmt::Debug>::fmt": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::fmt::Formatter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "core::result::Result",
            "map::IterMut",
            "map::ValuesMut",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "<map::ValuesMut<'_, K, V> as core::iter::ExactSizeIterator>::len": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::IterMut",
            "map::ValuesMut",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "<map::ValuesMut<'a, K, V> as core::iter::Iterator>::fold": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ops::FnMut",
            "core::ptr::NonNull",
            "map::IterMut",
            "map::ValuesMut",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "<map::ValuesMut<'a, K, V> as core::iter::Iterator>::next": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "map::IterMut",
            "map::ValuesMut",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "<map::ValuesMut<'a, K, V> as core::iter::Iterator>::size_hint": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "map::IterMut",
            "map::ValuesMut",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "<raw::Bucket<T> as core::clone::Clone>::clone": [
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::Bucket"
        ],
        "<raw::Fallibility as core::clone::Clone>::clone": [
            "raw::Fallibility"
        ],
        "<raw::FullBucketsIndices as core::iter::Iterator>::next": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "raw::FullBucketsIndices"
        ],
        "<raw::FullBucketsIndices as core::iter::Iterator>::size_hint": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "raw::FullBucketsIndices"
        ],
        "<raw::ProbeSeq as core::clone::Clone>::clone": [
            "raw::ProbeSeq"
        ],
        "<raw::RawDrain<'_, T, A> as core::iter::Iterator>::next": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawDrain",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTableInner"
        ],
        "<raw::RawDrain<'_, T, A> as core::iter::Iterator>::size_hint": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawDrain",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTableInner"
        ],
        "<raw::RawDrain<'_, T, A> as core::ops::Drop>::drop": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawDrain",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTableInner"
        ],
        "<raw::RawIntoIter<T, A> as core::default::Default>::default": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawIntoIter",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "<raw::RawIntoIter<T, A> as core::iter::Iterator>::next": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawIntoIter",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "<raw::RawIntoIter<T, A> as core::iter::Iterator>::size_hint": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawIntoIter",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "<raw::RawIntoIter<T, A> as core::ops::Drop>::drop": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawIntoIter",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "<raw::RawIter<T> as core::clone::Clone>::clone": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "<raw::RawIter<T> as core::default::Default>::default": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "<raw::RawIter<T> as core::iter::Iterator>::fold": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::Sized",
            "core::ops::FnMut",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "<raw::RawIter<T> as core::iter::Iterator>::next": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "<raw::RawIter<T> as core::iter::Iterator>::size_hint": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "<raw::RawIterHash<T> as core::clone::Clone>::clone": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "control::group::sse2::Group",
            "control::tag::Tag",
            "core::arch::x86_64::__m128i",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::ProbeSeq",
            "raw::RawIterHash",
            "raw::RawIterHashInner"
        ],
        "<raw::RawIterHash<T> as core::default::Default>::default": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "control::group::sse2::Group",
            "control::tag::Tag",
            "core::arch::x86_64::__m128i",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::ProbeSeq",
            "raw::RawIterHash",
            "raw::RawIterHashInner"
        ],
        "<raw::RawIterHash<T> as core::iter::Iterator>::next": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "control::group::sse2::Group",
            "control::tag::Tag",
            "core::arch::x86_64::__m128i",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "raw::ProbeSeq",
            "raw::RawIterHash",
            "raw::RawIterHashInner"
        ],
        "<raw::RawIterHashInner as core::clone::Clone>::clone": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "control::group::sse2::Group",
            "control::tag::Tag",
            "core::arch::x86_64::__m128i",
            "core::ptr::NonNull",
            "raw::ProbeSeq",
            "raw::RawIterHashInner"
        ],
        "<raw::RawIterHashInner as core::iter::Iterator>::next": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "control::group::sse2::Group",
            "control::tag::Tag",
            "core::arch::x86_64::__m128i",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "raw::ProbeSeq",
            "raw::RawIterHashInner"
        ],
        "<raw::RawIterRange<T> as core::clone::Clone>::clone": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawIterRange"
        ],
        "<raw::RawIterRange<T> as core::iter::Iterator>::next": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawIterRange"
        ],
        "<raw::RawIterRange<T> as core::iter::Iterator>::size_hint": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawIterRange"
        ],
        "<raw::RawTable<T, A> as core::clone::Clone>::clone": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "<raw::RawTable<T, A> as core::clone::Clone>::clone_from": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "<raw::RawTable<T, A> as core::default::Default>::default": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "<raw::RawTable<T, A> as core::iter::IntoIterator>::into_iter": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawIntoIter",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "<raw::RawTable<T, A> as core::ops::Drop>::drop": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "<raw::RawTable<T, A> as raw::RawTableClone>::clone_from_spec": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "<raw::TableLayout as core::clone::Clone>::clone": [
            "raw::TableLayout"
        ],
        "<raw_entry::RawEntryBuilder<'_, K, V, S, A> as core::fmt::Debug>::fmt": [
            "allocator_api2::alloc::Allocator",
            "core::fmt::Formatter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "core::result::Result",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner",
            "raw_entry::RawEntryBuilder"
        ],
        "<raw_entry::RawEntryBuilderMut<'_, K, V, S, A> as core::fmt::Debug>::fmt": [
            "allocator_api2::alloc::Allocator",
            "core::fmt::Formatter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "core::result::Result",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner",
            "raw_entry::RawEntryBuilderMut"
        ],
        "<raw_entry::RawEntryMut<'_, K, V, S, A> as core::fmt::Debug>::fmt": [
            "allocator_api2::alloc::Allocator",
            "core::fmt::Formatter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "core::result::Result",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner",
            "raw_entry::RawEntryMut",
            "raw_entry::RawOccupiedEntryMut",
            "raw_entry::RawVacantEntryMut"
        ],
        "<raw_entry::RawOccupiedEntryMut<'_, K, V, S, A> as core::fmt::Debug>::fmt": [
            "allocator_api2::alloc::Allocator",
            "core::fmt::Formatter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "core::result::Result",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner",
            "raw_entry::RawOccupiedEntryMut"
        ],
        "<raw_entry::RawVacantEntryMut<'_, K, V, S, A> as core::fmt::Debug>::fmt": [
            "allocator_api2::alloc::Allocator",
            "core::fmt::Formatter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "core::result::Result",
            "raw::RawTable",
            "raw::RawTableInner",
            "raw_entry::RawVacantEntryMut"
        ],
        "<scopeguard::ScopeGuard<T, F> as core::ops::Deref>::deref": [
            "core::marker::Sized",
            "core::ops::FnMut",
            "scopeguard::ScopeGuard"
        ],
        "<scopeguard::ScopeGuard<T, F> as core::ops::DerefMut>::deref_mut": [
            "core::marker::Sized",
            "core::ops::FnMut",
            "scopeguard::ScopeGuard"
        ],
        "<scopeguard::ScopeGuard<T, F> as core::ops::Drop>::drop": [
            "core::marker::Sized",
            "core::ops::FnMut",
            "scopeguard::ScopeGuard"
        ],
        "<set::Difference<'_, T, S, A> as core::clone::Clone>::clone": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "map::Iter",
            "map::Keys",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::Difference",
            "set::HashSet",
            "set::Iter"
        ],
        "<set::Difference<'_, T, S, A> as core::fmt::Debug>::fmt": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::fmt::Formatter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "core::result::Result",
            "map::HashMap",
            "map::Iter",
            "map::Keys",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::Difference",
            "set::HashSet",
            "set::Iter"
        ],
        "<set::Difference<'a, T, S, A> as core::iter::Iterator>::fold": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ops::FnMut",
            "core::ptr::NonNull",
            "map::HashMap",
            "map::Iter",
            "map::Keys",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::Difference",
            "set::HashSet",
            "set::Iter"
        ],
        "<set::Difference<'a, T, S, A> as core::iter::Iterator>::next": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "map::HashMap",
            "map::Iter",
            "map::Keys",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::Difference",
            "set::HashSet",
            "set::Iter"
        ],
        "<set::Difference<'a, T, S, A> as core::iter::Iterator>::size_hint": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "map::HashMap",
            "map::Iter",
            "map::Keys",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::Difference",
            "set::HashSet",
            "set::Iter"
        ],
        "<set::Drain<'_, K, A> as core::fmt::Debug>::fmt": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::fmt::Formatter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "core::result::Result",
            "map::Drain",
            "raw::Bucket",
            "raw::RawDrain",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTableInner",
            "set::Drain"
        ],
        "<set::Drain<'_, K, A> as core::iter::ExactSizeIterator>::len": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::Drain",
            "raw::Bucket",
            "raw::RawDrain",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTableInner",
            "set::Drain"
        ],
        "<set::Drain<'_, K, A> as core::iter::Iterator>::fold": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ops::FnMut",
            "core::ptr::NonNull",
            "map::Drain",
            "raw::Bucket",
            "raw::RawDrain",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTableInner",
            "set::Drain"
        ],
        "<set::Drain<'_, K, A> as core::iter::Iterator>::next": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "map::Drain",
            "raw::Bucket",
            "raw::RawDrain",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTableInner",
            "set::Drain"
        ],
        "<set::Drain<'_, K, A> as core::iter::Iterator>::size_hint": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "map::Drain",
            "raw::Bucket",
            "raw::RawDrain",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTableInner",
            "set::Drain"
        ],
        "<set::Entry<'_, T, S, A> as core::fmt::Debug>::fmt": [
            "allocator_api2::alloc::Allocator",
            "core::fmt::Formatter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "core::result::Result",
            "map::HashMap",
            "map::OccupiedEntry",
            "map::VacantEntry",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::Entry",
            "set::OccupiedEntry",
            "set::VacantEntry"
        ],
        "<set::ExtractIf<'_, K, F, A> as core::iter::Iterator>::next": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawExtractIf",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::ExtractIf"
        ],
        "<set::ExtractIf<'_, K, F, A> as core::iter::Iterator>::size_hint": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawExtractIf",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::ExtractIf"
        ],
        "<set::HashSet<T, S, A> as core::clone::Clone>::clone": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::HashSet"
        ],
        "<set::HashSet<T, S, A> as core::clone::Clone>::clone_from": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::HashSet"
        ],
        "<set::HashSet<T, S, A> as core::cmp::PartialEq>::eq": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::HashSet"
        ],
        "<set::HashSet<T, S, A> as core::convert::From<map::HashMap<T, (), S, A>>>::from": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::HashSet"
        ],
        "<set::HashSet<T, S, A> as core::default::Default>::default": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::HashSet"
        ],
        "<set::HashSet<T, S, A> as core::fmt::Debug>::fmt": [
            "allocator_api2::alloc::Allocator",
            "core::fmt::Formatter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "core::result::Result",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::HashSet"
        ],
        "<set::HashSet<T, S, A> as core::iter::Extend<&'a T>>::extend": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "core::iter::IntoIterator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::HashSet"
        ],
        "<set::HashSet<T, S, A> as core::iter::Extend<T>>::extend": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "core::iter::IntoIterator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::HashSet"
        ],
        "<set::HashSet<T, S, A> as core::iter::FromIterator<T>>::from_iter": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "core::iter::IntoIterator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::HashSet"
        ],
        "<set::HashSet<T, S, A> as core::iter::IntoIterator>::into_iter": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "map::HashMap",
            "map::IntoIter",
            "raw::Bucket",
            "raw::RawIntoIter",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::HashSet",
            "set::IntoIter"
        ],
        "<set::HashSet<T, S, A> as core::ops::BitAndAssign<&set::HashSet<T, S, A>>>::bitand_assign": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::HashSet"
        ],
        "<set::HashSet<T, S, A> as core::ops::BitOrAssign<&set::HashSet<T, S, A>>>::bitor_assign": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::HashSet"
        ],
        "<set::HashSet<T, S, A> as core::ops::BitXorAssign<&set::HashSet<T, S, A>>>::bitxor_assign": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::HashSet"
        ],
        "<set::HashSet<T, S, A> as core::ops::SubAssign<&set::HashSet<T, S, A>>>::sub_assign": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::HashSet"
        ],
        "<set::HashSet<T, foldhash::fast::RandomState, A> as core::convert::From<[T; N]>>::from": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::HashSet"
        ],
        "<set::Intersection<'_, T, S, A> as core::clone::Clone>::clone": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "map::Iter",
            "map::Keys",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::HashSet",
            "set::Intersection",
            "set::Iter"
        ],
        "<set::Intersection<'_, T, S, A> as core::fmt::Debug>::fmt": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::fmt::Formatter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "core::result::Result",
            "map::HashMap",
            "map::Iter",
            "map::Keys",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::HashSet",
            "set::Intersection",
            "set::Iter"
        ],
        "<set::Intersection<'a, T, S, A> as core::iter::Iterator>::fold": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ops::FnMut",
            "core::ptr::NonNull",
            "map::HashMap",
            "map::Iter",
            "map::Keys",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::HashSet",
            "set::Intersection",
            "set::Iter"
        ],
        "<set::Intersection<'a, T, S, A> as core::iter::Iterator>::next": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "map::HashMap",
            "map::Iter",
            "map::Keys",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::HashSet",
            "set::Intersection",
            "set::Iter"
        ],
        "<set::Intersection<'a, T, S, A> as core::iter::Iterator>::size_hint": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "map::HashMap",
            "map::Iter",
            "map::Keys",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::HashSet",
            "set::Intersection",
            "set::Iter"
        ],
        "<set::IntoIter<K, A> as core::default::Default>::default": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "map::IntoIter",
            "raw::Bucket",
            "raw::RawIntoIter",
            "raw::RawIter",
            "raw::RawIterRange",
            "set::IntoIter"
        ],
        "<set::IntoIter<K, A> as core::fmt::Debug>::fmt": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::fmt::Formatter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "core::result::Result",
            "map::IntoIter",
            "raw::Bucket",
            "raw::RawIntoIter",
            "raw::RawIter",
            "raw::RawIterRange",
            "set::IntoIter"
        ],
        "<set::IntoIter<K, A> as core::iter::ExactSizeIterator>::len": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "map::IntoIter",
            "raw::Bucket",
            "raw::RawIntoIter",
            "raw::RawIter",
            "raw::RawIterRange",
            "set::IntoIter"
        ],
        "<set::IntoIter<K, A> as core::iter::Iterator>::fold": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ops::FnMut",
            "core::option::Option",
            "core::ptr::NonNull",
            "map::IntoIter",
            "raw::Bucket",
            "raw::RawIntoIter",
            "raw::RawIter",
            "raw::RawIterRange",
            "set::IntoIter"
        ],
        "<set::IntoIter<K, A> as core::iter::Iterator>::next": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "map::IntoIter",
            "raw::Bucket",
            "raw::RawIntoIter",
            "raw::RawIter",
            "raw::RawIterRange",
            "set::IntoIter"
        ],
        "<set::IntoIter<K, A> as core::iter::Iterator>::size_hint": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "map::IntoIter",
            "raw::Bucket",
            "raw::RawIntoIter",
            "raw::RawIter",
            "raw::RawIterRange",
            "set::IntoIter"
        ],
        "<set::Iter<'_, K> as core::clone::Clone>::clone": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::Iter",
            "map::Keys",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange",
            "set::Iter"
        ],
        "<set::Iter<'_, K> as core::default::Default>::default": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::Iter",
            "map::Keys",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange",
            "set::Iter"
        ],
        "<set::Iter<'_, K> as core::fmt::Debug>::fmt": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::fmt::Formatter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "core::result::Result",
            "map::Iter",
            "map::Keys",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange",
            "set::Iter"
        ],
        "<set::Iter<'_, K> as core::iter::ExactSizeIterator>::len": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::Iter",
            "map::Keys",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange",
            "set::Iter"
        ],
        "<set::Iter<'a, K> as core::iter::Iterator>::fold": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ops::FnMut",
            "core::ptr::NonNull",
            "map::Iter",
            "map::Keys",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange",
            "set::Iter"
        ],
        "<set::Iter<'a, K> as core::iter::Iterator>::next": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "map::Iter",
            "map::Keys",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange",
            "set::Iter"
        ],
        "<set::Iter<'a, K> as core::iter::Iterator>::size_hint": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "map::Iter",
            "map::Keys",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange",
            "set::Iter"
        ],
        "<set::OccupiedEntry<'_, T, S, A> as core::fmt::Debug>::fmt": [
            "allocator_api2::alloc::Allocator",
            "core::fmt::Formatter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "core::result::Result",
            "map::HashMap",
            "map::OccupiedEntry",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::OccupiedEntry"
        ],
        "<set::SymmetricDifference<'_, T, S, A> as core::clone::Clone>::clone": [
            "allocator_api2::alloc::Allocator",
            "core::iter::Chain",
            "core::marker::Sized",
            "set::SymmetricDifference"
        ],
        "<set::SymmetricDifference<'_, T, S, A> as core::fmt::Debug>::fmt": [
            "allocator_api2::alloc::Allocator",
            "core::fmt::Formatter",
            "core::iter::Chain",
            "core::marker::Sized",
            "core::result::Result",
            "set::SymmetricDifference"
        ],
        "<set::SymmetricDifference<'a, T, S, A> as core::iter::Iterator>::fold": [
            "allocator_api2::alloc::Allocator",
            "core::iter::Chain",
            "core::marker::Sized",
            "core::ops::FnMut",
            "set::SymmetricDifference"
        ],
        "<set::SymmetricDifference<'a, T, S, A> as core::iter::Iterator>::next": [
            "allocator_api2::alloc::Allocator",
            "core::iter::Chain",
            "core::marker::Sized",
            "core::option::Option",
            "set::SymmetricDifference"
        ],
        "<set::SymmetricDifference<'a, T, S, A> as core::iter::Iterator>::size_hint": [
            "allocator_api2::alloc::Allocator",
            "core::iter::Chain",
            "core::marker::Sized",
            "core::option::Option",
            "set::SymmetricDifference"
        ],
        "<set::Union<'_, T, S, A> as core::clone::Clone>::clone": [
            "allocator_api2::alloc::Allocator",
            "core::iter::Chain",
            "core::marker::Sized",
            "set::Union"
        ],
        "<set::Union<'_, T, S, A> as core::fmt::Debug>::fmt": [
            "allocator_api2::alloc::Allocator",
            "core::fmt::Formatter",
            "core::iter::Chain",
            "core::marker::Sized",
            "core::result::Result",
            "set::Union"
        ],
        "<set::Union<'a, T, S, A> as core::iter::Iterator>::fold": [
            "allocator_api2::alloc::Allocator",
            "core::iter::Chain",
            "core::marker::Sized",
            "core::ops::FnMut",
            "set::Union"
        ],
        "<set::Union<'a, T, S, A> as core::iter::Iterator>::next": [
            "allocator_api2::alloc::Allocator",
            "core::iter::Chain",
            "core::marker::Sized",
            "core::option::Option",
            "set::Union"
        ],
        "<set::Union<'a, T, S, A> as core::iter::Iterator>::size_hint": [
            "allocator_api2::alloc::Allocator",
            "core::iter::Chain",
            "core::marker::Sized",
            "core::option::Option",
            "set::Union"
        ],
        "<set::VacantEntry<'_, T, S, A> as core::fmt::Debug>::fmt": [
            "allocator_api2::alloc::Allocator",
            "core::fmt::Formatter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "core::result::Result",
            "map::HashMap",
            "map::VacantEntry",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::VacantEntry"
        ],
        "<table::AbsentEntry<'_, T, A> as core::fmt::Debug>::fmt": [
            "allocator_api2::alloc::Allocator",
            "core::fmt::Formatter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "core::result::Result",
            "raw::RawTable",
            "raw::RawTableInner",
            "table::AbsentEntry",
            "table::HashTable"
        ],
        "<table::Drain<'_, T, A> as core::fmt::Debug>::fmt": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::fmt::Formatter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "core::result::Result",
            "raw::Bucket",
            "raw::RawDrain",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTableInner",
            "table::Drain"
        ],
        "<table::Drain<'_, T, A> as core::iter::ExactSizeIterator>::len": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawDrain",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTableInner",
            "table::Drain"
        ],
        "<table::Drain<'_, T, A> as core::iter::Iterator>::fold": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ops::FnMut",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawDrain",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTableInner",
            "table::Drain"
        ],
        "<table::Drain<'_, T, A> as core::iter::Iterator>::next": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawDrain",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTableInner",
            "table::Drain"
        ],
        "<table::Drain<'_, T, A> as core::iter::Iterator>::size_hint": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawDrain",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTableInner",
            "table::Drain"
        ],
        "<table::Entry<'_, T, A> as core::fmt::Debug>::fmt": [
            "allocator_api2::alloc::Allocator",
            "core::fmt::Formatter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "core::result::Result",
            "raw::Bucket",
            "raw::InsertSlot",
            "raw::RawTable",
            "raw::RawTableInner",
            "table::Entry",
            "table::HashTable",
            "table::OccupiedEntry",
            "table::VacantEntry"
        ],
        "<table::ExtractIf<'_, T, F, A> as core::iter::Iterator>::next": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawExtractIf",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTable",
            "raw::RawTableInner",
            "table::ExtractIf"
        ],
        "<table::ExtractIf<'_, T, F, A> as core::iter::Iterator>::size_hint": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawExtractIf",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTable",
            "raw::RawTableInner",
            "table::ExtractIf"
        ],
        "<table::HashTable<T, A> as core::clone::Clone>::clone": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::RawTable",
            "raw::RawTableInner",
            "table::HashTable"
        ],
        "<table::HashTable<T, A> as core::default::Default>::default": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::RawTable",
            "raw::RawTableInner",
            "table::HashTable"
        ],
        "<table::HashTable<T, A> as core::fmt::Debug>::fmt": [
            "allocator_api2::alloc::Allocator",
            "core::fmt::Formatter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "core::result::Result",
            "raw::RawTable",
            "raw::RawTableInner",
            "table::HashTable"
        ],
        "<table::HashTable<T, A> as core::iter::IntoIterator>::into_iter": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawIntoIter",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTable",
            "raw::RawTableInner",
            "table::HashTable",
            "table::IntoIter"
        ],
        "<table::IntoIter<T, A> as core::default::Default>::default": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawIntoIter",
            "raw::RawIter",
            "raw::RawIterRange",
            "table::IntoIter"
        ],
        "<table::IntoIter<T, A> as core::fmt::Debug>::fmt": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::fmt::Formatter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "core::result::Result",
            "raw::Bucket",
            "raw::RawIntoIter",
            "raw::RawIter",
            "raw::RawIterRange",
            "table::IntoIter"
        ],
        "<table::IntoIter<T, A> as core::iter::ExactSizeIterator>::len": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawIntoIter",
            "raw::RawIter",
            "raw::RawIterRange",
            "table::IntoIter"
        ],
        "<table::IntoIter<T, A> as core::iter::Iterator>::fold": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ops::FnMut",
            "core::option::Option",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawIntoIter",
            "raw::RawIter",
            "raw::RawIterRange",
            "table::IntoIter"
        ],
        "<table::IntoIter<T, A> as core::iter::Iterator>::next": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawIntoIter",
            "raw::RawIter",
            "raw::RawIterRange",
            "table::IntoIter"
        ],
        "<table::IntoIter<T, A> as core::iter::Iterator>::size_hint": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawIntoIter",
            "raw::RawIter",
            "raw::RawIterRange",
            "table::IntoIter"
        ],
        "<table::Iter<'_, T> as core::default::Default>::default": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange",
            "table::Iter"
        ],
        "<table::Iter<'_, T> as core::fmt::Debug>::fmt": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::fmt::Formatter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "core::result::Result",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange",
            "table::Iter"
        ],
        "<table::Iter<'_, T> as core::iter::ExactSizeIterator>::len": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange",
            "table::Iter"
        ],
        "<table::Iter<'a, T> as core::clone::Clone>::clone": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange",
            "table::Iter"
        ],
        "<table::Iter<'a, T> as core::iter::Iterator>::fold": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ops::FnMut",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange",
            "table::Iter"
        ],
        "<table::Iter<'a, T> as core::iter::Iterator>::next": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange",
            "table::Iter"
        ],
        "<table::Iter<'a, T> as core::iter::Iterator>::size_hint": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange",
            "table::Iter"
        ],
        "<table::IterHash<'_, T> as core::default::Default>::default": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "control::group::sse2::Group",
            "control::tag::Tag",
            "core::arch::x86_64::__m128i",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::ProbeSeq",
            "raw::RawIterHash",
            "raw::RawIterHashInner",
            "table::IterHash"
        ],
        "<table::IterHash<'_, T> as core::fmt::Debug>::fmt": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "control::group::sse2::Group",
            "control::tag::Tag",
            "core::arch::x86_64::__m128i",
            "core::fmt::Formatter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "core::result::Result",
            "raw::ProbeSeq",
            "raw::RawIterHash",
            "raw::RawIterHashInner",
            "table::IterHash"
        ],
        "<table::IterHash<'a, T> as core::clone::Clone>::clone": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "control::group::sse2::Group",
            "control::tag::Tag",
            "core::arch::x86_64::__m128i",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::ProbeSeq",
            "raw::RawIterHash",
            "raw::RawIterHashInner",
            "table::IterHash"
        ],
        "<table::IterHash<'a, T> as core::iter::Iterator>::fold": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "control::group::sse2::Group",
            "control::tag::Tag",
            "core::arch::x86_64::__m128i",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ops::FnMut",
            "core::ptr::NonNull",
            "raw::ProbeSeq",
            "raw::RawIterHash",
            "raw::RawIterHashInner",
            "table::IterHash"
        ],
        "<table::IterHash<'a, T> as core::iter::Iterator>::next": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "control::group::sse2::Group",
            "control::tag::Tag",
            "core::arch::x86_64::__m128i",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "raw::ProbeSeq",
            "raw::RawIterHash",
            "raw::RawIterHashInner",
            "table::IterHash"
        ],
        "<table::IterHashMut<'_, T> as core::default::Default>::default": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "control::group::sse2::Group",
            "control::tag::Tag",
            "core::arch::x86_64::__m128i",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::ProbeSeq",
            "raw::RawIterHash",
            "raw::RawIterHashInner",
            "table::IterHashMut"
        ],
        "<table::IterHashMut<'_, T> as core::fmt::Debug>::fmt": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "control::group::sse2::Group",
            "control::tag::Tag",
            "core::arch::x86_64::__m128i",
            "core::fmt::Formatter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "core::result::Result",
            "raw::ProbeSeq",
            "raw::RawIterHash",
            "raw::RawIterHashInner",
            "table::IterHashMut"
        ],
        "<table::IterHashMut<'a, T> as core::iter::Iterator>::fold": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "control::group::sse2::Group",
            "control::tag::Tag",
            "core::arch::x86_64::__m128i",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ops::FnMut",
            "core::ptr::NonNull",
            "raw::ProbeSeq",
            "raw::RawIterHash",
            "raw::RawIterHashInner",
            "table::IterHashMut"
        ],
        "<table::IterHashMut<'a, T> as core::iter::Iterator>::next": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "control::group::sse2::Group",
            "control::tag::Tag",
            "core::arch::x86_64::__m128i",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "raw::ProbeSeq",
            "raw::RawIterHash",
            "raw::RawIterHashInner",
            "table::IterHashMut"
        ],
        "<table::IterMut<'_, T> as core::default::Default>::default": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange",
            "table::IterMut"
        ],
        "<table::IterMut<'_, T> as core::fmt::Debug>::fmt": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::fmt::Formatter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "core::result::Result",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange",
            "table::IterMut"
        ],
        "<table::IterMut<'_, T> as core::iter::ExactSizeIterator>::len": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange",
            "table::IterMut"
        ],
        "<table::IterMut<'a, T> as core::iter::Iterator>::fold": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ops::FnMut",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange",
            "table::IterMut"
        ],
        "<table::IterMut<'a, T> as core::iter::Iterator>::next": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange",
            "table::IterMut"
        ],
        "<table::IterMut<'a, T> as core::iter::Iterator>::size_hint": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange",
            "table::IterMut"
        ],
        "<table::OccupiedEntry<'_, T, A> as core::fmt::Debug>::fmt": [
            "allocator_api2::alloc::Allocator",
            "core::fmt::Formatter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "core::result::Result",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner",
            "table::HashTable",
            "table::OccupiedEntry"
        ],
        "<table::VacantEntry<'_, T, A> as core::fmt::Debug>::fmt": [
            "allocator_api2::alloc::Allocator",
            "core::fmt::Formatter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "core::result::Result",
            "raw::InsertSlot",
            "raw::RawTable",
            "raw::RawTableInner",
            "table::HashTable",
            "table::VacantEntry"
        ],
        "TryReserveError": [
            "TryReserveError",
            "core::alloc::Layout"
        ],
        "control::bitmask::BitMask": [
            "control::bitmask::BitMask"
        ],
        "control::bitmask::BitMask::any_bit_set": [
            "control::bitmask::BitMask"
        ],
        "control::bitmask::BitMask::invert": [
            "control::bitmask::BitMask"
        ],
        "control::bitmask::BitMask::leading_zeros": [
            "control::bitmask::BitMask"
        ],
        "control::bitmask::BitMask::lowest_set_bit": [
            "control::bitmask::BitMask",
            "core::marker::Sized",
            "core::option::Option"
        ],
        "control::bitmask::BitMask::nonzero_trailing_zeros": [
            "core::marker::Sized",
            "core::num::NonZero",
            "core::num::ZeroablePrimitive"
        ],
        "control::bitmask::BitMask::remove_lowest_bit": [
            "control::bitmask::BitMask"
        ],
        "control::bitmask::BitMask::trailing_zeros": [
            "control::bitmask::BitMask"
        ],
        "control::bitmask::BitMaskIter": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter"
        ],
        "control::group::sse2::Group": [
            "control::group::sse2::Group",
            "core::arch::x86_64::__m128i"
        ],
        "control::group::sse2::Group::convert_special_to_empty_and_full_to_deleted": [
            "control::group::sse2::Group",
            "core::arch::x86_64::__m128i"
        ],
        "control::group::sse2::Group::load": [
            "control::group::sse2::Group",
            "control::tag::Tag",
            "core::arch::x86_64::__m128i"
        ],
        "control::group::sse2::Group::load_aligned": [
            "control::group::sse2::Group",
            "control::tag::Tag",
            "core::arch::x86_64::__m128i"
        ],
        "control::group::sse2::Group::match_empty": [
            "control::bitmask::BitMask",
            "control::group::sse2::Group",
            "core::arch::x86_64::__m128i"
        ],
        "control::group::sse2::Group::match_empty_or_deleted": [
            "control::bitmask::BitMask",
            "control::group::sse2::Group",
            "core::arch::x86_64::__m128i"
        ],
        "control::group::sse2::Group::match_full": [
            "control::bitmask::BitMask",
            "control::group::sse2::Group",
            "core::arch::x86_64::__m128i"
        ],
        "control::group::sse2::Group::match_tag": [
            "control::bitmask::BitMask",
            "control::group::sse2::Group",
            "control::tag::Tag",
            "core::arch::x86_64::__m128i"
        ],
        "control::group::sse2::Group::static_empty": [
            "control::tag::Tag"
        ],
        "control::group::sse2::Group::static_empty::AlignedTags": [
            "control::group::sse2::Group",
            "control::group::sse2::Group::static_empty::AlignedTags",
            "control::tag::Tag",
            "core::arch::x86_64::__m128i"
        ],
        "control::group::sse2::Group::store_aligned": [
            "control::group::sse2::Group",
            "control::tag::Tag",
            "core::arch::x86_64::__m128i"
        ],
        "control::tag::Tag": [
            "control::tag::Tag"
        ],
        "control::tag::Tag::full": [
            "control::tag::Tag"
        ],
        "control::tag::Tag::is_full": [
            "control::tag::Tag"
        ],
        "control::tag::Tag::is_special": [
            "control::tag::Tag"
        ],
        "control::tag::Tag::special_is_empty": [
            "control::tag::Tag"
        ],
        "control::tag::TagSliceExt::fill_empty": [],
        "control::tag::TagSliceExt::fill_tag": [
            "control::tag::Tag"
        ],
        "map::Drain": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::Drain",
            "raw::Bucket",
            "raw::RawDrain",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTableInner"
        ],
        "map::Drain::<'_, K, V, A>::iter": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::Drain",
            "map::Iter",
            "raw::Bucket",
            "raw::RawDrain",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTableInner"
        ],
        "map::Entry": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::Entry",
            "map::HashMap",
            "map::OccupiedEntry",
            "map::VacantEntry",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::Entry::<'a, K, V, S, A>::and_modify": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ops::FnOnce",
            "core::ptr::NonNull",
            "map::Entry",
            "map::HashMap",
            "map::OccupiedEntry",
            "map::VacantEntry",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::Entry::<'a, K, V, S, A>::and_replace_entry_with": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ops::FnOnce",
            "core::ptr::NonNull",
            "map::Entry",
            "map::HashMap",
            "map::OccupiedEntry",
            "map::VacantEntry",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::Entry::<'a, K, V, S, A>::insert": [
            "allocator_api2::alloc::Allocator",
            "core::hash::BuildHasher",
            "core::hash::Hash",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::Entry",
            "map::HashMap",
            "map::OccupiedEntry",
            "map::VacantEntry",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::Entry::<'a, K, V, S, A>::key": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::Entry",
            "map::HashMap",
            "map::OccupiedEntry",
            "map::VacantEntry",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::Entry::<'a, K, V, S, A>::or_default": [
            "allocator_api2::alloc::Allocator",
            "core::hash::BuildHasher",
            "core::hash::Hash",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::Entry",
            "map::HashMap",
            "map::OccupiedEntry",
            "map::VacantEntry",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::Entry::<'a, K, V, S, A>::or_insert": [
            "allocator_api2::alloc::Allocator",
            "core::hash::BuildHasher",
            "core::hash::Hash",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::Entry",
            "map::HashMap",
            "map::OccupiedEntry",
            "map::VacantEntry",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::Entry::<'a, K, V, S, A>::or_insert_with": [
            "allocator_api2::alloc::Allocator",
            "core::hash::BuildHasher",
            "core::hash::Hash",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ops::FnOnce",
            "core::ptr::NonNull",
            "map::Entry",
            "map::HashMap",
            "map::OccupiedEntry",
            "map::VacantEntry",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::Entry::<'a, K, V, S, A>::or_insert_with_key": [
            "allocator_api2::alloc::Allocator",
            "core::hash::BuildHasher",
            "core::hash::Hash",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ops::FnOnce",
            "core::ptr::NonNull",
            "map::Entry",
            "map::HashMap",
            "map::OccupiedEntry",
            "map::VacantEntry",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::EntryRef": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::EntryRef",
            "map::HashMap",
            "map::OccupiedEntry",
            "map::VacantEntryRef",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::EntryRef::<'a, 'b, K, Q, V, S, A>::and_modify": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ops::FnOnce",
            "core::ptr::NonNull",
            "map::EntryRef",
            "map::HashMap",
            "map::OccupiedEntry",
            "map::VacantEntryRef",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::EntryRef::<'a, 'b, K, Q, V, S, A>::insert": [
            "allocator_api2::alloc::Allocator",
            "core::convert::Into",
            "core::hash::BuildHasher",
            "core::hash::Hash",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::EntryRef",
            "map::HashMap",
            "map::OccupiedEntry",
            "map::VacantEntryRef",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::EntryRef::<'a, 'b, K, Q, V, S, A>::key": [
            "allocator_api2::alloc::Allocator",
            "core::borrow::Borrow",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::EntryRef",
            "map::HashMap",
            "map::OccupiedEntry",
            "map::VacantEntryRef",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::EntryRef::<'a, 'b, K, Q, V, S, A>::or_default": [
            "allocator_api2::alloc::Allocator",
            "core::convert::Into",
            "core::hash::BuildHasher",
            "core::hash::Hash",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::EntryRef",
            "map::HashMap",
            "map::OccupiedEntry",
            "map::VacantEntryRef",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::EntryRef::<'a, 'b, K, Q, V, S, A>::or_insert": [
            "allocator_api2::alloc::Allocator",
            "core::convert::Into",
            "core::hash::BuildHasher",
            "core::hash::Hash",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::EntryRef",
            "map::HashMap",
            "map::OccupiedEntry",
            "map::VacantEntryRef",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::EntryRef::<'a, 'b, K, Q, V, S, A>::or_insert_with": [
            "allocator_api2::alloc::Allocator",
            "core::convert::Into",
            "core::hash::BuildHasher",
            "core::hash::Hash",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ops::FnOnce",
            "core::ptr::NonNull",
            "map::EntryRef",
            "map::HashMap",
            "map::OccupiedEntry",
            "map::VacantEntryRef",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::EntryRef::<'a, 'b, K, Q, V, S, A>::or_insert_with_key": [
            "allocator_api2::alloc::Allocator",
            "core::borrow::Borrow",
            "core::convert::Into",
            "core::hash::BuildHasher",
            "core::hash::Hash",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ops::FnOnce",
            "core::ptr::NonNull",
            "map::EntryRef",
            "map::HashMap",
            "map::OccupiedEntry",
            "map::VacantEntryRef",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::ExtractIf": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::ExtractIf",
            "raw::Bucket",
            "raw::RawExtractIf",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::HashMap": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::HashMap::<K, V, S, A>::allocation_size": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::HashMap::<K, V, S, A>::allocator": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::HashMap::<K, V, S, A>::build_hashes_inner": [
            "allocator_api2::alloc::Allocator",
            "core::hash::Hash",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "equivalent::Equivalent",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::HashMap::<K, V, S, A>::capacity": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::HashMap::<K, V, S, A>::clear": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::HashMap::<K, V, S, A>::contains_key": [
            "allocator_api2::alloc::Allocator",
            "core::hash::Hash",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "equivalent::Equivalent",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::HashMap::<K, V, S, A>::drain": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::Drain",
            "map::HashMap",
            "raw::Bucket",
            "raw::RawDrain",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::HashMap::<K, V, S, A>::entry": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::Entry",
            "map::HashMap",
            "map::OccupiedEntry",
            "map::VacantEntry",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::HashMap::<K, V, S, A>::entry_ref": [
            "allocator_api2::alloc::Allocator",
            "core::hash::Hash",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "equivalent::Equivalent",
            "map::EntryRef",
            "map::HashMap",
            "map::OccupiedEntry",
            "map::VacantEntryRef",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::HashMap::<K, V, S, A>::extract_if": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ops::FnMut",
            "core::ptr::NonNull",
            "map::ExtractIf",
            "map::HashMap",
            "raw::Bucket",
            "raw::RawExtractIf",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::HashMap::<K, V, S, A>::find_or_find_insert_slot": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "core::result::Result",
            "equivalent::Equivalent",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::HashMap::<K, V, S, A>::get": [
            "allocator_api2::alloc::Allocator",
            "core::hash::Hash",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "equivalent::Equivalent",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::HashMap::<K, V, S, A>::get_inner": [
            "allocator_api2::alloc::Allocator",
            "core::hash::Hash",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "equivalent::Equivalent",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::HashMap::<K, V, S, A>::get_inner_mut": [
            "allocator_api2::alloc::Allocator",
            "core::hash::Hash",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "equivalent::Equivalent",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::HashMap::<K, V, S, A>::get_key_value": [
            "allocator_api2::alloc::Allocator",
            "core::hash::Hash",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "equivalent::Equivalent",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::HashMap::<K, V, S, A>::get_key_value_mut": [
            "allocator_api2::alloc::Allocator",
            "core::hash::Hash",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "equivalent::Equivalent",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::HashMap::<K, V, S, A>::get_many_key_value_mut": [
            "allocator_api2::alloc::Allocator",
            "core::hash::Hash",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "equivalent::Equivalent",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::HashMap::<K, V, S, A>::get_many_key_value_unchecked_mut": [
            "allocator_api2::alloc::Allocator",
            "core::hash::Hash",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "equivalent::Equivalent",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::HashMap::<K, V, S, A>::get_many_mut": [
            "allocator_api2::alloc::Allocator",
            "core::hash::Hash",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "equivalent::Equivalent",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::HashMap::<K, V, S, A>::get_many_mut_inner": [
            "allocator_api2::alloc::Allocator",
            "core::hash::Hash",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "equivalent::Equivalent",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::HashMap::<K, V, S, A>::get_many_unchecked_mut": [
            "allocator_api2::alloc::Allocator",
            "core::hash::Hash",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "equivalent::Equivalent",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::HashMap::<K, V, S, A>::get_many_unchecked_mut_inner": [
            "allocator_api2::alloc::Allocator",
            "core::hash::Hash",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "equivalent::Equivalent",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::HashMap::<K, V, S, A>::get_mut": [
            "allocator_api2::alloc::Allocator",
            "core::hash::Hash",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "equivalent::Equivalent",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::HashMap::<K, V, S, A>::hasher": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::HashMap::<K, V, S, A>::insert": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::HashMap::<K, V, S, A>::insert_unique_unchecked": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::HashMap::<K, V, S, A>::into_keys": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "map::HashMap",
            "map::IntoIter",
            "map::IntoKeys",
            "raw::Bucket",
            "raw::RawIntoIter",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::HashMap::<K, V, S, A>::into_values": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "map::HashMap",
            "map::IntoIter",
            "map::IntoValues",
            "raw::Bucket",
            "raw::RawIntoIter",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::HashMap::<K, V, S, A>::is_empty": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::HashMap::<K, V, S, A>::iter": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "map::Iter",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::HashMap::<K, V, S, A>::iter_mut": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "map::IterMut",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::HashMap::<K, V, S, A>::keys": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "map::Iter",
            "map::Keys",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::HashMap::<K, V, S, A>::len": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::HashMap::<K, V, S, A>::remove": [
            "allocator_api2::alloc::Allocator",
            "core::hash::Hash",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "equivalent::Equivalent",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::HashMap::<K, V, S, A>::remove_entry": [
            "allocator_api2::alloc::Allocator",
            "core::hash::Hash",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "equivalent::Equivalent",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::HashMap::<K, V, S, A>::reserve": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::HashMap::<K, V, S, A>::retain": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ops::FnMut",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::HashMap::<K, V, S, A>::shrink_to": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::HashMap::<K, V, S, A>::shrink_to_fit": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::HashMap::<K, V, S, A>::try_insert": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "core::result::Result",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::HashMap::<K, V, S, A>::try_reserve": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "core::result::Result",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::HashMap::<K, V, S, A>::values": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "map::Iter",
            "map::Values",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::HashMap::<K, V, S, A>::values_mut": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "map::IterMut",
            "map::ValuesMut",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::HashMap::<K, V, S, A>::with_capacity_and_hasher_in": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::HashMap::<K, V, S, A>::with_hasher_in": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::HashMap::<K, V, S>::with_capacity_and_hasher": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::HashMap::<K, V, S>::with_hasher": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::HashMap::<K, V, foldhash::fast::RandomState, A>::new_in": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::HashMap::<K, V, foldhash::fast::RandomState, A>::with_capacity_in": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::HashMap::<K, V>::new": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::HashMap::<K, V>::with_capacity": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::IntoIter": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "map::IntoIter",
            "raw::Bucket",
            "raw::RawIntoIter",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "map::IntoIter::<K, V, A>::iter": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "map::IntoIter",
            "map::Iter",
            "raw::Bucket",
            "raw::RawIntoIter",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "map::IntoKeys": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "map::IntoIter",
            "map::IntoKeys",
            "raw::Bucket",
            "raw::RawIntoIter",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "map::IntoValues": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "map::IntoIter",
            "map::IntoValues",
            "raw::Bucket",
            "raw::RawIntoIter",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "map::Iter": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::Iter",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "map::IterMut": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::IterMut",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "map::IterMut::<'_, K, V>::iter": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::Iter",
            "map::IterMut",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "map::Keys": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::Iter",
            "map::Keys",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "map::OccupiedEntry": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "map::OccupiedEntry",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::OccupiedEntry::<'a, K, V, S, A>::get": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "map::OccupiedEntry",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::OccupiedEntry::<'a, K, V, S, A>::get_mut": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "map::OccupiedEntry",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::OccupiedEntry::<'a, K, V, S, A>::insert": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "map::OccupiedEntry",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::OccupiedEntry::<'a, K, V, S, A>::into_mut": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "map::OccupiedEntry",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::OccupiedEntry::<'a, K, V, S, A>::key": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "map::OccupiedEntry",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::OccupiedEntry::<'a, K, V, S, A>::remove": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "map::OccupiedEntry",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::OccupiedEntry::<'a, K, V, S, A>::remove_entry": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "map::OccupiedEntry",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::OccupiedEntry::<'a, K, V, S, A>::replace_entry_with": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ops::FnOnce",
            "core::ptr::NonNull",
            "map::Entry",
            "map::HashMap",
            "map::OccupiedEntry",
            "map::VacantEntry",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::OccupiedError": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "map::OccupiedEntry",
            "map::OccupiedError",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::VacantEntry": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "map::VacantEntry",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::VacantEntry::<'a, K, V, S, A>::insert": [
            "allocator_api2::alloc::Allocator",
            "core::hash::BuildHasher",
            "core::hash::Hash",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "map::VacantEntry",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::VacantEntry::<'a, K, V, S, A>::insert_entry": [
            "allocator_api2::alloc::Allocator",
            "core::hash::BuildHasher",
            "core::hash::Hash",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "map::OccupiedEntry",
            "map::VacantEntry",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::VacantEntry::<'a, K, V, S, A>::into_key": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "map::VacantEntry",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::VacantEntry::<'a, K, V, S, A>::key": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "map::VacantEntry",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::VacantEntryRef": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "map::VacantEntryRef",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::VacantEntryRef::<'a, 'b, K, Q, V, S, A>::insert": [
            "allocator_api2::alloc::Allocator",
            "core::convert::Into",
            "core::hash::BuildHasher",
            "core::hash::Hash",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "map::VacantEntryRef",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::VacantEntryRef::<'a, 'b, K, Q, V, S, A>::insert_entry": [
            "allocator_api2::alloc::Allocator",
            "core::convert::Into",
            "core::hash::BuildHasher",
            "core::hash::Hash",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "map::OccupiedEntry",
            "map::VacantEntryRef",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::VacantEntryRef::<'a, 'b, K, Q, V, S, A>::key": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "map::VacantEntryRef",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::Values": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::Iter",
            "map::Values",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "map::ValuesMut": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::IterMut",
            "map::ValuesMut",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "map::assert_covariance": [],
        "map::assert_covariance::drain": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::Drain",
            "raw::Bucket",
            "raw::RawDrain",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTableInner"
        ],
        "map::assert_covariance::into_iter_key": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "map::IntoIter",
            "raw::Bucket",
            "raw::RawIntoIter",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "map::assert_covariance::into_iter_val": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "map::IntoIter",
            "raw::Bucket",
            "raw::RawIntoIter",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "map::assert_covariance::iter_key": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::Iter",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "map::assert_covariance::iter_val": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::Iter",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "map::assert_covariance::keys_key": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::Iter",
            "map::Keys",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "map::assert_covariance::keys_val": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::Iter",
            "map::Keys",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "map::assert_covariance::map_key": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::assert_covariance::map_val": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "map::assert_covariance::values_key": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::Iter",
            "map::Values",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "map::assert_covariance::values_val": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::Iter",
            "map::Values",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "map::equivalent": [
            "core::marker::Sized",
            "equivalent::Equivalent"
        ],
        "map::equivalent_key": [
            "core::marker::Sized",
            "equivalent::Equivalent"
        ],
        "map::make_hash": [
            "core::hash::BuildHasher",
            "core::hash::Hash",
            "core::marker::Sized"
        ],
        "map::make_hasher": [
            "core::hash::BuildHasher",
            "core::hash::Hash",
            "core::marker::Sized"
        ],
        "raw::Bucket": [
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::Bucket"
        ],
        "raw::Bucket::<T>::as_mut": [
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::Bucket"
        ],
        "raw::Bucket::<T>::as_non_null": [
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::Bucket"
        ],
        "raw::Bucket::<T>::as_ptr": [
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::Bucket"
        ],
        "raw::Bucket::<T>::as_ref": [
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::Bucket"
        ],
        "raw::Bucket::<T>::drop": [
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::Bucket"
        ],
        "raw::Bucket::<T>::from_base_index": [
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::Bucket"
        ],
        "raw::Bucket::<T>::next_n": [
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::Bucket"
        ],
        "raw::Bucket::<T>::read": [
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::Bucket"
        ],
        "raw::Bucket::<T>::to_base_index": [
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::Bucket"
        ],
        "raw::Bucket::<T>::write": [
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::Bucket"
        ],
        "raw::Fallibility": [
            "raw::Fallibility"
        ],
        "raw::Fallibility::alloc_err": [
            "TryReserveError",
            "core::alloc::Layout",
            "raw::Fallibility"
        ],
        "raw::Fallibility::capacity_overflow": [
            "TryReserveError",
            "core::alloc::Layout",
            "raw::Fallibility"
        ],
        "raw::FullBucketsIndices": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::ptr::NonNull",
            "raw::FullBucketsIndices"
        ],
        "raw::FullBucketsIndices::next_impl": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "raw::FullBucketsIndices"
        ],
        "raw::InsertSlot": [
            "raw::InsertSlot"
        ],
        "raw::ProbeSeq": [
            "raw::ProbeSeq"
        ],
        "raw::ProbeSeq::move_next": [
            "raw::ProbeSeq"
        ],
        "raw::RawDrain": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawDrain",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTableInner"
        ],
        "raw::RawDrain::<'_, T, A>::iter": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawDrain",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTableInner"
        ],
        "raw::RawExtractIf": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawExtractIf",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "raw::RawExtractIf::<'_, T, A>::next": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ops::FnMut",
            "core::option::Option",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawExtractIf",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "raw::RawIntoIter": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawIntoIter",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "raw::RawIntoIter::<T, A>::iter": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawIntoIter",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "raw::RawIter": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "raw::RawIter::<T>::drop_elements": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange"
        ],
        "raw::RawIterHash": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "control::group::sse2::Group",
            "control::tag::Tag",
            "core::arch::x86_64::__m128i",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::ProbeSeq",
            "raw::RawIterHash",
            "raw::RawIterHashInner"
        ],
        "raw::RawIterHash::<T>::new": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "control::group::sse2::Group",
            "control::tag::Tag",
            "core::arch::x86_64::__m128i",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::ProbeSeq",
            "raw::RawIterHash",
            "raw::RawIterHashInner",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "raw::RawIterHashInner": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "control::group::sse2::Group",
            "control::tag::Tag",
            "core::arch::x86_64::__m128i",
            "core::ptr::NonNull",
            "raw::ProbeSeq",
            "raw::RawIterHashInner"
        ],
        "raw::RawIterHashInner::new": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "control::group::sse2::Group",
            "control::tag::Tag",
            "core::arch::x86_64::__m128i",
            "core::ptr::NonNull",
            "raw::ProbeSeq",
            "raw::RawIterHashInner",
            "raw::RawTableInner"
        ],
        "raw::RawIterRange": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawIterRange"
        ],
        "raw::RawIterRange::<T>::fold_impl": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::Sized",
            "core::ops::FnMut",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawIterRange"
        ],
        "raw::RawIterRange::<T>::new": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawIterRange"
        ],
        "raw::RawIterRange::<T>::next_impl": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawIterRange"
        ],
        "raw::RawTable": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "raw::RawTable::<T, A>::allocation_size": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "raw::RawTable::<T, A>::allocator": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "raw::RawTable::<T, A>::bucket": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "raw::RawTable::<T, A>::bucket_index": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "raw::RawTable::<T, A>::buckets": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "raw::RawTable::<T, A>::capacity": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "raw::RawTable::<T, A>::clear": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "raw::RawTable::<T, A>::clear_no_drop": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "raw::RawTable::<T, A>::clone_from_impl": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "raw::RawTable::<T, A>::data_end": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "raw::RawTable::<T, A>::drain": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawDrain",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "raw::RawTable::<T, A>::drain_iter_from": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawDrain",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "raw::RawTable::<T, A>::erase": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "raw::RawTable::<T, A>::erase_no_drop": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "raw::RawTable::<T, A>::find": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ops::FnMut",
            "core::option::Option",
            "core::ptr::NonNull",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "raw::RawTable::<T, A>::find_or_find_insert_slot": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ops::Fn",
            "core::ops::FnMut",
            "core::ptr::NonNull",
            "core::result::Result",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "raw::RawTable::<T, A>::get": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ops::FnMut",
            "core::option::Option",
            "core::ptr::NonNull",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "raw::RawTable::<T, A>::get_many_mut": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ops::FnMut",
            "core::option::Option",
            "core::ptr::NonNull",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "raw::RawTable::<T, A>::get_many_mut_pointers": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ops::FnMut",
            "core::option::Option",
            "core::ptr::NonNull",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "raw::RawTable::<T, A>::get_many_unchecked_mut": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ops::FnMut",
            "core::option::Option",
            "core::ptr::NonNull",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "raw::RawTable::<T, A>::get_mut": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ops::FnMut",
            "core::option::Option",
            "core::ptr::NonNull",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "raw::RawTable::<T, A>::insert": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ops::Fn",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "raw::RawTable::<T, A>::insert_entry": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ops::Fn",
            "core::ptr::NonNull",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "raw::RawTable::<T, A>::insert_in_slot": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::InsertSlot",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "raw::RawTable::<T, A>::into_allocation": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "raw::RawTable::<T, A>::into_iter_from": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawIntoIter",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "raw::RawTable::<T, A>::is_bucket_full": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "raw::RawTable::<T, A>::is_empty": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "raw::RawTable::<T, A>::iter": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "raw::RawTable::<T, A>::iter_hash": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "control::group::sse2::Group",
            "control::tag::Tag",
            "core::arch::x86_64::__m128i",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::ProbeSeq",
            "raw::RawIterHash",
            "raw::RawIterHashInner",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "raw::RawTable::<T, A>::len": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "raw::RawTable::<T, A>::new_in": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "raw::RawTable::<T, A>::new_uninitialized": [
            "core::marker::Sized",
            "core::result::Result",
            "raw::Fallibility"
        ],
        "raw::RawTable::<T, A>::remove": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::InsertSlot",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "raw::RawTable::<T, A>::remove_entry": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ops::FnMut",
            "core::option::Option",
            "core::ptr::NonNull",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "raw::RawTable::<T, A>::replace_bucket_with": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ops::FnOnce",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "raw::RawTable::<T, A>::reserve": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ops::Fn",
            "core::ptr::NonNull",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "raw::RawTable::<T, A>::reserve_rehash": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ops::Fn",
            "core::ptr::NonNull",
            "core::result::Result",
            "raw::Fallibility",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "raw::RawTable::<T, A>::resize": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ops::Fn",
            "core::ptr::NonNull",
            "core::result::Result",
            "raw::Fallibility",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "raw::RawTable::<T, A>::shrink_to": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ops::Fn",
            "core::ptr::NonNull",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "raw::RawTable::<T, A>::try_reserve": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ops::Fn",
            "core::ptr::NonNull",
            "core::result::Result",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "raw::RawTable::<T, A>::with_capacity_in": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "raw::RawTable::<T>::new": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "raw::RawTable::<T>::with_capacity": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::RawTable",
            "raw::RawTableInner"
        ],
        "raw::RawTableClone::clone_from_spec": [],
        "raw::RawTableInner": [
            "core::ptr::NonNull",
            "raw::RawTableInner"
        ],
        "raw::RawTableInner::allocation_info": [
            "core::alloc::Layout",
            "core::ptr::NonNull",
            "raw::RawTableInner",
            "raw::TableLayout"
        ],
        "raw::RawTableInner::allocation_size_or_zero": [
            "core::ptr::NonNull",
            "raw::RawTableInner",
            "raw::TableLayout"
        ],
        "raw::RawTableInner::bucket": [
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawTableInner"
        ],
        "raw::RawTableInner::bucket_ptr": [
            "core::ptr::NonNull",
            "raw::RawTableInner"
        ],
        "raw::RawTableInner::buckets": [
            "core::ptr::NonNull",
            "raw::RawTableInner"
        ],
        "raw::RawTableInner::clear_no_drop": [
            "core::ptr::NonNull",
            "raw::RawTableInner"
        ],
        "raw::RawTableInner::ctrl": [
            "control::tag::Tag",
            "core::ptr::NonNull",
            "raw::RawTableInner"
        ],
        "raw::RawTableInner::ctrl_slice": [
            "control::tag::Tag",
            "core::ptr::NonNull",
            "raw::RawTableInner"
        ],
        "raw::RawTableInner::data_end": [
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::RawTableInner"
        ],
        "raw::RawTableInner::drop_elements": [
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::RawTableInner"
        ],
        "raw::RawTableInner::drop_inner_table": [
            "allocator_api2::alloc::Allocator",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::RawTableInner",
            "raw::TableLayout"
        ],
        "raw::RawTableInner::erase": [
            "core::ptr::NonNull",
            "raw::RawTableInner"
        ],
        "raw::RawTableInner::fallible_with_capacity": [
            "allocator_api2::alloc::Allocator",
            "core::marker::Sized",
            "core::result::Result",
            "raw::Fallibility",
            "raw::TableLayout"
        ],
        "raw::RawTableInner::find_inner": [
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "raw::RawTableInner"
        ],
        "raw::RawTableInner::find_insert_slot": [
            "core::ptr::NonNull",
            "raw::InsertSlot",
            "raw::RawTableInner"
        ],
        "raw::RawTableInner::find_insert_slot_in_group": [
            "control::group::sse2::Group",
            "core::arch::x86_64::__m128i",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "raw::ProbeSeq",
            "raw::RawTableInner"
        ],
        "raw::RawTableInner::find_or_find_insert_slot_inner": [
            "core::marker::Sized",
            "core::ptr::NonNull",
            "core::result::Result",
            "raw::RawTableInner"
        ],
        "raw::RawTableInner::fix_insert_slot": [
            "core::ptr::NonNull",
            "raw::InsertSlot",
            "raw::RawTableInner"
        ],
        "raw::RawTableInner::free_buckets": [
            "allocator_api2::alloc::Allocator",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::RawTableInner",
            "raw::TableLayout"
        ],
        "raw::RawTableInner::full_buckets_indices": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::ptr::NonNull",
            "raw::FullBucketsIndices",
            "raw::RawTableInner"
        ],
        "raw::RawTableInner::is_bucket_full": [
            "core::ptr::NonNull",
            "raw::RawTableInner"
        ],
        "raw::RawTableInner::is_empty_singleton": [
            "core::ptr::NonNull",
            "raw::RawTableInner"
        ],
        "raw::RawTableInner::is_in_same_group": [
            "core::ptr::NonNull",
            "raw::RawTableInner"
        ],
        "raw::RawTableInner::iter": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTableInner"
        ],
        "raw::RawTableInner::new": [
            "core::ptr::NonNull",
            "raw::RawTableInner"
        ],
        "raw::RawTableInner::new_uninitialized": [
            "allocator_api2::alloc::Allocator",
            "core::marker::Sized",
            "core::result::Result",
            "raw::Fallibility",
            "raw::TableLayout"
        ],
        "raw::RawTableInner::num_ctrl_bytes": [
            "core::ptr::NonNull",
            "raw::RawTableInner"
        ],
        "raw::RawTableInner::prepare_insert_slot": [
            "control::tag::Tag",
            "core::ptr::NonNull",
            "raw::RawTableInner"
        ],
        "raw::RawTableInner::prepare_rehash_in_place": [
            "core::ptr::NonNull",
            "raw::RawTableInner"
        ],
        "raw::RawTableInner::prepare_resize": [
            "allocator_api2::alloc::Allocator",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "core::result::Result",
            "raw::Fallibility",
            "raw::RawTableInner",
            "raw::TableLayout"
        ],
        "raw::RawTableInner::probe_seq": [
            "core::ptr::NonNull",
            "raw::ProbeSeq",
            "raw::RawTableInner"
        ],
        "raw::RawTableInner::record_item_insert_at": [
            "control::tag::Tag",
            "core::ptr::NonNull",
            "raw::RawTableInner"
        ],
        "raw::RawTableInner::rehash_in_place": [
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "raw::RawTableInner"
        ],
        "raw::RawTableInner::replace_ctrl_hash": [
            "control::tag::Tag",
            "core::ptr::NonNull",
            "raw::RawTableInner"
        ],
        "raw::RawTableInner::reserve_rehash_inner": [
            "allocator_api2::alloc::Allocator",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "core::result::Result",
            "raw::Fallibility",
            "raw::RawTableInner",
            "raw::TableLayout"
        ],
        "raw::RawTableInner::resize_inner": [
            "allocator_api2::alloc::Allocator",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "core::result::Result",
            "raw::Fallibility",
            "raw::RawTableInner",
            "raw::TableLayout"
        ],
        "raw::RawTableInner::set_ctrl": [
            "control::tag::Tag",
            "core::ptr::NonNull",
            "raw::RawTableInner"
        ],
        "raw::RawTableInner::set_ctrl_hash": [
            "core::ptr::NonNull",
            "raw::RawTableInner"
        ],
        "raw::RawTableInner::with_capacity": [
            "allocator_api2::alloc::Allocator",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::RawTableInner",
            "raw::TableLayout"
        ],
        "raw::TableLayout": [
            "raw::TableLayout"
        ],
        "raw::TableLayout::calculate_layout_for": [
            "core::marker::Sized",
            "core::option::Option",
            "raw::TableLayout"
        ],
        "raw::TableLayout::new": [
            "core::marker::Sized",
            "raw::TableLayout"
        ],
        "raw::alloc::inner::do_alloc": [
            "allocator_api2::alloc::Allocator",
            "core::alloc::Layout",
            "core::marker::Sized",
            "core::result::Result"
        ],
        "raw::bucket_mask_to_capacity": [],
        "raw::capacity_to_buckets": [
            "core::marker::Sized",
            "core::option::Option",
            "raw::TableLayout"
        ],
        "raw::h1": [],
        "raw::offset_from": [
            "core::marker::Sized"
        ],
        "raw_entry::<impl map::HashMap<K, V, S, A>>::raw_entry": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner",
            "raw_entry::RawEntryBuilder"
        ],
        "raw_entry::<impl map::HashMap<K, V, S, A>>::raw_entry_mut": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner",
            "raw_entry::RawEntryBuilderMut"
        ],
        "raw_entry::RawEntryBuilder": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner",
            "raw_entry::RawEntryBuilder"
        ],
        "raw_entry::RawEntryBuilder::<'a, K, V, S, A>::from_hash": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ops::FnMut",
            "core::option::Option",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner",
            "raw_entry::RawEntryBuilder"
        ],
        "raw_entry::RawEntryBuilder::<'a, K, V, S, A>::from_key": [
            "allocator_api2::alloc::Allocator",
            "core::hash::BuildHasher",
            "core::hash::Hash",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "equivalent::Equivalent",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner",
            "raw_entry::RawEntryBuilder"
        ],
        "raw_entry::RawEntryBuilder::<'a, K, V, S, A>::from_key_hashed_nocheck": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "equivalent::Equivalent",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner",
            "raw_entry::RawEntryBuilder"
        ],
        "raw_entry::RawEntryBuilder::<'a, K, V, S, A>::search": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ops::FnMut",
            "core::option::Option",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner",
            "raw_entry::RawEntryBuilder"
        ],
        "raw_entry::RawEntryBuilderMut": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner",
            "raw_entry::RawEntryBuilderMut"
        ],
        "raw_entry::RawEntryBuilderMut::<'a, K, V, S, A>::from_hash": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ops::FnMut",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner",
            "raw_entry::RawEntryBuilderMut",
            "raw_entry::RawEntryMut",
            "raw_entry::RawOccupiedEntryMut",
            "raw_entry::RawVacantEntryMut"
        ],
        "raw_entry::RawEntryBuilderMut::<'a, K, V, S, A>::from_key": [
            "allocator_api2::alloc::Allocator",
            "core::hash::BuildHasher",
            "core::hash::Hash",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "equivalent::Equivalent",
            "map::HashMap",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner",
            "raw_entry::RawEntryBuilderMut",
            "raw_entry::RawEntryMut",
            "raw_entry::RawOccupiedEntryMut",
            "raw_entry::RawVacantEntryMut"
        ],
        "raw_entry::RawEntryBuilderMut::<'a, K, V, S, A>::from_key_hashed_nocheck": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "equivalent::Equivalent",
            "map::HashMap",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner",
            "raw_entry::RawEntryBuilderMut",
            "raw_entry::RawEntryMut",
            "raw_entry::RawOccupiedEntryMut",
            "raw_entry::RawVacantEntryMut"
        ],
        "raw_entry::RawEntryBuilderMut::<'a, K, V, S, A>::search": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ops::FnMut",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner",
            "raw_entry::RawEntryBuilderMut",
            "raw_entry::RawEntryMut",
            "raw_entry::RawOccupiedEntryMut",
            "raw_entry::RawVacantEntryMut"
        ],
        "raw_entry::RawEntryMut": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner",
            "raw_entry::RawEntryMut",
            "raw_entry::RawOccupiedEntryMut",
            "raw_entry::RawVacantEntryMut"
        ],
        "raw_entry::RawEntryMut::<'a, K, V, S, A>::and_modify": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ops::FnOnce",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner",
            "raw_entry::RawEntryMut",
            "raw_entry::RawOccupiedEntryMut",
            "raw_entry::RawVacantEntryMut"
        ],
        "raw_entry::RawEntryMut::<'a, K, V, S, A>::and_replace_entry_with": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ops::FnOnce",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner",
            "raw_entry::RawEntryMut",
            "raw_entry::RawOccupiedEntryMut",
            "raw_entry::RawVacantEntryMut"
        ],
        "raw_entry::RawEntryMut::<'a, K, V, S, A>::insert": [
            "allocator_api2::alloc::Allocator",
            "core::hash::BuildHasher",
            "core::hash::Hash",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner",
            "raw_entry::RawEntryMut",
            "raw_entry::RawOccupiedEntryMut",
            "raw_entry::RawVacantEntryMut"
        ],
        "raw_entry::RawEntryMut::<'a, K, V, S, A>::or_insert": [
            "allocator_api2::alloc::Allocator",
            "core::hash::BuildHasher",
            "core::hash::Hash",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner",
            "raw_entry::RawEntryMut",
            "raw_entry::RawOccupiedEntryMut",
            "raw_entry::RawVacantEntryMut"
        ],
        "raw_entry::RawEntryMut::<'a, K, V, S, A>::or_insert_with": [
            "allocator_api2::alloc::Allocator",
            "core::hash::BuildHasher",
            "core::hash::Hash",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ops::FnOnce",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner",
            "raw_entry::RawEntryMut",
            "raw_entry::RawOccupiedEntryMut",
            "raw_entry::RawVacantEntryMut"
        ],
        "raw_entry::RawOccupiedEntryMut": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner",
            "raw_entry::RawOccupiedEntryMut"
        ],
        "raw_entry::RawOccupiedEntryMut::<'a, K, V, S, A>::get": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner",
            "raw_entry::RawOccupiedEntryMut"
        ],
        "raw_entry::RawOccupiedEntryMut::<'a, K, V, S, A>::get_key_value": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner",
            "raw_entry::RawOccupiedEntryMut"
        ],
        "raw_entry::RawOccupiedEntryMut::<'a, K, V, S, A>::get_key_value_mut": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner",
            "raw_entry::RawOccupiedEntryMut"
        ],
        "raw_entry::RawOccupiedEntryMut::<'a, K, V, S, A>::get_mut": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner",
            "raw_entry::RawOccupiedEntryMut"
        ],
        "raw_entry::RawOccupiedEntryMut::<'a, K, V, S, A>::insert": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner",
            "raw_entry::RawOccupiedEntryMut"
        ],
        "raw_entry::RawOccupiedEntryMut::<'a, K, V, S, A>::insert_key": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner",
            "raw_entry::RawOccupiedEntryMut"
        ],
        "raw_entry::RawOccupiedEntryMut::<'a, K, V, S, A>::into_key": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner",
            "raw_entry::RawOccupiedEntryMut"
        ],
        "raw_entry::RawOccupiedEntryMut::<'a, K, V, S, A>::into_key_value": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner",
            "raw_entry::RawOccupiedEntryMut"
        ],
        "raw_entry::RawOccupiedEntryMut::<'a, K, V, S, A>::into_mut": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner",
            "raw_entry::RawOccupiedEntryMut"
        ],
        "raw_entry::RawOccupiedEntryMut::<'a, K, V, S, A>::key": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner",
            "raw_entry::RawOccupiedEntryMut"
        ],
        "raw_entry::RawOccupiedEntryMut::<'a, K, V, S, A>::key_mut": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner",
            "raw_entry::RawOccupiedEntryMut"
        ],
        "raw_entry::RawOccupiedEntryMut::<'a, K, V, S, A>::remove": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner",
            "raw_entry::RawOccupiedEntryMut"
        ],
        "raw_entry::RawOccupiedEntryMut::<'a, K, V, S, A>::remove_entry": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner",
            "raw_entry::RawOccupiedEntryMut"
        ],
        "raw_entry::RawOccupiedEntryMut::<'a, K, V, S, A>::replace_entry_with": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ops::FnOnce",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner",
            "raw_entry::RawEntryMut",
            "raw_entry::RawOccupiedEntryMut",
            "raw_entry::RawVacantEntryMut"
        ],
        "raw_entry::RawVacantEntryMut": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::RawTable",
            "raw::RawTableInner",
            "raw_entry::RawVacantEntryMut"
        ],
        "raw_entry::RawVacantEntryMut::<'a, K, V, S, A>::insert": [
            "allocator_api2::alloc::Allocator",
            "core::hash::BuildHasher",
            "core::hash::Hash",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::RawTable",
            "raw::RawTableInner",
            "raw_entry::RawVacantEntryMut"
        ],
        "raw_entry::RawVacantEntryMut::<'a, K, V, S, A>::insert_entry": [
            "allocator_api2::alloc::Allocator",
            "core::hash::BuildHasher",
            "core::hash::Hash",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner",
            "raw_entry::RawOccupiedEntryMut",
            "raw_entry::RawVacantEntryMut"
        ],
        "raw_entry::RawVacantEntryMut::<'a, K, V, S, A>::insert_hashed_nocheck": [
            "allocator_api2::alloc::Allocator",
            "core::hash::BuildHasher",
            "core::hash::Hash",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::RawTable",
            "raw::RawTableInner",
            "raw_entry::RawVacantEntryMut"
        ],
        "raw_entry::RawVacantEntryMut::<'a, K, V, S, A>::insert_with_hasher": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ops::Fn",
            "core::ptr::NonNull",
            "raw::RawTable",
            "raw::RawTableInner",
            "raw_entry::RawVacantEntryMut"
        ],
        "scopeguard::ScopeGuard": [
            "core::marker::Sized",
            "core::ops::FnMut",
            "scopeguard::ScopeGuard"
        ],
        "scopeguard::ScopeGuard::<T, F>::into_inner": [
            "core::marker::Sized",
            "core::ops::FnMut",
            "scopeguard::ScopeGuard"
        ],
        "scopeguard::guard": [
            "core::marker::Sized",
            "core::ops::FnMut",
            "scopeguard::ScopeGuard"
        ],
        "set::Difference": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "map::Iter",
            "map::Keys",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::Difference",
            "set::HashSet",
            "set::Iter"
        ],
        "set::Drain": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::Drain",
            "raw::Bucket",
            "raw::RawDrain",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTableInner",
            "set::Drain"
        ],
        "set::Entry": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "map::OccupiedEntry",
            "map::VacantEntry",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::Entry",
            "set::OccupiedEntry",
            "set::VacantEntry"
        ],
        "set::Entry::<'a, T, S, A>::get": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "map::OccupiedEntry",
            "map::VacantEntry",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::Entry",
            "set::OccupiedEntry",
            "set::VacantEntry"
        ],
        "set::Entry::<'a, T, S, A>::insert": [
            "allocator_api2::alloc::Allocator",
            "core::hash::BuildHasher",
            "core::hash::Hash",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "map::OccupiedEntry",
            "map::VacantEntry",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::Entry",
            "set::OccupiedEntry",
            "set::VacantEntry"
        ],
        "set::Entry::<'a, T, S, A>::or_insert": [
            "allocator_api2::alloc::Allocator",
            "core::hash::BuildHasher",
            "core::hash::Hash",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "map::OccupiedEntry",
            "map::VacantEntry",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::Entry",
            "set::OccupiedEntry",
            "set::VacantEntry"
        ],
        "set::ExtractIf": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawExtractIf",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::ExtractIf"
        ],
        "set::HashSet": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::HashSet"
        ],
        "set::HashSet::<T, S, A>::allocation_size": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::HashSet"
        ],
        "set::HashSet::<T, S, A>::allocator": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::HashSet"
        ],
        "set::HashSet::<T, S, A>::capacity": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::HashSet"
        ],
        "set::HashSet::<T, S, A>::clear": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::HashSet"
        ],
        "set::HashSet::<T, S, A>::contains": [
            "allocator_api2::alloc::Allocator",
            "core::hash::Hash",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "equivalent::Equivalent",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::HashSet"
        ],
        "set::HashSet::<T, S, A>::difference": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "map::Iter",
            "map::Keys",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::Difference",
            "set::HashSet",
            "set::Iter"
        ],
        "set::HashSet::<T, S, A>::drain": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::Drain",
            "map::HashMap",
            "raw::Bucket",
            "raw::RawDrain",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::Drain",
            "set::HashSet"
        ],
        "set::HashSet::<T, S, A>::entry": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "map::OccupiedEntry",
            "map::VacantEntry",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::Entry",
            "set::HashSet",
            "set::OccupiedEntry",
            "set::VacantEntry"
        ],
        "set::HashSet::<T, S, A>::extract_if": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ops::FnMut",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::Bucket",
            "raw::RawExtractIf",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::ExtractIf",
            "set::HashSet"
        ],
        "set::HashSet::<T, S, A>::get": [
            "allocator_api2::alloc::Allocator",
            "core::hash::Hash",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "equivalent::Equivalent",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::HashSet"
        ],
        "set::HashSet::<T, S, A>::get_or_insert": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::HashSet"
        ],
        "set::HashSet::<T, S, A>::get_or_insert_with": [
            "allocator_api2::alloc::Allocator",
            "core::hash::Hash",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ops::FnOnce",
            "core::ptr::NonNull",
            "equivalent::Equivalent",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::HashSet"
        ],
        "set::HashSet::<T, S, A>::hasher": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::HashSet"
        ],
        "set::HashSet::<T, S, A>::insert": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::HashSet"
        ],
        "set::HashSet::<T, S, A>::insert_unique_unchecked": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::HashSet"
        ],
        "set::HashSet::<T, S, A>::intersection": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "map::Iter",
            "map::Keys",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::HashSet",
            "set::Intersection",
            "set::Iter"
        ],
        "set::HashSet::<T, S, A>::is_disjoint": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::HashSet"
        ],
        "set::HashSet::<T, S, A>::is_empty": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::HashSet"
        ],
        "set::HashSet::<T, S, A>::is_subset": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::HashSet"
        ],
        "set::HashSet::<T, S, A>::is_superset": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::HashSet"
        ],
        "set::HashSet::<T, S, A>::iter": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "map::Iter",
            "map::Keys",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::HashSet",
            "set::Iter"
        ],
        "set::HashSet::<T, S, A>::len": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::HashSet"
        ],
        "set::HashSet::<T, S, A>::remove": [
            "allocator_api2::alloc::Allocator",
            "core::hash::Hash",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "equivalent::Equivalent",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::HashSet"
        ],
        "set::HashSet::<T, S, A>::replace": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::HashSet"
        ],
        "set::HashSet::<T, S, A>::reserve": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::HashSet"
        ],
        "set::HashSet::<T, S, A>::retain": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ops::FnMut",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::HashSet"
        ],
        "set::HashSet::<T, S, A>::shrink_to": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::HashSet"
        ],
        "set::HashSet::<T, S, A>::shrink_to_fit": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::HashSet"
        ],
        "set::HashSet::<T, S, A>::symmetric_difference": [
            "allocator_api2::alloc::Allocator",
            "core::iter::Chain",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::HashSet",
            "set::SymmetricDifference"
        ],
        "set::HashSet::<T, S, A>::take": [
            "allocator_api2::alloc::Allocator",
            "core::hash::Hash",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "equivalent::Equivalent",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::HashSet"
        ],
        "set::HashSet::<T, S, A>::try_reserve": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "core::result::Result",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::HashSet"
        ],
        "set::HashSet::<T, S, A>::union": [
            "allocator_api2::alloc::Allocator",
            "core::iter::Chain",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::HashSet",
            "set::Union"
        ],
        "set::HashSet::<T, S, A>::with_capacity_and_hasher_in": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::HashSet"
        ],
        "set::HashSet::<T, S, A>::with_hasher_in": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::HashSet"
        ],
        "set::HashSet::<T, S>::with_capacity_and_hasher": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::HashSet"
        ],
        "set::HashSet::<T, S>::with_hasher": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::HashSet"
        ],
        "set::HashSet::<T, foldhash::fast::RandomState, A>::new_in": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::HashSet"
        ],
        "set::HashSet::<T, foldhash::fast::RandomState, A>::with_capacity_in": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::HashSet"
        ],
        "set::HashSet::<T>::new": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::HashSet"
        ],
        "set::HashSet::<T>::with_capacity": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::HashSet"
        ],
        "set::Intersection": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "map::Iter",
            "map::Keys",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::HashSet",
            "set::Intersection",
            "set::Iter"
        ],
        "set::IntoIter": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "map::IntoIter",
            "raw::Bucket",
            "raw::RawIntoIter",
            "raw::RawIter",
            "raw::RawIterRange",
            "set::IntoIter"
        ],
        "set::Iter": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::Iter",
            "map::Keys",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange",
            "set::Iter"
        ],
        "set::OccupiedEntry": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "map::OccupiedEntry",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::OccupiedEntry"
        ],
        "set::OccupiedEntry::<'_, T, S, A>::get": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "map::OccupiedEntry",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::OccupiedEntry"
        ],
        "set::OccupiedEntry::<'_, T, S, A>::remove": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "map::OccupiedEntry",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::OccupiedEntry"
        ],
        "set::SymmetricDifference": [
            "allocator_api2::alloc::Allocator",
            "core::iter::Chain",
            "core::marker::Sized",
            "set::SymmetricDifference"
        ],
        "set::Union": [
            "allocator_api2::alloc::Allocator",
            "core::iter::Chain",
            "core::marker::Sized",
            "set::Union"
        ],
        "set::VacantEntry": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "map::VacantEntry",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::VacantEntry"
        ],
        "set::VacantEntry::<'a, T, S, A>::get": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "map::VacantEntry",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::VacantEntry"
        ],
        "set::VacantEntry::<'a, T, S, A>::insert": [
            "allocator_api2::alloc::Allocator",
            "core::hash::BuildHasher",
            "core::hash::Hash",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "map::OccupiedEntry",
            "map::VacantEntry",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::OccupiedEntry",
            "set::VacantEntry"
        ],
        "set::VacantEntry::<'a, T, S, A>::into_value": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "map::VacantEntry",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::VacantEntry"
        ],
        "set::assert_covariance": [],
        "set::assert_covariance::difference": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "map::Iter",
            "map::Keys",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::Difference",
            "set::HashSet",
            "set::Iter"
        ],
        "set::assert_covariance::drain": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::Drain",
            "raw::Bucket",
            "raw::RawDrain",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTableInner",
            "set::Drain"
        ],
        "set::assert_covariance::intersection": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "map::Iter",
            "map::Keys",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::HashSet",
            "set::Intersection",
            "set::Iter"
        ],
        "set::assert_covariance::into_iter": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "map::IntoIter",
            "raw::Bucket",
            "raw::RawIntoIter",
            "raw::RawIter",
            "raw::RawIterRange",
            "set::IntoIter"
        ],
        "set::assert_covariance::iter": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::Iter",
            "map::Keys",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange",
            "set::Iter"
        ],
        "set::assert_covariance::set": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "map::HashMap",
            "raw::RawTable",
            "raw::RawTableInner",
            "set::HashSet"
        ],
        "set::assert_covariance::symmetric_difference": [
            "allocator_api2::alloc::Allocator",
            "core::iter::Chain",
            "core::marker::Sized",
            "set::SymmetricDifference"
        ],
        "set::assert_covariance::union": [
            "allocator_api2::alloc::Allocator",
            "core::iter::Chain",
            "core::marker::Sized",
            "set::Union"
        ],
        "table::AbsentEntry": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::RawTable",
            "raw::RawTableInner",
            "table::AbsentEntry",
            "table::HashTable"
        ],
        "table::AbsentEntry::<'a, T, A>::into_table": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::RawTable",
            "raw::RawTableInner",
            "table::AbsentEntry",
            "table::HashTable"
        ],
        "table::Drain": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawDrain",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTableInner",
            "table::Drain"
        ],
        "table::Entry": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::InsertSlot",
            "raw::RawTable",
            "raw::RawTableInner",
            "table::Entry",
            "table::HashTable",
            "table::OccupiedEntry",
            "table::VacantEntry"
        ],
        "table::Entry::<'a, T, A>::and_modify": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ops::FnOnce",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::InsertSlot",
            "raw::RawTable",
            "raw::RawTableInner",
            "table::Entry",
            "table::HashTable",
            "table::OccupiedEntry",
            "table::VacantEntry"
        ],
        "table::Entry::<'a, T, A>::insert": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::InsertSlot",
            "raw::RawTable",
            "raw::RawTableInner",
            "table::Entry",
            "table::HashTable",
            "table::OccupiedEntry",
            "table::VacantEntry"
        ],
        "table::Entry::<'a, T, A>::or_insert": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::InsertSlot",
            "raw::RawTable",
            "raw::RawTableInner",
            "table::Entry",
            "table::HashTable",
            "table::OccupiedEntry",
            "table::VacantEntry"
        ],
        "table::Entry::<'a, T, A>::or_insert_with": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ops::FnOnce",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::InsertSlot",
            "raw::RawTable",
            "raw::RawTableInner",
            "table::Entry",
            "table::HashTable",
            "table::OccupiedEntry",
            "table::VacantEntry"
        ],
        "table::ExtractIf": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawExtractIf",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTable",
            "raw::RawTableInner",
            "table::ExtractIf"
        ],
        "table::HashTable": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::RawTable",
            "raw::RawTableInner",
            "table::HashTable"
        ],
        "table::HashTable::<T, A>::allocation_size": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::RawTable",
            "raw::RawTableInner",
            "table::HashTable"
        ],
        "table::HashTable::<T, A>::allocator": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::RawTable",
            "raw::RawTableInner",
            "table::HashTable"
        ],
        "table::HashTable::<T, A>::capacity": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::RawTable",
            "raw::RawTableInner",
            "table::HashTable"
        ],
        "table::HashTable::<T, A>::clear": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::RawTable",
            "raw::RawTableInner",
            "table::HashTable"
        ],
        "table::HashTable::<T, A>::drain": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawDrain",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTable",
            "raw::RawTableInner",
            "table::Drain",
            "table::HashTable"
        ],
        "table::HashTable::<T, A>::entry": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ops::Fn",
            "core::ops::FnMut",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::InsertSlot",
            "raw::RawTable",
            "raw::RawTableInner",
            "table::Entry",
            "table::HashTable",
            "table::OccupiedEntry",
            "table::VacantEntry"
        ],
        "table::HashTable::<T, A>::extract_if": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ops::FnMut",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawExtractIf",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTable",
            "raw::RawTableInner",
            "table::ExtractIf",
            "table::HashTable"
        ],
        "table::HashTable::<T, A>::find": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ops::FnMut",
            "core::option::Option",
            "core::ptr::NonNull",
            "raw::RawTable",
            "raw::RawTableInner",
            "table::HashTable"
        ],
        "table::HashTable::<T, A>::find_entry": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ops::FnMut",
            "core::ptr::NonNull",
            "core::result::Result",
            "raw::RawTable",
            "raw::RawTableInner",
            "table::HashTable"
        ],
        "table::HashTable::<T, A>::find_mut": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ops::FnMut",
            "core::option::Option",
            "core::ptr::NonNull",
            "raw::RawTable",
            "raw::RawTableInner",
            "table::HashTable"
        ],
        "table::HashTable::<T, A>::get_many_mut": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ops::FnMut",
            "core::option::Option",
            "core::ptr::NonNull",
            "raw::RawTable",
            "raw::RawTableInner",
            "table::HashTable"
        ],
        "table::HashTable::<T, A>::get_many_unchecked_mut": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ops::FnMut",
            "core::option::Option",
            "core::ptr::NonNull",
            "raw::RawTable",
            "raw::RawTableInner",
            "table::HashTable"
        ],
        "table::HashTable::<T, A>::insert_unique": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ops::Fn",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner",
            "table::HashTable",
            "table::OccupiedEntry"
        ],
        "table::HashTable::<T, A>::is_empty": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::RawTable",
            "raw::RawTableInner",
            "table::HashTable"
        ],
        "table::HashTable::<T, A>::iter": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTable",
            "raw::RawTableInner",
            "table::HashTable",
            "table::Iter"
        ],
        "table::HashTable::<T, A>::iter_hash": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "control::group::sse2::Group",
            "control::tag::Tag",
            "core::arch::x86_64::__m128i",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::ProbeSeq",
            "raw::RawIterHash",
            "raw::RawIterHashInner",
            "raw::RawTable",
            "raw::RawTableInner",
            "table::HashTable",
            "table::IterHash"
        ],
        "table::HashTable::<T, A>::iter_hash_mut": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "control::group::sse2::Group",
            "control::tag::Tag",
            "core::arch::x86_64::__m128i",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::ProbeSeq",
            "raw::RawIterHash",
            "raw::RawIterHashInner",
            "raw::RawTable",
            "raw::RawTableInner",
            "table::HashTable",
            "table::IterHashMut"
        ],
        "table::HashTable::<T, A>::iter_mut": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange",
            "raw::RawTable",
            "raw::RawTableInner",
            "table::HashTable",
            "table::IterMut"
        ],
        "table::HashTable::<T, A>::len": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::RawTable",
            "raw::RawTableInner",
            "table::HashTable"
        ],
        "table::HashTable::<T, A>::new_in": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::RawTable",
            "raw::RawTableInner",
            "table::HashTable"
        ],
        "table::HashTable::<T, A>::reserve": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ops::Fn",
            "core::ptr::NonNull",
            "raw::RawTable",
            "raw::RawTableInner",
            "table::HashTable"
        ],
        "table::HashTable::<T, A>::retain": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ops::FnMut",
            "core::ptr::NonNull",
            "raw::RawTable",
            "raw::RawTableInner",
            "table::HashTable"
        ],
        "table::HashTable::<T, A>::shrink_to": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ops::Fn",
            "core::ptr::NonNull",
            "raw::RawTable",
            "raw::RawTableInner",
            "table::HashTable"
        ],
        "table::HashTable::<T, A>::shrink_to_fit": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ops::Fn",
            "core::ptr::NonNull",
            "raw::RawTable",
            "raw::RawTableInner",
            "table::HashTable"
        ],
        "table::HashTable::<T, A>::try_reserve": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ops::Fn",
            "core::ptr::NonNull",
            "core::result::Result",
            "raw::RawTable",
            "raw::RawTableInner",
            "table::HashTable"
        ],
        "table::HashTable::<T, A>::with_capacity_in": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::RawTable",
            "raw::RawTableInner",
            "table::HashTable"
        ],
        "table::HashTable::<T>::new": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::RawTable",
            "raw::RawTableInner",
            "table::HashTable"
        ],
        "table::HashTable::<T>::with_capacity": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::RawTable",
            "raw::RawTableInner",
            "table::HashTable"
        ],
        "table::IntoIter": [
            "allocator_api2::alloc::Allocator",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::option::Option",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawIntoIter",
            "raw::RawIter",
            "raw::RawIterRange",
            "table::IntoIter"
        ],
        "table::Iter": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange",
            "table::Iter"
        ],
        "table::IterHash": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "control::group::sse2::Group",
            "control::tag::Tag",
            "core::arch::x86_64::__m128i",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::ProbeSeq",
            "raw::RawIterHash",
            "raw::RawIterHashInner",
            "table::IterHash"
        ],
        "table::IterHashMut": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "control::group::sse2::Group",
            "control::tag::Tag",
            "core::arch::x86_64::__m128i",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::ProbeSeq",
            "raw::RawIterHash",
            "raw::RawIterHashInner",
            "table::IterHashMut"
        ],
        "table::IterMut": [
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawIter",
            "raw::RawIterRange",
            "table::IterMut"
        ],
        "table::OccupiedEntry": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner",
            "table::HashTable",
            "table::OccupiedEntry"
        ],
        "table::OccupiedEntry::<'a, T, A>::get": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner",
            "table::HashTable",
            "table::OccupiedEntry"
        ],
        "table::OccupiedEntry::<'a, T, A>::get_mut": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner",
            "table::HashTable",
            "table::OccupiedEntry"
        ],
        "table::OccupiedEntry::<'a, T, A>::into_mut": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner",
            "table::HashTable",
            "table::OccupiedEntry"
        ],
        "table::OccupiedEntry::<'a, T, A>::into_table": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::RawTable",
            "raw::RawTableInner",
            "table::HashTable",
            "table::OccupiedEntry"
        ],
        "table::OccupiedEntry::<'a, T, A>::remove": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::InsertSlot",
            "raw::RawTable",
            "raw::RawTableInner",
            "table::HashTable",
            "table::OccupiedEntry",
            "table::VacantEntry"
        ],
        "table::VacantEntry": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::InsertSlot",
            "raw::RawTable",
            "raw::RawTableInner",
            "table::HashTable",
            "table::VacantEntry"
        ],
        "table::VacantEntry::<'a, T, A>::insert": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::Bucket",
            "raw::InsertSlot",
            "raw::RawTable",
            "raw::RawTableInner",
            "table::HashTable",
            "table::OccupiedEntry",
            "table::VacantEntry"
        ],
        "table::VacantEntry::<'a, T, A>::into_table": [
            "allocator_api2::alloc::Allocator",
            "core::marker::PhantomData",
            "core::marker::Sized",
            "core::ptr::NonNull",
            "raw::InsertSlot",
            "raw::RawTable",
            "raw::RawTableInner",
            "table::HashTable",
            "table::VacantEntry"
        ],
        "util::invalid_mut": [
            "core::marker::Sized"
        ]
    },
    "glob_path_import": {
        "map": "hash_map::",
        "raw_entry": "map::",
        "set": "hash_set::",
        "table": "hash_table::"
    },
    "self_to_fn": {
        "<T as raw::SizedTypeProperties>::T": [
            "impl<T> SizedTypeProperties for T {}"
        ],
        "TryReserveError": [
            "Clone",
            "Debug",
            "Eq",
            "PartialEq"
        ],
        "control::bitmask::BitMask": [
            "Clone",
            "Copy",
            "impl BitMask {\n    /// Returns a new `BitMask` with all bits inverted.\n    #[inline]\n    #[must_use]\n    #[allow(dead_code)]\n    pub(crate) fn invert(self) -> Self {\n        BitMask(self.0 ^ BITMASK_MASK)\n    }\n\n    /// Returns a new `BitMask` with the lowest bit removed.\n    #[inline]\n    #[must_use]\n    fn remove_lowest_bit(self) -> Self {\n        BitMask(self.0 & (self.0 - 1))\n    }\n\n    /// Returns whether the `BitMask` has at least one set bit.\n    #[inline]\n    pub(crate) fn any_bit_set(self) -> bool {\n        self.0 != 0\n    }\n\n    /// Returns the first set bit in the `BitMask`, if there is one.\n    #[inline]\n    pub(crate) fn lowest_set_bit(self) -> Option<usize> {\n        if let Some(nonzero) = NonZeroBitMaskWord::new(self.0) {\n            Some(Self::nonzero_trailing_zeros(nonzero))\n        } else {\n            None\n        }\n    }\n\n    /// Returns the number of trailing zeroes in the `BitMask`.\n    #[inline]\n    pub(crate) fn trailing_zeros(self) -> usize {\n        // ARM doesn't have a trailing_zeroes instruction, and instead uses\n        // reverse_bits (RBIT) + leading_zeroes (CLZ). However older ARM\n        // versions (pre-ARMv7) don't have RBIT and need to emulate it\n        // instead. Since we only have 1 bit set in each byte on ARM, we can\n        // use swap_bytes (REV) + leading_zeroes instead.\n        if cfg!(target_arch = \"arm\") && BITMASK_STRIDE % 8 == 0 {\n            self.0.swap_bytes().leading_zeros() as usize / BITMASK_STRIDE\n        } else {\n            self.0.trailing_zeros() as usize / BITMASK_STRIDE\n        }\n    }\n\n    /// Same as above but takes a `NonZeroBitMaskWord`.\n    #[inline]\n    fn nonzero_trailing_zeros(nonzero: NonZeroBitMaskWord) -> usize {\n        if cfg!(target_arch = \"arm\") && BITMASK_STRIDE % 8 == 0 {\n            // SAFETY: A byte-swapped non-zero value is still non-zero.\n            let swapped = unsafe { NonZeroBitMaskWord::new_unchecked(nonzero.get().swap_bytes()) };\n            swapped.leading_zeros() as usize / BITMASK_STRIDE\n        } else {\n            nonzero.trailing_zeros() as usize / BITMASK_STRIDE\n        }\n    }\n\n    /// Returns the number of leading zeroes in the `BitMask`.\n    #[inline]\n    pub(crate) fn leading_zeros(self) -> usize {\n        self.0.leading_zeros() as usize / BITMASK_STRIDE\n    }\n}",
            "impl IntoIterator for BitMask {\n    type Item = usize;\n    type IntoIter = BitMaskIter;\n\n    #[inline]\n    fn into_iter(self) -> BitMaskIter {\n        // A BitMask only requires each element (group of bits) to be non-zero.\n        // However for iteration we need each element to only contain 1 bit.\n        BitMaskIter(BitMask(self.0 & BITMASK_ITER_MASK))\n    }\n}"
        ],
        "control::bitmask::BitMaskIter": [
            "Clone",
            "impl Iterator for BitMaskIter {\n    type Item = usize;\n\n    #[inline]\n    fn next(&mut self) -> Option<usize> {\n        let bit = self.0.lowest_set_bit()?;\n        self.0 = self.0.remove_lowest_bit();\n        Some(bit)\n    }\n}"
        ],
        "control::group::sse2::Group": [
            "Clone",
            "Copy",
            "impl Group {\n    /// Number of bytes in the group.\n    pub(crate) const WIDTH: usize = mem::size_of::<Self>();\n\n    /// Returns a full group of empty tags, suitable for use as the initial\n    /// value for an empty hash table.\n    ///\n    /// This is guaranteed to be aligned to the group size.\n    #[inline]\n    #[allow(clippy::items_after_statements)]\n    pub(crate) const fn static_empty() -> &'static [Tag; Group::WIDTH] {\n        #[repr(C)]\n        struct AlignedTags {\n            _align: [Group; 0],\n            tags: [Tag; Group::WIDTH],\n        }\n        const ALIGNED_TAGS: AlignedTags = AlignedTags {\n            _align: [],\n            tags: [Tag::EMPTY; Group::WIDTH],\n        };\n        &ALIGNED_TAGS.tags\n    }\n\n    /// Loads a group of tags starting at the given address.\n    #[inline]\n    #[allow(clippy::cast_ptr_alignment)] // unaligned load\n    pub(crate) unsafe fn load(ptr: *const Tag) -> Self {\n        Group(x86::_mm_loadu_si128(ptr.cast()))\n    }\n\n    /// Loads a group of tags starting at the given address, which must be\n    /// aligned to `mem::align_of::<Group>()`.\n    #[inline]\n    #[allow(clippy::cast_ptr_alignment)]\n    pub(crate) unsafe fn load_aligned(ptr: *const Tag) -> Self {\n        debug_assert_eq!(ptr.align_offset(mem::align_of::<Self>()), 0);\n        Group(x86::_mm_load_si128(ptr.cast()))\n    }\n\n    /// Stores the group of tags to the given address, which must be\n    /// aligned to `mem::align_of::<Group>()`.\n    #[inline]\n    #[allow(clippy::cast_ptr_alignment)]\n    pub(crate) unsafe fn store_aligned(self, ptr: *mut Tag) {\n        debug_assert_eq!(ptr.align_offset(mem::align_of::<Self>()), 0);\n        x86::_mm_store_si128(ptr.cast(), self.0);\n    }\n\n    /// Returns a `BitMask` indicating all tags in the group which have\n    /// the given value.\n    #[inline]\n    pub(crate) fn match_tag(self, tag: Tag) -> BitMask {\n        #[allow(\n            clippy::cast_possible_wrap, // tag.0: Tag as i8\n            // tag: i32 as u16\n            //   note: _mm_movemask_epi8 returns a 16-bit mask in a i32, the\n            //   upper 16-bits of the i32 are zeroed:\n            clippy::cast_sign_loss,\n            clippy::cast_possible_truncation\n        )]\n        unsafe {\n            let cmp = x86::_mm_cmpeq_epi8(self.0, x86::_mm_set1_epi8(tag.0 as i8));\n            BitMask(x86::_mm_movemask_epi8(cmp) as u16)\n        }\n    }\n\n    /// Returns a `BitMask` indicating all tags in the group which are\n    /// `EMPTY`.\n    #[inline]\n    pub(crate) fn match_empty(self) -> BitMask {\n        self.match_tag(Tag::EMPTY)\n    }\n\n    /// Returns a `BitMask` indicating all tags in the group which are\n    /// `EMPTY` or `DELETED`.\n    #[inline]\n    pub(crate) fn match_empty_or_deleted(self) -> BitMask {\n        #[allow(\n            // tag: i32 as u16\n            //   note: _mm_movemask_epi8 returns a 16-bit mask in a i32, the\n            //   upper 16-bits of the i32 are zeroed:\n            clippy::cast_sign_loss,\n            clippy::cast_possible_truncation\n        )]\n        unsafe {\n            // A tag is EMPTY or DELETED iff the high bit is set\n            BitMask(x86::_mm_movemask_epi8(self.0) as u16)\n        }\n    }\n\n    /// Returns a `BitMask` indicating all tags in the group which are full.\n    #[inline]\n    pub(crate) fn match_full(&self) -> BitMask {\n        self.match_empty_or_deleted().invert()\n    }\n\n    /// Performs the following transformation on all tags in the group:\n    /// - `EMPTY => EMPTY`\n    /// - `DELETED => EMPTY`\n    /// - `FULL => DELETED`\n    #[inline]\n    pub(crate) fn convert_special_to_empty_and_full_to_deleted(self) -> Self {\n        // Map high_bit = 1 (EMPTY or DELETED) to 1111_1111\n        // and high_bit = 0 (FULL) to 1000_0000\n        //\n        // Here's this logic expanded to concrete values:\n        //   let special = 0 > tag = 1111_1111 (true) or 0000_0000 (false)\n        //   1111_1111 | 1000_0000 = 1111_1111\n        //   0000_0000 | 1000_0000 = 1000_0000\n        #[allow(\n            clippy::cast_possible_wrap, // tag: Tag::DELETED.0 as i8\n        )]\n        unsafe {\n            let zero = x86::_mm_setzero_si128();\n            let special = x86::_mm_cmpgt_epi8(zero, self.0);\n            Group(x86::_mm_or_si128(\n                special,\n                x86::_mm_set1_epi8(Tag::DELETED.0 as i8),\n            ))\n        }\n    }\n}"
        ],
        "control::tag::Tag": [
            "Clone",
            "Copy",
            "Eq",
            "PartialEq",
            "impl Tag {\n    /// Control tag value for an empty bucket.\n    pub(crate) const EMPTY: Tag = Tag(0b1111_1111);\n\n    /// Control tag value for a deleted bucket.\n    pub(crate) const DELETED: Tag = Tag(0b1000_0000);\n\n    /// Checks whether a control tag represents a full bucket (top bit is clear).\n    #[inline]\n    pub(crate) const fn is_full(self) -> bool {\n        self.0 & 0x80 == 0\n    }\n\n    /// Checks whether a control tag represents a special value (top bit is set).\n    #[inline]\n    pub(crate) const fn is_special(self) -> bool {\n        self.0 & 0x80 != 0\n    }\n\n    /// Checks whether a special control value is EMPTY (just check 1 bit).\n    #[inline]\n    pub(crate) const fn special_is_empty(self) -> bool {\n        debug_assert!(self.is_special());\n        self.0 & 0x01 != 0\n    }\n\n    /// Creates a control tag representing a full bucket with the given hash.\n    #[inline]\n    #[allow(clippy::cast_possible_truncation)]\n    pub(crate) const fn full(hash: u64) -> Tag {\n        // Constant for function that grabs the top 7 bits of the hash.\n        const MIN_HASH_LEN: usize = if mem::size_of::<usize>() < mem::size_of::<u64>() {\n            mem::size_of::<usize>()\n        } else {\n            mem::size_of::<u64>()\n        };\n\n        // Grab the top 7 bits of the hash. While the hash is normally a full 64-bit\n        // value, some hash functions (such as FxHash) produce a usize result\n        // instead, which means that the top 32 bits are 0 on 32-bit platforms.\n        // So we use MIN_HASH_LEN constant to handle this.\n        let top7 = hash >> (MIN_HASH_LEN * 8 - 7);\n        Tag((top7 & 0x7f) as u8) // truncation\n    }\n}",
            "impl fmt::Debug for Tag {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        if self.is_special() {\n            if self.special_is_empty() {\n                f.pad(\"EMPTY\")\n            } else {\n                f.pad(\"DELETED\")\n            }\n        } else {\n            f.debug_tuple(\"full\").field(&(self.0 & 0x7F)).finish()\n        }\n    }\n}"
        ],
        "map::Drain": [
            "impl<K, V, A: Allocator> Drain<'_, K, V, A> {\n    /// Returns a iterator of references over the remaining items.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub(super) fn iter(&self) -> Iter<'_, K, V> {\n        Iter {\n            inner: self.inner.iter(),\n            marker: PhantomData,\n        }\n    }\n}",
            "impl<K, V, A: Allocator> ExactSizeIterator for Drain<'_, K, V, A> {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn len(&self) -> usize {\n        self.inner.len()\n    }\n}",
            "impl<K, V, A: Allocator> FusedIterator for Drain<'_, K, V, A> {}",
            "impl<K, V, A: Allocator> Iterator for Drain<'_, K, V, A> {\n    type Item = (K, V);\n\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn next(&mut self) -> Option<(K, V)> {\n        self.inner.next()\n    }\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.inner.size_hint()\n    }\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn fold<B, F>(self, init: B, f: F) -> B\n    where\n        Self: Sized,\n        F: FnMut(B, Self::Item) -> B,\n    {\n        self.inner.fold(init, f)\n    }\n}",
            "impl<K, V, A> fmt::Debug for Drain<'_, K, V, A>\nwhere\n    K: fmt::Debug,\n    V: fmt::Debug,\n    A: Allocator,\n{\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_list().entries(self.iter()).finish()\n    }\n}"
        ],
        "map::Entry": [
            "impl<'a, K, V, S, A: Allocator> Entry<'a, K, V, S, A> {\n    /// Sets the value of the entry, and returns an `OccupiedEntry`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut map: HashMap<&str, u32> = HashMap::new();\n    /// let entry = map.entry(\"horseyland\").insert(37);\n    ///\n    /// assert_eq!(entry.key(), &\"horseyland\");\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn insert(self, value: V) -> OccupiedEntry<'a, K, V, S, A>\n    where\n        K: Hash,\n        S: BuildHasher,\n    {\n        match self {\n            Entry::Occupied(mut entry) => {\n                entry.insert(value);\n                entry\n            }\n            Entry::Vacant(entry) => entry.insert_entry(value),\n        }\n    }\n\n    /// Ensures a value is in the entry by inserting the default if empty, and returns\n    /// a mutable reference to the value in the entry.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut map: HashMap<&str, u32> = HashMap::new();\n    ///\n    /// // nonexistent key\n    /// map.entry(\"poneyland\").or_insert(3);\n    /// assert_eq!(map[\"poneyland\"], 3);\n    ///\n    /// // existing key\n    /// *map.entry(\"poneyland\").or_insert(10) *= 2;\n    /// assert_eq!(map[\"poneyland\"], 6);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn or_insert(self, default: V) -> &'a mut V\n    where\n        K: Hash,\n        S: BuildHasher,\n    {\n        match self {\n            Entry::Occupied(entry) => entry.into_mut(),\n            Entry::Vacant(entry) => entry.insert(default),\n        }\n    }\n\n    /// Ensures a value is in the entry by inserting the result of the default function if empty,\n    /// and returns a mutable reference to the value in the entry.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut map: HashMap<&str, u32> = HashMap::new();\n    ///\n    /// // nonexistent key\n    /// map.entry(\"poneyland\").or_insert_with(|| 3);\n    /// assert_eq!(map[\"poneyland\"], 3);\n    ///\n    /// // existing key\n    /// *map.entry(\"poneyland\").or_insert_with(|| 10) *= 2;\n    /// assert_eq!(map[\"poneyland\"], 6);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn or_insert_with<F: FnOnce() -> V>(self, default: F) -> &'a mut V\n    where\n        K: Hash,\n        S: BuildHasher,\n    {\n        match self {\n            Entry::Occupied(entry) => entry.into_mut(),\n            Entry::Vacant(entry) => entry.insert(default()),\n        }\n    }\n\n    /// Ensures a value is in the entry by inserting, if empty, the result of the default function.\n    /// This method allows for generating key-derived values for insertion by providing the default\n    /// function a reference to the key that was moved during the `.entry(key)` method call.\n    ///\n    /// The reference to the moved key is provided so that cloning or copying the key is\n    /// unnecessary, unlike with `.or_insert_with(|| ... )`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut map: HashMap<&str, usize> = HashMap::new();\n    ///\n    /// // nonexistent key\n    /// map.entry(\"poneyland\").or_insert_with_key(|key| key.chars().count());\n    /// assert_eq!(map[\"poneyland\"], 9);\n    ///\n    /// // existing key\n    /// *map.entry(\"poneyland\").or_insert_with_key(|key| key.chars().count() * 10) *= 2;\n    /// assert_eq!(map[\"poneyland\"], 18);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn or_insert_with_key<F: FnOnce(&K) -> V>(self, default: F) -> &'a mut V\n    where\n        K: Hash,\n        S: BuildHasher,\n    {\n        match self {\n            Entry::Occupied(entry) => entry.into_mut(),\n            Entry::Vacant(entry) => {\n                let value = default(entry.key());\n                entry.insert(value)\n            }\n        }\n    }\n\n    /// Returns a reference to this entry's key.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut map: HashMap<&str, u32> = HashMap::new();\n    /// map.entry(\"poneyland\").or_insert(3);\n    /// // existing key\n    /// assert_eq!(map.entry(\"poneyland\").key(), &\"poneyland\");\n    /// // nonexistent key\n    /// assert_eq!(map.entry(\"horseland\").key(), &\"horseland\");\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn key(&self) -> &K {\n        match *self {\n            Entry::Occupied(ref entry) => entry.key(),\n            Entry::Vacant(ref entry) => entry.key(),\n        }\n    }\n\n    /// Provides in-place mutable access to an occupied entry before any\n    /// potential inserts into the map.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut map: HashMap<&str, u32> = HashMap::new();\n    ///\n    /// map.entry(\"poneyland\")\n    ///    .and_modify(|e| { *e += 1 })\n    ///    .or_insert(42);\n    /// assert_eq!(map[\"poneyland\"], 42);\n    ///\n    /// map.entry(\"poneyland\")\n    ///    .and_modify(|e| { *e += 1 })\n    ///    .or_insert(42);\n    /// assert_eq!(map[\"poneyland\"], 43);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn and_modify<F>(self, f: F) -> Self\n    where\n        F: FnOnce(&mut V),\n    {\n        match self {\n            Entry::Occupied(mut entry) => {\n                f(entry.get_mut());\n                Entry::Occupied(entry)\n            }\n            Entry::Vacant(entry) => Entry::Vacant(entry),\n        }\n    }\n\n    /// Provides shared access to the key and owned access to the value of\n    /// an occupied entry and allows to replace or remove it based on the\n    /// value of the returned option.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    /// use hashbrown::hash_map::Entry;\n    ///\n    /// let mut map: HashMap<&str, u32> = HashMap::new();\n    ///\n    /// let entry = map\n    ///     .entry(\"poneyland\")\n    ///     .and_replace_entry_with(|_k, _v| panic!());\n    ///\n    /// match entry {\n    ///     Entry::Vacant(e) => {\n    ///         assert_eq!(e.key(), &\"poneyland\");\n    ///     }\n    ///     Entry::Occupied(_) => panic!(),\n    /// }\n    ///\n    /// map.insert(\"poneyland\", 42);\n    ///\n    /// let entry = map\n    ///     .entry(\"poneyland\")\n    ///     .and_replace_entry_with(|k, v| {\n    ///         assert_eq!(k, &\"poneyland\");\n    ///         assert_eq!(v, 42);\n    ///         Some(v + 1)\n    ///     });\n    ///\n    /// match entry {\n    ///     Entry::Occupied(e) => {\n    ///         assert_eq!(e.key(), &\"poneyland\");\n    ///         assert_eq!(e.get(), &43);\n    ///     }\n    ///     Entry::Vacant(_) => panic!(),\n    /// }\n    ///\n    /// assert_eq!(map[\"poneyland\"], 43);\n    ///\n    /// let entry = map\n    ///     .entry(\"poneyland\")\n    ///     .and_replace_entry_with(|_k, _v| None);\n    ///\n    /// match entry {\n    ///     Entry::Vacant(e) => assert_eq!(e.key(), &\"poneyland\"),\n    ///     Entry::Occupied(_) => panic!(),\n    /// }\n    ///\n    /// assert!(!map.contains_key(\"poneyland\"));\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn and_replace_entry_with<F>(self, f: F) -> Self\n    where\n        F: FnOnce(&K, V) -> Option<V>,\n    {\n        match self {\n            Entry::Occupied(entry) => entry.replace_entry_with(f),\n            Entry::Vacant(_) => self,\n        }\n    }\n}",
            "impl<'a, K, V: Default, S, A: Allocator> Entry<'a, K, V, S, A> {\n    /// Ensures a value is in the entry by inserting the default value if empty,\n    /// and returns a mutable reference to the value in the entry.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut map: HashMap<&str, Option<u32>> = HashMap::new();\n    ///\n    /// // nonexistent key\n    /// map.entry(\"poneyland\").or_default();\n    /// assert_eq!(map[\"poneyland\"], None);\n    ///\n    /// map.insert(\"horseland\", Some(3));\n    ///\n    /// // existing key\n    /// assert_eq!(map.entry(\"horseland\").or_default(), &mut Some(3));\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn or_default(self) -> &'a mut V\n    where\n        K: Hash,\n        S: BuildHasher,\n    {\n        match self {\n            Entry::Occupied(entry) => entry.into_mut(),\n            Entry::Vacant(entry) => entry.insert(Default::default()),\n        }\n    }\n}",
            "impl<K: Debug, V: Debug, S, A: Allocator> Debug for Entry<'_, K, V, S, A> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        match *self {\n            Entry::Vacant(ref v) => f.debug_tuple(\"Entry\").field(v).finish(),\n            Entry::Occupied(ref o) => f.debug_tuple(\"Entry\").field(o).finish(),\n        }\n    }\n}"
        ],
        "map::EntryRef": [
            "impl<'a, 'b, K, Q: ?Sized, V, S, A: Allocator> EntryRef<'a, 'b, K, Q, V, S, A> {\n    /// Sets the value of the entry, and returns an `OccupiedEntry`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut map: HashMap<String, u32> = HashMap::new();\n    /// let entry = map.entry_ref(\"horseyland\").insert(37);\n    ///\n    /// assert_eq!(entry.key(), \"horseyland\");\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn insert(self, value: V) -> OccupiedEntry<'a, K, V, S, A>\n    where\n        K: Hash,\n        &'b Q: Into<K>,\n        S: BuildHasher,\n    {\n        match self {\n            EntryRef::Occupied(mut entry) => {\n                entry.insert(value);\n                entry\n            }\n            EntryRef::Vacant(entry) => entry.insert_entry(value),\n        }\n    }\n\n    /// Ensures a value is in the entry by inserting the default if empty, and returns\n    /// a mutable reference to the value in the entry.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut map: HashMap<String, u32> = HashMap::new();\n    ///\n    /// // nonexistent key\n    /// map.entry_ref(\"poneyland\").or_insert(3);\n    /// assert_eq!(map[\"poneyland\"], 3);\n    ///\n    /// // existing key\n    /// *map.entry_ref(\"poneyland\").or_insert(10) *= 2;\n    /// assert_eq!(map[\"poneyland\"], 6);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn or_insert(self, default: V) -> &'a mut V\n    where\n        K: Hash,\n        &'b Q: Into<K>,\n        S: BuildHasher,\n    {\n        match self {\n            EntryRef::Occupied(entry) => entry.into_mut(),\n            EntryRef::Vacant(entry) => entry.insert(default),\n        }\n    }\n\n    /// Ensures a value is in the entry by inserting the result of the default function if empty,\n    /// and returns a mutable reference to the value in the entry.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut map: HashMap<String, u32> = HashMap::new();\n    ///\n    /// // nonexistent key\n    /// map.entry_ref(\"poneyland\").or_insert_with(|| 3);\n    /// assert_eq!(map[\"poneyland\"], 3);\n    ///\n    /// // existing key\n    /// *map.entry_ref(\"poneyland\").or_insert_with(|| 10) *= 2;\n    /// assert_eq!(map[\"poneyland\"], 6);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn or_insert_with<F: FnOnce() -> V>(self, default: F) -> &'a mut V\n    where\n        K: Hash,\n        &'b Q: Into<K>,\n        S: BuildHasher,\n    {\n        match self {\n            EntryRef::Occupied(entry) => entry.into_mut(),\n            EntryRef::Vacant(entry) => entry.insert(default()),\n        }\n    }\n\n    /// Ensures a value is in the entry by inserting, if empty, the result of the default function.\n    /// This method allows for generating key-derived values for insertion by providing the default\n    /// function an access to the borrower form of the key.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut map: HashMap<String, usize> = HashMap::new();\n    ///\n    /// // nonexistent key\n    /// map.entry_ref(\"poneyland\").or_insert_with_key(|key| key.chars().count());\n    /// assert_eq!(map[\"poneyland\"], 9);\n    ///\n    /// // existing key\n    /// *map.entry_ref(\"poneyland\").or_insert_with_key(|key| key.chars().count() * 10) *= 2;\n    /// assert_eq!(map[\"poneyland\"], 18);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn or_insert_with_key<F: FnOnce(&Q) -> V>(self, default: F) -> &'a mut V\n    where\n        K: Hash + Borrow<Q>,\n        &'b Q: Into<K>,\n        S: BuildHasher,\n    {\n        match self {\n            EntryRef::Occupied(entry) => entry.into_mut(),\n            EntryRef::Vacant(entry) => {\n                let value = default(entry.key);\n                entry.insert(value)\n            }\n        }\n    }\n\n    /// Returns a reference to this entry's key.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut map: HashMap<String, u32> = HashMap::new();\n    /// map.entry_ref(\"poneyland\").or_insert(3);\n    /// // existing key\n    /// assert_eq!(map.entry_ref(\"poneyland\").key(), \"poneyland\");\n    /// // nonexistent key\n    /// assert_eq!(map.entry_ref(\"horseland\").key(), \"horseland\");\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn key(&self) -> &Q\n    where\n        K: Borrow<Q>,\n    {\n        match *self {\n            EntryRef::Occupied(ref entry) => entry.key().borrow(),\n            EntryRef::Vacant(ref entry) => entry.key(),\n        }\n    }\n\n    /// Provides in-place mutable access to an occupied entry before any\n    /// potential inserts into the map.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut map: HashMap<String, u32> = HashMap::new();\n    ///\n    /// map.entry_ref(\"poneyland\")\n    ///    .and_modify(|e| { *e += 1 })\n    ///    .or_insert(42);\n    /// assert_eq!(map[\"poneyland\"], 42);\n    ///\n    /// map.entry_ref(\"poneyland\")\n    ///    .and_modify(|e| { *e += 1 })\n    ///    .or_insert(42);\n    /// assert_eq!(map[\"poneyland\"], 43);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn and_modify<F>(self, f: F) -> Self\n    where\n        F: FnOnce(&mut V),\n    {\n        match self {\n            EntryRef::Occupied(mut entry) => {\n                f(entry.get_mut());\n                EntryRef::Occupied(entry)\n            }\n            EntryRef::Vacant(entry) => EntryRef::Vacant(entry),\n        }\n    }\n}",
            "impl<'a, 'b, K, Q: ?Sized, V: Default, S, A: Allocator> EntryRef<'a, 'b, K, Q, V, S, A> {\n    /// Ensures a value is in the entry by inserting the default value if empty,\n    /// and returns a mutable reference to the value in the entry.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut map: HashMap<String, Option<u32>> = HashMap::new();\n    ///\n    /// // nonexistent key\n    /// map.entry_ref(\"poneyland\").or_default();\n    /// assert_eq!(map[\"poneyland\"], None);\n    ///\n    /// map.insert(\"horseland\".to_string(), Some(3));\n    ///\n    /// // existing key\n    /// assert_eq!(map.entry_ref(\"horseland\").or_default(), &mut Some(3));\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn or_default(self) -> &'a mut V\n    where\n        K: Hash,\n        &'b Q: Into<K>,\n        S: BuildHasher,\n    {\n        match self {\n            EntryRef::Occupied(entry) => entry.into_mut(),\n            EntryRef::Vacant(entry) => entry.insert(Default::default()),\n        }\n    }\n}",
            "impl<K, Q, V, S, A> Debug for EntryRef<'_, '_, K, Q, V, S, A>\nwhere\n    K: Debug + Borrow<Q>,\n    Q: Debug + ?Sized,\n    V: Debug,\n    A: Allocator,\n{\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        match *self {\n            EntryRef::Vacant(ref v) => f.debug_tuple(\"EntryRef\").field(v).finish(),\n            EntryRef::Occupied(ref o) => f.debug_tuple(\"EntryRef\").field(o).finish(),\n        }\n    }\n}"
        ],
        "map::ExtractIf": [
            "impl<K, V, F, A> Iterator for ExtractIf<'_, K, V, F, A>\nwhere\n    F: FnMut(&K, &mut V) -> bool,\n    A: Allocator,\n{\n    type Item = (K, V);\n\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn next(&mut self) -> Option<Self::Item> {\n        self.inner.next(|&mut (ref k, ref mut v)| (self.f)(k, v))\n    }\n\n    #[inline]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        (0, self.inner.iter.size_hint().1)\n    }\n}",
            "impl<K, V, F> FusedIterator for ExtractIf<'_, K, V, F> where F: FnMut(&K, &mut V) -> bool {}"
        ],
        "map::HashMap": [
            "impl<'a, K, V, S, A> Extend<&'a (K, V)> for HashMap<K, V, S, A>\nwhere\n    K: Eq + Hash + Copy,\n    V: Copy,\n    S: BuildHasher,\n    A: Allocator,\n{\n    /// Inserts all new key-values from the iterator to existing `HashMap<K, V, S, A>`.\n    /// Replace values with existing keys with new values returned from the iterator.\n    /// The keys and values must implement [`Copy`] trait.\n    ///\n    /// [`Copy`]: https://doc.rust-lang.org/core/marker/trait.Copy.html\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::hash_map::HashMap;\n    ///\n    /// let mut map = HashMap::new();\n    /// map.insert(1, 100);\n    ///\n    /// let arr = [(1, 1), (2, 2)];\n    /// let some_iter = arr.iter();\n    /// map.extend(some_iter);\n    /// // Replace values with existing keys with new values returned from the iterator.\n    /// // So that the map.get(&1) doesn't return Some(&100).\n    /// assert_eq!(map.get(&1), Some(&1));\n    ///\n    /// let some_vec: Vec<_> = vec![(3, 3), (4, 4)];\n    /// map.extend(&some_vec);\n    ///\n    /// let some_arr = [(5, 5), (6, 6)];\n    /// map.extend(&some_arr);\n    ///\n    /// let mut vec: Vec<_> = map.into_iter().collect();\n    /// // The `IntoIter` iterator produces items in arbitrary order, so the\n    /// // items must be sorted to test them against a sorted array.\n    /// vec.sort_unstable();\n    /// assert_eq!(vec, [(1, 1), (2, 2), (3, 3), (4, 4), (5, 5), (6, 6)]);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn extend<T: IntoIterator<Item = &'a (K, V)>>(&mut self, iter: T) {\n        self.extend(iter.into_iter().map(|&(key, value)| (key, value)));\n    }\n\n    #[inline]\n    #[cfg(feature = \"nightly\")]\n    fn extend_one(&mut self, &(k, v): &'a (K, V)) {\n        self.insert(k, v);\n    }\n\n    #[inline]\n    #[cfg(feature = \"nightly\")]\n    fn extend_reserve(&mut self, additional: usize) {\n        Extend::<(K, V)>::extend_reserve(self, additional);\n    }\n}",
            "impl<'a, K, V, S, A> Extend<(&'a K, &'a V)> for HashMap<K, V, S, A>\nwhere\n    K: Eq + Hash + Copy,\n    V: Copy,\n    S: BuildHasher,\n    A: Allocator,\n{\n    /// Inserts all new key-values from the iterator to existing `HashMap<K, V, S, A>`.\n    /// Replace values with existing keys with new values returned from the iterator.\n    /// The keys and values must implement [`Copy`] trait.\n    ///\n    /// [`Copy`]: https://doc.rust-lang.org/core/marker/trait.Copy.html\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::hash_map::HashMap;\n    ///\n    /// let mut map = HashMap::new();\n    /// map.insert(1, 100);\n    ///\n    /// let arr = [(1, 1), (2, 2)];\n    /// let some_iter = arr.iter().map(|(k, v)| (k, v));\n    /// map.extend(some_iter);\n    /// // Replace values with existing keys with new values returned from the iterator.\n    /// // So that the map.get(&1) doesn't return Some(&100).\n    /// assert_eq!(map.get(&1), Some(&1));\n    ///\n    /// let some_vec: Vec<_> = vec![(3, 3), (4, 4)];\n    /// map.extend(some_vec.iter().map(|(k, v)| (k, v)));\n    ///\n    /// let some_arr = [(5, 5), (6, 6)];\n    /// map.extend(some_arr.iter().map(|(k, v)| (k, v)));\n    ///\n    /// // You can also extend from another HashMap\n    /// let mut new_map = HashMap::new();\n    /// new_map.extend(&map);\n    /// assert_eq!(new_map, map);\n    ///\n    /// let mut vec: Vec<_> = new_map.into_iter().collect();\n    /// // The `IntoIter` iterator produces items in arbitrary order, so the\n    /// // items must be sorted to test them against a sorted array.\n    /// vec.sort_unstable();\n    /// assert_eq!(vec, [(1, 1), (2, 2), (3, 3), (4, 4), (5, 5), (6, 6)]);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn extend<T: IntoIterator<Item = (&'a K, &'a V)>>(&mut self, iter: T) {\n        self.extend(iter.into_iter().map(|(&key, &value)| (key, value)));\n    }\n\n    #[inline]\n    #[cfg(feature = \"nightly\")]\n    fn extend_one(&mut self, (k, v): (&'a K, &'a V)) {\n        self.insert(*k, *v);\n    }\n\n    #[inline]\n    #[cfg(feature = \"nightly\")]\n    fn extend_reserve(&mut self, additional: usize) {\n        Extend::<(K, V)>::extend_reserve(self, additional);\n    }\n}",
            "impl<K, Q, V, S, A> Index<&Q> for HashMap<K, V, S, A>\nwhere\n    K: Eq + Hash,\n    Q: Hash + Equivalent<K> + ?Sized,\n    S: BuildHasher,\n    A: Allocator,\n{\n    type Output = V;\n\n    /// Returns a reference to the value corresponding to the supplied key.\n    ///\n    /// # Panics\n    ///\n    /// Panics if the key is not present in the `HashMap`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let map: HashMap<_, _> = [(\"a\", \"One\"), (\"b\", \"Two\")].into();\n    ///\n    /// assert_eq!(map[&\"a\"], \"One\");\n    /// assert_eq!(map[&\"b\"], \"Two\");\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn index(&self, key: &Q) -> &V {\n        self.get(key).expect(\"no entry found for key\")\n    }\n}",
            "impl<K, V, A, const N: usize> From<[(K, V); N]> for HashMap<K, V, DefaultHashBuilder, A>\nwhere\n    K: Eq + Hash,\n    A: Default + Allocator,\n{\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let map1 = HashMap::from([(1, 2), (3, 4)]);\n    /// let map2: HashMap<_, _> = [(1, 2), (3, 4)].into();\n    /// assert_eq!(map1, map2);\n    /// ```\n    fn from(arr: [(K, V); N]) -> Self {\n        arr.into_iter().collect()\n    }\n}",
            "impl<K, V, A: Allocator> HashMap<K, V, DefaultHashBuilder, A> {\n    /// Creates an empty `HashMap` using the given allocator.\n    ///\n    /// The hash map is initially created with a capacity of 0, so it will not allocate until it\n    /// is first inserted into.\n    ///\n    /// # HashDoS resistance\n    ///\n    /// The `hash_builder` normally use a fixed key by default and that does\n    /// not allow the `HashMap` to be protected against attacks such as [`HashDoS`].\n    /// Users who require HashDoS resistance should explicitly use\n    /// [`std::collections::hash_map::RandomState`]\n    /// as the hasher when creating a [`HashMap`], for example with\n    /// [`with_hasher_in`](HashMap::with_hasher_in) method.\n    ///\n    /// [`HashDoS`]: https://en.wikipedia.org/wiki/Collision_attack\n    /// [`std::collections::hash_map::RandomState`]: https://doc.rust-lang.org/std/collections/hash_map/struct.RandomState.html\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    /// use bumpalo::Bump;\n    ///\n    /// let bump = Bump::new();\n    /// let mut map = HashMap::new_in(&bump);\n    ///\n    /// // The created HashMap holds none elements\n    /// assert_eq!(map.len(), 0);\n    ///\n    /// // The created HashMap also doesn't allocate memory\n    /// assert_eq!(map.capacity(), 0);\n    ///\n    /// // Now we insert element inside created HashMap\n    /// map.insert(\"One\", 1);\n    /// // We can see that the HashMap holds 1 element\n    /// assert_eq!(map.len(), 1);\n    /// // And it also allocates some capacity\n    /// assert!(map.capacity() > 1);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn new_in(alloc: A) -> Self {\n        Self::with_hasher_in(DefaultHashBuilder::default(), alloc)\n    }\n\n    /// Creates an empty `HashMap` with the specified capacity using the given allocator.\n    ///\n    /// The hash map will be able to hold at least `capacity` elements without\n    /// reallocating. If `capacity` is 0, the hash map will not allocate.\n    ///\n    /// # HashDoS resistance\n    ///\n    /// The `hash_builder` normally use a fixed key by default and that does\n    /// not allow the `HashMap` to be protected against attacks such as [`HashDoS`].\n    /// Users who require HashDoS resistance should explicitly use\n    /// [`std::collections::hash_map::RandomState`]\n    /// as the hasher when creating a [`HashMap`], for example with\n    /// [`with_capacity_and_hasher_in`](HashMap::with_capacity_and_hasher_in) method.\n    ///\n    /// [`HashDoS`]: https://en.wikipedia.org/wiki/Collision_attack\n    /// [`std::collections::hash_map::RandomState`]: https://doc.rust-lang.org/std/collections/hash_map/struct.RandomState.html\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    /// use bumpalo::Bump;\n    ///\n    /// let bump = Bump::new();\n    /// let mut map = HashMap::with_capacity_in(5, &bump);\n    ///\n    /// // The created HashMap holds none elements\n    /// assert_eq!(map.len(), 0);\n    /// // But it can hold at least 5 elements without reallocating\n    /// let empty_map_capacity = map.capacity();\n    /// assert!(empty_map_capacity >= 5);\n    ///\n    /// // Now we insert some 5 elements inside created HashMap\n    /// map.insert(\"One\",   1);\n    /// map.insert(\"Two\",   2);\n    /// map.insert(\"Three\", 3);\n    /// map.insert(\"Four\",  4);\n    /// map.insert(\"Five\",  5);\n    ///\n    /// // We can see that the HashMap holds 5 elements\n    /// assert_eq!(map.len(), 5);\n    /// // But its capacity isn't changed\n    /// assert_eq!(map.capacity(), empty_map_capacity)\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn with_capacity_in(capacity: usize, alloc: A) -> Self {\n        Self::with_capacity_and_hasher_in(capacity, DefaultHashBuilder::default(), alloc)\n    }\n}",
            "impl<K, V, S, A: Allocator> HashMap<K, V, S, A> {\n    /// Creates a raw entry builder for the `HashMap`.\n    ///\n    /// Raw entries provide the lowest level of control for searching and\n    /// manipulating a map. They must be manually initialized with a hash and\n    /// then manually searched. After this, insertions into a vacant entry\n    /// still require an owned key to be provided.\n    ///\n    /// Raw entries are useful for such exotic situations as:\n    ///\n    /// * Hash memoization\n    /// * Deferring the creation of an owned key until it is known to be required\n    /// * Using a search key that doesn't work with the Borrow trait\n    /// * Using custom comparison logic without newtype wrappers\n    ///\n    /// Because raw entries provide much more low-level control, it's much easier\n    /// to put the `HashMap` into an inconsistent state which, while memory-safe,\n    /// will cause the map to produce seemingly random results. Higher-level and\n    /// more foolproof APIs like `entry` should be preferred when possible.\n    ///\n    /// In particular, the hash used to initialized the raw entry must still be\n    /// consistent with the hash of the key that is ultimately stored in the entry.\n    /// This is because implementations of `HashMap` may need to recompute hashes\n    /// when resizing, at which point only the keys are available.\n    ///\n    /// Raw entries give mutable access to the keys. This must not be used\n    /// to modify how the key would compare or hash, as the map will not re-evaluate\n    /// where the key should go, meaning the keys may become \"lost\" if their\n    /// location does not reflect their state. For instance, if you change a key\n    /// so that the map now contains keys which compare equal, search may start\n    /// acting erratically, with two keys randomly masking each other. Implementations\n    /// are free to assume this doesn't happen (within the limits of memory-safety).\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use core::hash::{BuildHasher, Hash};\n    /// use hashbrown::hash_map::{HashMap, RawEntryMut};\n    ///\n    /// let mut map = HashMap::new();\n    /// map.extend([(\"a\", 100), (\"b\", 200), (\"c\", 300)]);\n    ///\n    /// fn compute_hash<K: Hash + ?Sized, S: BuildHasher>(hash_builder: &S, key: &K) -> u64 {\n    ///     use core::hash::Hasher;\n    ///     let mut state = hash_builder.build_hasher();\n    ///     key.hash(&mut state);\n    ///     state.finish()\n    /// }\n    ///\n    /// // Existing key (insert and update)\n    /// match map.raw_entry_mut().from_key(&\"a\") {\n    ///     RawEntryMut::Vacant(_) => unreachable!(),\n    ///     RawEntryMut::Occupied(mut view) => {\n    ///         assert_eq!(view.get(), &100);\n    ///         let v = view.get_mut();\n    ///         let new_v = (*v) * 10;\n    ///         *v = new_v;\n    ///         assert_eq!(view.insert(1111), 1000);\n    ///     }\n    /// }\n    ///\n    /// assert_eq!(map[&\"a\"], 1111);\n    /// assert_eq!(map.len(), 3);\n    ///\n    /// // Existing key (take)\n    /// let hash = compute_hash(map.hasher(), &\"c\");\n    /// match map.raw_entry_mut().from_key_hashed_nocheck(hash, &\"c\") {\n    ///     RawEntryMut::Vacant(_) => unreachable!(),\n    ///     RawEntryMut::Occupied(view) => {\n    ///         assert_eq!(view.remove_entry(), (\"c\", 300));\n    ///     }\n    /// }\n    /// assert_eq!(map.raw_entry().from_key(&\"c\"), None);\n    /// assert_eq!(map.len(), 2);\n    ///\n    /// // Nonexistent key (insert and update)\n    /// let key = \"d\";\n    /// let hash = compute_hash(map.hasher(), &key);\n    /// match map.raw_entry_mut().from_hash(hash, |q| *q == key) {\n    ///     RawEntryMut::Occupied(_) => unreachable!(),\n    ///     RawEntryMut::Vacant(view) => {\n    ///         let (k, value) = view.insert(\"d\", 4000);\n    ///         assert_eq!((*k, *value), (\"d\", 4000));\n    ///         *value = 40000;\n    ///     }\n    /// }\n    /// assert_eq!(map[&\"d\"], 40000);\n    /// assert_eq!(map.len(), 3);\n    ///\n    /// match map.raw_entry_mut().from_hash(hash, |q| *q == key) {\n    ///     RawEntryMut::Vacant(_) => unreachable!(),\n    ///     RawEntryMut::Occupied(view) => {\n    ///         assert_eq!(view.remove_entry(), (\"d\", 40000));\n    ///     }\n    /// }\n    /// assert_eq!(map.get(&\"d\"), None);\n    /// assert_eq!(map.len(), 2);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn raw_entry_mut(&mut self) -> RawEntryBuilderMut<'_, K, V, S, A> {\n        RawEntryBuilderMut { map: self }\n    }\n\n    /// Creates a raw immutable entry builder for the `HashMap`.\n    ///\n    /// Raw entries provide the lowest level of control for searching and\n    /// manipulating a map. They must be manually initialized with a hash and\n    /// then manually searched.\n    ///\n    /// This is useful for\n    /// * Hash memoization\n    /// * Using a search key that doesn't work with the Borrow trait\n    /// * Using custom comparison logic without newtype wrappers\n    ///\n    /// Unless you are in such a situation, higher-level and more foolproof APIs like\n    /// `get` should be preferred.\n    ///\n    /// Immutable raw entries have very limited use; you might instead want `raw_entry_mut`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use core::hash::{BuildHasher, Hash};\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut map = HashMap::new();\n    /// map.extend([(\"a\", 100), (\"b\", 200), (\"c\", 300)]);\n    ///\n    /// fn compute_hash<K: Hash + ?Sized, S: BuildHasher>(hash_builder: &S, key: &K) -> u64 {\n    ///     use core::hash::Hasher;\n    ///     let mut state = hash_builder.build_hasher();\n    ///     key.hash(&mut state);\n    ///     state.finish()\n    /// }\n    ///\n    /// for k in [\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"] {\n    ///     let hash = compute_hash(map.hasher(), k);\n    ///     let v = map.get(&k).cloned();\n    ///     let kv = v.as_ref().map(|v| (&k, v));\n    ///\n    ///     println!(\"Key: {} and value: {:?}\", k, v);\n    ///\n    ///     assert_eq!(map.raw_entry().from_key(&k), kv);\n    ///     assert_eq!(map.raw_entry().from_hash(hash, |q| *q == k), kv);\n    ///     assert_eq!(map.raw_entry().from_key_hashed_nocheck(hash, &k), kv);\n    /// }\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn raw_entry(&self) -> RawEntryBuilder<'_, K, V, S, A> {\n        RawEntryBuilder { map: self }\n    }\n}",
            "impl<K, V, S, A: Allocator> HashMap<K, V, S, A> {\n    /// Returns a reference to the underlying allocator.\n    #[inline]\n    pub fn allocator(&self) -> &A {\n        self.table.allocator()\n    }\n\n    /// Creates an empty `HashMap` which will use the given hash builder to hash\n    /// keys. It will be allocated with the given allocator.\n    ///\n    /// The hash map is initially created with a capacity of 0, so it will not allocate until it\n    /// is first inserted into.\n    ///\n    /// # HashDoS resistance\n    ///\n    /// The `hash_builder` normally use a fixed key by default and that does\n    /// not allow the `HashMap` to be protected against attacks such as [`HashDoS`].\n    /// Users who require HashDoS resistance should explicitly use\n    /// [`std::collections::hash_map::RandomState`]\n    /// as the hasher when creating a [`HashMap`].\n    ///\n    /// [`HashDoS`]: https://en.wikipedia.org/wiki/Collision_attack\n    /// [`std::collections::hash_map::RandomState`]: https://doc.rust-lang.org/std/collections/hash_map/struct.RandomState.html\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    /// use hashbrown::DefaultHashBuilder;\n    ///\n    /// let s = DefaultHashBuilder::default();\n    /// let mut map = HashMap::with_hasher(s);\n    /// map.insert(1, 2);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    #[cfg_attr(feature = \"rustc-dep-of-std\", rustc_const_stable_indirect)]\n    pub const fn with_hasher_in(hash_builder: S, alloc: A) -> Self {\n        Self {\n            hash_builder,\n            table: RawTable::new_in(alloc),\n        }\n    }\n\n    /// Creates an empty `HashMap` with the specified capacity, using `hash_builder`\n    /// to hash the keys. It will be allocated with the given allocator.\n    ///\n    /// The hash map will be able to hold at least `capacity` elements without\n    /// reallocating. If `capacity` is 0, the hash map will not allocate.\n    ///\n    /// # HashDoS resistance\n    ///\n    /// The `hash_builder` normally use a fixed key by default and that does\n    /// not allow the `HashMap` to be protected against attacks such as [`HashDoS`].\n    /// Users who require HashDoS resistance should explicitly use\n    /// [`std::collections::hash_map::RandomState`]\n    /// as the hasher when creating a [`HashMap`].\n    ///\n    /// [`HashDoS`]: https://en.wikipedia.org/wiki/Collision_attack\n    /// [`std::collections::hash_map::RandomState`]: https://doc.rust-lang.org/std/collections/hash_map/struct.RandomState.html\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    /// use hashbrown::DefaultHashBuilder;\n    ///\n    /// let s = DefaultHashBuilder::default();\n    /// let mut map = HashMap::with_capacity_and_hasher(10, s);\n    /// map.insert(1, 2);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn with_capacity_and_hasher_in(capacity: usize, hash_builder: S, alloc: A) -> Self {\n        Self {\n            hash_builder,\n            table: RawTable::with_capacity_in(capacity, alloc),\n        }\n    }\n\n    /// Returns a reference to the map's [`BuildHasher`].\n    ///\n    /// [`BuildHasher`]: https://doc.rust-lang.org/std/hash/trait.BuildHasher.html\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    /// use hashbrown::DefaultHashBuilder;\n    ///\n    /// let hasher = DefaultHashBuilder::default();\n    /// let map: HashMap<i32, i32> = HashMap::with_hasher(hasher);\n    /// let hasher: &DefaultHashBuilder = map.hasher();\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn hasher(&self) -> &S {\n        &self.hash_builder\n    }\n\n    /// Returns the number of elements the map can hold without reallocating.\n    ///\n    /// This number is a lower bound; the `HashMap<K, V>` might be able to hold\n    /// more, but is guaranteed to be able to hold at least this many.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    /// let map: HashMap<i32, i32> = HashMap::with_capacity(100);\n    /// assert_eq!(map.len(), 0);\n    /// assert!(map.capacity() >= 100);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn capacity(&self) -> usize {\n        self.table.capacity()\n    }\n\n    /// An iterator visiting all keys in arbitrary order.\n    /// The iterator element type is `&'a K`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut map = HashMap::new();\n    /// map.insert(\"a\", 1);\n    /// map.insert(\"b\", 2);\n    /// map.insert(\"c\", 3);\n    /// assert_eq!(map.len(), 3);\n    /// let mut vec: Vec<&str> = Vec::new();\n    ///\n    /// for key in map.keys() {\n    ///     println!(\"{}\", key);\n    ///     vec.push(*key);\n    /// }\n    ///\n    /// // The `Keys` iterator produces keys in arbitrary order, so the\n    /// // keys must be sorted to test them against a sorted array.\n    /// vec.sort_unstable();\n    /// assert_eq!(vec, [\"a\", \"b\", \"c\"]);\n    ///\n    /// assert_eq!(map.len(), 3);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn keys(&self) -> Keys<'_, K, V> {\n        Keys { inner: self.iter() }\n    }\n\n    /// An iterator visiting all values in arbitrary order.\n    /// The iterator element type is `&'a V`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut map = HashMap::new();\n    /// map.insert(\"a\", 1);\n    /// map.insert(\"b\", 2);\n    /// map.insert(\"c\", 3);\n    /// assert_eq!(map.len(), 3);\n    /// let mut vec: Vec<i32> = Vec::new();\n    ///\n    /// for val in map.values() {\n    ///     println!(\"{}\", val);\n    ///     vec.push(*val);\n    /// }\n    ///\n    /// // The `Values` iterator produces values in arbitrary order, so the\n    /// // values must be sorted to test them against a sorted array.\n    /// vec.sort_unstable();\n    /// assert_eq!(vec, [1, 2, 3]);\n    ///\n    /// assert_eq!(map.len(), 3);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn values(&self) -> Values<'_, K, V> {\n        Values { inner: self.iter() }\n    }\n\n    /// An iterator visiting all values mutably in arbitrary order.\n    /// The iterator element type is `&'a mut V`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut map = HashMap::new();\n    ///\n    /// map.insert(\"a\", 1);\n    /// map.insert(\"b\", 2);\n    /// map.insert(\"c\", 3);\n    ///\n    /// for val in map.values_mut() {\n    ///     *val = *val + 10;\n    /// }\n    ///\n    /// assert_eq!(map.len(), 3);\n    /// let mut vec: Vec<i32> = Vec::new();\n    ///\n    /// for val in map.values() {\n    ///     println!(\"{}\", val);\n    ///     vec.push(*val);\n    /// }\n    ///\n    /// // The `Values` iterator produces values in arbitrary order, so the\n    /// // values must be sorted to test them against a sorted array.\n    /// vec.sort_unstable();\n    /// assert_eq!(vec, [11, 12, 13]);\n    ///\n    /// assert_eq!(map.len(), 3);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn values_mut(&mut self) -> ValuesMut<'_, K, V> {\n        ValuesMut {\n            inner: self.iter_mut(),\n        }\n    }\n\n    /// An iterator visiting all key-value pairs in arbitrary order.\n    /// The iterator element type is `(&'a K, &'a V)`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut map = HashMap::new();\n    /// map.insert(\"a\", 1);\n    /// map.insert(\"b\", 2);\n    /// map.insert(\"c\", 3);\n    /// assert_eq!(map.len(), 3);\n    /// let mut vec: Vec<(&str, i32)> = Vec::new();\n    ///\n    /// for (key, val) in map.iter() {\n    ///     println!(\"key: {} val: {}\", key, val);\n    ///     vec.push((*key, *val));\n    /// }\n    ///\n    /// // The `Iter` iterator produces items in arbitrary order, so the\n    /// // items must be sorted to test them against a sorted array.\n    /// vec.sort_unstable();\n    /// assert_eq!(vec, [(\"a\", 1), (\"b\", 2), (\"c\", 3)]);\n    ///\n    /// assert_eq!(map.len(), 3);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn iter(&self) -> Iter<'_, K, V> {\n        // Here we tie the lifetime of self to the iter.\n        unsafe {\n            Iter {\n                inner: self.table.iter(),\n                marker: PhantomData,\n            }\n        }\n    }\n\n    /// An iterator visiting all key-value pairs in arbitrary order,\n    /// with mutable references to the values.\n    /// The iterator element type is `(&'a K, &'a mut V)`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut map = HashMap::new();\n    /// map.insert(\"a\", 1);\n    /// map.insert(\"b\", 2);\n    /// map.insert(\"c\", 3);\n    ///\n    /// // Update all values\n    /// for (_, val) in map.iter_mut() {\n    ///     *val *= 2;\n    /// }\n    ///\n    /// assert_eq!(map.len(), 3);\n    /// let mut vec: Vec<(&str, i32)> = Vec::new();\n    ///\n    /// for (key, val) in &map {\n    ///     println!(\"key: {} val: {}\", key, val);\n    ///     vec.push((*key, *val));\n    /// }\n    ///\n    /// // The `Iter` iterator produces items in arbitrary order, so the\n    /// // items must be sorted to test them against a sorted array.\n    /// vec.sort_unstable();\n    /// assert_eq!(vec, [(\"a\", 2), (\"b\", 4), (\"c\", 6)]);\n    ///\n    /// assert_eq!(map.len(), 3);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn iter_mut(&mut self) -> IterMut<'_, K, V> {\n        // Here we tie the lifetime of self to the iter.\n        unsafe {\n            IterMut {\n                inner: self.table.iter(),\n                marker: PhantomData,\n            }\n        }\n    }\n\n    #[cfg(test)]\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn raw_capacity(&self) -> usize {\n        self.table.buckets()\n    }\n\n    /// Returns the number of elements in the map.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut a = HashMap::new();\n    /// assert_eq!(a.len(), 0);\n    /// a.insert(1, \"a\");\n    /// assert_eq!(a.len(), 1);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn len(&self) -> usize {\n        self.table.len()\n    }\n\n    /// Returns `true` if the map contains no elements.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut a = HashMap::new();\n    /// assert!(a.is_empty());\n    /// a.insert(1, \"a\");\n    /// assert!(!a.is_empty());\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn is_empty(&self) -> bool {\n        self.len() == 0\n    }\n\n    /// Clears the map, returning all key-value pairs as an iterator. Keeps the\n    /// allocated memory for reuse.\n    ///\n    /// If the returned iterator is dropped before being fully consumed, it\n    /// drops the remaining key-value pairs. The returned iterator keeps a\n    /// mutable borrow on the vector to optimize its implementation.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut a = HashMap::new();\n    /// a.insert(1, \"a\");\n    /// a.insert(2, \"b\");\n    /// let capacity_before_drain = a.capacity();\n    ///\n    /// for (k, v) in a.drain().take(1) {\n    ///     assert!(k == 1 || k == 2);\n    ///     assert!(v == \"a\" || v == \"b\");\n    /// }\n    ///\n    /// // As we can see, the map is empty and contains no element.\n    /// assert!(a.is_empty() && a.len() == 0);\n    /// // But map capacity is equal to old one.\n    /// assert_eq!(a.capacity(), capacity_before_drain);\n    ///\n    /// let mut a = HashMap::new();\n    /// a.insert(1, \"a\");\n    /// a.insert(2, \"b\");\n    ///\n    /// {   // Iterator is dropped without being consumed.\n    ///     let d = a.drain();\n    /// }\n    ///\n    /// // But the map is empty even if we do not use Drain iterator.\n    /// assert!(a.is_empty());\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn drain(&mut self) -> Drain<'_, K, V, A> {\n        Drain {\n            inner: self.table.drain(),\n        }\n    }\n\n    /// Retains only the elements specified by the predicate. Keeps the\n    /// allocated memory for reuse.\n    ///\n    /// In other words, remove all pairs `(k, v)` such that `f(&k, &mut v)` returns `false`.\n    /// The elements are visited in unsorted (and unspecified) order.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut map: HashMap<i32, i32> = (0..8).map(|x|(x, x*10)).collect();\n    /// assert_eq!(map.len(), 8);\n    ///\n    /// map.retain(|&k, _| k % 2 == 0);\n    ///\n    /// // We can see, that the number of elements inside map is changed.\n    /// assert_eq!(map.len(), 4);\n    ///\n    /// let mut vec: Vec<(i32, i32)> = map.iter().map(|(&k, &v)| (k, v)).collect();\n    /// vec.sort_unstable();\n    /// assert_eq!(vec, [(0, 0), (2, 20), (4, 40), (6, 60)]);\n    /// ```\n    pub fn retain<F>(&mut self, mut f: F)\n    where\n        F: FnMut(&K, &mut V) -> bool,\n    {\n        // Here we only use `iter` as a temporary, preventing use-after-free\n        unsafe {\n            for item in self.table.iter() {\n                let &mut (ref key, ref mut value) = item.as_mut();\n                if !f(key, value) {\n                    self.table.erase(item);\n                }\n            }\n        }\n    }\n\n    /// Drains elements which are true under the given predicate,\n    /// and returns an iterator over the removed items.\n    ///\n    /// In other words, move all pairs `(k, v)` such that `f(&k, &mut v)` returns `true` out\n    /// into another iterator.\n    ///\n    /// Note that `extract_if` lets you mutate every value in the filter closure, regardless of\n    /// whether you choose to keep or remove it.\n    ///\n    /// If the returned `ExtractIf` is not exhausted, e.g. because it is dropped without iterating\n    /// or the iteration short-circuits, then the remaining elements will be retained.\n    /// Use [`retain()`] with a negated predicate if you do not need the returned iterator.\n    ///\n    /// Keeps the allocated memory for reuse.\n    ///\n    /// [`retain()`]: HashMap::retain\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut map: HashMap<i32, i32> = (0..8).map(|x| (x, x)).collect();\n    ///\n    /// let drained: HashMap<i32, i32> = map.extract_if(|k, _v| k % 2 == 0).collect();\n    ///\n    /// let mut evens = drained.keys().cloned().collect::<Vec<_>>();\n    /// let mut odds = map.keys().cloned().collect::<Vec<_>>();\n    /// evens.sort();\n    /// odds.sort();\n    ///\n    /// assert_eq!(evens, vec![0, 2, 4, 6]);\n    /// assert_eq!(odds, vec![1, 3, 5, 7]);\n    ///\n    /// let mut map: HashMap<i32, i32> = (0..8).map(|x| (x, x)).collect();\n    ///\n    /// {   // Iterator is dropped without being consumed.\n    ///     let d = map.extract_if(|k, _v| k % 2 != 0);\n    /// }\n    ///\n    /// // ExtractIf was not exhausted, therefore no elements were drained.\n    /// assert_eq!(map.len(), 8);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn extract_if<F>(&mut self, f: F) -> ExtractIf<'_, K, V, F, A>\n    where\n        F: FnMut(&K, &mut V) -> bool,\n    {\n        ExtractIf {\n            f,\n            inner: RawExtractIf {\n                iter: unsafe { self.table.iter() },\n                table: &mut self.table,\n            },\n        }\n    }\n\n    /// Clears the map, removing all key-value pairs. Keeps the allocated memory\n    /// for reuse.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut a = HashMap::new();\n    /// a.insert(1, \"a\");\n    /// let capacity_before_clear = a.capacity();\n    ///\n    /// a.clear();\n    ///\n    /// // Map is empty.\n    /// assert!(a.is_empty());\n    /// // But map capacity is equal to old one.\n    /// assert_eq!(a.capacity(), capacity_before_clear);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn clear(&mut self) {\n        self.table.clear();\n    }\n\n    /// Creates a consuming iterator visiting all the keys in arbitrary order.\n    /// The map cannot be used after calling this.\n    /// The iterator element type is `K`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut map = HashMap::new();\n    /// map.insert(\"a\", 1);\n    /// map.insert(\"b\", 2);\n    /// map.insert(\"c\", 3);\n    ///\n    /// let mut vec: Vec<&str> = map.into_keys().collect();\n    ///\n    /// // The `IntoKeys` iterator produces keys in arbitrary order, so the\n    /// // keys must be sorted to test them against a sorted array.\n    /// vec.sort_unstable();\n    /// assert_eq!(vec, [\"a\", \"b\", \"c\"]);\n    /// ```\n    #[inline]\n    pub fn into_keys(self) -> IntoKeys<K, V, A> {\n        IntoKeys {\n            inner: self.into_iter(),\n        }\n    }\n\n    /// Creates a consuming iterator visiting all the values in arbitrary order.\n    /// The map cannot be used after calling this.\n    /// The iterator element type is `V`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut map = HashMap::new();\n    /// map.insert(\"a\", 1);\n    /// map.insert(\"b\", 2);\n    /// map.insert(\"c\", 3);\n    ///\n    /// let mut vec: Vec<i32> = map.into_values().collect();\n    ///\n    /// // The `IntoValues` iterator produces values in arbitrary order, so\n    /// // the values must be sorted to test them against a sorted array.\n    /// vec.sort_unstable();\n    /// assert_eq!(vec, [1, 2, 3]);\n    /// ```\n    #[inline]\n    pub fn into_values(self) -> IntoValues<K, V, A> {\n        IntoValues {\n            inner: self.into_iter(),\n        }\n    }\n}",
            "impl<K, V, S, A: Allocator> IntoIterator for HashMap<K, V, S, A> {\n    type Item = (K, V);\n    type IntoIter = IntoIter<K, V, A>;\n\n    /// Creates a consuming iterator, that is, one that moves each key-value\n    /// pair out of the map in arbitrary order. The map cannot be used after\n    /// calling this.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let map: HashMap<_, _> = [(\"a\", 1), (\"b\", 2), (\"c\", 3)].into();\n    ///\n    /// // Not possible with .iter()\n    /// let mut vec: Vec<(&str, i32)> = map.into_iter().collect();\n    /// // The `IntoIter` iterator produces items in arbitrary order, so\n    /// // the items must be sorted to test them against a sorted array.\n    /// vec.sort_unstable();\n    /// assert_eq!(vec, [(\"a\", 1), (\"b\", 2), (\"c\", 3)]);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn into_iter(self) -> IntoIter<K, V, A> {\n        IntoIter {\n            inner: self.table.into_iter(),\n        }\n    }\n}",
            "impl<K, V, S, A> Debug for HashMap<K, V, S, A>\nwhere\n    K: Debug,\n    V: Debug,\n    A: Allocator,\n{\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_map().entries(self.iter()).finish()\n    }\n}",
            "impl<K, V, S, A> Default for HashMap<K, V, S, A>\nwhere\n    S: Default,\n    A: Default + Allocator,\n{\n    /// Creates an empty `HashMap<K, V, S, A>`, with the `Default` value for the hasher and allocator.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    /// use std::collections::hash_map::RandomState;\n    ///\n    /// // You can specify all types of HashMap, including hasher and allocator.\n    /// // Created map is empty and don't allocate memory\n    /// let map: HashMap<u32, String> = Default::default();\n    /// assert_eq!(map.capacity(), 0);\n    /// let map: HashMap<u32, String, RandomState> = HashMap::default();\n    /// assert_eq!(map.capacity(), 0);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn default() -> Self {\n        Self::with_hasher_in(Default::default(), Default::default())\n    }\n}",
            "impl<K, V, S, A> Eq for HashMap<K, V, S, A>\nwhere\n    K: Eq + Hash,\n    V: Eq,\n    S: BuildHasher,\n    A: Allocator,\n{\n}",
            "impl<K, V, S, A> Extend<(K, V)> for HashMap<K, V, S, A>\nwhere\n    K: Eq + Hash,\n    S: BuildHasher,\n    A: Allocator,\n{\n    /// Inserts all new key-values from the iterator to existing `HashMap<K, V, S, A>`.\n    /// Replace values with existing keys with new values returned from the iterator.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::hash_map::HashMap;\n    ///\n    /// let mut map = HashMap::new();\n    /// map.insert(1, 100);\n    ///\n    /// let some_iter = [(1, 1), (2, 2)].into_iter();\n    /// map.extend(some_iter);\n    /// // Replace values with existing keys with new values returned from the iterator.\n    /// // So that the map.get(&1) doesn't return Some(&100).\n    /// assert_eq!(map.get(&1), Some(&1));\n    ///\n    /// let some_vec: Vec<_> = vec![(3, 3), (4, 4)];\n    /// map.extend(some_vec);\n    ///\n    /// let some_arr = [(5, 5), (6, 6)];\n    /// map.extend(some_arr);\n    /// let old_map_len = map.len();\n    ///\n    /// // You can also extend from another HashMap\n    /// let mut new_map = HashMap::new();\n    /// new_map.extend(map);\n    /// assert_eq!(new_map.len(), old_map_len);\n    ///\n    /// let mut vec: Vec<_> = new_map.into_iter().collect();\n    /// // The `IntoIter` iterator produces items in arbitrary order, so the\n    /// // items must be sorted to test them against a sorted array.\n    /// vec.sort_unstable();\n    /// assert_eq!(vec, [(1, 1), (2, 2), (3, 3), (4, 4), (5, 5), (6, 6)]);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn extend<T: IntoIterator<Item = (K, V)>>(&mut self, iter: T) {\n        // Keys may be already present or show multiple times in the iterator.\n        // Reserve the entire hint lower bound if the map is empty.\n        // Otherwise reserve half the hint (rounded up), so the map\n        // will only resize twice in the worst case.\n        let iter = iter.into_iter();\n        let reserve = if self.is_empty() {\n            iter.size_hint().0\n        } else {\n            (iter.size_hint().0 + 1) / 2\n        };\n        self.reserve(reserve);\n        iter.for_each(move |(k, v)| {\n            self.insert(k, v);\n        });\n    }\n\n    #[inline]\n    #[cfg(feature = \"nightly\")]\n    fn extend_one(&mut self, (k, v): (K, V)) {\n        self.insert(k, v);\n    }\n\n    #[inline]\n    #[cfg(feature = \"nightly\")]\n    fn extend_reserve(&mut self, additional: usize) {\n        // Keys may be already present or show multiple times in the iterator.\n        // Reserve the entire hint lower bound if the map is empty.\n        // Otherwise reserve half the hint (rounded up), so the map\n        // will only resize twice in the worst case.\n        let reserve = if self.is_empty() {\n            additional\n        } else {\n            (additional + 1) / 2\n        };\n        self.reserve(reserve);\n    }\n}",
            "impl<K, V, S, A> FromIterator<(K, V)> for HashMap<K, V, S, A>\nwhere\n    K: Eq + Hash,\n    S: BuildHasher + Default,\n    A: Default + Allocator,\n{\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn from_iter<T: IntoIterator<Item = (K, V)>>(iter: T) -> Self {\n        let iter = iter.into_iter();\n        let mut map =\n            Self::with_capacity_and_hasher_in(iter.size_hint().0, S::default(), A::default());\n        iter.for_each(|(k, v)| {\n            map.insert(k, v);\n        });\n        map\n    }\n}",
            "impl<K, V, S, A> HashMap<K, V, S, A>\nwhere\n    K: Eq + Hash,\n    S: BuildHasher,\n    A: Allocator,\n{\n    /// Reserves capacity for at least `additional` more elements to be inserted\n    /// in the `HashMap`. The collection may reserve more space to avoid\n    /// frequent reallocations.\n    ///\n    /// # Panics\n    ///\n    /// Panics if the new capacity exceeds [`isize::MAX`] bytes and [`abort`] the program\n    /// in case of allocation error. Use [`try_reserve`](HashMap::try_reserve) instead\n    /// if you want to handle memory allocation failure.\n    ///\n    /// [`isize::MAX`]: https://doc.rust-lang.org/std/primitive.isize.html\n    /// [`abort`]: https://doc.rust-lang.org/alloc/alloc/fn.handle_alloc_error.html\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    /// let mut map: HashMap<&str, i32> = HashMap::new();\n    /// // Map is empty and doesn't allocate memory\n    /// assert_eq!(map.capacity(), 0);\n    ///\n    /// map.reserve(10);\n    ///\n    /// // And now map can hold at least 10 elements\n    /// assert!(map.capacity() >= 10);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn reserve(&mut self, additional: usize) {\n        self.table\n            .reserve(additional, make_hasher::<_, V, S>(&self.hash_builder));\n    }\n\n    /// Tries to reserve capacity for at least `additional` more elements to be inserted\n    /// in the given `HashMap<K,V>`. The collection may reserve more space to avoid\n    /// frequent reallocations.\n    ///\n    /// # Errors\n    ///\n    /// If the capacity overflows, or the allocator reports a failure, then an error\n    /// is returned.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut map: HashMap<&str, isize> = HashMap::new();\n    /// // Map is empty and doesn't allocate memory\n    /// assert_eq!(map.capacity(), 0);\n    ///\n    /// map.try_reserve(10).expect(\"why is the test harness OOMing on 10 bytes?\");\n    ///\n    /// // And now map can hold at least 10 elements\n    /// assert!(map.capacity() >= 10);\n    /// ```\n    /// If the capacity overflows, or the allocator reports a failure, then an error\n    /// is returned:\n    /// ```\n    /// # fn test() {\n    /// use hashbrown::HashMap;\n    /// use hashbrown::TryReserveError;\n    /// let mut map: HashMap<i32, i32> = HashMap::new();\n    ///\n    /// match map.try_reserve(usize::MAX) {\n    ///     Err(error) => match error {\n    ///         TryReserveError::CapacityOverflow => {}\n    ///         _ => panic!(\"TryReserveError::AllocError ?\"),\n    ///     },\n    ///     _ => panic!(),\n    /// }\n    /// # }\n    /// # fn main() {\n    /// #     #[cfg(not(miri))]\n    /// #     test()\n    /// # }\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn try_reserve(&mut self, additional: usize) -> Result<(), TryReserveError> {\n        self.table\n            .try_reserve(additional, make_hasher::<_, V, S>(&self.hash_builder))\n    }\n\n    /// Shrinks the capacity of the map as much as possible. It will drop\n    /// down as much as possible while maintaining the internal rules\n    /// and possibly leaving some space in accordance with the resize policy.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut map: HashMap<i32, i32> = HashMap::with_capacity(100);\n    /// map.insert(1, 2);\n    /// map.insert(3, 4);\n    /// assert!(map.capacity() >= 100);\n    /// map.shrink_to_fit();\n    /// assert!(map.capacity() >= 2);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn shrink_to_fit(&mut self) {\n        self.table\n            .shrink_to(0, make_hasher::<_, V, S>(&self.hash_builder));\n    }\n\n    /// Shrinks the capacity of the map with a lower limit. It will drop\n    /// down no lower than the supplied limit while maintaining the internal rules\n    /// and possibly leaving some space in accordance with the resize policy.\n    ///\n    /// This function does nothing if the current capacity is smaller than the\n    /// supplied minimum capacity.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut map: HashMap<i32, i32> = HashMap::with_capacity(100);\n    /// map.insert(1, 2);\n    /// map.insert(3, 4);\n    /// assert!(map.capacity() >= 100);\n    /// map.shrink_to(10);\n    /// assert!(map.capacity() >= 10);\n    /// map.shrink_to(0);\n    /// assert!(map.capacity() >= 2);\n    /// map.shrink_to(10);\n    /// assert!(map.capacity() >= 2);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn shrink_to(&mut self, min_capacity: usize) {\n        self.table\n            .shrink_to(min_capacity, make_hasher::<_, V, S>(&self.hash_builder));\n    }\n\n    /// Gets the given key's corresponding entry in the map for in-place manipulation.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut letters = HashMap::new();\n    ///\n    /// for ch in \"a short treatise on fungi\".chars() {\n    ///     let counter = letters.entry(ch).or_insert(0);\n    ///     *counter += 1;\n    /// }\n    ///\n    /// assert_eq!(letters[&'s'], 2);\n    /// assert_eq!(letters[&'t'], 3);\n    /// assert_eq!(letters[&'u'], 1);\n    /// assert_eq!(letters.get(&'y'), None);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn entry(&mut self, key: K) -> Entry<'_, K, V, S, A> {\n        let hash = make_hash::<K, S>(&self.hash_builder, &key);\n        if let Some(elem) = self.table.find(hash, equivalent_key(&key)) {\n            Entry::Occupied(OccupiedEntry {\n                hash,\n                elem,\n                table: self,\n            })\n        } else {\n            Entry::Vacant(VacantEntry {\n                hash,\n                key,\n                table: self,\n            })\n        }\n    }\n\n    /// Gets the given key's corresponding entry by reference in the map for in-place manipulation.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut words: HashMap<String, usize> = HashMap::new();\n    /// let source = [\"poneyland\", \"horseyland\", \"poneyland\", \"poneyland\"];\n    /// for (i, &s) in source.iter().enumerate() {\n    ///     let counter = words.entry_ref(s).or_insert(0);\n    ///     *counter += 1;\n    /// }\n    ///\n    /// assert_eq!(words[\"poneyland\"], 3);\n    /// assert_eq!(words[\"horseyland\"], 1);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn entry_ref<'a, 'b, Q>(&'a mut self, key: &'b Q) -> EntryRef<'a, 'b, K, Q, V, S, A>\n    where\n        Q: Hash + Equivalent<K> + ?Sized,\n    {\n        let hash = make_hash::<Q, S>(&self.hash_builder, key);\n        if let Some(elem) = self.table.find(hash, equivalent_key(key)) {\n            EntryRef::Occupied(OccupiedEntry {\n                hash,\n                elem,\n                table: self,\n            })\n        } else {\n            EntryRef::Vacant(VacantEntryRef {\n                hash,\n                key,\n                table: self,\n            })\n        }\n    }\n\n    /// Returns a reference to the value corresponding to the key.\n    ///\n    /// The key may be any borrowed form of the map's key type, but\n    /// [`Hash`] and [`Eq`] on the borrowed form *must* match those for\n    /// the key type.\n    ///\n    /// [`Eq`]: https://doc.rust-lang.org/std/cmp/trait.Eq.html\n    /// [`Hash`]: https://doc.rust-lang.org/std/hash/trait.Hash.html\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut map = HashMap::new();\n    /// map.insert(1, \"a\");\n    /// assert_eq!(map.get(&1), Some(&\"a\"));\n    /// assert_eq!(map.get(&2), None);\n    /// ```\n    #[inline]\n    pub fn get<Q>(&self, k: &Q) -> Option<&V>\n    where\n        Q: Hash + Equivalent<K> + ?Sized,\n    {\n        // Avoid `Option::map` because it bloats LLVM IR.\n        match self.get_inner(k) {\n            Some((_, v)) => Some(v),\n            None => None,\n        }\n    }\n\n    /// Returns the key-value pair corresponding to the supplied key.\n    ///\n    /// The supplied key may be any borrowed form of the map's key type, but\n    /// [`Hash`] and [`Eq`] on the borrowed form *must* match those for\n    /// the key type.\n    ///\n    /// [`Eq`]: https://doc.rust-lang.org/std/cmp/trait.Eq.html\n    /// [`Hash`]: https://doc.rust-lang.org/std/hash/trait.Hash.html\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut map = HashMap::new();\n    /// map.insert(1, \"a\");\n    /// assert_eq!(map.get_key_value(&1), Some((&1, &\"a\")));\n    /// assert_eq!(map.get_key_value(&2), None);\n    /// ```\n    #[inline]\n    pub fn get_key_value<Q>(&self, k: &Q) -> Option<(&K, &V)>\n    where\n        Q: Hash + Equivalent<K> + ?Sized,\n    {\n        // Avoid `Option::map` because it bloats LLVM IR.\n        match self.get_inner(k) {\n            Some((key, value)) => Some((key, value)),\n            None => None,\n        }\n    }\n\n    #[inline]\n    fn get_inner<Q>(&self, k: &Q) -> Option<&(K, V)>\n    where\n        Q: Hash + Equivalent<K> + ?Sized,\n    {\n        if self.table.is_empty() {\n            None\n        } else {\n            let hash = make_hash::<Q, S>(&self.hash_builder, k);\n            self.table.get(hash, equivalent_key(k))\n        }\n    }\n\n    /// Returns the key-value pair corresponding to the supplied key, with a mutable reference to value.\n    ///\n    /// The supplied key may be any borrowed form of the map's key type, but\n    /// [`Hash`] and [`Eq`] on the borrowed form *must* match those for\n    /// the key type.\n    ///\n    /// [`Eq`]: https://doc.rust-lang.org/std/cmp/trait.Eq.html\n    /// [`Hash`]: https://doc.rust-lang.org/std/hash/trait.Hash.html\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut map = HashMap::new();\n    /// map.insert(1, \"a\");\n    /// let (k, v) = map.get_key_value_mut(&1).unwrap();\n    /// assert_eq!(k, &1);\n    /// assert_eq!(v, &mut \"a\");\n    /// *v = \"b\";\n    /// assert_eq!(map.get_key_value_mut(&1), Some((&1, &mut \"b\")));\n    /// assert_eq!(map.get_key_value_mut(&2), None);\n    /// ```\n    #[inline]\n    pub fn get_key_value_mut<Q>(&mut self, k: &Q) -> Option<(&K, &mut V)>\n    where\n        Q: Hash + Equivalent<K> + ?Sized,\n    {\n        // Avoid `Option::map` because it bloats LLVM IR.\n        match self.get_inner_mut(k) {\n            Some(&mut (ref key, ref mut value)) => Some((key, value)),\n            None => None,\n        }\n    }\n\n    /// Returns `true` if the map contains a value for the specified key.\n    ///\n    /// The key may be any borrowed form of the map's key type, but\n    /// [`Hash`] and [`Eq`] on the borrowed form *must* match those for\n    /// the key type.\n    ///\n    /// [`Eq`]: https://doc.rust-lang.org/std/cmp/trait.Eq.html\n    /// [`Hash`]: https://doc.rust-lang.org/std/hash/trait.Hash.html\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut map = HashMap::new();\n    /// map.insert(1, \"a\");\n    /// assert_eq!(map.contains_key(&1), true);\n    /// assert_eq!(map.contains_key(&2), false);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn contains_key<Q>(&self, k: &Q) -> bool\n    where\n        Q: Hash + Equivalent<K> + ?Sized,\n    {\n        self.get_inner(k).is_some()\n    }\n\n    /// Returns a mutable reference to the value corresponding to the key.\n    ///\n    /// The key may be any borrowed form of the map's key type, but\n    /// [`Hash`] and [`Eq`] on the borrowed form *must* match those for\n    /// the key type.\n    ///\n    /// [`Eq`]: https://doc.rust-lang.org/std/cmp/trait.Eq.html\n    /// [`Hash`]: https://doc.rust-lang.org/std/hash/trait.Hash.html\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut map = HashMap::new();\n    /// map.insert(1, \"a\");\n    /// if let Some(x) = map.get_mut(&1) {\n    ///     *x = \"b\";\n    /// }\n    /// assert_eq!(map[&1], \"b\");\n    ///\n    /// assert_eq!(map.get_mut(&2), None);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn get_mut<Q>(&mut self, k: &Q) -> Option<&mut V>\n    where\n        Q: Hash + Equivalent<K> + ?Sized,\n    {\n        // Avoid `Option::map` because it bloats LLVM IR.\n        match self.get_inner_mut(k) {\n            Some(&mut (_, ref mut v)) => Some(v),\n            None => None,\n        }\n    }\n\n    #[inline]\n    fn get_inner_mut<Q>(&mut self, k: &Q) -> Option<&mut (K, V)>\n    where\n        Q: Hash + Equivalent<K> + ?Sized,\n    {\n        if self.table.is_empty() {\n            None\n        } else {\n            let hash = make_hash::<Q, S>(&self.hash_builder, k);\n            self.table.get_mut(hash, equivalent_key(k))\n        }\n    }\n\n    /// Attempts to get mutable references to `N` values in the map at once.\n    ///\n    /// Returns an array of length `N` with the results of each query. For soundness, at most one\n    /// mutable reference will be returned to any value. `None` will be used if the key is missing.\n    ///\n    /// # Panics\n    ///\n    /// Panics if any keys are overlapping.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut libraries = HashMap::new();\n    /// libraries.insert(\"Bodleian Library\".to_string(), 1602);\n    /// libraries.insert(\"Athenum\".to_string(), 1807);\n    /// libraries.insert(\"Herzogin-Anna-Amalia-Bibliothek\".to_string(), 1691);\n    /// libraries.insert(\"Library of Congress\".to_string(), 1800);\n    ///\n    /// // Get Athenum and Bodleian Library\n    /// let [Some(a), Some(b)] = libraries.get_many_mut([\n    ///     \"Athenum\",\n    ///     \"Bodleian Library\",\n    /// ]) else { panic!() };\n    ///\n    /// // Assert values of Athenum and Library of Congress\n    /// let got = libraries.get_many_mut([\n    ///     \"Athenum\",\n    ///     \"Library of Congress\",\n    /// ]);\n    /// assert_eq!(\n    ///     got,\n    ///     [\n    ///         Some(&mut 1807),\n    ///         Some(&mut 1800),\n    ///     ],\n    /// );\n    ///\n    /// // Missing keys result in None\n    /// let got = libraries.get_many_mut([\n    ///     \"Athenum\",\n    ///     \"New York Public Library\",\n    /// ]);\n    /// assert_eq!(\n    ///     got,\n    ///     [\n    ///         Some(&mut 1807),\n    ///         None\n    ///     ]\n    /// );\n    /// ```\n    ///\n    /// ```should_panic\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut libraries = HashMap::new();\n    /// libraries.insert(\"Athenum\".to_string(), 1807);\n    ///\n    /// // Duplicate keys panic!\n    /// let got = libraries.get_many_mut([\n    ///     \"Athenum\",\n    ///     \"Athenum\",\n    /// ]);\n    /// ```\n    pub fn get_many_mut<Q, const N: usize>(&mut self, ks: [&Q; N]) -> [Option<&'_ mut V>; N]\n    where\n        Q: Hash + Equivalent<K> + ?Sized,\n    {\n        self.get_many_mut_inner(ks).map(|res| res.map(|(_, v)| v))\n    }\n\n    /// Attempts to get mutable references to `N` values in the map at once, without validating that\n    /// the values are unique.\n    ///\n    /// Returns an array of length `N` with the results of each query. `None` will be used if\n    /// the key is missing.\n    ///\n    /// For a safe alternative see [`get_many_mut`](`HashMap::get_many_mut`).\n    ///\n    /// # Safety\n    ///\n    /// Calling this method with overlapping keys is *[undefined behavior]* even if the resulting\n    /// references are not used.\n    ///\n    /// [undefined behavior]: https://doc.rust-lang.org/reference/behavior-considered-undefined.html\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut libraries = HashMap::new();\n    /// libraries.insert(\"Bodleian Library\".to_string(), 1602);\n    /// libraries.insert(\"Athenum\".to_string(), 1807);\n    /// libraries.insert(\"Herzogin-Anna-Amalia-Bibliothek\".to_string(), 1691);\n    /// libraries.insert(\"Library of Congress\".to_string(), 1800);\n    ///\n    /// // SAFETY: The keys do not overlap.\n    /// let [Some(a), Some(b)] = (unsafe { libraries.get_many_unchecked_mut([\n    ///     \"Athenum\",\n    ///     \"Bodleian Library\",\n    /// ]) }) else { panic!() };\n    ///\n    /// // SAFETY: The keys do not overlap.\n    /// let got = unsafe { libraries.get_many_unchecked_mut([\n    ///     \"Athenum\",\n    ///     \"Library of Congress\",\n    /// ]) };\n    /// assert_eq!(\n    ///     got,\n    ///     [\n    ///         Some(&mut 1807),\n    ///         Some(&mut 1800),\n    ///     ],\n    /// );\n    ///\n    /// // SAFETY: The keys do not overlap.\n    /// let got = unsafe { libraries.get_many_unchecked_mut([\n    ///     \"Athenum\",\n    ///     \"New York Public Library\",\n    /// ]) };\n    /// // Missing keys result in None\n    /// assert_eq!(got, [Some(&mut 1807), None]);\n    /// ```\n    pub unsafe fn get_many_unchecked_mut<Q, const N: usize>(\n        &mut self,\n        ks: [&Q; N],\n    ) -> [Option<&'_ mut V>; N]\n    where\n        Q: Hash + Equivalent<K> + ?Sized,\n    {\n        self.get_many_unchecked_mut_inner(ks)\n            .map(|res| res.map(|(_, v)| v))\n    }\n\n    /// Attempts to get mutable references to `N` values in the map at once, with immutable\n    /// references to the corresponding keys.\n    ///\n    /// Returns an array of length `N` with the results of each query. For soundness, at most one\n    /// mutable reference will be returned to any value. `None` will be used if the key is missing.\n    ///\n    /// # Panics\n    ///\n    /// Panics if any keys are overlapping.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut libraries = HashMap::new();\n    /// libraries.insert(\"Bodleian Library\".to_string(), 1602);\n    /// libraries.insert(\"Athenum\".to_string(), 1807);\n    /// libraries.insert(\"Herzogin-Anna-Amalia-Bibliothek\".to_string(), 1691);\n    /// libraries.insert(\"Library of Congress\".to_string(), 1800);\n    ///\n    /// let got = libraries.get_many_key_value_mut([\n    ///     \"Bodleian Library\",\n    ///     \"Herzogin-Anna-Amalia-Bibliothek\",\n    /// ]);\n    /// assert_eq!(\n    ///     got,\n    ///     [\n    ///         Some((&\"Bodleian Library\".to_string(), &mut 1602)),\n    ///         Some((&\"Herzogin-Anna-Amalia-Bibliothek\".to_string(), &mut 1691)),\n    ///     ],\n    /// );\n    /// // Missing keys result in None\n    /// let got = libraries.get_many_key_value_mut([\n    ///     \"Bodleian Library\",\n    ///     \"Gewandhaus\",\n    /// ]);\n    /// assert_eq!(got, [Some((&\"Bodleian Library\".to_string(), &mut 1602)), None]);\n    /// ```\n    ///\n    /// ```should_panic\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut libraries = HashMap::new();\n    /// libraries.insert(\"Bodleian Library\".to_string(), 1602);\n    /// libraries.insert(\"Herzogin-Anna-Amalia-Bibliothek\".to_string(), 1691);\n    ///\n    /// // Duplicate keys result in panic!\n    /// let got = libraries.get_many_key_value_mut([\n    ///     \"Bodleian Library\",\n    ///     \"Herzogin-Anna-Amalia-Bibliothek\",\n    ///     \"Herzogin-Anna-Amalia-Bibliothek\",\n    /// ]);\n    /// ```\n    pub fn get_many_key_value_mut<Q, const N: usize>(\n        &mut self,\n        ks: [&Q; N],\n    ) -> [Option<(&'_ K, &'_ mut V)>; N]\n    where\n        Q: Hash + Equivalent<K> + ?Sized,\n    {\n        self.get_many_mut_inner(ks)\n            .map(|res| res.map(|(k, v)| (&*k, v)))\n    }\n\n    /// Attempts to get mutable references to `N` values in the map at once, with immutable\n    /// references to the corresponding keys, without validating that the values are unique.\n    ///\n    /// Returns an array of length `N` with the results of each query. `None` will be returned if\n    /// any of the keys are missing.\n    ///\n    /// For a safe alternative see [`get_many_key_value_mut`](`HashMap::get_many_key_value_mut`).\n    ///\n    /// # Safety\n    ///\n    /// Calling this method with overlapping keys is *[undefined behavior]* even if the resulting\n    /// references are not used.\n    ///\n    /// [undefined behavior]: https://doc.rust-lang.org/reference/behavior-considered-undefined.html\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut libraries = HashMap::new();\n    /// libraries.insert(\"Bodleian Library\".to_string(), 1602);\n    /// libraries.insert(\"Athenum\".to_string(), 1807);\n    /// libraries.insert(\"Herzogin-Anna-Amalia-Bibliothek\".to_string(), 1691);\n    /// libraries.insert(\"Library of Congress\".to_string(), 1800);\n    ///\n    /// let got = libraries.get_many_key_value_mut([\n    ///     \"Bodleian Library\",\n    ///     \"Herzogin-Anna-Amalia-Bibliothek\",\n    /// ]);\n    /// assert_eq!(\n    ///     got,\n    ///     [\n    ///         Some((&\"Bodleian Library\".to_string(), &mut 1602)),\n    ///         Some((&\"Herzogin-Anna-Amalia-Bibliothek\".to_string(), &mut 1691)),\n    ///     ],\n    /// );\n    /// // Missing keys result in None\n    /// let got = libraries.get_many_key_value_mut([\n    ///     \"Bodleian Library\",\n    ///     \"Gewandhaus\",\n    /// ]);\n    /// assert_eq!(\n    ///     got,\n    ///     [\n    ///         Some((&\"Bodleian Library\".to_string(), &mut 1602)),\n    ///         None,\n    ///     ],\n    /// );\n    /// ```\n    pub unsafe fn get_many_key_value_unchecked_mut<Q, const N: usize>(\n        &mut self,\n        ks: [&Q; N],\n    ) -> [Option<(&'_ K, &'_ mut V)>; N]\n    where\n        Q: Hash + Equivalent<K> + ?Sized,\n    {\n        self.get_many_unchecked_mut_inner(ks)\n            .map(|res| res.map(|(k, v)| (&*k, v)))\n    }\n\n    fn get_many_mut_inner<Q, const N: usize>(&mut self, ks: [&Q; N]) -> [Option<&'_ mut (K, V)>; N]\n    where\n        Q: Hash + Equivalent<K> + ?Sized,\n    {\n        let hashes = self.build_hashes_inner(ks);\n        self.table\n            .get_many_mut(hashes, |i, (k, _)| ks[i].equivalent(k))\n    }\n\n    unsafe fn get_many_unchecked_mut_inner<Q, const N: usize>(\n        &mut self,\n        ks: [&Q; N],\n    ) -> [Option<&'_ mut (K, V)>; N]\n    where\n        Q: Hash + Equivalent<K> + ?Sized,\n    {\n        let hashes = self.build_hashes_inner(ks);\n        self.table\n            .get_many_unchecked_mut(hashes, |i, (k, _)| ks[i].equivalent(k))\n    }\n\n    fn build_hashes_inner<Q, const N: usize>(&self, ks: [&Q; N]) -> [u64; N]\n    where\n        Q: Hash + Equivalent<K> + ?Sized,\n    {\n        let mut hashes = [0_u64; N];\n        for i in 0..N {\n            hashes[i] = make_hash::<Q, S>(&self.hash_builder, ks[i]);\n        }\n        hashes\n    }\n\n    /// Inserts a key-value pair into the map.\n    ///\n    /// If the map did not have this key present, [`None`] is returned.\n    ///\n    /// If the map did have this key present, the value is updated, and the old\n    /// value is returned. The key is not updated, though; this matters for\n    /// types that can be `==` without being identical. See the [`std::collections`]\n    /// [module-level documentation] for more.\n    ///\n    /// [`None`]: https://doc.rust-lang.org/std/option/enum.Option.html#variant.None\n    /// [`std::collections`]: https://doc.rust-lang.org/std/collections/index.html\n    /// [module-level documentation]: https://doc.rust-lang.org/std/collections/index.html#insert-and-complex-keys\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut map = HashMap::new();\n    /// assert_eq!(map.insert(37, \"a\"), None);\n    /// assert_eq!(map.is_empty(), false);\n    ///\n    /// map.insert(37, \"b\");\n    /// assert_eq!(map.insert(37, \"c\"), Some(\"b\"));\n    /// assert_eq!(map[&37], \"c\");\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn insert(&mut self, k: K, v: V) -> Option<V> {\n        let hash = make_hash::<K, S>(&self.hash_builder, &k);\n        match self.find_or_find_insert_slot(hash, &k) {\n            Ok(bucket) => Some(mem::replace(unsafe { &mut bucket.as_mut().1 }, v)),\n            Err(slot) => {\n                unsafe {\n                    self.table.insert_in_slot(hash, slot, (k, v));\n                }\n                None\n            }\n        }\n    }\n\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub(crate) fn find_or_find_insert_slot<Q>(\n        &mut self,\n        hash: u64,\n        key: &Q,\n    ) -> Result<Bucket<(K, V)>, crate::raw::InsertSlot>\n    where\n        Q: Equivalent<K> + ?Sized,\n    {\n        self.table.find_or_find_insert_slot(\n            hash,\n            equivalent_key(key),\n            make_hasher(&self.hash_builder),\n        )\n    }\n\n    /// Insert a key-value pair into the map without checking\n    /// if the key already exists in the map.\n    ///\n    /// This operation is faster than regular insert, because it does not perform\n    /// lookup before insertion.\n    ///\n    /// This operation is useful during initial population of the map.\n    /// For example, when constructing a map from another map, we know\n    /// that keys are unique.\n    ///\n    /// Returns a reference to the key and value just inserted.\n    ///\n    /// # Safety\n    ///\n    /// This operation is safe if a key does not exist in the map.\n    ///\n    /// However, if a key exists in the map already, the behavior is unspecified:\n    /// this operation may panic, loop forever, or any following operation with the map\n    /// may panic, loop forever or return arbitrary result.\n    ///\n    /// That said, this operation (and following operations) are guaranteed to\n    /// not violate memory safety.\n    ///\n    /// However this operation is still unsafe because the resulting `HashMap`\n    /// may be passed to unsafe code which does expect the map to behave\n    /// correctly, and would cause unsoundness as a result.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut map1 = HashMap::new();\n    /// assert_eq!(map1.insert(1, \"a\"), None);\n    /// assert_eq!(map1.insert(2, \"b\"), None);\n    /// assert_eq!(map1.insert(3, \"c\"), None);\n    /// assert_eq!(map1.len(), 3);\n    ///\n    /// let mut map2 = HashMap::new();\n    ///\n    /// for (key, value) in map1.into_iter() {\n    ///     unsafe {\n    ///         map2.insert_unique_unchecked(key, value);\n    ///     }\n    /// }\n    ///\n    /// let (key, value) = unsafe { map2.insert_unique_unchecked(4, \"d\") };\n    /// assert_eq!(key, &4);\n    /// assert_eq!(value, &mut \"d\");\n    /// *value = \"e\";\n    ///\n    /// assert_eq!(map2[&1], \"a\");\n    /// assert_eq!(map2[&2], \"b\");\n    /// assert_eq!(map2[&3], \"c\");\n    /// assert_eq!(map2[&4], \"e\");\n    /// assert_eq!(map2.len(), 4);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub unsafe fn insert_unique_unchecked(&mut self, k: K, v: V) -> (&K, &mut V) {\n        let hash = make_hash::<K, S>(&self.hash_builder, &k);\n        let bucket = self\n            .table\n            .insert(hash, (k, v), make_hasher::<_, V, S>(&self.hash_builder));\n        let (k_ref, v_ref) = unsafe { bucket.as_mut() };\n        (k_ref, v_ref)\n    }\n\n    /// Tries to insert a key-value pair into the map, and returns\n    /// a mutable reference to the value in the entry.\n    ///\n    /// # Errors\n    ///\n    /// If the map already had this key present, nothing is updated, and\n    /// an error containing the occupied entry and the value is returned.\n    ///\n    /// # Examples\n    ///\n    /// Basic usage:\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    /// use hashbrown::hash_map::OccupiedError;\n    ///\n    /// let mut map = HashMap::new();\n    /// assert_eq!(map.try_insert(37, \"a\").unwrap(), &\"a\");\n    ///\n    /// match map.try_insert(37, \"b\") {\n    ///     Err(OccupiedError { entry, value }) => {\n    ///         assert_eq!(entry.key(), &37);\n    ///         assert_eq!(entry.get(), &\"a\");\n    ///         assert_eq!(value, \"b\");\n    ///     }\n    ///     _ => panic!()\n    /// }\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn try_insert(\n        &mut self,\n        key: K,\n        value: V,\n    ) -> Result<&mut V, OccupiedError<'_, K, V, S, A>> {\n        match self.entry(key) {\n            Entry::Occupied(entry) => Err(OccupiedError { entry, value }),\n            Entry::Vacant(entry) => Ok(entry.insert(value)),\n        }\n    }\n\n    /// Removes a key from the map, returning the value at the key if the key\n    /// was previously in the map. Keeps the allocated memory for reuse.\n    ///\n    /// The key may be any borrowed form of the map's key type, but\n    /// [`Hash`] and [`Eq`] on the borrowed form *must* match those for\n    /// the key type.\n    ///\n    /// [`Eq`]: https://doc.rust-lang.org/std/cmp/trait.Eq.html\n    /// [`Hash`]: https://doc.rust-lang.org/std/hash/trait.Hash.html\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut map = HashMap::new();\n    /// // The map is empty\n    /// assert!(map.is_empty() && map.capacity() == 0);\n    ///\n    /// map.insert(1, \"a\");\n    ///\n    /// assert_eq!(map.remove(&1), Some(\"a\"));\n    /// assert_eq!(map.remove(&1), None);\n    ///\n    /// // Now map holds none elements\n    /// assert!(map.is_empty());\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn remove<Q>(&mut self, k: &Q) -> Option<V>\n    where\n        Q: Hash + Equivalent<K> + ?Sized,\n    {\n        // Avoid `Option::map` because it bloats LLVM IR.\n        match self.remove_entry(k) {\n            Some((_, v)) => Some(v),\n            None => None,\n        }\n    }\n\n    /// Removes a key from the map, returning the stored key and value if the\n    /// key was previously in the map. Keeps the allocated memory for reuse.\n    ///\n    /// The key may be any borrowed form of the map's key type, but\n    /// [`Hash`] and [`Eq`] on the borrowed form *must* match those for\n    /// the key type.\n    ///\n    /// [`Eq`]: https://doc.rust-lang.org/std/cmp/trait.Eq.html\n    /// [`Hash`]: https://doc.rust-lang.org/std/hash/trait.Hash.html\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut map = HashMap::new();\n    /// // The map is empty\n    /// assert!(map.is_empty() && map.capacity() == 0);\n    ///\n    /// map.insert(1, \"a\");\n    ///\n    /// assert_eq!(map.remove_entry(&1), Some((1, \"a\")));\n    /// assert_eq!(map.remove(&1), None);\n    ///\n    /// // Now map hold none elements\n    /// assert!(map.is_empty());\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn remove_entry<Q>(&mut self, k: &Q) -> Option<(K, V)>\n    where\n        Q: Hash + Equivalent<K> + ?Sized,\n    {\n        let hash = make_hash::<Q, S>(&self.hash_builder, k);\n        self.table.remove_entry(hash, equivalent_key(k))\n    }\n\n    /// Returns the total amount of memory allocated internally by the hash\n    /// set, in bytes.\n    ///\n    /// The returned number is informational only. It is intended to be\n    /// primarily used for memory profiling.\n    #[inline]\n    pub fn allocation_size(&self) -> usize {\n        self.table.allocation_size()\n    }\n}",
            "impl<K, V, S, A> PartialEq for HashMap<K, V, S, A>\nwhere\n    K: Eq + Hash,\n    V: PartialEq,\n    S: BuildHasher,\n    A: Allocator,\n{\n    fn eq(&self, other: &Self) -> bool {\n        if self.len() != other.len() {\n            return false;\n        }\n\n        self.iter()\n            .all(|(key, value)| other.get(key).map_or(false, |v| *value == *v))\n    }\n}",
            "impl<K, V, S> HashMap<K, V, S> {\n    /// Creates an empty `HashMap` which will use the given hash builder to hash\n    /// keys.\n    ///\n    /// The hash map is initially created with a capacity of 0, so it will not\n    /// allocate until it is first inserted into.\n    ///\n    /// # HashDoS resistance\n    ///\n    /// The `hash_builder` normally use a fixed key by default and that does\n    /// not allow the `HashMap` to be protected against attacks such as [`HashDoS`].\n    /// Users who require HashDoS resistance should explicitly use\n    /// [`std::collections::hash_map::RandomState`]\n    /// as the hasher when creating a [`HashMap`].\n    ///\n    /// The `hash_builder` passed should implement the [`BuildHasher`] trait for\n    /// the `HashMap` to be useful, see its documentation for details.\n    ///\n    /// [`HashDoS`]: https://en.wikipedia.org/wiki/Collision_attack\n    /// [`std::collections::hash_map::RandomState`]: https://doc.rust-lang.org/std/collections/hash_map/struct.RandomState.html\n    /// [`BuildHasher`]: https://doc.rust-lang.org/std/hash/trait.BuildHasher.html\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    /// use hashbrown::DefaultHashBuilder;\n    ///\n    /// let s = DefaultHashBuilder::default();\n    /// let mut map = HashMap::with_hasher(s);\n    /// assert_eq!(map.len(), 0);\n    /// assert_eq!(map.capacity(), 0);\n    ///\n    /// map.insert(1, 2);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    #[cfg_attr(feature = \"rustc-dep-of-std\", rustc_const_stable_indirect)]\n    pub const fn with_hasher(hash_builder: S) -> Self {\n        Self {\n            hash_builder,\n            table: RawTable::new(),\n        }\n    }\n\n    /// Creates an empty `HashMap` with the specified capacity, using `hash_builder`\n    /// to hash the keys.\n    ///\n    /// The hash map will be able to hold at least `capacity` elements without\n    /// reallocating. If `capacity` is 0, the hash map will not allocate.\n    ///\n    /// # HashDoS resistance\n    ///\n    /// The `hash_builder` normally use a fixed key by default and that does\n    /// not allow the `HashMap` to be protected against attacks such as [`HashDoS`].\n    /// Users who require HashDoS resistance should explicitly use\n    /// [`std::collections::hash_map::RandomState`]\n    /// as the hasher when creating a [`HashMap`].\n    ///\n    /// The `hash_builder` passed should implement the [`BuildHasher`] trait for\n    /// the `HashMap` to be useful, see its documentation for details.\n    ///\n    /// [`HashDoS`]: https://en.wikipedia.org/wiki/Collision_attack\n    /// [`std::collections::hash_map::RandomState`]: https://doc.rust-lang.org/std/collections/hash_map/struct.RandomState.html\n    /// [`BuildHasher`]: https://doc.rust-lang.org/std/hash/trait.BuildHasher.html\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    /// use hashbrown::DefaultHashBuilder;\n    ///\n    /// let s = DefaultHashBuilder::default();\n    /// let mut map = HashMap::with_capacity_and_hasher(10, s);\n    /// assert_eq!(map.len(), 0);\n    /// assert!(map.capacity() >= 10);\n    ///\n    /// map.insert(1, 2);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn with_capacity_and_hasher(capacity: usize, hash_builder: S) -> Self {\n        Self {\n            hash_builder,\n            table: RawTable::with_capacity(capacity),\n        }\n    }\n}",
            "impl<K, V> HashMap<K, V, DefaultHashBuilder> {\n    /// Creates an empty `HashMap`.\n    ///\n    /// The hash map is initially created with a capacity of 0, so it will not allocate until it\n    /// is first inserted into.\n    ///\n    /// # HashDoS resistance\n    ///\n    /// The `hash_builder` normally use a fixed key by default and that does\n    /// not allow the `HashMap` to be protected against attacks such as [`HashDoS`].\n    /// Users who require HashDoS resistance should explicitly use\n    /// [`std::collections::hash_map::RandomState`]\n    /// as the hasher when creating a [`HashMap`], for example with\n    /// [`with_hasher`](HashMap::with_hasher) method.\n    ///\n    /// [`HashDoS`]: https://en.wikipedia.org/wiki/Collision_attack\n    /// [`std::collections::hash_map::RandomState`]: https://doc.rust-lang.org/std/collections/hash_map/struct.RandomState.html\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    /// let mut map: HashMap<&str, i32> = HashMap::new();\n    /// assert_eq!(map.len(), 0);\n    /// assert_eq!(map.capacity(), 0);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn new() -> Self {\n        Self::default()\n    }\n\n    /// Creates an empty `HashMap` with the specified capacity.\n    ///\n    /// The hash map will be able to hold at least `capacity` elements without\n    /// reallocating. If `capacity` is 0, the hash map will not allocate.\n    ///\n    /// # HashDoS resistance\n    ///\n    /// The `hash_builder` normally use a fixed key by default and that does\n    /// not allow the `HashMap` to be protected against attacks such as [`HashDoS`].\n    /// Users who require HashDoS resistance should explicitly use\n    /// [`std::collections::hash_map::RandomState`]\n    /// as the hasher when creating a [`HashMap`], for example with\n    /// [`with_capacity_and_hasher`](HashMap::with_capacity_and_hasher) method.\n    ///\n    /// [`HashDoS`]: https://en.wikipedia.org/wiki/Collision_attack\n    /// [`std::collections::hash_map::RandomState`]: https://doc.rust-lang.org/std/collections/hash_map/struct.RandomState.html\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    /// let mut map: HashMap<&str, i32> = HashMap::with_capacity(10);\n    /// assert_eq!(map.len(), 0);\n    /// assert!(map.capacity() >= 10);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn with_capacity(capacity: usize) -> Self {\n        Self::with_capacity_and_hasher(capacity, DefaultHashBuilder::default())\n    }\n}",
            "impl<K: Clone, V: Clone, S: Clone, A: Allocator + Clone> Clone for HashMap<K, V, S, A> {\n    fn clone(&self) -> Self {\n        HashMap {\n            hash_builder: self.hash_builder.clone(),\n            table: self.table.clone(),\n        }\n    }\n\n    fn clone_from(&mut self, source: &Self) {\n        self.table.clone_from(&source.table);\n\n        // Update hash_builder only if we successfully cloned all elements.\n        self.hash_builder.clone_from(&source.hash_builder);\n    }\n}"
        ],
        "map::IntoIter": [
            "impl<K, V, A: Allocator> Default for IntoIter<K, V, A> {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn default() -> Self {\n        Self {\n            inner: Default::default(),\n        }\n    }\n}",
            "impl<K, V, A: Allocator> ExactSizeIterator for IntoIter<K, V, A> {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn len(&self) -> usize {\n        self.inner.len()\n    }\n}",
            "impl<K, V, A: Allocator> FusedIterator for IntoIter<K, V, A> {}",
            "impl<K, V, A: Allocator> IntoIter<K, V, A> {\n    /// Returns a iterator of references over the remaining items.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub(super) fn iter(&self) -> Iter<'_, K, V> {\n        Iter {\n            inner: self.inner.iter(),\n            marker: PhantomData,\n        }\n    }\n}",
            "impl<K, V, A: Allocator> Iterator for IntoIter<K, V, A> {\n    type Item = (K, V);\n\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn next(&mut self) -> Option<(K, V)> {\n        self.inner.next()\n    }\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.inner.size_hint()\n    }\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn fold<B, F>(self, init: B, f: F) -> B\n    where\n        Self: Sized,\n        F: FnMut(B, Self::Item) -> B,\n    {\n        self.inner.fold(init, f)\n    }\n}",
            "impl<K: Debug, V: Debug, A: Allocator> fmt::Debug for IntoIter<K, V, A> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_list().entries(self.iter()).finish()\n    }\n}"
        ],
        "map::IntoKeys": [
            "impl<K, V, A: Allocator> Default for IntoKeys<K, V, A> {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn default() -> Self {\n        Self {\n            inner: Default::default(),\n        }\n    }\n}",
            "impl<K, V, A: Allocator> ExactSizeIterator for IntoKeys<K, V, A> {\n    #[inline]\n    fn len(&self) -> usize {\n        self.inner.len()\n    }\n}",
            "impl<K, V, A: Allocator> FusedIterator for IntoKeys<K, V, A> {}",
            "impl<K, V, A: Allocator> Iterator for IntoKeys<K, V, A> {\n    type Item = K;\n\n    #[inline]\n    fn next(&mut self) -> Option<K> {\n        self.inner.next().map(|(k, _)| k)\n    }\n    #[inline]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.inner.size_hint()\n    }\n    #[inline]\n    fn fold<B, F>(self, init: B, mut f: F) -> B\n    where\n        Self: Sized,\n        F: FnMut(B, Self::Item) -> B,\n    {\n        self.inner.fold(init, |acc, (k, _)| f(acc, k))\n    }\n}",
            "impl<K: Debug, V: Debug, A: Allocator> fmt::Debug for IntoKeys<K, V, A> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_list()\n            .entries(self.inner.iter().map(|(k, _)| k))\n            .finish()\n    }\n}"
        ],
        "map::IntoValues": [
            "impl<K, V, A: Allocator> Default for IntoValues<K, V, A> {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn default() -> Self {\n        Self {\n            inner: Default::default(),\n        }\n    }\n}",
            "impl<K, V, A: Allocator> ExactSizeIterator for IntoValues<K, V, A> {\n    #[inline]\n    fn len(&self) -> usize {\n        self.inner.len()\n    }\n}",
            "impl<K, V, A: Allocator> FusedIterator for IntoValues<K, V, A> {}",
            "impl<K, V, A: Allocator> Iterator for IntoValues<K, V, A> {\n    type Item = V;\n\n    #[inline]\n    fn next(&mut self) -> Option<V> {\n        self.inner.next().map(|(_, v)| v)\n    }\n    #[inline]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.inner.size_hint()\n    }\n    #[inline]\n    fn fold<B, F>(self, init: B, mut f: F) -> B\n    where\n        Self: Sized,\n        F: FnMut(B, Self::Item) -> B,\n    {\n        self.inner.fold(init, |acc, (_, v)| f(acc, v))\n    }\n}",
            "impl<K, V: Debug, A: Allocator> fmt::Debug for IntoValues<K, V, A> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_list()\n            .entries(self.inner.iter().map(|(_, v)| v))\n            .finish()\n    }\n}"
        ],
        "map::Iter": [
            "impl<'a, K, V> Iterator for Iter<'a, K, V> {\n    type Item = (&'a K, &'a V);\n\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn next(&mut self) -> Option<(&'a K, &'a V)> {\n        // Avoid `Option::map` because it bloats LLVM IR.\n        match self.inner.next() {\n            Some(x) => unsafe {\n                let r = x.as_ref();\n                Some((&r.0, &r.1))\n            },\n            None => None,\n        }\n    }\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.inner.size_hint()\n    }\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn fold<B, F>(self, init: B, mut f: F) -> B\n    where\n        Self: Sized,\n        F: FnMut(B, Self::Item) -> B,\n    {\n        self.inner.fold(init, |acc, x| unsafe {\n            let (k, v) = x.as_ref();\n            f(acc, (k, v))\n        })\n    }\n}",
            "impl<K, V> Clone for Iter<'_, K, V> {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn clone(&self) -> Self {\n        Iter {\n            inner: self.inner.clone(),\n            marker: PhantomData,\n        }\n    }\n}",
            "impl<K, V> Default for Iter<'_, K, V> {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn default() -> Self {\n        Self {\n            inner: Default::default(),\n            marker: PhantomData,\n        }\n    }\n}",
            "impl<K, V> ExactSizeIterator for Iter<'_, K, V> {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn len(&self) -> usize {\n        self.inner.len()\n    }\n}",
            "impl<K, V> FusedIterator for Iter<'_, K, V> {}",
            "impl<K: Debug, V: Debug> fmt::Debug for Iter<'_, K, V> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_list().entries(self.clone()).finish()\n    }\n}"
        ],
        "map::IterMut": [
            "impl<'a, K, V> Iterator for IterMut<'a, K, V> {\n    type Item = (&'a K, &'a mut V);\n\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn next(&mut self) -> Option<(&'a K, &'a mut V)> {\n        // Avoid `Option::map` because it bloats LLVM IR.\n        match self.inner.next() {\n            Some(x) => unsafe {\n                let r = x.as_mut();\n                Some((&r.0, &mut r.1))\n            },\n            None => None,\n        }\n    }\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.inner.size_hint()\n    }\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn fold<B, F>(self, init: B, mut f: F) -> B\n    where\n        Self: Sized,\n        F: FnMut(B, Self::Item) -> B,\n    {\n        self.inner.fold(init, |acc, x| unsafe {\n            let (k, v) = x.as_mut();\n            f(acc, (k, v))\n        })\n    }\n}",
            "impl<K, V> Default for IterMut<'_, K, V> {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn default() -> Self {\n        Self {\n            inner: Default::default(),\n            marker: PhantomData,\n        }\n    }\n}",
            "impl<K, V> ExactSizeIterator for IterMut<'_, K, V> {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn len(&self) -> usize {\n        self.inner.len()\n    }\n}",
            "impl<K, V> FusedIterator for IterMut<'_, K, V> {}",
            "impl<K, V> IterMut<'_, K, V> {\n    /// Returns a iterator of references over the remaining items.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub(super) fn iter(&self) -> Iter<'_, K, V> {\n        Iter {\n            inner: self.inner.clone(),\n            marker: PhantomData,\n        }\n    }\n}",
            "impl<K, V> fmt::Debug for IterMut<'_, K, V>\nwhere\n    K: fmt::Debug,\n    V: fmt::Debug,\n{\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_list().entries(self.iter()).finish()\n    }\n}",
            "unsafe impl<K: Send, V: Send> Send for IterMut<'_, K, V> {}"
        ],
        "map::Keys": [
            "impl<'a, K, V> Iterator for Keys<'a, K, V> {\n    type Item = &'a K;\n\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn next(&mut self) -> Option<&'a K> {\n        // Avoid `Option::map` because it bloats LLVM IR.\n        match self.inner.next() {\n            Some((k, _)) => Some(k),\n            None => None,\n        }\n    }\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.inner.size_hint()\n    }\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn fold<B, F>(self, init: B, mut f: F) -> B\n    where\n        Self: Sized,\n        F: FnMut(B, Self::Item) -> B,\n    {\n        self.inner.fold(init, |acc, (k, _)| f(acc, k))\n    }\n}",
            "impl<K, V> Clone for Keys<'_, K, V> {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn clone(&self) -> Self {\n        Keys {\n            inner: self.inner.clone(),\n        }\n    }\n}",
            "impl<K, V> Default for Keys<'_, K, V> {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn default() -> Self {\n        Self {\n            inner: Default::default(),\n        }\n    }\n}",
            "impl<K, V> ExactSizeIterator for Keys<'_, K, V> {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn len(&self) -> usize {\n        self.inner.len()\n    }\n}",
            "impl<K, V> FusedIterator for Keys<'_, K, V> {}",
            "impl<K: Debug, V> fmt::Debug for Keys<'_, K, V> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_list().entries(self.clone()).finish()\n    }\n}"
        ],
        "map::OccupiedEntry": [
            "impl<'a, K, V, S, A: Allocator> OccupiedEntry<'a, K, V, S, A> {\n    /// Gets a reference to the key in the entry.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::hash_map::{Entry, HashMap};\n    ///\n    /// let mut map: HashMap<&str, u32> = HashMap::new();\n    /// map.entry(\"poneyland\").or_insert(12);\n    ///\n    /// match map.entry(\"poneyland\") {\n    ///     Entry::Vacant(_) => panic!(),\n    ///     Entry::Occupied(entry) => assert_eq!(entry.key(), &\"poneyland\"),\n    /// }\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn key(&self) -> &K {\n        unsafe { &self.elem.as_ref().0 }\n    }\n\n    /// Take the ownership of the key and value from the map.\n    /// Keeps the allocated memory for reuse.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    /// use hashbrown::hash_map::Entry;\n    ///\n    /// let mut map: HashMap<&str, u32> = HashMap::new();\n    /// // The map is empty\n    /// assert!(map.is_empty() && map.capacity() == 0);\n    ///\n    /// map.entry(\"poneyland\").or_insert(12);\n    ///\n    /// if let Entry::Occupied(o) = map.entry(\"poneyland\") {\n    ///     // We delete the entry from the map.\n    ///     assert_eq!(o.remove_entry(), (\"poneyland\", 12));\n    /// }\n    ///\n    /// assert_eq!(map.contains_key(\"poneyland\"), false);\n    /// // Now map hold none elements\n    /// assert!(map.is_empty());\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn remove_entry(self) -> (K, V) {\n        unsafe { self.table.table.remove(self.elem).0 }\n    }\n\n    /// Gets a reference to the value in the entry.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    /// use hashbrown::hash_map::Entry;\n    ///\n    /// let mut map: HashMap<&str, u32> = HashMap::new();\n    /// map.entry(\"poneyland\").or_insert(12);\n    ///\n    /// match map.entry(\"poneyland\") {\n    ///     Entry::Vacant(_) => panic!(),\n    ///     Entry::Occupied(entry) => assert_eq!(entry.get(), &12),\n    /// }\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn get(&self) -> &V {\n        unsafe { &self.elem.as_ref().1 }\n    }\n\n    /// Gets a mutable reference to the value in the entry.\n    ///\n    /// If you need a reference to the `OccupiedEntry` which may outlive the\n    /// destruction of the `Entry` value, see [`into_mut`].\n    ///\n    /// [`into_mut`]: #method.into_mut\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    /// use hashbrown::hash_map::Entry;\n    ///\n    /// let mut map: HashMap<&str, u32> = HashMap::new();\n    /// map.entry(\"poneyland\").or_insert(12);\n    ///\n    /// assert_eq!(map[\"poneyland\"], 12);\n    /// if let Entry::Occupied(mut o) = map.entry(\"poneyland\") {\n    ///     *o.get_mut() += 10;\n    ///     assert_eq!(*o.get(), 22);\n    ///\n    ///     // We can use the same Entry multiple times.\n    ///     *o.get_mut() += 2;\n    /// }\n    ///\n    /// assert_eq!(map[\"poneyland\"], 24);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn get_mut(&mut self) -> &mut V {\n        unsafe { &mut self.elem.as_mut().1 }\n    }\n\n    /// Converts the `OccupiedEntry` into a mutable reference to the value in the entry\n    /// with a lifetime bound to the map itself.\n    ///\n    /// If you need multiple references to the `OccupiedEntry`, see [`get_mut`].\n    ///\n    /// [`get_mut`]: #method.get_mut\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::hash_map::{Entry, HashMap};\n    ///\n    /// let mut map: HashMap<&str, u32> = HashMap::new();\n    /// map.entry(\"poneyland\").or_insert(12);\n    ///\n    /// assert_eq!(map[\"poneyland\"], 12);\n    ///\n    /// let value: &mut u32;\n    /// match map.entry(\"poneyland\") {\n    ///     Entry::Occupied(entry) => value = entry.into_mut(),\n    ///     Entry::Vacant(_) => panic!(),\n    /// }\n    /// *value += 10;\n    ///\n    /// assert_eq!(map[\"poneyland\"], 22);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn into_mut(self) -> &'a mut V {\n        unsafe { &mut self.elem.as_mut().1 }\n    }\n\n    /// Sets the value of the entry, and returns the entry's old value.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    /// use hashbrown::hash_map::Entry;\n    ///\n    /// let mut map: HashMap<&str, u32> = HashMap::new();\n    /// map.entry(\"poneyland\").or_insert(12);\n    ///\n    /// if let Entry::Occupied(mut o) = map.entry(\"poneyland\") {\n    ///     assert_eq!(o.insert(15), 12);\n    /// }\n    ///\n    /// assert_eq!(map[\"poneyland\"], 15);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn insert(&mut self, value: V) -> V {\n        mem::replace(self.get_mut(), value)\n    }\n\n    /// Takes the value out of the entry, and returns it.\n    /// Keeps the allocated memory for reuse.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    /// use hashbrown::hash_map::Entry;\n    ///\n    /// let mut map: HashMap<&str, u32> = HashMap::new();\n    /// // The map is empty\n    /// assert!(map.is_empty() && map.capacity() == 0);\n    ///\n    /// map.entry(\"poneyland\").or_insert(12);\n    ///\n    /// if let Entry::Occupied(o) = map.entry(\"poneyland\") {\n    ///     assert_eq!(o.remove(), 12);\n    /// }\n    ///\n    /// assert_eq!(map.contains_key(\"poneyland\"), false);\n    /// // Now map hold none elements\n    /// assert!(map.is_empty());\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn remove(self) -> V {\n        self.remove_entry().1\n    }\n\n    /// Provides shared access to the key and owned access to the value of\n    /// the entry and allows to replace or remove it based on the\n    /// value of the returned option.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    /// use hashbrown::hash_map::Entry;\n    ///\n    /// let mut map: HashMap<&str, u32> = HashMap::new();\n    /// map.insert(\"poneyland\", 42);\n    ///\n    /// let entry = match map.entry(\"poneyland\") {\n    ///     Entry::Occupied(e) => {\n    ///         e.replace_entry_with(|k, v| {\n    ///             assert_eq!(k, &\"poneyland\");\n    ///             assert_eq!(v, 42);\n    ///             Some(v + 1)\n    ///         })\n    ///     }\n    ///     Entry::Vacant(_) => panic!(),\n    /// };\n    ///\n    /// match entry {\n    ///     Entry::Occupied(e) => {\n    ///         assert_eq!(e.key(), &\"poneyland\");\n    ///         assert_eq!(e.get(), &43);\n    ///     }\n    ///     Entry::Vacant(_) => panic!(),\n    /// }\n    ///\n    /// assert_eq!(map[\"poneyland\"], 43);\n    ///\n    /// let entry = match map.entry(\"poneyland\") {\n    ///     Entry::Occupied(e) => e.replace_entry_with(|_k, _v| None),\n    ///     Entry::Vacant(_) => panic!(),\n    /// };\n    ///\n    /// match entry {\n    ///     Entry::Vacant(e) => {\n    ///         assert_eq!(e.key(), &\"poneyland\");\n    ///     }\n    ///     Entry::Occupied(_) => panic!(),\n    /// }\n    ///\n    /// assert!(!map.contains_key(\"poneyland\"));\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn replace_entry_with<F>(self, f: F) -> Entry<'a, K, V, S, A>\n    where\n        F: FnOnce(&K, V) -> Option<V>,\n    {\n        unsafe {\n            let mut spare_key = None;\n\n            self.table\n                .table\n                .replace_bucket_with(self.elem.clone(), |(key, value)| {\n                    if let Some(new_value) = f(&key, value) {\n                        Some((key, new_value))\n                    } else {\n                        spare_key = Some(key);\n                        None\n                    }\n                });\n\n            if let Some(key) = spare_key {\n                Entry::Vacant(VacantEntry {\n                    hash: self.hash,\n                    key,\n                    table: self.table,\n                })\n            } else {\n                Entry::Occupied(self)\n            }\n        }\n    }\n}",
            "impl<K: Debug, V: Debug, S, A: Allocator> Debug for OccupiedEntry<'_, K, V, S, A> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_struct(\"OccupiedEntry\")\n            .field(\"key\", self.key())\n            .field(\"value\", self.get())\n            .finish()\n    }\n}",
            "unsafe impl<K, V, S, A> Send for OccupiedEntry<'_, K, V, S, A>\nwhere\n    K: Send,\n    V: Send,\n    S: Send,\n    A: Send + Allocator,\n{\n}",
            "unsafe impl<K, V, S, A> Sync for OccupiedEntry<'_, K, V, S, A>\nwhere\n    K: Sync,\n    V: Sync,\n    S: Sync,\n    A: Sync + Allocator,\n{\n}"
        ],
        "map::OccupiedError": [
            "impl<K: Debug, V: Debug, S, A: Allocator> Debug for OccupiedError<'_, K, V, S, A> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_struct(\"OccupiedError\")\n            .field(\"key\", self.entry.key())\n            .field(\"old_value\", self.entry.get())\n            .field(\"new_value\", &self.value)\n            .finish()\n    }\n}",
            "impl<K: Debug, V: Debug, S, A: Allocator> fmt::Display for OccupiedError<'_, K, V, S, A> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        write!(\n            f,\n            \"failed to insert {:?}, key {:?} already exists with value {:?}\",\n            self.value,\n            self.entry.key(),\n            self.entry.get(),\n        )\n    }\n}"
        ],
        "map::VacantEntry": [
            "impl<'a, K, V, S, A: Allocator> VacantEntry<'a, K, V, S, A> {\n    /// Gets a reference to the key that would be used when inserting a value\n    /// through the `VacantEntry`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut map: HashMap<&str, u32> = HashMap::new();\n    /// assert_eq!(map.entry(\"poneyland\").key(), &\"poneyland\");\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn key(&self) -> &K {\n        &self.key\n    }\n\n    /// Take ownership of the key.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::hash_map::{Entry, HashMap};\n    ///\n    /// let mut map: HashMap<&str, u32> = HashMap::new();\n    ///\n    /// match map.entry(\"poneyland\") {\n    ///     Entry::Occupied(_) => panic!(),\n    ///     Entry::Vacant(v) => assert_eq!(v.into_key(), \"poneyland\"),\n    /// }\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn into_key(self) -> K {\n        self.key\n    }\n\n    /// Sets the value of the entry with the [`VacantEntry`]'s key,\n    /// and returns a mutable reference to it.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    /// use hashbrown::hash_map::Entry;\n    ///\n    /// let mut map: HashMap<&str, u32> = HashMap::new();\n    ///\n    /// if let Entry::Vacant(o) = map.entry(\"poneyland\") {\n    ///     o.insert(37);\n    /// }\n    /// assert_eq!(map[\"poneyland\"], 37);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn insert(self, value: V) -> &'a mut V\n    where\n        K: Hash,\n        S: BuildHasher,\n    {\n        let table = &mut self.table.table;\n        let entry = table.insert_entry(\n            self.hash,\n            (self.key, value),\n            make_hasher::<_, V, S>(&self.table.hash_builder),\n        );\n        &mut entry.1\n    }\n\n    /// Sets the value of the entry with the [`VacantEntry`]'s key,\n    /// and returns an [`OccupiedEntry`].\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    /// use hashbrown::hash_map::Entry;\n    ///\n    /// let mut map: HashMap<&str, u32> = HashMap::new();\n    ///\n    /// if let Entry::Vacant(v) = map.entry(\"poneyland\") {\n    ///     let o = v.insert_entry(37);\n    ///     assert_eq!(o.get(), &37);\n    /// }\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn insert_entry(self, value: V) -> OccupiedEntry<'a, K, V, S, A>\n    where\n        K: Hash,\n        S: BuildHasher,\n    {\n        let elem = self.table.table.insert(\n            self.hash,\n            (self.key, value),\n            make_hasher::<_, V, S>(&self.table.hash_builder),\n        );\n        OccupiedEntry {\n            hash: self.hash,\n            elem,\n            table: self.table,\n        }\n    }\n}",
            "impl<K: Debug, V, S, A: Allocator> Debug for VacantEntry<'_, K, V, S, A> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_tuple(\"VacantEntry\").field(self.key()).finish()\n    }\n}"
        ],
        "map::VacantEntryRef": [
            "impl<'a, 'b, K, Q: ?Sized, V, S, A: Allocator> VacantEntryRef<'a, 'b, K, Q, V, S, A> {\n    /// Gets a reference to the key that would be used when inserting a value\n    /// through the `VacantEntryRef`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut map: HashMap<String, u32> = HashMap::new();\n    /// let key: &str = \"poneyland\";\n    /// assert_eq!(map.entry_ref(key).key(), \"poneyland\");\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn key(&self) -> &'b Q {\n        self.key\n    }\n\n    /// Sets the value of the entry with the `VacantEntryRef`'s key,\n    /// and returns a mutable reference to it.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    /// use hashbrown::hash_map::EntryRef;\n    ///\n    /// let mut map: HashMap<String, u32> = HashMap::new();\n    /// let key: &str = \"poneyland\";\n    ///\n    /// if let EntryRef::Vacant(o) = map.entry_ref(key) {\n    ///     o.insert(37);\n    /// }\n    /// assert_eq!(map[\"poneyland\"], 37);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn insert(self, value: V) -> &'a mut V\n    where\n        K: Hash,\n        &'b Q: Into<K>,\n        S: BuildHasher,\n    {\n        let table = &mut self.table.table;\n        let entry = table.insert_entry(\n            self.hash,\n            (self.key.into(), value),\n            make_hasher::<_, V, S>(&self.table.hash_builder),\n        );\n        &mut entry.1\n    }\n\n    /// Sets the value of the entry with the [`VacantEntryRef`]'s key,\n    /// and returns an [`OccupiedEntry`].\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    /// use hashbrown::hash_map::EntryRef;\n    ///\n    /// let mut map: HashMap<&str, u32> = HashMap::new();\n    ///\n    /// if let EntryRef::Vacant(v) = map.entry_ref(\"poneyland\") {\n    ///     let o = v.insert_entry(37);\n    ///     assert_eq!(o.get(), &37);\n    /// }\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn insert_entry(self, value: V) -> OccupiedEntry<'a, K, V, S, A>\n    where\n        K: Hash,\n        &'b Q: Into<K>,\n        S: BuildHasher,\n    {\n        let elem = self.table.table.insert(\n            self.hash,\n            (self.key.into(), value),\n            make_hasher::<_, V, S>(&self.table.hash_builder),\n        );\n        OccupiedEntry {\n            hash: self.hash,\n            elem,\n            table: self.table,\n        }\n    }\n}",
            "impl<K, Q, V, S, A> Debug for VacantEntryRef<'_, '_, K, Q, V, S, A>\nwhere\n    K: Borrow<Q>,\n    Q: Debug + ?Sized,\n    A: Allocator,\n{\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_tuple(\"VacantEntryRef\").field(&self.key()).finish()\n    }\n}"
        ],
        "map::Values": [
            "impl<'a, K, V> Iterator for Values<'a, K, V> {\n    type Item = &'a V;\n\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn next(&mut self) -> Option<&'a V> {\n        // Avoid `Option::map` because it bloats LLVM IR.\n        match self.inner.next() {\n            Some((_, v)) => Some(v),\n            None => None,\n        }\n    }\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.inner.size_hint()\n    }\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn fold<B, F>(self, init: B, mut f: F) -> B\n    where\n        Self: Sized,\n        F: FnMut(B, Self::Item) -> B,\n    {\n        self.inner.fold(init, |acc, (_, v)| f(acc, v))\n    }\n}",
            "impl<K, V: Debug> fmt::Debug for Values<'_, K, V> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_list().entries(self.clone()).finish()\n    }\n}",
            "impl<K, V> Clone for Values<'_, K, V> {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn clone(&self) -> Self {\n        Values {\n            inner: self.inner.clone(),\n        }\n    }\n}",
            "impl<K, V> Default for Values<'_, K, V> {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn default() -> Self {\n        Self {\n            inner: Default::default(),\n        }\n    }\n}",
            "impl<K, V> ExactSizeIterator for Values<'_, K, V> {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn len(&self) -> usize {\n        self.inner.len()\n    }\n}",
            "impl<K, V> FusedIterator for Values<'_, K, V> {}"
        ],
        "map::ValuesMut": [
            "impl<'a, K, V> Iterator for ValuesMut<'a, K, V> {\n    type Item = &'a mut V;\n\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn next(&mut self) -> Option<&'a mut V> {\n        // Avoid `Option::map` because it bloats LLVM IR.\n        match self.inner.next() {\n            Some((_, v)) => Some(v),\n            None => None,\n        }\n    }\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.inner.size_hint()\n    }\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn fold<B, F>(self, init: B, mut f: F) -> B\n    where\n        Self: Sized,\n        F: FnMut(B, Self::Item) -> B,\n    {\n        self.inner.fold(init, |acc, (_, v)| f(acc, v))\n    }\n}",
            "impl<K, V: Debug> fmt::Debug for ValuesMut<'_, K, V> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_list()\n            .entries(self.inner.iter().map(|(_, val)| val))\n            .finish()\n    }\n}",
            "impl<K, V> Default for ValuesMut<'_, K, V> {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn default() -> Self {\n        Self {\n            inner: Default::default(),\n        }\n    }\n}",
            "impl<K, V> ExactSizeIterator for ValuesMut<'_, K, V> {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn len(&self) -> usize {\n        self.inner.len()\n    }\n}",
            "impl<K, V> FusedIterator for ValuesMut<'_, K, V> {}"
        ],
        "raw::Bucket": [
            "impl<T> Bucket<T> {\n    /// Creates a [`Bucket`] that contain pointer to the data.\n    /// The pointer calculation is performed by calculating the\n    /// offset from given `base` pointer (convenience for\n    /// `base.as_ptr().sub(index)`).\n    ///\n    /// `index` is in units of `T`; e.g., an `index` of 3 represents a pointer\n    /// offset of `3 * size_of::<T>()` bytes.\n    ///\n    /// If the `T` is a ZST, then we instead track the index of the element\n    /// in the table so that `erase` works properly (return\n    /// `NonNull::new_unchecked((index + 1) as *mut T)`)\n    ///\n    /// # Safety\n    ///\n    /// If `mem::size_of::<T>() != 0`, then the safety rules are directly derived\n    /// from the safety rules for [`<*mut T>::sub`] method of `*mut T` and the safety\n    /// rules of [`NonNull::new_unchecked`] function.\n    ///\n    /// Thus, in order to uphold the safety contracts for the [`<*mut T>::sub`] method\n    /// and [`NonNull::new_unchecked`] function, as well as for the correct\n    /// logic of the work of this crate, the following rules are necessary and\n    /// sufficient:\n    ///\n    /// * the `base` pointer must not be `dangling` and must points to the\n    ///   end of the first `value element` from the `data part` of the table, i.e.\n    ///   must be the pointer that returned by [`RawTable::data_end`] or by\n    ///   [`RawTableInner::data_end<T>`];\n    ///\n    /// * `index` must not be greater than `RawTableInner.bucket_mask`, i.e.\n    ///   `index <= RawTableInner.bucket_mask` or, in other words, `(index + 1)`\n    ///   must be no greater than the number returned by the function\n    ///   [`RawTable::buckets`] or [`RawTableInner::buckets`].\n    ///\n    /// If `mem::size_of::<T>() == 0`, then the only requirement is that the\n    /// `index` must not be greater than `RawTableInner.bucket_mask`, i.e.\n    /// `index <= RawTableInner.bucket_mask` or, in other words, `(index + 1)`\n    /// must be no greater than the number returned by the function\n    /// [`RawTable::buckets`] or [`RawTableInner::buckets`].\n    ///\n    /// [`Bucket`]: crate::raw::Bucket\n    /// [`<*mut T>::sub`]: https://doc.rust-lang.org/core/primitive.pointer.html#method.sub-1\n    /// [`NonNull::new_unchecked`]: https://doc.rust-lang.org/stable/std/ptr/struct.NonNull.html#method.new_unchecked\n    /// [`RawTable::data_end`]: crate::raw::RawTable::data_end\n    /// [`RawTableInner::data_end<T>`]: RawTableInner::data_end<T>\n    /// [`RawTable::buckets`]: crate::raw::RawTable::buckets\n    /// [`RawTableInner::buckets`]: RawTableInner::buckets\n    #[inline]\n    unsafe fn from_base_index(base: NonNull<T>, index: usize) -> Self {\n        // If mem::size_of::<T>() != 0 then return a pointer to an `element` in\n        // the data part of the table (we start counting from \"0\", so that\n        // in the expression T[last], the \"last\" index actually one less than the\n        // \"buckets\" number in the table, i.e. \"last = RawTableInner.bucket_mask\"):\n        //\n        //                   `from_base_index(base, 1).as_ptr()` returns a pointer that\n        //                   points here in the data part of the table\n        //                   (to the start of T1)\n        //                        |\n        //                        |        `base: NonNull<T>` must point here\n        //                        |         (to the end of T0 or to the start of C0)\n        //                        v         v\n        // [Padding], Tlast, ..., |T1|, T0, |C0, C1, ..., Clast\n        //                           ^\n        //                           `from_base_index(base, 1)` returns a pointer\n        //                           that points here in the data part of the table\n        //                           (to the end of T1)\n        //\n        // where: T0...Tlast - our stored data; C0...Clast - control bytes\n        // or metadata for data.\n        let ptr = if T::IS_ZERO_SIZED {\n            // won't overflow because index must be less than length (bucket_mask)\n            // and bucket_mask is guaranteed to be less than `isize::MAX`\n            // (see TableLayout::calculate_layout_for method)\n            invalid_mut(index + 1)\n        } else {\n            base.as_ptr().sub(index)\n        };\n        Self {\n            ptr: NonNull::new_unchecked(ptr),\n        }\n    }\n\n    /// Calculates the index of a [`Bucket`] as distance between two pointers\n    /// (convenience for `base.as_ptr().offset_from(self.ptr.as_ptr()) as usize`).\n    /// The returned value is in units of T: the distance in bytes divided by\n    /// [`core::mem::size_of::<T>()`].\n    ///\n    /// If the `T` is a ZST, then we return the index of the element in\n    /// the table so that `erase` works properly (return `self.ptr.as_ptr() as usize - 1`).\n    ///\n    /// This function is the inverse of [`from_base_index`].\n    ///\n    /// # Safety\n    ///\n    /// If `mem::size_of::<T>() != 0`, then the safety rules are directly derived\n    /// from the safety rules for [`<*const T>::offset_from`] method of `*const T`.\n    ///\n    /// Thus, in order to uphold the safety contracts for [`<*const T>::offset_from`]\n    /// method, as well as for the correct logic of the work of this crate, the\n    /// following rules are necessary and sufficient:\n    ///\n    /// * `base` contained pointer must not be `dangling` and must point to the\n    ///   end of the first `element` from the `data part` of the table, i.e.\n    ///   must be a pointer that returns by [`RawTable::data_end`] or by\n    ///   [`RawTableInner::data_end<T>`];\n    ///\n    /// * `self` also must not contain dangling pointer;\n    ///\n    /// * both `self` and `base` must be created from the same [`RawTable`]\n    ///   (or [`RawTableInner`]).\n    ///\n    /// If `mem::size_of::<T>() == 0`, this function is always safe.\n    ///\n    /// [`Bucket`]: crate::raw::Bucket\n    /// [`from_base_index`]: crate::raw::Bucket::from_base_index\n    /// [`RawTable::data_end`]: crate::raw::RawTable::data_end\n    /// [`RawTableInner::data_end<T>`]: RawTableInner::data_end<T>\n    /// [`RawTable`]: crate::raw::RawTable\n    /// [`RawTableInner`]: RawTableInner\n    /// [`<*const T>::offset_from`]: https://doc.rust-lang.org/nightly/core/primitive.pointer.html#method.offset_from\n    #[inline]\n    unsafe fn to_base_index(&self, base: NonNull<T>) -> usize {\n        // If mem::size_of::<T>() != 0 then return an index under which we used to store the\n        // `element` in the data part of the table (we start counting from \"0\", so\n        // that in the expression T[last], the \"last\" index actually is one less than the\n        // \"buckets\" number in the table, i.e. \"last = RawTableInner.bucket_mask\").\n        // For example for 5th element in table calculation is performed like this:\n        //\n        //                        mem::size_of::<T>()\n        //                          |\n        //                          |         `self = from_base_index(base, 5)` that returns pointer\n        //                          |         that points here in the data part of the table\n        //                          |         (to the end of T5)\n        //                          |           |                    `base: NonNull<T>` must point here\n        //                          v           |                    (to the end of T0 or to the start of C0)\n        //                        /???\\         v                      v\n        // [Padding], Tlast, ..., |T10|, ..., T5|, T4, T3, T2, T1, T0, |C0, C1, C2, C3, C4, C5, ..., C10, ..., Clast\n        //                                      \\__________  __________/\n        //                                                 \\/\n        //                                     `bucket.to_base_index(base)` = 5\n        //                                     (base.as_ptr() as usize - self.ptr.as_ptr() as usize) / mem::size_of::<T>()\n        //\n        // where: T0...Tlast - our stored data; C0...Clast - control bytes or metadata for data.\n        if T::IS_ZERO_SIZED {\n            // this can not be UB\n            self.ptr.as_ptr() as usize - 1\n        } else {\n            offset_from(base.as_ptr(), self.ptr.as_ptr())\n        }\n    }\n\n    /// Acquires the underlying raw pointer `*mut T` to `data`.\n    ///\n    /// # Note\n    ///\n    /// If `T` is not [`Copy`], do not use `*mut T` methods that can cause calling the\n    /// destructor of `T` (for example the [`<*mut T>::drop_in_place`] method), because\n    /// for properly dropping the data we also need to clear `data` control bytes. If we\n    /// drop data, but do not clear `data control byte` it leads to double drop when\n    /// [`RawTable`] goes out of scope.\n    ///\n    /// If you modify an already initialized `value`, so [`Hash`] and [`Eq`] on the new\n    /// `T` value and its borrowed form *must* match those for the old `T` value, as the map\n    /// will not re-evaluate where the new value should go, meaning the value may become\n    /// \"lost\" if their location does not reflect their state.\n    ///\n    /// [`RawTable`]: crate::raw::RawTable\n    /// [`<*mut T>::drop_in_place`]: https://doc.rust-lang.org/core/primitive.pointer.html#method.drop_in_place\n    /// [`Hash`]: https://doc.rust-lang.org/core/hash/trait.Hash.html\n    /// [`Eq`]: https://doc.rust-lang.org/core/cmp/trait.Eq.html\n    #[inline]\n    pub fn as_ptr(&self) -> *mut T {\n        if T::IS_ZERO_SIZED {\n            // Just return an arbitrary ZST pointer which is properly aligned\n            // invalid pointer is good enough for ZST\n            invalid_mut(mem::align_of::<T>())\n        } else {\n            unsafe { self.ptr.as_ptr().sub(1) }\n        }\n    }\n\n    /// Acquires the underlying non-null pointer `*mut T` to `data`.\n    #[inline]\n    fn as_non_null(&self) -> NonNull<T> {\n        // SAFETY: `self.ptr` is already a `NonNull`\n        unsafe { NonNull::new_unchecked(self.as_ptr()) }\n    }\n\n    /// Create a new [`Bucket`] that is offset from the `self` by the given\n    /// `offset`. The pointer calculation is performed by calculating the\n    /// offset from `self` pointer (convenience for `self.ptr.as_ptr().sub(offset)`).\n    /// This function is used for iterators.\n    ///\n    /// `offset` is in units of `T`; e.g., a `offset` of 3 represents a pointer\n    /// offset of `3 * size_of::<T>()` bytes.\n    ///\n    /// # Safety\n    ///\n    /// If `mem::size_of::<T>() != 0`, then the safety rules are directly derived\n    /// from the safety rules for [`<*mut T>::sub`] method of `*mut T` and safety\n    /// rules of [`NonNull::new_unchecked`] function.\n    ///\n    /// Thus, in order to uphold the safety contracts for [`<*mut T>::sub`] method\n    /// and [`NonNull::new_unchecked`] function, as well as for the correct\n    /// logic of the work of this crate, the following rules are necessary and\n    /// sufficient:\n    ///\n    /// * `self` contained pointer must not be `dangling`;\n    ///\n    /// * `self.to_base_index() + offset` must not be greater than `RawTableInner.bucket_mask`,\n    ///   i.e. `(self.to_base_index() + offset) <= RawTableInner.bucket_mask` or, in other\n    ///   words, `self.to_base_index() + offset + 1` must be no greater than the number returned\n    ///   by the function [`RawTable::buckets`] or [`RawTableInner::buckets`].\n    ///\n    /// If `mem::size_of::<T>() == 0`, then the only requirement is that the\n    /// `self.to_base_index() + offset` must not be greater than `RawTableInner.bucket_mask`,\n    /// i.e. `(self.to_base_index() + offset) <= RawTableInner.bucket_mask` or, in other words,\n    /// `self.to_base_index() + offset + 1` must be no greater than the number returned by the\n    /// function [`RawTable::buckets`] or [`RawTableInner::buckets`].\n    ///\n    /// [`Bucket`]: crate::raw::Bucket\n    /// [`<*mut T>::sub`]: https://doc.rust-lang.org/core/primitive.pointer.html#method.sub-1\n    /// [`NonNull::new_unchecked`]: https://doc.rust-lang.org/stable/std/ptr/struct.NonNull.html#method.new_unchecked\n    /// [`RawTable::buckets`]: crate::raw::RawTable::buckets\n    /// [`RawTableInner::buckets`]: RawTableInner::buckets\n    #[inline]\n    unsafe fn next_n(&self, offset: usize) -> Self {\n        let ptr = if T::IS_ZERO_SIZED {\n            // invalid pointer is good enough for ZST\n            invalid_mut(self.ptr.as_ptr() as usize + offset)\n        } else {\n            self.ptr.as_ptr().sub(offset)\n        };\n        Self {\n            ptr: NonNull::new_unchecked(ptr),\n        }\n    }\n\n    /// Executes the destructor (if any) of the pointed-to `data`.\n    ///\n    /// # Safety\n    ///\n    /// See [`ptr::drop_in_place`] for safety concerns.\n    ///\n    /// You should use [`RawTable::erase`] instead of this function,\n    /// or be careful with calling this function directly, because for\n    /// properly dropping the data we need also clear `data` control bytes.\n    /// If we drop data, but do not erase `data control byte` it leads to\n    /// double drop when [`RawTable`] goes out of scope.\n    ///\n    /// [`ptr::drop_in_place`]: https://doc.rust-lang.org/core/ptr/fn.drop_in_place.html\n    /// [`RawTable`]: crate::raw::RawTable\n    /// [`RawTable::erase`]: crate::raw::RawTable::erase\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub(crate) unsafe fn drop(&self) {\n        self.as_ptr().drop_in_place();\n    }\n\n    /// Reads the `value` from `self` without moving it. This leaves the\n    /// memory in `self` unchanged.\n    ///\n    /// # Safety\n    ///\n    /// See [`ptr::read`] for safety concerns.\n    ///\n    /// You should use [`RawTable::remove`] instead of this function,\n    /// or be careful with calling this function directly, because compiler\n    /// calls its destructor when the read `value` goes out of scope. It\n    /// can cause double dropping when [`RawTable`] goes out of scope,\n    /// because of not erased `data control byte`.\n    ///\n    /// [`ptr::read`]: https://doc.rust-lang.org/core/ptr/fn.read.html\n    /// [`RawTable`]: crate::raw::RawTable\n    /// [`RawTable::remove`]: crate::raw::RawTable::remove\n    #[inline]\n    pub(crate) unsafe fn read(&self) -> T {\n        self.as_ptr().read()\n    }\n\n    /// Overwrites a memory location with the given `value` without reading\n    /// or dropping the old value (like [`ptr::write`] function).\n    ///\n    /// # Safety\n    ///\n    /// See [`ptr::write`] for safety concerns.\n    ///\n    /// # Note\n    ///\n    /// [`Hash`] and [`Eq`] on the new `T` value and its borrowed form *must* match\n    /// those for the old `T` value, as the map will not re-evaluate where the new\n    /// value should go, meaning the value may become \"lost\" if their location\n    /// does not reflect their state.\n    ///\n    /// [`ptr::write`]: https://doc.rust-lang.org/core/ptr/fn.write.html\n    /// [`Hash`]: https://doc.rust-lang.org/core/hash/trait.Hash.html\n    /// [`Eq`]: https://doc.rust-lang.org/core/cmp/trait.Eq.html\n    #[inline]\n    pub(crate) unsafe fn write(&self, val: T) {\n        self.as_ptr().write(val);\n    }\n\n    /// Returns a shared immutable reference to the `value`.\n    ///\n    /// # Safety\n    ///\n    /// See [`NonNull::as_ref`] for safety concerns.\n    ///\n    /// [`NonNull::as_ref`]: https://doc.rust-lang.org/core/ptr/struct.NonNull.html#method.as_ref\n    #[inline]\n    pub unsafe fn as_ref<'a>(&self) -> &'a T {\n        &*self.as_ptr()\n    }\n\n    /// Returns a unique mutable reference to the `value`.\n    ///\n    /// # Safety\n    ///\n    /// See [`NonNull::as_mut`] for safety concerns.\n    ///\n    /// # Note\n    ///\n    /// [`Hash`] and [`Eq`] on the new `T` value and its borrowed form *must* match\n    /// those for the old `T` value, as the map will not re-evaluate where the new\n    /// value should go, meaning the value may become \"lost\" if their location\n    /// does not reflect their state.\n    ///\n    /// [`NonNull::as_mut`]: https://doc.rust-lang.org/core/ptr/struct.NonNull.html#method.as_mut\n    /// [`Hash`]: https://doc.rust-lang.org/core/hash/trait.Hash.html\n    /// [`Eq`]: https://doc.rust-lang.org/core/cmp/trait.Eq.html\n    #[inline]\n    pub unsafe fn as_mut<'a>(&self) -> &'a mut T {\n        &mut *self.as_ptr()\n    }\n}",
            "impl<T> Clone for Bucket<T> {\n    #[inline]\n    fn clone(&self) -> Self {\n        Self { ptr: self.ptr }\n    }\n}",
            "unsafe impl<T> Send for Bucket<T> {}"
        ],
        "raw::Fallibility": [
            "Clone",
            "Copy",
            "impl Fallibility {\n    /// Error to return on capacity overflow.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn capacity_overflow(self) -> TryReserveError {\n        match self {\n            Fallibility::Fallible => TryReserveError::CapacityOverflow,\n            Fallibility::Infallible => panic!(\"Hash table capacity overflow\"),\n        }\n    }\n\n    /// Error to return on allocation error.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn alloc_err(self, layout: Layout) -> TryReserveError {\n        match self {\n            Fallibility::Fallible => TryReserveError::AllocError { layout },\n            Fallibility::Infallible => handle_alloc_error(layout),\n        }\n    }\n}"
        ],
        "raw::FullBucketsIndices": [
            "impl ExactSizeIterator for FullBucketsIndices {}",
            "impl FullBucketsIndices {\n    /// Advances the iterator and returns the next value.\n    ///\n    /// # Safety\n    ///\n    /// If any of the following conditions are violated, the result is\n    /// [`Undefined Behavior`]:\n    ///\n    /// * The [`RawTableInner`] / [`RawTable`] must be alive and not moved,\n    ///   i.e. table outlives the `FullBucketsIndices`;\n    ///\n    /// * It never tries to iterate after getting all elements.\n    ///\n    /// [`Undefined Behavior`]: https://doc.rust-lang.org/reference/behavior-considered-undefined.html\n    #[inline(always)]\n    unsafe fn next_impl(&mut self) -> Option<usize> {\n        loop {\n            if let Some(index) = self.current_group.next() {\n                // The returned `self.group_first_index + index` will always\n                // be in the range `0..self.buckets()`. See explanation below.\n                return Some(self.group_first_index + index);\n            }\n\n            // SAFETY: The caller of this function ensures that:\n            //\n            // 1. It never tries to iterate after getting all the elements;\n            // 2. The table is alive and did not moved;\n            // 3. The first `self.ctrl` pointed to the start of the array of control bytes.\n            //\n            // Taking the above into account, we always stay within the bounds, because:\n            //\n            // 1. For tables smaller than the group width (self.buckets() <= Group::WIDTH),\n            //    we will never end up in the given branch, since we should have already\n            //    yielded all the elements of the table.\n            //\n            // 2. For tables larger than the group width. The number of buckets is a\n            //    power of two (2 ^ n), Group::WIDTH is also power of two (2 ^ k). Since\n            //    `(2 ^ n) > (2 ^ k)`, than `(2 ^ n) % (2 ^ k) = 0`. As we start from the\n            //    the start of the array of control bytes, and never try to iterate after\n            //    getting all the elements, the last `self.ctrl` will be equal to\n            //    the `self.buckets() - Group::WIDTH`, so `self.current_group.next()`\n            //    will always contains indices within the range `0..Group::WIDTH`,\n            //    and subsequent `self.group_first_index + index` will always return a\n            //    number less than `self.buckets()`.\n            self.ctrl = NonNull::new_unchecked(self.ctrl.as_ptr().add(Group::WIDTH));\n\n            // SAFETY: See explanation above.\n            self.current_group = Group::load_aligned(self.ctrl.as_ptr().cast())\n                .match_full()\n                .into_iter();\n            self.group_first_index += Group::WIDTH;\n        }\n    }\n}",
            "impl FusedIterator for FullBucketsIndices {}",
            "impl Iterator for FullBucketsIndices {\n    type Item = usize;\n\n    /// Advances the iterator and returns the next value. It is up to\n    /// the caller to ensure that the `RawTable` outlives the `FullBucketsIndices`,\n    /// because we cannot make the `next` method unsafe.\n    #[inline(always)]\n    fn next(&mut self) -> Option<usize> {\n        // Return if we already yielded all items.\n        if self.items == 0 {\n            return None;\n        }\n\n        let nxt = unsafe {\n            // SAFETY:\n            // 1. We check number of items to yield using `items` field.\n            // 2. The caller ensures that the table is alive and has not moved.\n            self.next_impl()\n        };\n\n        debug_assert!(nxt.is_some());\n        self.items -= 1;\n\n        nxt\n    }\n\n    #[inline(always)]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        (self.items, Some(self.items))\n    }\n}"
        ],
        "raw::ProbeSeq": [
            "Clone",
            "impl ProbeSeq {\n    #[inline]\n    fn move_next(&mut self, bucket_mask: usize) {\n        // We should have found an empty bucket by now and ended the probe.\n        debug_assert!(\n            self.stride <= bucket_mask,\n            \"Went past end of probe sequence\"\n        );\n\n        self.stride += Group::WIDTH;\n        self.pos += self.stride;\n        self.pos &= bucket_mask;\n    }\n}"
        ],
        "raw::RawDrain": [
            "impl<T, A: Allocator> Drop for RawDrain<'_, T, A> {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn drop(&mut self) {\n        unsafe {\n            // Drop all remaining elements. Note that this may panic.\n            self.iter.drop_elements();\n\n            // Reset the contents of the table now that all elements have been\n            // dropped.\n            self.table.clear_no_drop();\n\n            // Move the now empty table back to its original location.\n            self.orig_table\n                .as_ptr()\n                .copy_from_nonoverlapping(&self.table, 1);\n        }\n    }\n}",
            "impl<T, A: Allocator> ExactSizeIterator for RawDrain<'_, T, A> {}",
            "impl<T, A: Allocator> FusedIterator for RawDrain<'_, T, A> {}",
            "impl<T, A: Allocator> Iterator for RawDrain<'_, T, A> {\n    type Item = T;\n\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn next(&mut self) -> Option<T> {\n        unsafe {\n            let item = self.iter.next()?;\n            Some(item.read())\n        }\n    }\n\n    #[inline]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.iter.size_hint()\n    }\n}",
            "impl<T, A: Allocator> RawDrain<'_, T, A> {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn iter(&self) -> RawIter<T> {\n        self.iter.clone()\n    }\n}",
            "unsafe impl<T, A: Allocator> Send for RawDrain<'_, T, A>\nwhere\n    T: Send,\n    A: Send,\n{\n}",
            "unsafe impl<T, A: Allocator> Sync for RawDrain<'_, T, A>\nwhere\n    T: Sync,\n    A: Sync,\n{\n}"
        ],
        "raw::RawExtractIf": [
            "impl<T, A: Allocator> RawExtractIf<'_, T, A> {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub(crate) fn next<F>(&mut self, mut f: F) -> Option<T>\n    where\n        F: FnMut(&mut T) -> bool,\n    {\n        unsafe {\n            for item in &mut self.iter {\n                if f(item.as_mut()) {\n                    return Some(self.table.remove(item).0);\n                }\n            }\n        }\n        None\n    }\n}"
        ],
        "raw::RawIntoIter": [
            "impl<T, A: Allocator> Default for RawIntoIter<T, A> {\n    fn default() -> Self {\n        Self {\n            iter: Default::default(),\n            allocation: None,\n            marker: PhantomData,\n        }\n    }\n}",
            "impl<T, A: Allocator> Drop for RawIntoIter<T, A> {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn drop(&mut self) {\n        unsafe {\n            // Drop all remaining elements\n            self.iter.drop_elements();\n\n            // Free the table\n            if let Some((ptr, layout, ref alloc)) = self.allocation {\n                alloc.deallocate(ptr, layout);\n            }\n        }\n    }\n}",
            "impl<T, A: Allocator> ExactSizeIterator for RawIntoIter<T, A> {}",
            "impl<T, A: Allocator> FusedIterator for RawIntoIter<T, A> {}",
            "impl<T, A: Allocator> Iterator for RawIntoIter<T, A> {\n    type Item = T;\n\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn next(&mut self) -> Option<T> {\n        unsafe { Some(self.iter.next()?.read()) }\n    }\n\n    #[inline]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.iter.size_hint()\n    }\n}",
            "impl<T, A: Allocator> RawIntoIter<T, A> {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn iter(&self) -> RawIter<T> {\n        self.iter.clone()\n    }\n}",
            "unsafe impl<T, A: Allocator> Send for RawIntoIter<T, A>\nwhere\n    T: Send,\n    A: Send,\n{\n}",
            "unsafe impl<T, A: Allocator> Sync for RawIntoIter<T, A>\nwhere\n    T: Sync,\n    A: Sync,\n{\n}"
        ],
        "raw::RawIter": [
            "impl<T> Clone for RawIter<T> {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn clone(&self) -> Self {\n        Self {\n            iter: self.iter.clone(),\n            items: self.items,\n        }\n    }\n}",
            "impl<T> Default for RawIter<T> {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn default() -> Self {\n        // SAFETY: Because the table is static, it always outlives the iter.\n        unsafe { RawTableInner::NEW.iter() }\n    }\n}",
            "impl<T> ExactSizeIterator for RawIter<T> {}",
            "impl<T> FusedIterator for RawIter<T> {}",
            "impl<T> Iterator for RawIter<T> {\n    type Item = Bucket<T>;\n\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn next(&mut self) -> Option<Bucket<T>> {\n        // Inner iterator iterates over buckets\n        // so it can do unnecessary work if we already yielded all items.\n        if self.items == 0 {\n            return None;\n        }\n\n        let nxt = unsafe {\n            // SAFETY: We check number of items to yield using `items` field.\n            self.iter.next_impl::<false>()\n        };\n\n        debug_assert!(nxt.is_some());\n        self.items -= 1;\n\n        nxt\n    }\n\n    #[inline]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        (self.items, Some(self.items))\n    }\n\n    #[inline]\n    fn fold<B, F>(self, init: B, f: F) -> B\n    where\n        Self: Sized,\n        F: FnMut(B, Self::Item) -> B,\n    {\n        unsafe { self.iter.fold_impl(self.items, init, f) }\n    }\n}",
            "impl<T> RawIter<T> {\n    unsafe fn drop_elements(&mut self) {\n        if T::NEEDS_DROP && self.items != 0 {\n            for item in self {\n                item.drop();\n            }\n        }\n    }\n}"
        ],
        "raw::RawIterHash": [
            "impl<T> Clone for RawIterHash<T> {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn clone(&self) -> Self {\n        Self {\n            inner: self.inner.clone(),\n            _marker: PhantomData,\n        }\n    }\n}",
            "impl<T> Default for RawIterHash<T> {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn default() -> Self {\n        Self {\n            // SAFETY: Because the table is static, it always outlives the iter.\n            inner: unsafe { RawIterHashInner::new(&RawTableInner::NEW, 0) },\n            _marker: PhantomData,\n        }\n    }\n}",
            "impl<T> Iterator for RawIterHash<T> {\n    type Item = Bucket<T>;\n\n    fn next(&mut self) -> Option<Bucket<T>> {\n        unsafe {\n            match self.inner.next() {\n                Some(index) => {\n                    // Can't use `RawTable::bucket` here as we don't have\n                    // an actual `RawTable` reference to use.\n                    debug_assert!(index <= self.inner.bucket_mask);\n                    let bucket = Bucket::from_base_index(self.inner.ctrl.cast(), index);\n                    Some(bucket)\n                }\n                None => None,\n            }\n        }\n    }\n}",
            "impl<T> RawIterHash<T> {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    unsafe fn new<A: Allocator>(table: &RawTable<T, A>, hash: u64) -> Self {\n        RawIterHash {\n            inner: RawIterHashInner::new(&table.table, hash),\n            _marker: PhantomData,\n        }\n    }\n}"
        ],
        "raw::RawIterHashInner": [
            "Clone",
            "impl Iterator for RawIterHashInner {\n    type Item = usize;\n\n    fn next(&mut self) -> Option<Self::Item> {\n        unsafe {\n            loop {\n                if let Some(bit) = self.bitmask.next() {\n                    let index = (self.probe_seq.pos + bit) & self.bucket_mask;\n                    return Some(index);\n                }\n                if likely(self.group.match_empty().any_bit_set()) {\n                    return None;\n                }\n                self.probe_seq.move_next(self.bucket_mask);\n\n                // Can't use `RawTableInner::ctrl` here as we don't have\n                // an actual `RawTableInner` reference to use.\n                let index = self.probe_seq.pos;\n                debug_assert!(index < self.bucket_mask + 1 + Group::WIDTH);\n                let group_ctrl = self.ctrl.as_ptr().add(index).cast();\n\n                self.group = Group::load(group_ctrl);\n                self.bitmask = self.group.match_tag(self.tag_hash).into_iter();\n            }\n        }\n    }\n}",
            "impl RawIterHashInner {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    unsafe fn new(table: &RawTableInner, hash: u64) -> Self {\n        let tag_hash = Tag::full(hash);\n        let probe_seq = table.probe_seq(hash);\n        let group = Group::load(table.ctrl(probe_seq.pos));\n        let bitmask = group.match_tag(tag_hash).into_iter();\n\n        RawIterHashInner {\n            bucket_mask: table.bucket_mask,\n            ctrl: table.ctrl,\n            tag_hash,\n            probe_seq,\n            group,\n            bitmask,\n        }\n    }\n}"
        ],
        "raw::RawIterRange": [
            "impl<T> Clone for RawIterRange<T> {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn clone(&self) -> Self {\n        Self {\n            data: self.data.clone(),\n            next_ctrl: self.next_ctrl,\n            current_group: self.current_group.clone(),\n            end: self.end,\n        }\n    }\n}",
            "impl<T> FusedIterator for RawIterRange<T> {}",
            "impl<T> Iterator for RawIterRange<T> {\n    type Item = Bucket<T>;\n\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn next(&mut self) -> Option<Bucket<T>> {\n        unsafe {\n            // SAFETY: We set checker flag to true.\n            self.next_impl::<true>()\n        }\n    }\n\n    #[inline]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        // We don't have an item count, so just guess based on the range size.\n        let remaining_buckets = if self.end > self.next_ctrl {\n            unsafe { offset_from(self.end, self.next_ctrl) }\n        } else {\n            0\n        };\n\n        // Add a group width to include the group we are currently processing.\n        (0, Some(Group::WIDTH + remaining_buckets))\n    }\n}",
            "impl<T> RawIterRange<T> {\n    /// Returns a `RawIterRange` covering a subset of a table.\n    ///\n    /// # Safety\n    ///\n    /// If any of the following conditions are violated, the result is\n    /// [`undefined behavior`]:\n    ///\n    /// * `ctrl` must be [valid] for reads, i.e. table outlives the `RawIterRange`;\n    ///\n    /// * `ctrl` must be properly aligned to the group size (`Group::WIDTH`);\n    ///\n    /// * `ctrl` must point to the array of properly initialized control bytes;\n    ///\n    /// * `data` must be the [`Bucket`] at the `ctrl` index in the table;\n    ///\n    /// * the value of `len` must be less than or equal to the number of table buckets,\n    ///   and the returned value of `ctrl.as_ptr().add(len).offset_from(ctrl.as_ptr())`\n    ///   must be positive.\n    ///\n    /// * The `ctrl.add(len)` pointer must be either in bounds or one\n    ///   byte past the end of the same [allocated table].\n    ///\n    /// * The `len` must be a power of two.\n    ///\n    /// [valid]: https://doc.rust-lang.org/std/ptr/index.html#safety\n    /// [`undefined behavior`]: https://doc.rust-lang.org/reference/behavior-considered-undefined.html\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    unsafe fn new(ctrl: *const u8, data: Bucket<T>, len: usize) -> Self {\n        debug_assert_ne!(len, 0);\n        debug_assert_eq!(ctrl as usize % Group::WIDTH, 0);\n        // SAFETY: The caller must uphold the safety rules for the [`RawIterRange::new`]\n        let end = ctrl.add(len);\n\n        // Load the first group and advance ctrl to point to the next group\n        // SAFETY: The caller must uphold the safety rules for the [`RawIterRange::new`]\n        let current_group = Group::load_aligned(ctrl.cast()).match_full();\n        let next_ctrl = ctrl.add(Group::WIDTH);\n\n        Self {\n            current_group: current_group.into_iter(),\n            data,\n            next_ctrl,\n            end,\n        }\n    }\n\n    /// Splits a `RawIterRange` into two halves.\n    ///\n    /// Returns `None` if the remaining range is smaller than or equal to the\n    /// group width.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    #[cfg(feature = \"rayon\")]\n    pub(crate) fn split(mut self) -> (Self, Option<RawIterRange<T>>) {\n        unsafe {\n            if self.end <= self.next_ctrl {\n                // Nothing to split if the group that we are current processing\n                // is the last one.\n                (self, None)\n            } else {\n                // len is the remaining number of elements after the group that\n                // we are currently processing. It must be a multiple of the\n                // group size (small tables are caught by the check above).\n                let len = offset_from(self.end, self.next_ctrl);\n                debug_assert_eq!(len % Group::WIDTH, 0);\n\n                // Split the remaining elements into two halves, but round the\n                // midpoint down in case there is an odd number of groups\n                // remaining. This ensures that:\n                // - The tail is at least 1 group long.\n                // - The split is roughly even considering we still have the\n                //   current group to process.\n                let mid = (len / 2) & !(Group::WIDTH - 1);\n\n                let tail = Self::new(\n                    self.next_ctrl.add(mid),\n                    self.data.next_n(Group::WIDTH).next_n(mid),\n                    len - mid,\n                );\n                debug_assert_eq!(\n                    self.data.next_n(Group::WIDTH).next_n(mid).ptr,\n                    tail.data.ptr\n                );\n                debug_assert_eq!(self.end, tail.end);\n                self.end = self.next_ctrl.add(mid);\n                debug_assert_eq!(self.end.add(Group::WIDTH), tail.next_ctrl);\n                (self, Some(tail))\n            }\n        }\n    }\n\n    /// # Safety\n    /// If `DO_CHECK_PTR_RANGE` is false, caller must ensure that we never try to iterate\n    /// after yielding all elements.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    unsafe fn next_impl<const DO_CHECK_PTR_RANGE: bool>(&mut self) -> Option<Bucket<T>> {\n        loop {\n            if let Some(index) = self.current_group.next() {\n                return Some(self.data.next_n(index));\n            }\n\n            if DO_CHECK_PTR_RANGE && self.next_ctrl >= self.end {\n                return None;\n            }\n\n            // We might read past self.end up to the next group boundary,\n            // but this is fine because it only occurs on tables smaller\n            // than the group size where the trailing control bytes are all\n            // EMPTY. On larger tables self.end is guaranteed to be aligned\n            // to the group size (since tables are power-of-two sized).\n            self.current_group = Group::load_aligned(self.next_ctrl.cast())\n                .match_full()\n                .into_iter();\n            self.data = self.data.next_n(Group::WIDTH);\n            self.next_ctrl = self.next_ctrl.add(Group::WIDTH);\n        }\n    }\n\n    /// Folds every element into an accumulator by applying an operation,\n    /// returning the final result.\n    ///\n    /// `fold_impl()` takes three arguments: the number of items remaining in\n    /// the iterator, an initial value, and a closure with two arguments: an\n    /// 'accumulator', and an element. The closure returns the value that the\n    /// accumulator should have for the next iteration.\n    ///\n    /// The initial value is the value the accumulator will have on the first call.\n    ///\n    /// After applying this closure to every element of the iterator, `fold_impl()`\n    /// returns the accumulator.\n    ///\n    /// # Safety\n    ///\n    /// If any of the following conditions are violated, the result is\n    /// [`Undefined Behavior`]:\n    ///\n    /// * The [`RawTableInner`] / [`RawTable`] must be alive and not moved,\n    ///   i.e. table outlives the `RawIterRange`;\n    ///\n    /// * The provided `n` value must match the actual number of items\n    ///   in the table.\n    ///\n    /// [`Undefined Behavior`]: https://doc.rust-lang.org/reference/behavior-considered-undefined.html\n    #[allow(clippy::while_let_on_iterator)]\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    unsafe fn fold_impl<F, B>(mut self, mut n: usize, mut acc: B, mut f: F) -> B\n    where\n        F: FnMut(B, Bucket<T>) -> B,\n    {\n        loop {\n            while let Some(index) = self.current_group.next() {\n                // The returned `index` will always be in the range `0..Group::WIDTH`,\n                // so that calling `self.data.next_n(index)` is safe (see detailed explanation below).\n                debug_assert!(n != 0);\n                let bucket = self.data.next_n(index);\n                acc = f(acc, bucket);\n                n -= 1;\n            }\n\n            if n == 0 {\n                return acc;\n            }\n\n            // SAFETY: The caller of this function ensures that:\n            //\n            // 1. The provided `n` value matches the actual number of items in the table;\n            // 2. The table is alive and did not moved.\n            //\n            // Taking the above into account, we always stay within the bounds, because:\n            //\n            // 1. For tables smaller than the group width (self.buckets() <= Group::WIDTH),\n            //    we will never end up in the given branch, since we should have already\n            //    yielded all the elements of the table.\n            //\n            // 2. For tables larger than the group width. The number of buckets is a\n            //    power of two (2 ^ n), Group::WIDTH is also power of two (2 ^ k). Since\n            //    `(2 ^ n) > (2 ^ k)`, than `(2 ^ n) % (2 ^ k) = 0`. As we start from the\n            //    start of the array of control bytes, and never try to iterate after\n            //    getting all the elements, the last `self.current_group` will read bytes\n            //    from the `self.buckets() - Group::WIDTH` index.  We know also that\n            //    `self.current_group.next()` will always return indices within the range\n            //    `0..Group::WIDTH`.\n            //\n            //    Knowing all of the above and taking into account that we are synchronizing\n            //    the `self.data` index with the index we used to read the `self.current_group`,\n            //    the subsequent `self.data.next_n(index)` will always return a bucket with\n            //    an index number less than `self.buckets()`.\n            //\n            //    The last `self.next_ctrl`, whose index would be `self.buckets()`, will never\n            //    actually be read, since we should have already yielded all the elements of\n            //    the table.\n            self.current_group = Group::load_aligned(self.next_ctrl.cast())\n                .match_full()\n                .into_iter();\n            self.data = self.data.next_n(Group::WIDTH);\n            self.next_ctrl = self.next_ctrl.add(Group::WIDTH);\n        }\n    }\n}",
            "unsafe impl<T> Send for RawIterRange<T> {}",
            "unsafe impl<T> Sync for RawIterRange<T> {}"
        ],
        "raw::RawTable": [
            "impl<T, A: Allocator + Default> Default for RawTable<T, A> {\n    #[inline]\n    fn default() -> Self {\n        Self::new_in(Default::default())\n    }\n}",
            "impl<T, A: Allocator> Drop for RawTable<T, A> {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn drop(&mut self) {\n        unsafe {\n            // SAFETY:\n            // 1. We call the function only once;\n            // 2. We know for sure that `alloc` and `table_layout` matches the [`Allocator`]\n            //    and [`TableLayout`] that were used to allocate this table.\n            // 3. If the drop function of any elements fails, then only a memory leak will occur,\n            //    and we don't care because we are inside the `Drop` function of the `RawTable`,\n            //    so there won't be any table left in an inconsistent state.\n            self.table\n                .drop_inner_table::<T, _>(&self.alloc, Self::TABLE_LAYOUT);\n        }\n    }\n}",
            "impl<T, A: Allocator> IntoIterator for RawTable<T, A> {\n    type Item = T;\n    type IntoIter = RawIntoIter<T, A>;\n\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn into_iter(self) -> RawIntoIter<T, A> {\n        unsafe {\n            let iter = self.iter();\n            self.into_iter_from(iter)\n        }\n    }\n}",
            "impl<T, A: Allocator> RawTable<T, A> {\n    const TABLE_LAYOUT: TableLayout = TableLayout::new::<T>();\n\n    /// Creates a new empty hash table without allocating any memory, using the\n    /// given allocator.\n    ///\n    /// In effect this returns a table with exactly 1 bucket. However we can\n    /// leave the data pointer dangling since that bucket is never written to\n    /// due to our load factor forcing us to always have at least 1 free bucket.\n    #[inline]\n    #[cfg_attr(feature = \"rustc-dep-of-std\", rustc_const_stable_indirect)]\n    pub const fn new_in(alloc: A) -> Self {\n        Self {\n            table: RawTableInner::NEW,\n            alloc,\n            marker: PhantomData,\n        }\n    }\n\n    /// Allocates a new hash table with the given number of buckets.\n    ///\n    /// The control bytes are left uninitialized.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    unsafe fn new_uninitialized(\n        alloc: A,\n        buckets: usize,\n        fallibility: Fallibility,\n    ) -> Result<Self, TryReserveError> {\n        debug_assert!(buckets.is_power_of_two());\n\n        Ok(Self {\n            table: RawTableInner::new_uninitialized(\n                &alloc,\n                Self::TABLE_LAYOUT,\n                buckets,\n                fallibility,\n            )?,\n            alloc,\n            marker: PhantomData,\n        })\n    }\n\n    /// Allocates a new hash table using the given allocator, with at least enough capacity for\n    /// inserting the given number of elements without reallocating.\n    pub fn with_capacity_in(capacity: usize, alloc: A) -> Self {\n        Self {\n            table: RawTableInner::with_capacity(&alloc, Self::TABLE_LAYOUT, capacity),\n            alloc,\n            marker: PhantomData,\n        }\n    }\n\n    /// Returns a reference to the underlying allocator.\n    #[inline]\n    pub fn allocator(&self) -> &A {\n        &self.alloc\n    }\n\n    /// Returns pointer to one past last `data` element in the table as viewed from\n    /// the start point of the allocation.\n    ///\n    /// The caller must ensure that the `RawTable` outlives the returned [`NonNull<T>`],\n    /// otherwise using it may result in [`undefined behavior`].\n    ///\n    /// [`undefined behavior`]: https://doc.rust-lang.org/reference/behavior-considered-undefined.html\n    #[inline]\n    pub fn data_end(&self) -> NonNull<T> {\n        //                        `self.table.ctrl.cast()` returns pointer that\n        //                        points here (to the end of `T0`)\n        //                          \n        // [Pad], T_n, ..., T1, T0, |CT0, CT1, ..., CT_n|, CTa_0, CTa_1, ..., CTa_m\n        //                           \\________  ________/\n        //                                    \\/\n        //       `n = buckets - 1`, i.e. `RawTable::buckets() - 1`\n        //\n        // where: T0...T_n  - our stored data;\n        //        CT0...CT_n - control bytes or metadata for `data`.\n        //        CTa_0...CTa_m - additional control bytes, where `m = Group::WIDTH - 1` (so that the search\n        //                        with loading `Group` bytes from the heap works properly, even if the result\n        //                        of `h1(hash) & self.bucket_mask` is equal to `self.bucket_mask`). See also\n        //                        `RawTableInner::set_ctrl` function.\n        //\n        // P.S. `h1(hash) & self.bucket_mask` is the same as `hash as usize % self.buckets()` because the number\n        // of buckets is a power of two, and `self.bucket_mask = self.buckets() - 1`.\n        self.table.ctrl.cast()\n    }\n\n    /// Returns pointer to start of data table.\n    #[inline]\n    #[cfg(feature = \"nightly\")]\n    pub unsafe fn data_start(&self) -> NonNull<T> {\n        NonNull::new_unchecked(self.data_end().as_ptr().wrapping_sub(self.buckets()))\n    }\n\n    /// Returns the total amount of memory allocated internally by the hash\n    /// table, in bytes.\n    ///\n    /// The returned number is informational only. It is intended to be\n    /// primarily used for memory profiling.\n    #[inline]\n    pub fn allocation_size(&self) -> usize {\n        // SAFETY: We use the same `table_layout` that was used to allocate\n        // this table.\n        unsafe { self.table.allocation_size_or_zero(Self::TABLE_LAYOUT) }\n    }\n\n    /// Returns the index of a bucket from a `Bucket`.\n    #[inline]\n    pub unsafe fn bucket_index(&self, bucket: &Bucket<T>) -> usize {\n        bucket.to_base_index(self.data_end())\n    }\n\n    /// Returns a pointer to an element in the table.\n    ///\n    /// The caller must ensure that the `RawTable` outlives the returned [`Bucket<T>`],\n    /// otherwise using it may result in [`undefined behavior`].\n    ///\n    /// # Safety\n    ///\n    /// If `mem::size_of::<T>() != 0`, then the caller of this function must observe the\n    /// following safety rules:\n    ///\n    /// * The table must already be allocated;\n    ///\n    /// * The `index` must not be greater than the number returned by the [`RawTable::buckets`]\n    ///   function, i.e. `(index + 1) <= self.buckets()`.\n    ///\n    /// It is safe to call this function with index of zero (`index == 0`) on a table that has\n    /// not been allocated, but using the returned [`Bucket`] results in [`undefined behavior`].\n    ///\n    /// If `mem::size_of::<T>() == 0`, then the only requirement is that the `index` must\n    /// not be greater than the number returned by the [`RawTable::buckets`] function, i.e.\n    /// `(index + 1) <= self.buckets()`.\n    ///\n    /// [`RawTable::buckets`]: RawTable::buckets\n    /// [`undefined behavior`]: https://doc.rust-lang.org/reference/behavior-considered-undefined.html\n    #[inline]\n    pub unsafe fn bucket(&self, index: usize) -> Bucket<T> {\n        // If mem::size_of::<T>() != 0 then return a pointer to the `element` in the `data part` of the table\n        // (we start counting from \"0\", so that in the expression T[n], the \"n\" index actually one less than\n        // the \"buckets\" number of our `RawTable`, i.e. \"n = RawTable::buckets() - 1\"):\n        //\n        //           `table.bucket(3).as_ptr()` returns a pointer that points here in the `data`\n        //           part of the `RawTable`, i.e. to the start of T3 (see `Bucket::as_ptr`)\n        //                  |\n        //                  |               `base = self.data_end()` points here\n        //                  |               (to the start of CT0 or to the end of T0)\n        //                  v                 v\n        // [Pad], T_n, ..., |T3|, T2, T1, T0, |CT0, CT1, CT2, CT3, ..., CT_n, CTa_0, CTa_1, ..., CTa_m\n        //                     ^                                              \\__________  __________/\n        //        `table.bucket(3)` returns a pointer that points                        \\/\n        //         here in the `data` part of the `RawTable` (to              additional control bytes\n        //         the end of T3)                                              `m = Group::WIDTH - 1`\n        //\n        // where: T0...T_n  - our stored data;\n        //        CT0...CT_n - control bytes or metadata for `data`;\n        //        CTa_0...CTa_m - additional control bytes (so that the search with loading `Group` bytes from\n        //                        the heap works properly, even if the result of `h1(hash) & self.table.bucket_mask`\n        //                        is equal to `self.table.bucket_mask`). See also `RawTableInner::set_ctrl` function.\n        //\n        // P.S. `h1(hash) & self.table.bucket_mask` is the same as `hash as usize % self.buckets()` because the number\n        // of buckets is a power of two, and `self.table.bucket_mask = self.buckets() - 1`.\n        debug_assert_ne!(self.table.bucket_mask, 0);\n        debug_assert!(index < self.buckets());\n        Bucket::from_base_index(self.data_end(), index)\n    }\n\n    /// Erases an element from the table without dropping it.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    unsafe fn erase_no_drop(&mut self, item: &Bucket<T>) {\n        let index = self.bucket_index(item);\n        self.table.erase(index);\n    }\n\n    /// Erases an element from the table, dropping it in place.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    #[allow(clippy::needless_pass_by_value)]\n    pub unsafe fn erase(&mut self, item: Bucket<T>) {\n        // Erase the element from the table first since drop might panic.\n        self.erase_no_drop(&item);\n        item.drop();\n    }\n\n    /// Removes an element from the table, returning it.\n    ///\n    /// This also returns an `InsertSlot` pointing to the newly free bucket.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    #[allow(clippy::needless_pass_by_value)]\n    pub unsafe fn remove(&mut self, item: Bucket<T>) -> (T, InsertSlot) {\n        self.erase_no_drop(&item);\n        (\n            item.read(),\n            InsertSlot {\n                index: self.bucket_index(&item),\n            },\n        )\n    }\n\n    /// Finds and removes an element from the table, returning it.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn remove_entry(&mut self, hash: u64, eq: impl FnMut(&T) -> bool) -> Option<T> {\n        // Avoid `Option::map` because it bloats LLVM IR.\n        match self.find(hash, eq) {\n            Some(bucket) => Some(unsafe { self.remove(bucket).0 }),\n            None => None,\n        }\n    }\n\n    /// Marks all table buckets as empty without dropping their contents.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn clear_no_drop(&mut self) {\n        self.table.clear_no_drop();\n    }\n\n    /// Removes all elements from the table without freeing the backing memory.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn clear(&mut self) {\n        if self.is_empty() {\n            // Special case empty table to avoid surprising O(capacity) time.\n            return;\n        }\n        // Ensure that the table is reset even if one of the drops panic\n        let mut self_ = guard(self, |self_| self_.clear_no_drop());\n        unsafe {\n            // SAFETY: ScopeGuard sets to zero the `items` field of the table\n            // even in case of panic during the dropping of the elements so\n            // that there will be no double drop of the elements.\n            self_.table.drop_elements::<T>();\n        }\n    }\n\n    /// Shrinks the table to fit `max(self.len(), min_size)` elements.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn shrink_to(&mut self, min_size: usize, hasher: impl Fn(&T) -> u64) {\n        // Calculate the minimal number of elements that we need to reserve\n        // space for.\n        let min_size = usize::max(self.table.items, min_size);\n        if min_size == 0 {\n            let mut old_inner = mem::replace(&mut self.table, RawTableInner::NEW);\n            unsafe {\n                // SAFETY:\n                // 1. We call the function only once;\n                // 2. We know for sure that `alloc` and `table_layout` matches the [`Allocator`]\n                //    and [`TableLayout`] that were used to allocate this table.\n                // 3. If any elements' drop function panics, then there will only be a memory leak,\n                //    because we have replaced the inner table with a new one.\n                old_inner.drop_inner_table::<T, _>(&self.alloc, Self::TABLE_LAYOUT);\n            }\n            return;\n        }\n\n        // Calculate the number of buckets that we need for this number of\n        // elements. If the calculation overflows then the requested bucket\n        // count must be larger than what we have right and nothing needs to be\n        // done.\n        let min_buckets = match capacity_to_buckets(min_size, Self::TABLE_LAYOUT) {\n            Some(buckets) => buckets,\n            None => return,\n        };\n\n        // If we have more buckets than we need, shrink the table.\n        if min_buckets < self.buckets() {\n            // Fast path if the table is empty\n            if self.table.items == 0 {\n                let new_inner =\n                    RawTableInner::with_capacity(&self.alloc, Self::TABLE_LAYOUT, min_size);\n                let mut old_inner = mem::replace(&mut self.table, new_inner);\n                unsafe {\n                    // SAFETY:\n                    // 1. We call the function only once;\n                    // 2. We know for sure that `alloc` and `table_layout` matches the [`Allocator`]\n                    //    and [`TableLayout`] that were used to allocate this table.\n                    // 3. If any elements' drop function panics, then there will only be a memory leak,\n                    //    because we have replaced the inner table with a new one.\n                    old_inner.drop_inner_table::<T, _>(&self.alloc, Self::TABLE_LAYOUT);\n                }\n            } else {\n                // Avoid `Result::unwrap_or_else` because it bloats LLVM IR.\n                unsafe {\n                    // SAFETY:\n                    // 1. We know for sure that `min_size >= self.table.items`.\n                    // 2. The [`RawTableInner`] must already have properly initialized control bytes since\n                    //    we will never expose RawTable::new_uninitialized in a public API.\n                    if self\n                        .resize(min_size, hasher, Fallibility::Infallible)\n                        .is_err()\n                    {\n                        // SAFETY: The result of calling the `resize` function cannot be an error\n                        // because `fallibility == Fallibility::Infallible.\n                        hint::unreachable_unchecked()\n                    }\n                }\n            }\n        }\n    }\n\n    /// Ensures that at least `additional` items can be inserted into the table\n    /// without reallocation.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn reserve(&mut self, additional: usize, hasher: impl Fn(&T) -> u64) {\n        if unlikely(additional > self.table.growth_left) {\n            // Avoid `Result::unwrap_or_else` because it bloats LLVM IR.\n            unsafe {\n                // SAFETY: The [`RawTableInner`] must already have properly initialized control\n                // bytes since we will never expose RawTable::new_uninitialized in a public API.\n                if self\n                    .reserve_rehash(additional, hasher, Fallibility::Infallible)\n                    .is_err()\n                {\n                    // SAFETY: All allocation errors will be caught inside `RawTableInner::reserve_rehash`.\n                    hint::unreachable_unchecked()\n                }\n            }\n        }\n    }\n\n    /// Tries to ensure that at least `additional` items can be inserted into\n    /// the table without reallocation.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn try_reserve(\n        &mut self,\n        additional: usize,\n        hasher: impl Fn(&T) -> u64,\n    ) -> Result<(), TryReserveError> {\n        if additional > self.table.growth_left {\n            // SAFETY: The [`RawTableInner`] must already have properly initialized control\n            // bytes since we will never expose RawTable::new_uninitialized in a public API.\n            unsafe { self.reserve_rehash(additional, hasher, Fallibility::Fallible) }\n        } else {\n            Ok(())\n        }\n    }\n\n    /// Out-of-line slow path for `reserve` and `try_reserve`.\n    ///\n    /// # Safety\n    ///\n    /// The [`RawTableInner`] must have properly initialized control bytes,\n    /// otherwise calling this function results in [`undefined behavior`]\n    ///\n    /// [`undefined behavior`]: https://doc.rust-lang.org/reference/behavior-considered-undefined.html\n    #[cold]\n    #[inline(never)]\n    unsafe fn reserve_rehash(\n        &mut self,\n        additional: usize,\n        hasher: impl Fn(&T) -> u64,\n        fallibility: Fallibility,\n    ) -> Result<(), TryReserveError> {\n        unsafe {\n            // SAFETY:\n            // 1. We know for sure that `alloc` and `layout` matches the [`Allocator`] and\n            //    [`TableLayout`] that were used to allocate this table.\n            // 2. The `drop` function is the actual drop function of the elements stored in\n            //    the table.\n            // 3. The caller ensures that the control bytes of the `RawTableInner`\n            //    are already initialized.\n            self.table.reserve_rehash_inner(\n                &self.alloc,\n                additional,\n                &|table, index| hasher(table.bucket::<T>(index).as_ref()),\n                fallibility,\n                Self::TABLE_LAYOUT,\n                if T::NEEDS_DROP {\n                    Some(|ptr| ptr::drop_in_place(ptr as *mut T))\n                } else {\n                    None\n                },\n            )\n        }\n    }\n\n    /// Allocates a new table of a different size and moves the contents of the\n    /// current table into it.\n    ///\n    /// # Safety\n    ///\n    /// The [`RawTableInner`] must have properly initialized control bytes,\n    /// otherwise calling this function results in [`undefined behavior`]\n    ///\n    /// The caller of this function must ensure that `capacity >= self.table.items`\n    /// otherwise:\n    ///\n    /// * If `self.table.items != 0`, calling of this function with `capacity`\n    ///   equal to 0 (`capacity == 0`) results in [`undefined behavior`].\n    ///\n    /// * If `self.table.items > capacity_to_buckets(capacity, Self::TABLE_LAYOUT)`\n    ///   calling this function are never return (will loop infinitely).\n    ///\n    /// See [`RawTableInner::find_insert_slot`] for more information.\n    ///\n    /// [`RawTableInner::find_insert_slot`]: RawTableInner::find_insert_slot\n    /// [`undefined behavior`]: https://doc.rust-lang.org/reference/behavior-considered-undefined.html\n    unsafe fn resize(\n        &mut self,\n        capacity: usize,\n        hasher: impl Fn(&T) -> u64,\n        fallibility: Fallibility,\n    ) -> Result<(), TryReserveError> {\n        // SAFETY:\n        // 1. The caller of this function guarantees that `capacity >= self.table.items`.\n        // 2. We know for sure that `alloc` and `layout` matches the [`Allocator`] and\n        //    [`TableLayout`] that were used to allocate this table.\n        // 3. The caller ensures that the control bytes of the `RawTableInner`\n        //    are already initialized.\n        self.table.resize_inner(\n            &self.alloc,\n            capacity,\n            &|table, index| hasher(table.bucket::<T>(index).as_ref()),\n            fallibility,\n            Self::TABLE_LAYOUT,\n        )\n    }\n\n    /// Inserts a new element into the table, and returns its raw bucket.\n    ///\n    /// This does not check if the given element already exists in the table.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn insert(&mut self, hash: u64, value: T, hasher: impl Fn(&T) -> u64) -> Bucket<T> {\n        unsafe {\n            // SAFETY:\n            // 1. The [`RawTableInner`] must already have properly initialized control bytes since\n            //    we will never expose `RawTable::new_uninitialized` in a public API.\n            //\n            // 2. We reserve additional space (if necessary) right after calling this function.\n            let mut slot = self.table.find_insert_slot(hash);\n\n            // We can avoid growing the table once we have reached our load factor if we are replacing\n            // a tombstone. This works since the number of EMPTY slots does not change in this case.\n            //\n            // SAFETY: The function is guaranteed to return [`InsertSlot`] that contains an index\n            // in the range `0..=self.buckets()`.\n            let old_ctrl = *self.table.ctrl(slot.index);\n            if unlikely(self.table.growth_left == 0 && old_ctrl.special_is_empty()) {\n                self.reserve(1, hasher);\n                // SAFETY: We know for sure that `RawTableInner` has control bytes\n                // initialized and that there is extra space in the table.\n                slot = self.table.find_insert_slot(hash);\n            }\n\n            self.insert_in_slot(hash, slot, value)\n        }\n    }\n\n    /// Inserts a new element into the table, and returns a mutable reference to it.\n    ///\n    /// This does not check if the given element already exists in the table.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn insert_entry(&mut self, hash: u64, value: T, hasher: impl Fn(&T) -> u64) -> &mut T {\n        unsafe { self.insert(hash, value, hasher).as_mut() }\n    }\n\n    /// Inserts a new element into the table, without growing the table.\n    ///\n    /// There must be enough space in the table to insert the new element.\n    ///\n    /// This does not check if the given element already exists in the table.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    #[cfg(feature = \"rustc-internal-api\")]\n    pub unsafe fn insert_no_grow(&mut self, hash: u64, value: T) -> Bucket<T> {\n        let (index, old_ctrl) = self.table.prepare_insert_slot(hash);\n        let bucket = self.table.bucket(index);\n\n        // If we are replacing a DELETED entry then we don't need to update\n        // the load counter.\n        self.table.growth_left -= old_ctrl.special_is_empty() as usize;\n\n        bucket.write(value);\n        self.table.items += 1;\n        bucket\n    }\n\n    /// Temporary removes a bucket, applying the given function to the removed\n    /// element and optionally put back the returned value in the same bucket.\n    ///\n    /// Returns `true` if the bucket still contains an element\n    ///\n    /// This does not check if the given bucket is actually occupied.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub unsafe fn replace_bucket_with<F>(&mut self, bucket: Bucket<T>, f: F) -> bool\n    where\n        F: FnOnce(T) -> Option<T>,\n    {\n        let index = self.bucket_index(&bucket);\n        let old_ctrl = *self.table.ctrl(index);\n        debug_assert!(self.is_bucket_full(index));\n        let old_growth_left = self.table.growth_left;\n        let item = self.remove(bucket).0;\n        if let Some(new_item) = f(item) {\n            self.table.growth_left = old_growth_left;\n            self.table.set_ctrl(index, old_ctrl);\n            self.table.items += 1;\n            self.bucket(index).write(new_item);\n            true\n        } else {\n            false\n        }\n    }\n\n    /// Searches for an element in the table. If the element is not found,\n    /// returns `Err` with the position of a slot where an element with the\n    /// same hash could be inserted.\n    ///\n    /// This function may resize the table if additional space is required for\n    /// inserting an element.\n    #[inline]\n    pub fn find_or_find_insert_slot(\n        &mut self,\n        hash: u64,\n        mut eq: impl FnMut(&T) -> bool,\n        hasher: impl Fn(&T) -> u64,\n    ) -> Result<Bucket<T>, InsertSlot> {\n        self.reserve(1, hasher);\n\n        unsafe {\n            // SAFETY:\n            // 1. We know for sure that there is at least one empty `bucket` in the table.\n            // 2. The [`RawTableInner`] must already have properly initialized control bytes since we will\n            //    never expose `RawTable::new_uninitialized` in a public API.\n            // 3. The `find_or_find_insert_slot_inner` function returns the `index` of only the full bucket,\n            //    which is in the range `0..self.buckets()` (since there is at least one empty `bucket` in\n            //    the table), so calling `self.bucket(index)` and `Bucket::as_ref` is safe.\n            match self\n                .table\n                .find_or_find_insert_slot_inner(hash, &mut |index| eq(self.bucket(index).as_ref()))\n            {\n                // SAFETY: See explanation above.\n                Ok(index) => Ok(self.bucket(index)),\n                Err(slot) => Err(slot),\n            }\n        }\n    }\n\n    /// Inserts a new element into the table in the given slot, and returns its\n    /// raw bucket.\n    ///\n    /// # Safety\n    ///\n    /// `slot` must point to a slot previously returned by\n    /// `find_or_find_insert_slot`, and no mutation of the table must have\n    /// occurred since that call.\n    #[inline]\n    pub unsafe fn insert_in_slot(&mut self, hash: u64, slot: InsertSlot, value: T) -> Bucket<T> {\n        let old_ctrl = *self.table.ctrl(slot.index);\n        self.table.record_item_insert_at(slot.index, old_ctrl, hash);\n\n        let bucket = self.bucket(slot.index);\n        bucket.write(value);\n        bucket\n    }\n\n    /// Searches for an element in the table.\n    #[inline]\n    pub fn find(&self, hash: u64, mut eq: impl FnMut(&T) -> bool) -> Option<Bucket<T>> {\n        unsafe {\n            // SAFETY:\n            // 1. The [`RawTableInner`] must already have properly initialized control bytes since we\n            //    will never expose `RawTable::new_uninitialized` in a public API.\n            // 1. The `find_inner` function returns the `index` of only the full bucket, which is in\n            //    the range `0..self.buckets()`, so calling `self.bucket(index)` and `Bucket::as_ref`\n            //    is safe.\n            let result = self\n                .table\n                .find_inner(hash, &mut |index| eq(self.bucket(index).as_ref()));\n\n            // Avoid `Option::map` because it bloats LLVM IR.\n            match result {\n                // SAFETY: See explanation above.\n                Some(index) => Some(self.bucket(index)),\n                None => None,\n            }\n        }\n    }\n\n    /// Gets a reference to an element in the table.\n    #[inline]\n    pub fn get(&self, hash: u64, eq: impl FnMut(&T) -> bool) -> Option<&T> {\n        // Avoid `Option::map` because it bloats LLVM IR.\n        match self.find(hash, eq) {\n            Some(bucket) => Some(unsafe { bucket.as_ref() }),\n            None => None,\n        }\n    }\n\n    /// Gets a mutable reference to an element in the table.\n    #[inline]\n    pub fn get_mut(&mut self, hash: u64, eq: impl FnMut(&T) -> bool) -> Option<&mut T> {\n        // Avoid `Option::map` because it bloats LLVM IR.\n        match self.find(hash, eq) {\n            Some(bucket) => Some(unsafe { bucket.as_mut() }),\n            None => None,\n        }\n    }\n\n    /// Attempts to get mutable references to `N` entries in the table at once.\n    ///\n    /// Returns an array of length `N` with the results of each query.\n    ///\n    /// At most one mutable reference will be returned to any entry. `None` will be returned if any\n    /// of the hashes are duplicates. `None` will be returned if the hash is not found.\n    ///\n    /// The `eq` argument should be a closure such that `eq(i, k)` returns true if `k` is equal to\n    /// the `i`th key to be looked up.\n    pub fn get_many_mut<const N: usize>(\n        &mut self,\n        hashes: [u64; N],\n        eq: impl FnMut(usize, &T) -> bool,\n    ) -> [Option<&'_ mut T>; N] {\n        unsafe {\n            let ptrs = self.get_many_mut_pointers(hashes, eq);\n\n            for (i, cur) in ptrs.iter().enumerate() {\n                if cur.is_some() && ptrs[..i].contains(cur) {\n                    panic!(\"duplicate keys found\");\n                }\n            }\n            // All bucket are distinct from all previous buckets so we're clear to return the result\n            // of the lookup.\n\n            ptrs.map(|ptr| ptr.map(|mut ptr| ptr.as_mut()))\n        }\n    }\n\n    pub unsafe fn get_many_unchecked_mut<const N: usize>(\n        &mut self,\n        hashes: [u64; N],\n        eq: impl FnMut(usize, &T) -> bool,\n    ) -> [Option<&'_ mut T>; N] {\n        let ptrs = self.get_many_mut_pointers(hashes, eq);\n        ptrs.map(|ptr| ptr.map(|mut ptr| ptr.as_mut()))\n    }\n\n    unsafe fn get_many_mut_pointers<const N: usize>(\n        &mut self,\n        hashes: [u64; N],\n        mut eq: impl FnMut(usize, &T) -> bool,\n    ) -> [Option<NonNull<T>>; N] {\n        array::from_fn(|i| {\n            self.find(hashes[i], |k| eq(i, k))\n                .map(|cur| cur.as_non_null())\n        })\n    }\n\n    /// Returns the number of elements the map can hold without reallocating.\n    ///\n    /// This number is a lower bound; the table might be able to hold\n    /// more, but is guaranteed to be able to hold at least this many.\n    #[inline]\n    pub fn capacity(&self) -> usize {\n        self.table.items + self.table.growth_left\n    }\n\n    /// Returns the number of elements in the table.\n    #[inline]\n    pub fn len(&self) -> usize {\n        self.table.items\n    }\n\n    /// Returns `true` if the table contains no elements.\n    #[inline]\n    pub fn is_empty(&self) -> bool {\n        self.len() == 0\n    }\n\n    /// Returns the number of buckets in the table.\n    #[inline]\n    pub fn buckets(&self) -> usize {\n        self.table.bucket_mask + 1\n    }\n\n    /// Checks whether the bucket at `index` is full.\n    ///\n    /// # Safety\n    ///\n    /// The caller must ensure `index` is less than the number of buckets.\n    #[inline]\n    pub unsafe fn is_bucket_full(&self, index: usize) -> bool {\n        self.table.is_bucket_full(index)\n    }\n\n    /// Returns an iterator over every element in the table. It is up to\n    /// the caller to ensure that the `RawTable` outlives the `RawIter`.\n    /// Because we cannot make the `next` method unsafe on the `RawIter`\n    /// struct, we have to make the `iter` method unsafe.\n    #[inline]\n    pub unsafe fn iter(&self) -> RawIter<T> {\n        // SAFETY:\n        // 1. The caller must uphold the safety contract for `iter` method.\n        // 2. The [`RawTableInner`] must already have properly initialized control bytes since\n        //    we will never expose RawTable::new_uninitialized in a public API.\n        self.table.iter()\n    }\n\n    /// Returns an iterator over occupied buckets that could match a given hash.\n    ///\n    /// `RawTable` only stores 7 bits of the hash value, so this iterator may\n    /// return items that have a hash value different than the one provided. You\n    /// should always validate the returned values before using them.\n    ///\n    /// It is up to the caller to ensure that the `RawTable` outlives the\n    /// `RawIterHash`. Because we cannot make the `next` method unsafe on the\n    /// `RawIterHash` struct, we have to make the `iter_hash` method unsafe.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub unsafe fn iter_hash(&self, hash: u64) -> RawIterHash<T> {\n        RawIterHash::new(self, hash)\n    }\n\n    /// Returns an iterator which removes all elements from the table without\n    /// freeing the memory.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn drain(&mut self) -> RawDrain<'_, T, A> {\n        unsafe {\n            let iter = self.iter();\n            self.drain_iter_from(iter)\n        }\n    }\n\n    /// Returns an iterator which removes all elements from the table without\n    /// freeing the memory.\n    ///\n    /// Iteration starts at the provided iterator's current location.\n    ///\n    /// It is up to the caller to ensure that the iterator is valid for this\n    /// `RawTable` and covers all items that remain in the table.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub unsafe fn drain_iter_from(&mut self, iter: RawIter<T>) -> RawDrain<'_, T, A> {\n        debug_assert_eq!(iter.len(), self.len());\n        RawDrain {\n            iter,\n            table: mem::replace(&mut self.table, RawTableInner::NEW),\n            orig_table: NonNull::from(&mut self.table),\n            marker: PhantomData,\n        }\n    }\n\n    /// Returns an iterator which consumes all elements from the table.\n    ///\n    /// Iteration starts at the provided iterator's current location.\n    ///\n    /// It is up to the caller to ensure that the iterator is valid for this\n    /// `RawTable` and covers all items that remain in the table.\n    pub unsafe fn into_iter_from(self, iter: RawIter<T>) -> RawIntoIter<T, A> {\n        debug_assert_eq!(iter.len(), self.len());\n\n        let allocation = self.into_allocation();\n        RawIntoIter {\n            iter,\n            allocation,\n            marker: PhantomData,\n        }\n    }\n\n    /// Converts the table into a raw allocation. The contents of the table\n    /// should be dropped using a `RawIter` before freeing the allocation.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub(crate) fn into_allocation(self) -> Option<(NonNull<u8>, Layout, A)> {\n        let alloc = if self.table.is_empty_singleton() {\n            None\n        } else {\n            // Avoid `Option::unwrap_or_else` because it bloats LLVM IR.\n            let (layout, ctrl_offset) =\n                match Self::TABLE_LAYOUT.calculate_layout_for(self.table.buckets()) {\n                    Some(lco) => lco,\n                    None => unsafe { hint::unreachable_unchecked() },\n                };\n            Some((\n                unsafe { NonNull::new_unchecked(self.table.ctrl.as_ptr().sub(ctrl_offset).cast()) },\n                layout,\n                unsafe { ptr::read(&self.alloc) },\n            ))\n        };\n        mem::forget(self);\n        alloc\n    }\n}",
            "impl<T: Clone, A: Allocator + Clone> Clone for RawTable<T, A> {\n    fn clone(&self) -> Self {\n        if self.table.is_empty_singleton() {\n            Self::new_in(self.alloc.clone())\n        } else {\n            unsafe {\n                // Avoid `Result::ok_or_else` because it bloats LLVM IR.\n                //\n                // SAFETY: This is safe as we are taking the size of an already allocated table\n                // and therefore capacity overflow cannot occur, `self.table.buckets()` is power\n                // of two and all allocator errors will be caught inside `RawTableInner::new_uninitialized`.\n                let mut new_table = match Self::new_uninitialized(\n                    self.alloc.clone(),\n                    self.table.buckets(),\n                    Fallibility::Infallible,\n                ) {\n                    Ok(table) => table,\n                    Err(_) => hint::unreachable_unchecked(),\n                };\n\n                // Cloning elements may fail (the clone function may panic). But we don't\n                // need to worry about uninitialized control bits, since:\n                // 1. The number of items (elements) in the table is zero, which means that\n                //    the control bits will not be read by Drop function.\n                // 2. The `clone_from_spec` method will first copy all control bits from\n                //    `self` (thus initializing them). But this will not affect the `Drop`\n                //    function, since the `clone_from_spec` function sets `items` only after\n                //    successfully cloning all elements.\n                new_table.clone_from_spec(self);\n                new_table\n            }\n        }\n    }\n\n    fn clone_from(&mut self, source: &Self) {\n        if source.table.is_empty_singleton() {\n            let mut old_inner = mem::replace(&mut self.table, RawTableInner::NEW);\n            unsafe {\n                // SAFETY:\n                // 1. We call the function only once;\n                // 2. We know for sure that `alloc` and `table_layout` matches the [`Allocator`]\n                //    and [`TableLayout`] that were used to allocate this table.\n                // 3. If any elements' drop function panics, then there will only be a memory leak,\n                //    because we have replaced the inner table with a new one.\n                old_inner.drop_inner_table::<T, _>(&self.alloc, Self::TABLE_LAYOUT);\n            }\n        } else {\n            unsafe {\n                // Make sure that if any panics occurs, we clear the table and\n                // leave it in an empty state.\n                let mut self_ = guard(self, |self_| {\n                    self_.clear_no_drop();\n                });\n\n                // First, drop all our elements without clearing the control\n                // bytes. If this panics then the scope guard will clear the\n                // table, leaking any elements that were not dropped yet.\n                //\n                // This leak is unavoidable: we can't try dropping more elements\n                // since this could lead to another panic and abort the process.\n                //\n                // SAFETY: If something gets wrong we clear our table right after\n                // dropping the elements, so there is no double drop, since `items`\n                // will be equal to zero.\n                self_.table.drop_elements::<T>();\n\n                // If necessary, resize our table to match the source.\n                if self_.buckets() != source.buckets() {\n                    let new_inner = match RawTableInner::new_uninitialized(\n                        &self_.alloc,\n                        Self::TABLE_LAYOUT,\n                        source.buckets(),\n                        Fallibility::Infallible,\n                    ) {\n                        Ok(table) => table,\n                        Err(_) => hint::unreachable_unchecked(),\n                    };\n                    // Replace the old inner with new uninitialized one. It's ok, since if something gets\n                    // wrong `ScopeGuard` will initialize all control bytes and leave empty table.\n                    let mut old_inner = mem::replace(&mut self_.table, new_inner);\n                    if !old_inner.is_empty_singleton() {\n                        // SAFETY:\n                        // 1. We have checked that our table is allocated.\n                        // 2. We know for sure that `alloc` and `table_layout` matches\n                        // the [`Allocator`] and [`TableLayout`] that were used to allocate this table.\n                        old_inner.free_buckets(&self_.alloc, Self::TABLE_LAYOUT);\n                    }\n                }\n\n                // Cloning elements may fail (the clone function may panic), but the `ScopeGuard`\n                // inside the `clone_from_impl` function will take care of that, dropping all\n                // cloned elements if necessary. Our `ScopeGuard` will clear the table.\n                self_.clone_from_spec(source);\n\n                // Disarm the scope guard if cloning was successful.\n                ScopeGuard::into_inner(self_);\n            }\n        }\n    }\n}",
            "impl<T: Clone, A: Allocator + Clone> RawTable<T, A> {\n    /// Common code for `clone` and `clone_from`. Assumes:\n    /// - `self.buckets() == source.buckets()`.\n    /// - Any existing elements have been dropped.\n    /// - The control bytes are not initialized yet.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    unsafe fn clone_from_impl(&mut self, source: &Self) {\n        // Copy the control bytes unchanged. We do this in a single pass\n        source\n            .table\n            .ctrl(0)\n            .copy_to_nonoverlapping(self.table.ctrl(0), self.table.num_ctrl_bytes());\n\n        // The cloning of elements may panic, in which case we need\n        // to make sure we drop only the elements that have been\n        // cloned so far.\n        let mut guard = guard((0, &mut *self), |(index, self_)| {\n            if T::NEEDS_DROP {\n                for i in 0..*index {\n                    if self_.is_bucket_full(i) {\n                        self_.bucket(i).drop();\n                    }\n                }\n            }\n        });\n\n        for from in source.iter() {\n            let index = source.bucket_index(&from);\n            let to = guard.1.bucket(index);\n            to.write(from.as_ref().clone());\n\n            // Update the index in case we need to unwind.\n            guard.0 = index + 1;\n        }\n\n        // Successfully cloned all items, no need to clean up.\n        mem::forget(guard);\n\n        self.table.items = source.table.items;\n        self.table.growth_left = source.table.growth_left;\n    }\n}",
            "impl<T: Clone, A: Allocator + Clone> RawTableClone for RawTable<T, A> {\n    default_fn! {\n        #[cfg_attr(feature = \"inline-more\", inline)]\n        unsafe fn clone_from_spec(&mut self, source: &Self) {\n            self.clone_from_impl(source);\n        }\n    }\n}",
            "impl<T> RawTable<T, Global> {\n    /// Creates a new empty hash table without allocating any memory.\n    ///\n    /// In effect this returns a table with exactly 1 bucket. However we can\n    /// leave the data pointer dangling since that bucket is never written to\n    /// due to our load factor forcing us to always have at least 1 free bucket.\n    #[inline]\n    #[cfg_attr(feature = \"rustc-dep-of-std\", rustc_const_stable_indirect)]\n    pub const fn new() -> Self {\n        Self {\n            table: RawTableInner::NEW,\n            alloc: Global,\n            marker: PhantomData,\n        }\n    }\n\n    /// Allocates a new hash table with at least enough capacity for inserting\n    /// the given number of elements without reallocating.\n    pub fn with_capacity(capacity: usize) -> Self {\n        Self::with_capacity_in(capacity, Global)\n    }\n}",
            "unsafe impl<T, A: Allocator> Send for RawTable<T, A>\nwhere\n    T: Send,\n    A: Send,\n{\n}",
            "unsafe impl<T, A: Allocator> Sync for RawTable<T, A>\nwhere\n    T: Sync,\n    A: Sync,\n{\n}"
        ],
        "raw::RawTableInner": [
            "impl RawTableInner {\n    /// Allocates a new [`RawTableInner`] with the given number of buckets.\n    /// The control bytes and buckets are left uninitialized.\n    ///\n    /// # Safety\n    ///\n    /// The caller of this function must ensure that the `buckets` is power of two\n    /// and also initialize all control bytes of the length `self.bucket_mask + 1 +\n    /// Group::WIDTH` with the [`Tag::EMPTY`] bytes.\n    ///\n    /// See also [`Allocator`] API for other safety concerns.\n    ///\n    /// [`Allocator`]: https://doc.rust-lang.org/alloc/alloc/trait.Allocator.html\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    unsafe fn new_uninitialized<A>(\n        alloc: &A,\n        table_layout: TableLayout,\n        buckets: usize,\n        fallibility: Fallibility,\n    ) -> Result<Self, TryReserveError>\n    where\n        A: Allocator,\n    {\n        debug_assert!(buckets.is_power_of_two());\n\n        // Avoid `Option::ok_or_else` because it bloats LLVM IR.\n        let (layout, ctrl_offset) = match table_layout.calculate_layout_for(buckets) {\n            Some(lco) => lco,\n            None => return Err(fallibility.capacity_overflow()),\n        };\n\n        let ptr: NonNull<u8> = match do_alloc(alloc, layout) {\n            Ok(block) => block.cast(),\n            Err(_) => return Err(fallibility.alloc_err(layout)),\n        };\n\n        // SAFETY: null pointer will be caught in above check\n        let ctrl = NonNull::new_unchecked(ptr.as_ptr().add(ctrl_offset));\n        Ok(Self {\n            ctrl,\n            bucket_mask: buckets - 1,\n            items: 0,\n            growth_left: bucket_mask_to_capacity(buckets - 1),\n        })\n    }\n\n    /// Attempts to allocate a new [`RawTableInner`] with at least enough\n    /// capacity for inserting the given number of elements without reallocating.\n    ///\n    /// All the control bytes are initialized with the [`Tag::EMPTY`] bytes.\n    #[inline]\n    fn fallible_with_capacity<A>(\n        alloc: &A,\n        table_layout: TableLayout,\n        capacity: usize,\n        fallibility: Fallibility,\n    ) -> Result<Self, TryReserveError>\n    where\n        A: Allocator,\n    {\n        if capacity == 0 {\n            Ok(Self::NEW)\n        } else {\n            // SAFETY: We checked that we could successfully allocate the new table, and then\n            // initialized all control bytes with the constant `Tag::EMPTY` byte.\n            unsafe {\n                let buckets = capacity_to_buckets(capacity, table_layout)\n                    .ok_or_else(|| fallibility.capacity_overflow())?;\n\n                let mut result =\n                    Self::new_uninitialized(alloc, table_layout, buckets, fallibility)?;\n                // SAFETY: We checked that the table is allocated and therefore the table already has\n                // `self.bucket_mask + 1 + Group::WIDTH` number of control bytes (see TableLayout::calculate_layout_for)\n                // so writing `self.num_ctrl_bytes() == bucket_mask + 1 + Group::WIDTH` bytes is safe.\n                result.ctrl_slice().fill_empty();\n\n                Ok(result)\n            }\n        }\n    }\n\n    /// Allocates a new [`RawTableInner`] with at least enough capacity for inserting\n    /// the given number of elements without reallocating.\n    ///\n    /// Panics if the new capacity exceeds [`isize::MAX`] bytes and [`abort`] the program\n    /// in case of allocation error. Use [`fallible_with_capacity`] instead if you want to\n    /// handle memory allocation failure.\n    ///\n    /// All the control bytes are initialized with the [`Tag::EMPTY`] bytes.\n    ///\n    /// [`fallible_with_capacity`]: RawTableInner::fallible_with_capacity\n    /// [`abort`]: https://doc.rust-lang.org/alloc/alloc/fn.handle_alloc_error.html\n    fn with_capacity<A>(alloc: &A, table_layout: TableLayout, capacity: usize) -> Self\n    where\n        A: Allocator,\n    {\n        // Avoid `Result::unwrap_or_else` because it bloats LLVM IR.\n        match Self::fallible_with_capacity(alloc, table_layout, capacity, Fallibility::Infallible) {\n            Ok(table_inner) => table_inner,\n            // SAFETY: All allocation errors will be caught inside `RawTableInner::new_uninitialized`.\n            Err(_) => unsafe { hint::unreachable_unchecked() },\n        }\n    }\n\n    /// Fixes up an insertion slot returned by the [`RawTableInner::find_insert_slot_in_group`] method.\n    ///\n    /// In tables smaller than the group width (`self.buckets() < Group::WIDTH`), trailing control\n    /// bytes outside the range of the table are filled with [`Tag::EMPTY`] entries. These will unfortunately\n    /// trigger a match of [`RawTableInner::find_insert_slot_in_group`] function. This is because\n    /// the `Some(bit)` returned by `group.match_empty_or_deleted().lowest_set_bit()` after masking\n    /// (`(probe_seq.pos + bit) & self.bucket_mask`) may point to a full bucket that is already occupied.\n    /// We detect this situation here and perform a second scan starting at the beginning of the table.\n    /// This second scan is guaranteed to find an empty slot (due to the load factor) before hitting the\n    /// trailing control bytes (containing [`Tag::EMPTY`] bytes).\n    ///\n    /// If this function is called correctly, it is guaranteed to return [`InsertSlot`] with an\n    /// index of an empty or deleted bucket in the range `0..self.buckets()` (see `Warning` and\n    /// `Safety`).\n    ///\n    /// # Warning\n    ///\n    /// The table must have at least 1 empty or deleted `bucket`, otherwise if the table is less than\n    /// the group width (`self.buckets() < Group::WIDTH`) this function returns an index outside of the\n    /// table indices range `0..self.buckets()` (`0..=self.bucket_mask`). Attempt to write data at that\n    /// index will cause immediate [`undefined behavior`].\n    ///\n    /// # Safety\n    ///\n    /// The safety rules are directly derived from the safety rules for [`RawTableInner::ctrl`] method.\n    /// Thus, in order to uphold those safety contracts, as well as for the correct logic of the work\n    /// of this crate, the following rules are necessary and sufficient:\n    ///\n    /// * The [`RawTableInner`] must have properly initialized control bytes otherwise calling this\n    ///   function results in [`undefined behavior`].\n    ///\n    /// * This function must only be used on insertion slots found by [`RawTableInner::find_insert_slot_in_group`]\n    ///   (after the `find_insert_slot_in_group` function, but before insertion into the table).\n    ///\n    /// * The `index` must not be greater than the `self.bucket_mask`, i.e. `(index + 1) <= self.buckets()`\n    ///   (this one is provided by the [`RawTableInner::find_insert_slot_in_group`] function).\n    ///\n    /// Calling this function with an index not provided by [`RawTableInner::find_insert_slot_in_group`]\n    /// may result in [`undefined behavior`] even if the index satisfies the safety rules of the\n    /// [`RawTableInner::ctrl`] function (`index < self.bucket_mask + 1 + Group::WIDTH`).\n    ///\n    /// [`RawTableInner::ctrl`]: RawTableInner::ctrl\n    /// [`RawTableInner::find_insert_slot_in_group`]: RawTableInner::find_insert_slot_in_group\n    /// [`undefined behavior`]: https://doc.rust-lang.org/reference/behavior-considered-undefined.html\n    #[inline]\n    unsafe fn fix_insert_slot(&self, mut index: usize) -> InsertSlot {\n        // SAFETY: The caller of this function ensures that `index` is in the range `0..=self.bucket_mask`.\n        if unlikely(self.is_bucket_full(index)) {\n            debug_assert!(self.bucket_mask < Group::WIDTH);\n            // SAFETY:\n            //\n            // * Since the caller of this function ensures that the control bytes are properly\n            //   initialized and `ptr = self.ctrl(0)` points to the start of the array of control\n            //   bytes, therefore: `ctrl` is valid for reads, properly aligned to `Group::WIDTH`\n            //   and points to the properly initialized control bytes (see also\n            //   `TableLayout::calculate_layout_for` and `ptr::read`);\n            //\n            // * Because the caller of this function ensures that the index was provided by the\n            //   `self.find_insert_slot_in_group()` function, so for for tables larger than the\n            //   group width (self.buckets() >= Group::WIDTH), we will never end up in the given\n            //   branch, since `(probe_seq.pos + bit) & self.bucket_mask` in `find_insert_slot_in_group`\n            //   cannot return a full bucket index. For tables smaller than the group width, calling\n            //   the `unwrap_unchecked` function is also safe, as the trailing control bytes outside\n            //   the range of the table are filled with EMPTY bytes (and we know for sure that there\n            //   is at least one FULL bucket), so this second scan either finds an empty slot (due to\n            //   the load factor) or hits the trailing control bytes (containing EMPTY).\n            index = Group::load_aligned(self.ctrl(0))\n                .match_empty_or_deleted()\n                .lowest_set_bit()\n                .unwrap_unchecked();\n        }\n        InsertSlot { index }\n    }\n\n    /// Finds the position to insert something in a group.\n    ///\n    /// **This may have false positives and must be fixed up with `fix_insert_slot`\n    /// before it's used.**\n    ///\n    /// The function is guaranteed to return the index of an empty or deleted [`Bucket`]\n    /// in the range `0..self.buckets()` (`0..=self.bucket_mask`).\n    #[inline]\n    fn find_insert_slot_in_group(&self, group: &Group, probe_seq: &ProbeSeq) -> Option<usize> {\n        let bit = group.match_empty_or_deleted().lowest_set_bit();\n\n        if likely(bit.is_some()) {\n            // This is the same as `(probe_seq.pos + bit) % self.buckets()` because the number\n            // of buckets is a power of two, and `self.bucket_mask = self.buckets() - 1`.\n            Some((probe_seq.pos + bit.unwrap()) & self.bucket_mask)\n        } else {\n            None\n        }\n    }\n\n    /// Searches for an element in the table, or a potential slot where that element could\n    /// be inserted (an empty or deleted [`Bucket`] index).\n    ///\n    /// This uses dynamic dispatch to reduce the amount of code generated, but that is\n    /// eliminated by LLVM optimizations.\n    ///\n    /// This function does not make any changes to the `data` part of the table, or any\n    /// changes to the `items` or `growth_left` field of the table.\n    ///\n    /// The table must have at least 1 empty or deleted `bucket`, otherwise, if the\n    /// `eq: &mut dyn FnMut(usize) -> bool` function does not return `true`, this function\n    /// will never return (will go into an infinite loop) for tables larger than the group\n    /// width, or return an index outside of the table indices range if the table is less\n    /// than the group width.\n    ///\n    /// This function is guaranteed to provide the `eq: &mut dyn FnMut(usize) -> bool`\n    /// function with only `FULL` buckets' indices and return the `index` of the found\n    /// element (as `Ok(index)`). If the element is not found and there is at least 1\n    /// empty or deleted [`Bucket`] in the table, the function is guaranteed to return\n    /// [`InsertSlot`] with an index in the range `0..self.buckets()`, but in any case,\n    /// if this function returns [`InsertSlot`], it will contain an index in the range\n    /// `0..=self.buckets()`.\n    ///\n    /// # Safety\n    ///\n    /// The [`RawTableInner`] must have properly initialized control bytes otherwise calling\n    /// this function results in [`undefined behavior`].\n    ///\n    /// Attempt to write data at the [`InsertSlot`] returned by this function when the table is\n    /// less than the group width and if there was not at least one empty or deleted bucket in\n    /// the table will cause immediate [`undefined behavior`]. This is because in this case the\n    /// function will return `self.bucket_mask + 1` as an index due to the trailing [`Tag::EMPTY`]\n    /// control bytes outside the table range.\n    ///\n    /// [`undefined behavior`]: https://doc.rust-lang.org/reference/behavior-considered-undefined.html\n    #[inline]\n    unsafe fn find_or_find_insert_slot_inner(\n        &self,\n        hash: u64,\n        eq: &mut dyn FnMut(usize) -> bool,\n    ) -> Result<usize, InsertSlot> {\n        let mut insert_slot = None;\n\n        let tag_hash = Tag::full(hash);\n        let mut probe_seq = self.probe_seq(hash);\n\n        loop {\n            // SAFETY:\n            // * Caller of this function ensures that the control bytes are properly initialized.\n            //\n            // * `ProbeSeq.pos` cannot be greater than `self.bucket_mask = self.buckets() - 1`\n            //   of the table due to masking with `self.bucket_mask` and also because the number\n            //   of buckets is a power of two (see `self.probe_seq` function).\n            //\n            // * Even if `ProbeSeq.pos` returns `position == self.bucket_mask`, it is safe to\n            //   call `Group::load` due to the extended control bytes range, which is\n            //  `self.bucket_mask + 1 + Group::WIDTH` (in fact, this means that the last control\n            //   byte will never be read for the allocated table);\n            //\n            // * Also, even if `RawTableInner` is not already allocated, `ProbeSeq.pos` will\n            //   always return \"0\" (zero), so Group::load will read unaligned `Group::static_empty()`\n            //   bytes, which is safe (see RawTableInner::new).\n            let group = unsafe { Group::load(self.ctrl(probe_seq.pos)) };\n\n            for bit in group.match_tag(tag_hash) {\n                let index = (probe_seq.pos + bit) & self.bucket_mask;\n\n                if likely(eq(index)) {\n                    return Ok(index);\n                }\n            }\n\n            // We didn't find the element we were looking for in the group, try to get an\n            // insertion slot from the group if we don't have one yet.\n            if likely(insert_slot.is_none()) {\n                insert_slot = self.find_insert_slot_in_group(&group, &probe_seq);\n            }\n\n            if let Some(insert_slot) = insert_slot {\n                // Only stop the search if the group contains at least one empty element.\n                // Otherwise, the element that we are looking for might be in a following group.\n                if likely(group.match_empty().any_bit_set()) {\n                    // We must have found a insert slot by now, since the current group contains at\n                    // least one. For tables smaller than the group width, there will still be an\n                    // empty element in the current (and only) group due to the load factor.\n                    unsafe {\n                        // SAFETY:\n                        // * Caller of this function ensures that the control bytes are properly initialized.\n                        //\n                        // * We use this function with the slot / index found by `self.find_insert_slot_in_group`\n                        return Err(self.fix_insert_slot(insert_slot));\n                    }\n                }\n            }\n\n            probe_seq.move_next(self.bucket_mask);\n        }\n    }\n\n    /// Searches for an empty or deleted bucket which is suitable for inserting a new\n    /// element and sets the hash for that slot. Returns an index of that slot and the\n    /// old control byte stored in the found index.\n    ///\n    /// This function does not check if the given element exists in the table. Also,\n    /// this function does not check if there is enough space in the table to insert\n    /// a new element. The caller of the function must make sure that the table has at\n    /// least 1 empty or deleted `bucket`, otherwise this function will never return\n    /// (will go into an infinite loop) for tables larger than the group width, or\n    /// return an index outside of the table indices range if the table is less than\n    /// the group width.\n    ///\n    /// If there is at least 1 empty or deleted `bucket` in the table, the function is\n    /// guaranteed to return an `index` in the range `0..self.buckets()`, but in any case,\n    /// if this function returns an `index` it will be in the range `0..=self.buckets()`.\n    ///\n    /// This function does not make any changes to the `data` parts of the table,\n    /// or any changes to the `items` or `growth_left` field of the table.\n    ///\n    /// # Safety\n    ///\n    /// The safety rules are directly derived from the safety rules for the\n    /// [`RawTableInner::set_ctrl_hash`] and [`RawTableInner::find_insert_slot`] methods.\n    /// Thus, in order to uphold the safety contracts for that methods, as well as for\n    /// the correct logic of the work of this crate, you must observe the following rules\n    /// when calling this function:\n    ///\n    /// * The [`RawTableInner`] has already been allocated and has properly initialized\n    ///   control bytes otherwise calling this function results in [`undefined behavior`].\n    ///\n    /// * The caller of this function must ensure that the \"data\" parts of the table\n    ///   will have an entry in the returned index (matching the given hash) right\n    ///   after calling this function.\n    ///\n    /// Attempt to write data at the `index` returned by this function when the table is\n    /// less than the group width and if there was not at least one empty or deleted bucket in\n    /// the table will cause immediate [`undefined behavior`]. This is because in this case the\n    /// function will return `self.bucket_mask + 1` as an index due to the trailing [`Tag::EMPTY`]\n    /// control bytes outside the table range.\n    ///\n    /// The caller must independently increase the `items` field of the table, and also,\n    /// if the old control byte was [`Tag::EMPTY`], then decrease the table's `growth_left`\n    /// field, and do not change it if the old control byte was [`Tag::DELETED`].\n    ///\n    /// See also [`Bucket::as_ptr`] method, for more information about of properly removing\n    /// or saving `element` from / into the [`RawTable`] / [`RawTableInner`].\n    ///\n    /// [`Bucket::as_ptr`]: Bucket::as_ptr\n    /// [`undefined behavior`]: https://doc.rust-lang.org/reference/behavior-considered-undefined.html\n    /// [`RawTableInner::ctrl`]: RawTableInner::ctrl\n    /// [`RawTableInner::set_ctrl_hash`]: RawTableInner::set_ctrl_hash\n    /// [`RawTableInner::find_insert_slot`]: RawTableInner::find_insert_slot\n    #[inline]\n    unsafe fn prepare_insert_slot(&mut self, hash: u64) -> (usize, Tag) {\n        // SAFETY: Caller of this function ensures that the control bytes are properly initialized.\n        let index: usize = self.find_insert_slot(hash).index;\n        // SAFETY:\n        // 1. The `find_insert_slot` function either returns an `index` less than or\n        //    equal to `self.buckets() = self.bucket_mask + 1` of the table, or never\n        //    returns if it cannot find an empty or deleted slot.\n        // 2. The caller of this function guarantees that the table has already been\n        //    allocated\n        let old_ctrl = *self.ctrl(index);\n        self.set_ctrl_hash(index, hash);\n        (index, old_ctrl)\n    }\n\n    /// Searches for an empty or deleted bucket which is suitable for inserting\n    /// a new element, returning the `index` for the new [`Bucket`].\n    ///\n    /// This function does not make any changes to the `data` part of the table, or any\n    /// changes to the `items` or `growth_left` field of the table.\n    ///\n    /// The table must have at least 1 empty or deleted `bucket`, otherwise this function\n    /// will never return (will go into an infinite loop) for tables larger than the group\n    /// width, or return an index outside of the table indices range if the table is less\n    /// than the group width.\n    ///\n    /// If there is at least 1 empty or deleted `bucket` in the table, the function is\n    /// guaranteed to return [`InsertSlot`] with an index in the range `0..self.buckets()`,\n    /// but in any case, if this function returns [`InsertSlot`], it will contain an index\n    /// in the range `0..=self.buckets()`.\n    ///\n    /// # Safety\n    ///\n    /// The [`RawTableInner`] must have properly initialized control bytes otherwise calling\n    /// this function results in [`undefined behavior`].\n    ///\n    /// Attempt to write data at the [`InsertSlot`] returned by this function when the table is\n    /// less than the group width and if there was not at least one empty or deleted bucket in\n    /// the table will cause immediate [`undefined behavior`]. This is because in this case the\n    /// function will return `self.bucket_mask + 1` as an index due to the trailing [`Tag::EMPTY`]\n    /// control bytes outside the table range.\n    ///\n    /// [`undefined behavior`]: https://doc.rust-lang.org/reference/behavior-considered-undefined.html\n    #[inline]\n    unsafe fn find_insert_slot(&self, hash: u64) -> InsertSlot {\n        let mut probe_seq = self.probe_seq(hash);\n        loop {\n            // SAFETY:\n            // * Caller of this function ensures that the control bytes are properly initialized.\n            //\n            // * `ProbeSeq.pos` cannot be greater than `self.bucket_mask = self.buckets() - 1`\n            //   of the table due to masking with `self.bucket_mask` and also because the number\n            //   of buckets is a power of two (see `self.probe_seq` function).\n            //\n            // * Even if `ProbeSeq.pos` returns `position == self.bucket_mask`, it is safe to\n            //   call `Group::load` due to the extended control bytes range, which is\n            //  `self.bucket_mask + 1 + Group::WIDTH` (in fact, this means that the last control\n            //   byte will never be read for the allocated table);\n            //\n            // * Also, even if `RawTableInner` is not already allocated, `ProbeSeq.pos` will\n            //   always return \"0\" (zero), so Group::load will read unaligned `Group::static_empty()`\n            //   bytes, which is safe (see RawTableInner::new).\n            let group = unsafe { Group::load(self.ctrl(probe_seq.pos)) };\n\n            let index = self.find_insert_slot_in_group(&group, &probe_seq);\n            if likely(index.is_some()) {\n                // SAFETY:\n                // * Caller of this function ensures that the control bytes are properly initialized.\n                //\n                // * We use this function with the slot / index found by `self.find_insert_slot_in_group`\n                unsafe {\n                    return self.fix_insert_slot(index.unwrap_unchecked());\n                }\n            }\n            probe_seq.move_next(self.bucket_mask);\n        }\n    }\n\n    /// Searches for an element in a table, returning the `index` of the found element.\n    /// This uses dynamic dispatch to reduce the amount of code generated, but it is\n    /// eliminated by LLVM optimizations.\n    ///\n    /// This function does not make any changes to the `data` part of the table, or any\n    /// changes to the `items` or `growth_left` field of the table.\n    ///\n    /// The table must have at least 1 empty `bucket`, otherwise, if the\n    /// `eq: &mut dyn FnMut(usize) -> bool` function does not return `true`,\n    /// this function will also never return (will go into an infinite loop).\n    ///\n    /// This function is guaranteed to provide the `eq: &mut dyn FnMut(usize) -> bool`\n    /// function with only `FULL` buckets' indices and return the `index` of the found\n    /// element as `Some(index)`, so the index will always be in the range\n    /// `0..self.buckets()`.\n    ///\n    /// # Safety\n    ///\n    /// The [`RawTableInner`] must have properly initialized control bytes otherwise calling\n    /// this function results in [`undefined behavior`].\n    ///\n    /// [`undefined behavior`]: https://doc.rust-lang.org/reference/behavior-considered-undefined.html\n    #[inline(always)]\n    unsafe fn find_inner(&self, hash: u64, eq: &mut dyn FnMut(usize) -> bool) -> Option<usize> {\n        let tag_hash = Tag::full(hash);\n        let mut probe_seq = self.probe_seq(hash);\n\n        loop {\n            // SAFETY:\n            // * Caller of this function ensures that the control bytes are properly initialized.\n            //\n            // * `ProbeSeq.pos` cannot be greater than `self.bucket_mask = self.buckets() - 1`\n            //   of the table due to masking with `self.bucket_mask`.\n            //\n            // * Even if `ProbeSeq.pos` returns `position == self.bucket_mask`, it is safe to\n            //   call `Group::load` due to the extended control bytes range, which is\n            //  `self.bucket_mask + 1 + Group::WIDTH` (in fact, this means that the last control\n            //   byte will never be read for the allocated table);\n            //\n            // * Also, even if `RawTableInner` is not already allocated, `ProbeSeq.pos` will\n            //   always return \"0\" (zero), so Group::load will read unaligned `Group::static_empty()`\n            //   bytes, which is safe (see RawTableInner::new_in).\n            let group = unsafe { Group::load(self.ctrl(probe_seq.pos)) };\n\n            for bit in group.match_tag(tag_hash) {\n                // This is the same as `(probe_seq.pos + bit) % self.buckets()` because the number\n                // of buckets is a power of two, and `self.bucket_mask = self.buckets() - 1`.\n                let index = (probe_seq.pos + bit) & self.bucket_mask;\n\n                if likely(eq(index)) {\n                    return Some(index);\n                }\n            }\n\n            if likely(group.match_empty().any_bit_set()) {\n                return None;\n            }\n\n            probe_seq.move_next(self.bucket_mask);\n        }\n    }\n\n    /// Prepares for rehashing data in place (that is, without allocating new memory).\n    /// Converts all full index `control bytes` to `Tag::DELETED` and all `Tag::DELETED` control\n    /// bytes to `Tag::EMPTY`, i.e. performs the following conversion:\n    ///\n    /// - `Tag::EMPTY` control bytes   -> `Tag::EMPTY`;\n    /// - `Tag::DELETED` control bytes -> `Tag::EMPTY`;\n    /// - `FULL` control bytes    -> `Tag::DELETED`.\n    ///\n    /// This function does not make any changes to the `data` parts of the table,\n    /// or any changes to the `items` or `growth_left` field of the table.\n    ///\n    /// # Safety\n    ///\n    /// You must observe the following safety rules when calling this function:\n    ///\n    /// * The [`RawTableInner`] has already been allocated;\n    ///\n    /// * The caller of this function must convert the `Tag::DELETED` bytes back to `FULL`\n    ///   bytes when re-inserting them into their ideal position (which was impossible\n    ///   to do during the first insert due to tombstones). If the caller does not do\n    ///   this, then calling this function may result in a memory leak.\n    ///\n    /// * The [`RawTableInner`] must have properly initialized control bytes otherwise\n    ///   calling this function results in [`undefined behavior`].\n    ///\n    /// Calling this function on a table that has not been allocated results in\n    /// [`undefined behavior`].\n    ///\n    /// See also [`Bucket::as_ptr`] method, for more information about of properly removing\n    /// or saving `data element` from / into the [`RawTable`] / [`RawTableInner`].\n    ///\n    /// [`Bucket::as_ptr`]: Bucket::as_ptr\n    /// [`undefined behavior`]: https://doc.rust-lang.org/reference/behavior-considered-undefined.html\n    #[allow(clippy::mut_mut)]\n    #[inline]\n    unsafe fn prepare_rehash_in_place(&mut self) {\n        // Bulk convert all full control bytes to DELETED, and all DELETED control bytes to EMPTY.\n        // This effectively frees up all buckets containing a DELETED entry.\n        //\n        // SAFETY:\n        // 1. `i` is guaranteed to be within bounds since we are iterating from zero to `buckets - 1`;\n        // 2. Even if `i` will be `i == self.bucket_mask`, it is safe to call `Group::load_aligned`\n        //    due to the extended control bytes range, which is `self.bucket_mask + 1 + Group::WIDTH`;\n        // 3. The caller of this function guarantees that [`RawTableInner`] has already been allocated;\n        // 4. We can use `Group::load_aligned` and `Group::store_aligned` here since we start from 0\n        //    and go to the end with a step equal to `Group::WIDTH` (see TableLayout::calculate_layout_for).\n        for i in (0..self.buckets()).step_by(Group::WIDTH) {\n            let group = Group::load_aligned(self.ctrl(i));\n            let group = group.convert_special_to_empty_and_full_to_deleted();\n            group.store_aligned(self.ctrl(i));\n        }\n\n        // Fix up the trailing control bytes. See the comments in set_ctrl\n        // for the handling of tables smaller than the group width.\n        //\n        // SAFETY: The caller of this function guarantees that [`RawTableInner`]\n        // has already been allocated\n        if unlikely(self.buckets() < Group::WIDTH) {\n            // SAFETY: We have `self.bucket_mask + 1 + Group::WIDTH` number of control bytes,\n            // so copying `self.buckets() == self.bucket_mask + 1` bytes with offset equal to\n            // `Group::WIDTH` is safe\n            self.ctrl(0)\n                .copy_to(self.ctrl(Group::WIDTH), self.buckets());\n        } else {\n            // SAFETY: We have `self.bucket_mask + 1 + Group::WIDTH` number of\n            // control bytes,so copying `Group::WIDTH` bytes with offset equal\n            // to `self.buckets() == self.bucket_mask + 1` is safe\n            self.ctrl(0)\n                .copy_to(self.ctrl(self.buckets()), Group::WIDTH);\n        }\n    }\n\n    /// Returns an iterator over every element in the table.\n    ///\n    /// # Safety\n    ///\n    /// If any of the following conditions are violated, the result\n    /// is [`undefined behavior`]:\n    ///\n    /// * The caller has to ensure that the `RawTableInner` outlives the\n    ///   `RawIter`. Because we cannot make the `next` method unsafe on\n    ///   the `RawIter` struct, we have to make the `iter` method unsafe.\n    ///\n    /// * The [`RawTableInner`] must have properly initialized control bytes.\n    ///\n    /// The type `T` must be the actual type of the elements stored in the table,\n    /// otherwise using the returned [`RawIter`] results in [`undefined behavior`].\n    ///\n    /// [`undefined behavior`]: https://doc.rust-lang.org/reference/behavior-considered-undefined.html\n    #[inline]\n    unsafe fn iter<T>(&self) -> RawIter<T> {\n        // SAFETY:\n        // 1. Since the caller of this function ensures that the control bytes\n        //    are properly initialized and `self.data_end()` points to the start\n        //    of the array of control bytes, therefore: `ctrl` is valid for reads,\n        //    properly aligned to `Group::WIDTH` and points to the properly initialized\n        //    control bytes.\n        // 2. `data` bucket index in the table is equal to the `ctrl` index (i.e.\n        //    equal to zero).\n        // 3. We pass the exact value of buckets of the table to the function.\n        //\n        //                         `ctrl` points here (to the start\n        //                         of the first control byte `CT0`)\n        //                          \n        // [Pad], T_n, ..., T1, T0, |CT0, CT1, ..., CT_n|, CTa_0, CTa_1, ..., CTa_m\n        //                           \\________  ________/\n        //                                    \\/\n        //       `n = buckets - 1`, i.e. `RawTableInner::buckets() - 1`\n        //\n        // where: T0...T_n  - our stored data;\n        //        CT0...CT_n - control bytes or metadata for `data`.\n        //        CTa_0...CTa_m - additional control bytes, where `m = Group::WIDTH - 1` (so that the search\n        //                        with loading `Group` bytes from the heap works properly, even if the result\n        //                        of `h1(hash) & self.bucket_mask` is equal to `self.bucket_mask`). See also\n        //                        `RawTableInner::set_ctrl` function.\n        //\n        // P.S. `h1(hash) & self.bucket_mask` is the same as `hash as usize % self.buckets()` because the number\n        // of buckets is a power of two, and `self.bucket_mask = self.buckets() - 1`.\n        let data = Bucket::from_base_index(self.data_end(), 0);\n        RawIter {\n            // SAFETY: See explanation above\n            iter: RawIterRange::new(self.ctrl.as_ptr(), data, self.buckets()),\n            items: self.items,\n        }\n    }\n\n    /// Executes the destructors (if any) of the values stored in the table.\n    ///\n    /// # Note\n    ///\n    /// This function does not erase the control bytes of the table and does\n    /// not make any changes to the `items` or `growth_left` fields of the\n    /// table. If necessary, the caller of this function must manually set\n    /// up these table fields, for example using the [`clear_no_drop`] function.\n    ///\n    /// Be careful during calling this function, because drop function of\n    /// the elements can panic, and this can leave table in an inconsistent\n    /// state.\n    ///\n    /// # Safety\n    ///\n    /// The type `T` must be the actual type of the elements stored in the table,\n    /// otherwise calling this function may result in [`undefined behavior`].\n    ///\n    /// If `T` is a type that should be dropped and **the table is not empty**,\n    /// calling this function more than once results in [`undefined behavior`].\n    ///\n    /// If `T` is not [`Copy`], attempting to use values stored in the table after\n    /// calling this function may result in [`undefined behavior`].\n    ///\n    /// It is safe to call this function on a table that has not been allocated,\n    /// on a table with uninitialized control bytes, and on a table with no actual\n    /// data but with `Full` control bytes if `self.items == 0`.\n    ///\n    /// See also [`Bucket::drop`] / [`Bucket::as_ptr`] methods, for more information\n    /// about of properly removing or saving `element` from / into the [`RawTable`] /\n    /// [`RawTableInner`].\n    ///\n    /// [`Bucket::drop`]: Bucket::drop\n    /// [`Bucket::as_ptr`]: Bucket::as_ptr\n    /// [`clear_no_drop`]: RawTableInner::clear_no_drop\n    /// [`undefined behavior`]: https://doc.rust-lang.org/reference/behavior-considered-undefined.html\n    unsafe fn drop_elements<T>(&mut self) {\n        // Check that `self.items != 0`. Protects against the possibility\n        // of creating an iterator on an table with uninitialized control bytes.\n        if T::NEEDS_DROP && self.items != 0 {\n            // SAFETY: We know for sure that RawTableInner will outlive the\n            // returned `RawIter` iterator, and the caller of this function\n            // must uphold the safety contract for `drop_elements` method.\n            for item in self.iter::<T>() {\n                // SAFETY: The caller must uphold the safety contract for\n                // `drop_elements` method.\n                item.drop();\n            }\n        }\n    }\n\n    /// Executes the destructors (if any) of the values stored in the table and than\n    /// deallocates the table.\n    ///\n    /// # Note\n    ///\n    /// Calling this function automatically makes invalid (dangling) all instances of\n    /// buckets ([`Bucket`]) and makes invalid (dangling) the `ctrl` field of the table.\n    ///\n    /// This function does not make any changes to the `bucket_mask`, `items` or `growth_left`\n    /// fields of the table. If necessary, the caller of this function must manually set\n    /// up these table fields.\n    ///\n    /// # Safety\n    ///\n    /// If any of the following conditions are violated, the result is [`undefined behavior`]:\n    ///\n    /// * Calling this function more than once;\n    ///\n    /// * The type `T` must be the actual type of the elements stored in the table.\n    ///\n    /// * The `alloc` must be the same [`Allocator`] as the `Allocator` that was used\n    ///   to allocate this table.\n    ///\n    /// * The `table_layout` must be the same [`TableLayout`] as the `TableLayout` that\n    ///   was used to allocate this table.\n    ///\n    /// The caller of this function should pay attention to the possibility of the\n    /// elements' drop function panicking, because this:\n    ///\n    ///    * May leave the table in an inconsistent state;\n    ///\n    ///    * Memory is never deallocated, so a memory leak may occur.\n    ///\n    /// Attempt to use the `ctrl` field of the table (dereference) after calling this\n    /// function results in [`undefined behavior`].\n    ///\n    /// It is safe to call this function on a table that has not been allocated,\n    /// on a table with uninitialized control bytes, and on a table with no actual\n    /// data but with `Full` control bytes if `self.items == 0`.\n    ///\n    /// See also [`RawTableInner::drop_elements`] or [`RawTableInner::free_buckets`]\n    /// for more  information.\n    ///\n    /// [`RawTableInner::drop_elements`]: RawTableInner::drop_elements\n    /// [`RawTableInner::free_buckets`]: RawTableInner::free_buckets\n    /// [`undefined behavior`]: https://doc.rust-lang.org/reference/behavior-considered-undefined.html\n    unsafe fn drop_inner_table<T, A: Allocator>(&mut self, alloc: &A, table_layout: TableLayout) {\n        if !self.is_empty_singleton() {\n            unsafe {\n                // SAFETY: The caller must uphold the safety contract for `drop_inner_table` method.\n                self.drop_elements::<T>();\n                // SAFETY:\n                // 1. We have checked that our table is allocated.\n                // 2. The caller must uphold the safety contract for `drop_inner_table` method.\n                self.free_buckets(alloc, table_layout);\n            }\n        }\n    }\n\n    /// Returns a pointer to an element in the table (convenience for\n    /// `Bucket::from_base_index(self.data_end::<T>(), index)`).\n    ///\n    /// The caller must ensure that the `RawTableInner` outlives the returned [`Bucket<T>`],\n    /// otherwise using it may result in [`undefined behavior`].\n    ///\n    /// # Safety\n    ///\n    /// If `mem::size_of::<T>() != 0`, then the safety rules are directly derived from the\n    /// safety rules of the [`Bucket::from_base_index`] function. Therefore, when calling\n    /// this function, the following safety rules must be observed:\n    ///\n    /// * The table must already be allocated;\n    ///\n    /// * The `index` must not be greater than the number returned by the [`RawTableInner::buckets`]\n    ///   function, i.e. `(index + 1) <= self.buckets()`.\n    ///\n    /// * The type `T` must be the actual type of the elements stored in the table, otherwise\n    ///   using the returned [`Bucket`] may result in [`undefined behavior`].\n    ///\n    /// It is safe to call this function with index of zero (`index == 0`) on a table that has\n    /// not been allocated, but using the returned [`Bucket`] results in [`undefined behavior`].\n    ///\n    /// If `mem::size_of::<T>() == 0`, then the only requirement is that the `index` must\n    /// not be greater than the number returned by the [`RawTable::buckets`] function, i.e.\n    /// `(index + 1) <= self.buckets()`.\n    ///\n    /// ```none\n    /// If mem::size_of::<T>() != 0 then return a pointer to the `element` in the `data part` of the table\n    /// (we start counting from \"0\", so that in the expression T[n], the \"n\" index actually one less than\n    /// the \"buckets\" number of our `RawTableInner`, i.e. \"n = RawTableInner::buckets() - 1\"):\n    ///\n    ///           `table.bucket(3).as_ptr()` returns a pointer that points here in the `data`\n    ///           part of the `RawTableInner`, i.e. to the start of T3 (see [`Bucket::as_ptr`])\n    ///                  |\n    ///                  |               `base = table.data_end::<T>()` points here\n    ///                  |               (to the start of CT0 or to the end of T0)\n    ///                  v                 v\n    /// [Pad], T_n, ..., |T3|, T2, T1, T0, |CT0, CT1, CT2, CT3, ..., CT_n, CTa_0, CTa_1, ..., CTa_m\n    ///                     ^                                              \\__________  __________/\n    ///        `table.bucket(3)` returns a pointer that points                        \\/\n    ///         here in the `data` part of the `RawTableInner`             additional control bytes\n    ///         (to the end of T3)                                          `m = Group::WIDTH - 1`\n    ///\n    /// where: T0...T_n  - our stored data;\n    ///        CT0...CT_n - control bytes or metadata for `data`;\n    ///        CTa_0...CTa_m - additional control bytes (so that the search with loading `Group` bytes from\n    ///                        the heap works properly, even if the result of `h1(hash) & self.bucket_mask`\n    ///                        is equal to `self.bucket_mask`). See also `RawTableInner::set_ctrl` function.\n    ///\n    /// P.S. `h1(hash) & self.bucket_mask` is the same as `hash as usize % self.buckets()` because the number\n    /// of buckets is a power of two, and `self.bucket_mask = self.buckets() - 1`.\n    /// ```\n    ///\n    /// [`Bucket::from_base_index`]: Bucket::from_base_index\n    /// [`RawTableInner::buckets`]: RawTableInner::buckets\n    /// [`undefined behavior`]: https://doc.rust-lang.org/reference/behavior-considered-undefined.html\n    #[inline]\n    unsafe fn bucket<T>(&self, index: usize) -> Bucket<T> {\n        debug_assert_ne!(self.bucket_mask, 0);\n        debug_assert!(index < self.buckets());\n        Bucket::from_base_index(self.data_end(), index)\n    }\n\n    /// Returns a raw `*mut u8` pointer to the start of the `data` element in the table\n    /// (convenience for `self.data_end::<u8>().as_ptr().sub((index + 1) * size_of)`).\n    ///\n    /// The caller must ensure that the `RawTableInner` outlives the returned `*mut u8`,\n    /// otherwise using it may result in [`undefined behavior`].\n    ///\n    /// # Safety\n    ///\n    /// If any of the following conditions are violated, the result is [`undefined behavior`]:\n    ///\n    /// * The table must already be allocated;\n    ///\n    /// * The `index` must not be greater than the number returned by the [`RawTableInner::buckets`]\n    ///   function, i.e. `(index + 1) <= self.buckets()`;\n    ///\n    /// * The `size_of` must be equal to the size of the elements stored in the table;\n    ///\n    /// ```none\n    /// If mem::size_of::<T>() != 0 then return a pointer to the `element` in the `data part` of the table\n    /// (we start counting from \"0\", so that in the expression T[n], the \"n\" index actually one less than\n    /// the \"buckets\" number of our `RawTableInner`, i.e. \"n = RawTableInner::buckets() - 1\"):\n    ///\n    ///           `table.bucket_ptr(3, mem::size_of::<T>())` returns a pointer that points here in the\n    ///           `data` part of the `RawTableInner`, i.e. to the start of T3\n    ///                  |\n    ///                  |               `base = table.data_end::<u8>()` points here\n    ///                  |               (to the start of CT0 or to the end of T0)\n    ///                  v                 v\n    /// [Pad], T_n, ..., |T3|, T2, T1, T0, |CT0, CT1, CT2, CT3, ..., CT_n, CTa_0, CTa_1, ..., CTa_m\n    ///                                                                    \\__________  __________/\n    ///                                                                               \\/\n    ///                                                                    additional control bytes\n    ///                                                                     `m = Group::WIDTH - 1`\n    ///\n    /// where: T0...T_n  - our stored data;\n    ///        CT0...CT_n - control bytes or metadata for `data`;\n    ///        CTa_0...CTa_m - additional control bytes (so that the search with loading `Group` bytes from\n    ///                        the heap works properly, even if the result of `h1(hash) & self.bucket_mask`\n    ///                        is equal to `self.bucket_mask`). See also `RawTableInner::set_ctrl` function.\n    ///\n    /// P.S. `h1(hash) & self.bucket_mask` is the same as `hash as usize % self.buckets()` because the number\n    /// of buckets is a power of two, and `self.bucket_mask = self.buckets() - 1`.\n    /// ```\n    ///\n    /// [`RawTableInner::buckets`]: RawTableInner::buckets\n    /// [`undefined behavior`]: https://doc.rust-lang.org/reference/behavior-considered-undefined.html\n    #[inline]\n    unsafe fn bucket_ptr(&self, index: usize, size_of: usize) -> *mut u8 {\n        debug_assert_ne!(self.bucket_mask, 0);\n        debug_assert!(index < self.buckets());\n        let base: *mut u8 = self.data_end().as_ptr();\n        base.sub((index + 1) * size_of)\n    }\n\n    /// Returns pointer to one past last `data` element in the table as viewed from\n    /// the start point of the allocation (convenience for `self.ctrl.cast()`).\n    ///\n    /// This function actually returns a pointer to the end of the `data element` at\n    /// index \"0\" (zero).\n    ///\n    /// The caller must ensure that the `RawTableInner` outlives the returned [`NonNull<T>`],\n    /// otherwise using it may result in [`undefined behavior`].\n    ///\n    /// # Note\n    ///\n    /// The type `T` must be the actual type of the elements stored in the table, otherwise\n    /// using the returned [`NonNull<T>`] may result in [`undefined behavior`].\n    ///\n    /// ```none\n    ///                        `table.data_end::<T>()` returns pointer that points here\n    ///                        (to the end of `T0`)\n    ///                          \n    /// [Pad], T_n, ..., T1, T0, |CT0, CT1, ..., CT_n|, CTa_0, CTa_1, ..., CTa_m\n    ///                           \\________  ________/\n    ///                                    \\/\n    ///       `n = buckets - 1`, i.e. `RawTableInner::buckets() - 1`\n    ///\n    /// where: T0...T_n  - our stored data;\n    ///        CT0...CT_n - control bytes or metadata for `data`.\n    ///        CTa_0...CTa_m - additional control bytes, where `m = Group::WIDTH - 1` (so that the search\n    ///                        with loading `Group` bytes from the heap works properly, even if the result\n    ///                        of `h1(hash) & self.bucket_mask` is equal to `self.bucket_mask`). See also\n    ///                        `RawTableInner::set_ctrl` function.\n    ///\n    /// P.S. `h1(hash) & self.bucket_mask` is the same as `hash as usize % self.buckets()` because the number\n    /// of buckets is a power of two, and `self.bucket_mask = self.buckets() - 1`.\n    /// ```\n    ///\n    /// [`undefined behavior`]: https://doc.rust-lang.org/reference/behavior-considered-undefined.html\n    #[inline]\n    fn data_end<T>(&self) -> NonNull<T> {\n        self.ctrl.cast()\n    }\n\n    /// Returns an iterator-like object for a probe sequence on the table.\n    ///\n    /// This iterator never terminates, but is guaranteed to visit each bucket\n    /// group exactly once. The loop using `probe_seq` must terminate upon\n    /// reaching a group containing an empty bucket.\n    #[inline]\n    fn probe_seq(&self, hash: u64) -> ProbeSeq {\n        ProbeSeq {\n            // This is the same as `hash as usize % self.buckets()` because the number\n            // of buckets is a power of two, and `self.bucket_mask = self.buckets() - 1`.\n            pos: h1(hash) & self.bucket_mask,\n            stride: 0,\n        }\n    }\n\n    #[inline]\n    unsafe fn record_item_insert_at(&mut self, index: usize, old_ctrl: Tag, hash: u64) {\n        self.growth_left -= usize::from(old_ctrl.special_is_empty());\n        self.set_ctrl_hash(index, hash);\n        self.items += 1;\n    }\n\n    #[inline]\n    fn is_in_same_group(&self, i: usize, new_i: usize, hash: u64) -> bool {\n        let probe_seq_pos = self.probe_seq(hash).pos;\n        let probe_index =\n            |pos: usize| (pos.wrapping_sub(probe_seq_pos) & self.bucket_mask) / Group::WIDTH;\n        probe_index(i) == probe_index(new_i)\n    }\n\n    /// Sets a control byte to the hash, and possibly also the replicated control byte at\n    /// the end of the array.\n    ///\n    /// This function does not make any changes to the `data` parts of the table,\n    /// or any changes to the `items` or `growth_left` field of the table.\n    ///\n    /// # Safety\n    ///\n    /// The safety rules are directly derived from the safety rules for [`RawTableInner::set_ctrl`]\n    /// method. Thus, in order to uphold the safety contracts for the method, you must observe the\n    /// following rules when calling this function:\n    ///\n    /// * The [`RawTableInner`] has already been allocated;\n    ///\n    /// * The `index` must not be greater than the `RawTableInner.bucket_mask`, i.e.\n    ///   `index <= RawTableInner.bucket_mask` or, in other words, `(index + 1)` must\n    ///   be no greater than the number returned by the function [`RawTableInner::buckets`].\n    ///\n    /// Calling this function on a table that has not been allocated results in [`undefined behavior`].\n    ///\n    /// See also [`Bucket::as_ptr`] method, for more information about of properly removing\n    /// or saving `data element` from / into the [`RawTable`] / [`RawTableInner`].\n    ///\n    /// [`RawTableInner::set_ctrl`]: RawTableInner::set_ctrl\n    /// [`RawTableInner::buckets`]: RawTableInner::buckets\n    /// [`Bucket::as_ptr`]: Bucket::as_ptr\n    /// [`undefined behavior`]: https://doc.rust-lang.org/reference/behavior-considered-undefined.html\n    #[inline]\n    unsafe fn set_ctrl_hash(&mut self, index: usize, hash: u64) {\n        // SAFETY: The caller must uphold the safety rules for the [`RawTableInner::set_ctrl_hash`]\n        self.set_ctrl(index, Tag::full(hash));\n    }\n\n    /// Replaces the hash in the control byte at the given index with the provided one,\n    /// and possibly also replicates the new control byte at the end of the array of control\n    /// bytes, returning the old control byte.\n    ///\n    /// This function does not make any changes to the `data` parts of the table,\n    /// or any changes to the `items` or `growth_left` field of the table.\n    ///\n    /// # Safety\n    ///\n    /// The safety rules are directly derived from the safety rules for [`RawTableInner::set_ctrl_hash`]\n    /// and [`RawTableInner::ctrl`] methods. Thus, in order to uphold the safety contracts for both\n    /// methods, you must observe the following rules when calling this function:\n    ///\n    /// * The [`RawTableInner`] has already been allocated;\n    ///\n    /// * The `index` must not be greater than the `RawTableInner.bucket_mask`, i.e.\n    ///   `index <= RawTableInner.bucket_mask` or, in other words, `(index + 1)` must\n    ///   be no greater than the number returned by the function [`RawTableInner::buckets`].\n    ///\n    /// Calling this function on a table that has not been allocated results in [`undefined behavior`].\n    ///\n    /// See also [`Bucket::as_ptr`] method, for more information about of properly removing\n    /// or saving `data element` from / into the [`RawTable`] / [`RawTableInner`].\n    ///\n    /// [`RawTableInner::set_ctrl_hash`]: RawTableInner::set_ctrl_hash\n    /// [`RawTableInner::buckets`]: RawTableInner::buckets\n    /// [`Bucket::as_ptr`]: Bucket::as_ptr\n    /// [`undefined behavior`]: https://doc.rust-lang.org/reference/behavior-considered-undefined.html\n    #[inline]\n    unsafe fn replace_ctrl_hash(&mut self, index: usize, hash: u64) -> Tag {\n        // SAFETY: The caller must uphold the safety rules for the [`RawTableInner::replace_ctrl_hash`]\n        let prev_ctrl = *self.ctrl(index);\n        self.set_ctrl_hash(index, hash);\n        prev_ctrl\n    }\n\n    /// Sets a control byte, and possibly also the replicated control byte at\n    /// the end of the array.\n    ///\n    /// This function does not make any changes to the `data` parts of the table,\n    /// or any changes to the `items` or `growth_left` field of the table.\n    ///\n    /// # Safety\n    ///\n    /// You must observe the following safety rules when calling this function:\n    ///\n    /// * The [`RawTableInner`] has already been allocated;\n    ///\n    /// * The `index` must not be greater than the `RawTableInner.bucket_mask`, i.e.\n    ///   `index <= RawTableInner.bucket_mask` or, in other words, `(index + 1)` must\n    ///   be no greater than the number returned by the function [`RawTableInner::buckets`].\n    ///\n    /// Calling this function on a table that has not been allocated results in [`undefined behavior`].\n    ///\n    /// See also [`Bucket::as_ptr`] method, for more information about of properly removing\n    /// or saving `data element` from / into the [`RawTable`] / [`RawTableInner`].\n    ///\n    /// [`RawTableInner::buckets`]: RawTableInner::buckets\n    /// [`Bucket::as_ptr`]: Bucket::as_ptr\n    /// [`undefined behavior`]: https://doc.rust-lang.org/reference/behavior-considered-undefined.html\n    #[inline]\n    unsafe fn set_ctrl(&mut self, index: usize, ctrl: Tag) {\n        // Replicate the first Group::WIDTH control bytes at the end of\n        // the array without using a branch. If the tables smaller than\n        // the group width (self.buckets() < Group::WIDTH),\n        // `index2 = Group::WIDTH + index`, otherwise `index2` is:\n        //\n        // - If index >= Group::WIDTH then index == index2.\n        // - Otherwise index2 == self.bucket_mask + 1 + index.\n        //\n        // The very last replicated control byte is never actually read because\n        // we mask the initial index for unaligned loads, but we write it\n        // anyways because it makes the set_ctrl implementation simpler.\n        //\n        // If there are fewer buckets than Group::WIDTH then this code will\n        // replicate the buckets at the end of the trailing group. For example\n        // with 2 buckets and a group size of 4, the control bytes will look\n        // like this:\n        //\n        //     Real    |             Replicated\n        // ---------------------------------------------\n        // | [A] | [B] | [Tag::EMPTY] | [EMPTY] | [A] | [B] |\n        // ---------------------------------------------\n\n        // This is the same as `(index.wrapping_sub(Group::WIDTH)) % self.buckets() + Group::WIDTH`\n        // because the number of buckets is a power of two, and `self.bucket_mask = self.buckets() - 1`.\n        let index2 = ((index.wrapping_sub(Group::WIDTH)) & self.bucket_mask) + Group::WIDTH;\n\n        // SAFETY: The caller must uphold the safety rules for the [`RawTableInner::set_ctrl`]\n        *self.ctrl(index) = ctrl;\n        *self.ctrl(index2) = ctrl;\n    }\n\n    /// Returns a pointer to a control byte.\n    ///\n    /// # Safety\n    ///\n    /// For the allocated [`RawTableInner`], the result is [`Undefined Behavior`],\n    /// if the `index` is greater than the `self.bucket_mask + 1 + Group::WIDTH`.\n    /// In that case, calling this function with `index == self.bucket_mask + 1 + Group::WIDTH`\n    /// will return a pointer to the end of the allocated table and it is useless on its own.\n    ///\n    /// Calling this function with `index >= self.bucket_mask + 1 + Group::WIDTH` on a\n    /// table that has not been allocated results in [`Undefined Behavior`].\n    ///\n    /// So to satisfy both requirements you should always follow the rule that\n    /// `index < self.bucket_mask + 1 + Group::WIDTH`\n    ///\n    /// Calling this function on [`RawTableInner`] that are not already allocated is safe\n    /// for read-only purpose.\n    ///\n    /// See also [`Bucket::as_ptr()`] method, for more information about of properly removing\n    /// or saving `data element` from / into the [`RawTable`] / [`RawTableInner`].\n    ///\n    /// [`Bucket::as_ptr()`]: Bucket::as_ptr()\n    /// [`Undefined Behavior`]: https://doc.rust-lang.org/reference/behavior-considered-undefined.html\n    #[inline]\n    unsafe fn ctrl(&self, index: usize) -> *mut Tag {\n        debug_assert!(index < self.num_ctrl_bytes());\n        // SAFETY: The caller must uphold the safety rules for the [`RawTableInner::ctrl`]\n        self.ctrl.as_ptr().add(index).cast()\n    }\n\n    /// Gets the slice of all control bytes.\n    fn ctrl_slice(&mut self) -> &mut [Tag] {\n        // SAFETY: We've intiailized all control bytes, and have the correct number.\n        unsafe { slice::from_raw_parts_mut(self.ctrl.as_ptr().cast(), self.num_ctrl_bytes()) }\n    }\n\n    #[inline]\n    fn buckets(&self) -> usize {\n        self.bucket_mask + 1\n    }\n\n    /// Checks whether the bucket at `index` is full.\n    ///\n    /// # Safety\n    ///\n    /// The caller must ensure `index` is less than the number of buckets.\n    #[inline]\n    unsafe fn is_bucket_full(&self, index: usize) -> bool {\n        debug_assert!(index < self.buckets());\n        (*self.ctrl(index)).is_full()\n    }\n\n    #[inline]\n    fn num_ctrl_bytes(&self) -> usize {\n        self.bucket_mask + 1 + Group::WIDTH\n    }\n\n    #[inline]\n    fn is_empty_singleton(&self) -> bool {\n        self.bucket_mask == 0\n    }\n\n    /// Attempts to allocate a new hash table with at least enough capacity\n    /// for inserting the given number of elements without reallocating,\n    /// and return it inside `ScopeGuard` to protect against panic in the hash\n    /// function.\n    ///\n    /// # Note\n    ///\n    /// It is recommended (but not required):\n    ///\n    /// * That the new table's `capacity` be greater than or equal to `self.items`.\n    ///\n    /// * The `alloc` is the same [`Allocator`] as the `Allocator` used\n    ///   to allocate this table.\n    ///\n    /// * The `table_layout` is the same [`TableLayout`] as the `TableLayout` used\n    ///   to allocate this table.\n    ///\n    /// If `table_layout` does not match the `TableLayout` that was used to allocate\n    /// this table, then using `mem::swap` with the `self` and the new table returned\n    /// by this function results in [`undefined behavior`].\n    ///\n    /// [`undefined behavior`]: https://doc.rust-lang.org/reference/behavior-considered-undefined.html\n    #[allow(clippy::mut_mut)]\n    #[inline]\n    fn prepare_resize<'a, A>(\n        &self,\n        alloc: &'a A,\n        table_layout: TableLayout,\n        capacity: usize,\n        fallibility: Fallibility,\n    ) -> Result<crate::scopeguard::ScopeGuard<Self, impl FnMut(&mut Self) + 'a>, TryReserveError>\n    where\n        A: Allocator,\n    {\n        debug_assert!(self.items <= capacity);\n\n        // Allocate and initialize the new table.\n        let new_table =\n            RawTableInner::fallible_with_capacity(alloc, table_layout, capacity, fallibility)?;\n\n        // The hash function may panic, in which case we simply free the new\n        // table without dropping any elements that may have been copied into\n        // it.\n        //\n        // This guard is also used to free the old table on success, see\n        // the comment at the bottom of this function.\n        Ok(guard(new_table, move |self_| {\n            if !self_.is_empty_singleton() {\n                // SAFETY:\n                // 1. We have checked that our table is allocated.\n                // 2. We know for sure that the `alloc` and `table_layout` matches the\n                //    [`Allocator`] and [`TableLayout`] used to allocate this table.\n                unsafe { self_.free_buckets(alloc, table_layout) };\n            }\n        }))\n    }\n\n    /// Reserves or rehashes to make room for `additional` more elements.\n    ///\n    /// This uses dynamic dispatch to reduce the amount of\n    /// code generated, but it is eliminated by LLVM optimizations when inlined.\n    ///\n    /// # Safety\n    ///\n    /// If any of the following conditions are violated, the result is\n    /// [`undefined behavior`]:\n    ///\n    /// * The `alloc` must be the same [`Allocator`] as the `Allocator` used\n    ///   to allocate this table.\n    ///\n    /// * The `layout` must be the same [`TableLayout`] as the `TableLayout`\n    ///   used to allocate this table.\n    ///\n    /// * The `drop` function (`fn(*mut u8)`) must be the actual drop function of\n    ///   the elements stored in the table.\n    ///\n    /// * The [`RawTableInner`] must have properly initialized control bytes.\n    ///\n    /// [`undefined behavior`]: https://doc.rust-lang.org/reference/behavior-considered-undefined.html\n    #[allow(clippy::inline_always)]\n    #[inline(always)]\n    unsafe fn reserve_rehash_inner<A>(\n        &mut self,\n        alloc: &A,\n        additional: usize,\n        hasher: &dyn Fn(&mut Self, usize) -> u64,\n        fallibility: Fallibility,\n        layout: TableLayout,\n        drop: Option<unsafe fn(*mut u8)>,\n    ) -> Result<(), TryReserveError>\n    where\n        A: Allocator,\n    {\n        // Avoid `Option::ok_or_else` because it bloats LLVM IR.\n        let new_items = match self.items.checked_add(additional) {\n            Some(new_items) => new_items,\n            None => return Err(fallibility.capacity_overflow()),\n        };\n        let full_capacity = bucket_mask_to_capacity(self.bucket_mask);\n        if new_items <= full_capacity / 2 {\n            // Rehash in-place without re-allocating if we have plenty of spare\n            // capacity that is locked up due to DELETED entries.\n\n            // SAFETY:\n            // 1. We know for sure that `[`RawTableInner`]` has already been allocated\n            //    (since new_items <= full_capacity / 2);\n            // 2. The caller ensures that `drop` function is the actual drop function of\n            //    the elements stored in the table.\n            // 3. The caller ensures that `layout` matches the [`TableLayout`] that was\n            //    used to allocate this table.\n            // 4. The caller ensures that the control bytes of the `RawTableInner`\n            //    are already initialized.\n            self.rehash_in_place(hasher, layout.size, drop);\n            Ok(())\n        } else {\n            // Otherwise, conservatively resize to at least the next size up\n            // to avoid churning deletes into frequent rehashes.\n            //\n            // SAFETY:\n            // 1. We know for sure that `capacity >= self.items`.\n            // 2. The caller ensures that `alloc` and `layout` matches the [`Allocator`] and\n            //    [`TableLayout`] that were used to allocate this table.\n            // 3. The caller ensures that the control bytes of the `RawTableInner`\n            //    are already initialized.\n            self.resize_inner(\n                alloc,\n                usize::max(new_items, full_capacity + 1),\n                hasher,\n                fallibility,\n                layout,\n            )\n        }\n    }\n\n    /// Returns an iterator over full buckets indices in the table.\n    ///\n    /// # Safety\n    ///\n    /// Behavior is undefined if any of the following conditions are violated:\n    ///\n    /// * The caller has to ensure that the `RawTableInner` outlives the\n    ///   `FullBucketsIndices`. Because we cannot make the `next` method\n    ///   unsafe on the `FullBucketsIndices` struct, we have to make the\n    ///   `full_buckets_indices` method unsafe.\n    ///\n    /// * The [`RawTableInner`] must have properly initialized control bytes.\n    #[inline(always)]\n    unsafe fn full_buckets_indices(&self) -> FullBucketsIndices {\n        // SAFETY:\n        // 1. Since the caller of this function ensures that the control bytes\n        //    are properly initialized and `self.ctrl(0)` points to the start\n        //    of the array of control bytes, therefore: `ctrl` is valid for reads,\n        //    properly aligned to `Group::WIDTH` and points to the properly initialized\n        //    control bytes.\n        // 2. The value of `items` is equal to the amount of data (values) added\n        //    to the table.\n        //\n        //                         `ctrl` points here (to the start\n        //                         of the first control byte `CT0`)\n        //                          \n        // [Pad], T_n, ..., T1, T0, |CT0, CT1, ..., CT_n|, Group::WIDTH\n        //                           \\________  ________/\n        //                                    \\/\n        //       `n = buckets - 1`, i.e. `RawTableInner::buckets() - 1`\n        //\n        // where: T0...T_n  - our stored data;\n        //        CT0...CT_n - control bytes or metadata for `data`.\n        let ctrl = NonNull::new_unchecked(self.ctrl(0).cast::<u8>());\n\n        FullBucketsIndices {\n            // Load the first group\n            // SAFETY: See explanation above.\n            current_group: Group::load_aligned(ctrl.as_ptr().cast())\n                .match_full()\n                .into_iter(),\n            group_first_index: 0,\n            ctrl,\n            items: self.items,\n        }\n    }\n\n    /// Allocates a new table of a different size and moves the contents of the\n    /// current table into it.\n    ///\n    /// This uses dynamic dispatch to reduce the amount of\n    /// code generated, but it is eliminated by LLVM optimizations when inlined.\n    ///\n    /// # Safety\n    ///\n    /// If any of the following conditions are violated, the result is\n    /// [`undefined behavior`]:\n    ///\n    /// * The `alloc` must be the same [`Allocator`] as the `Allocator` used\n    ///   to allocate this table;\n    ///\n    /// * The `layout` must be the same [`TableLayout`] as the `TableLayout`\n    ///   used to allocate this table;\n    ///\n    /// * The [`RawTableInner`] must have properly initialized control bytes.\n    ///\n    /// The caller of this function must ensure that `capacity >= self.items`\n    /// otherwise:\n    ///\n    /// * If `self.items != 0`, calling of this function with `capacity == 0`\n    ///   results in [`undefined behavior`].\n    ///\n    /// * If `capacity_to_buckets(capacity) < Group::WIDTH` and\n    ///   `self.items > capacity_to_buckets(capacity)` calling this function\n    ///   results in [`undefined behavior`].\n    ///\n    /// * If `capacity_to_buckets(capacity) >= Group::WIDTH` and\n    ///   `self.items > capacity_to_buckets(capacity)` calling this function\n    ///   are never return (will go into an infinite loop).\n    ///\n    /// Note: It is recommended (but not required) that the new table's `capacity`\n    /// be greater than or equal to `self.items`. In case if `capacity <= self.items`\n    /// this function can never return. See [`RawTableInner::find_insert_slot`] for\n    /// more information.\n    ///\n    /// [`RawTableInner::find_insert_slot`]: RawTableInner::find_insert_slot\n    /// [`undefined behavior`]: https://doc.rust-lang.org/reference/behavior-considered-undefined.html\n    #[allow(clippy::inline_always)]\n    #[inline(always)]\n    unsafe fn resize_inner<A>(\n        &mut self,\n        alloc: &A,\n        capacity: usize,\n        hasher: &dyn Fn(&mut Self, usize) -> u64,\n        fallibility: Fallibility,\n        layout: TableLayout,\n    ) -> Result<(), TryReserveError>\n    where\n        A: Allocator,\n    {\n        // SAFETY: We know for sure that `alloc` and `layout` matches the [`Allocator`] and [`TableLayout`]\n        // that were used to allocate this table.\n        let mut new_table = self.prepare_resize(alloc, layout, capacity, fallibility)?;\n\n        // SAFETY: We know for sure that RawTableInner will outlive the\n        // returned `FullBucketsIndices` iterator, and the caller of this\n        // function ensures that the control bytes are properly initialized.\n        for full_byte_index in self.full_buckets_indices() {\n            // This may panic.\n            let hash = hasher(self, full_byte_index);\n\n            // SAFETY:\n            // We can use a simpler version of insert() here since:\n            // 1. There are no DELETED entries.\n            // 2. We know there is enough space in the table.\n            // 3. All elements are unique.\n            // 4. The caller of this function guarantees that `capacity > 0`\n            //    so `new_table` must already have some allocated memory.\n            // 5. We set `growth_left` and `items` fields of the new table\n            //    after the loop.\n            // 6. We insert into the table, at the returned index, the data\n            //    matching the given hash immediately after calling this function.\n            let (new_index, _) = new_table.prepare_insert_slot(hash);\n\n            // SAFETY:\n            //\n            // * `src` is valid for reads of `layout.size` bytes, since the\n            //   table is alive and the `full_byte_index` is guaranteed to be\n            //   within bounds (see `FullBucketsIndices::next_impl`);\n            //\n            // * `dst` is valid for writes of `layout.size` bytes, since the\n            //   caller ensures that `table_layout` matches the [`TableLayout`]\n            //   that was used to allocate old table and we have the `new_index`\n            //   returned by `prepare_insert_slot`.\n            //\n            // * Both `src` and `dst` are properly aligned.\n            //\n            // * Both `src` and `dst` point to different region of memory.\n            ptr::copy_nonoverlapping(\n                self.bucket_ptr(full_byte_index, layout.size),\n                new_table.bucket_ptr(new_index, layout.size),\n                layout.size,\n            );\n        }\n\n        // The hash function didn't panic, so we can safely set the\n        // `growth_left` and `items` fields of the new table.\n        new_table.growth_left -= self.items;\n        new_table.items = self.items;\n\n        // We successfully copied all elements without panicking. Now replace\n        // self with the new table. The old table will have its memory freed but\n        // the items will not be dropped (since they have been moved into the\n        // new table).\n        // SAFETY: The caller ensures that `table_layout` matches the [`TableLayout`]\n        // that was used to allocate this table.\n        mem::swap(self, &mut new_table);\n\n        Ok(())\n    }\n\n    /// Rehashes the contents of the table in place (i.e. without changing the\n    /// allocation).\n    ///\n    /// If `hasher` panics then some the table's contents may be lost.\n    ///\n    /// This uses dynamic dispatch to reduce the amount of\n    /// code generated, but it is eliminated by LLVM optimizations when inlined.\n    ///\n    /// # Safety\n    ///\n    /// If any of the following conditions are violated, the result is [`undefined behavior`]:\n    ///\n    /// * The `size_of` must be equal to the size of the elements stored in the table;\n    ///\n    /// * The `drop` function (`fn(*mut u8)`) must be the actual drop function of\n    ///   the elements stored in the table.\n    ///\n    /// * The [`RawTableInner`] has already been allocated;\n    ///\n    /// * The [`RawTableInner`] must have properly initialized control bytes.\n    ///\n    /// [`undefined behavior`]: https://doc.rust-lang.org/reference/behavior-considered-undefined.html\n    #[allow(clippy::inline_always)]\n    #[cfg_attr(feature = \"inline-more\", inline(always))]\n    #[cfg_attr(not(feature = \"inline-more\"), inline)]\n    unsafe fn rehash_in_place(\n        &mut self,\n        hasher: &dyn Fn(&mut Self, usize) -> u64,\n        size_of: usize,\n        drop: Option<unsafe fn(*mut u8)>,\n    ) {\n        // If the hash function panics then properly clean up any elements\n        // that we haven't rehashed yet. We unfortunately can't preserve the\n        // element since we lost their hash and have no way of recovering it\n        // without risking another panic.\n        self.prepare_rehash_in_place();\n\n        let mut guard = guard(self, move |self_| {\n            if let Some(drop) = drop {\n                for i in 0..self_.buckets() {\n                    if *self_.ctrl(i) == Tag::DELETED {\n                        self_.set_ctrl(i, Tag::EMPTY);\n                        drop(self_.bucket_ptr(i, size_of));\n                        self_.items -= 1;\n                    }\n                }\n            }\n            self_.growth_left = bucket_mask_to_capacity(self_.bucket_mask) - self_.items;\n        });\n\n        // At this point, DELETED elements are elements that we haven't\n        // rehashed yet. Find them and re-insert them at their ideal\n        // position.\n        'outer: for i in 0..guard.buckets() {\n            if *guard.ctrl(i) != Tag::DELETED {\n                continue;\n            }\n\n            let i_p = guard.bucket_ptr(i, size_of);\n\n            'inner: loop {\n                // Hash the current item\n                let hash = hasher(*guard, i);\n\n                // Search for a suitable place to put it\n                //\n                // SAFETY: Caller of this function ensures that the control bytes\n                // are properly initialized.\n                let new_i = guard.find_insert_slot(hash).index;\n\n                // Probing works by scanning through all of the control\n                // bytes in groups, which may not be aligned to the group\n                // size. If both the new and old position fall within the\n                // same unaligned group, then there is no benefit in moving\n                // it and we can just continue to the next item.\n                if likely(guard.is_in_same_group(i, new_i, hash)) {\n                    guard.set_ctrl_hash(i, hash);\n                    continue 'outer;\n                }\n\n                let new_i_p = guard.bucket_ptr(new_i, size_of);\n\n                // We are moving the current item to a new position. Write\n                // our H2 to the control byte of the new position.\n                let prev_ctrl = guard.replace_ctrl_hash(new_i, hash);\n                if prev_ctrl == Tag::EMPTY {\n                    guard.set_ctrl(i, Tag::EMPTY);\n                    // If the target slot is empty, simply move the current\n                    // element into the new slot and clear the old control\n                    // byte.\n                    ptr::copy_nonoverlapping(i_p, new_i_p, size_of);\n                    continue 'outer;\n                } else {\n                    // If the target slot is occupied, swap the two elements\n                    // and then continue processing the element that we just\n                    // swapped into the old slot.\n                    debug_assert_eq!(prev_ctrl, Tag::DELETED);\n                    ptr::swap_nonoverlapping(i_p, new_i_p, size_of);\n                    continue 'inner;\n                }\n            }\n        }\n\n        guard.growth_left = bucket_mask_to_capacity(guard.bucket_mask) - guard.items;\n\n        mem::forget(guard);\n    }\n\n    /// Deallocates the table without dropping any entries.\n    ///\n    /// # Note\n    ///\n    /// This function must be called only after [`drop_elements`](RawTableInner::drop_elements),\n    /// else it can lead to leaking of memory. Also calling this function automatically\n    /// makes invalid (dangling) all instances of buckets ([`Bucket`]) and makes invalid\n    /// (dangling) the `ctrl` field of the table.\n    ///\n    /// # Safety\n    ///\n    /// If any of the following conditions are violated, the result is [`Undefined Behavior`]:\n    ///\n    /// * The [`RawTableInner`] has already been allocated;\n    ///\n    /// * The `alloc` must be the same [`Allocator`] as the `Allocator` that was used\n    ///   to allocate this table.\n    ///\n    /// * The `table_layout` must be the same [`TableLayout`] as the `TableLayout` that was used\n    ///   to allocate this table.\n    ///\n    /// See also [`GlobalAlloc::dealloc`] or [`Allocator::deallocate`] for more  information.\n    ///\n    /// [`Undefined Behavior`]: https://doc.rust-lang.org/reference/behavior-considered-undefined.html\n    /// [`GlobalAlloc::dealloc`]: https://doc.rust-lang.org/alloc/alloc/trait.GlobalAlloc.html#tymethod.dealloc\n    /// [`Allocator::deallocate`]: https://doc.rust-lang.org/alloc/alloc/trait.Allocator.html#tymethod.deallocate\n    #[inline]\n    unsafe fn free_buckets<A>(&mut self, alloc: &A, table_layout: TableLayout)\n    where\n        A: Allocator,\n    {\n        // SAFETY: The caller must uphold the safety contract for `free_buckets`\n        // method.\n        let (ptr, layout) = self.allocation_info(table_layout);\n        alloc.deallocate(ptr, layout);\n    }\n\n    /// Returns a pointer to the allocated memory and the layout that was used to\n    /// allocate the table.\n    ///\n    /// # Safety\n    ///\n    /// Caller of this function must observe the following safety rules:\n    ///\n    /// * The [`RawTableInner`] has already been allocated, otherwise\n    ///   calling this function results in [`undefined behavior`]\n    ///\n    /// * The `table_layout` must be the same [`TableLayout`] as the `TableLayout`\n    ///   that was used to allocate this table. Failure to comply with this condition\n    ///   may result in [`undefined behavior`].\n    ///\n    /// See also [`GlobalAlloc::dealloc`] or [`Allocator::deallocate`] for more  information.\n    ///\n    /// [`undefined behavior`]: https://doc.rust-lang.org/reference/behavior-considered-undefined.html\n    /// [`GlobalAlloc::dealloc`]: https://doc.rust-lang.org/alloc/alloc/trait.GlobalAlloc.html#tymethod.dealloc\n    /// [`Allocator::deallocate`]: https://doc.rust-lang.org/alloc/alloc/trait.Allocator.html#tymethod.deallocate\n    #[inline]\n    unsafe fn allocation_info(&self, table_layout: TableLayout) -> (NonNull<u8>, Layout) {\n        debug_assert!(\n            !self.is_empty_singleton(),\n            \"this function can only be called on non-empty tables\"\n        );\n\n        // Avoid `Option::unwrap_or_else` because it bloats LLVM IR.\n        let (layout, ctrl_offset) = match table_layout.calculate_layout_for(self.buckets()) {\n            Some(lco) => lco,\n            None => unsafe { hint::unreachable_unchecked() },\n        };\n        (\n            // SAFETY: The caller must uphold the safety contract for `allocation_info` method.\n            unsafe { NonNull::new_unchecked(self.ctrl.as_ptr().sub(ctrl_offset)) },\n            layout,\n        )\n    }\n\n    /// Returns the total amount of memory allocated internally by the hash\n    /// table, in bytes.\n    ///\n    /// The returned number is informational only. It is intended to be\n    /// primarily used for memory profiling.\n    ///\n    /// # Safety\n    ///\n    /// The `table_layout` must be the same [`TableLayout`] as the `TableLayout`\n    /// that was used to allocate this table. Failure to comply with this condition\n    /// may result in [`undefined behavior`].\n    ///\n    ///\n    /// [`undefined behavior`]: https://doc.rust-lang.org/reference/behavior-considered-undefined.html\n    #[inline]\n    unsafe fn allocation_size_or_zero(&self, table_layout: TableLayout) -> usize {\n        if self.is_empty_singleton() {\n            0\n        } else {\n            // SAFETY:\n            // 1. We have checked that our table is allocated.\n            // 2. The caller ensures that `table_layout` matches the [`TableLayout`]\n            // that was used to allocate this table.\n            unsafe { self.allocation_info(table_layout).1.size() }\n        }\n    }\n\n    /// Marks all table buckets as empty without dropping their contents.\n    #[inline]\n    fn clear_no_drop(&mut self) {\n        if !self.is_empty_singleton() {\n            self.ctrl_slice().fill_empty();\n        }\n        self.items = 0;\n        self.growth_left = bucket_mask_to_capacity(self.bucket_mask);\n    }\n\n    /// Erases the [`Bucket`]'s control byte at the given index so that it does not\n    /// triggered as full, decreases the `items` of the table and, if it can be done,\n    /// increases `self.growth_left`.\n    ///\n    /// This function does not actually erase / drop the [`Bucket`] itself, i.e. it\n    /// does not make any changes to the `data` parts of the table. The caller of this\n    /// function must take care to properly drop the `data`, otherwise calling this\n    /// function may result in a memory leak.\n    ///\n    /// # Safety\n    ///\n    /// You must observe the following safety rules when calling this function:\n    ///\n    /// * The [`RawTableInner`] has already been allocated;\n    ///\n    /// * It must be the full control byte at the given position;\n    ///\n    /// * The `index` must not be greater than the `RawTableInner.bucket_mask`, i.e.\n    ///   `index <= RawTableInner.bucket_mask` or, in other words, `(index + 1)` must\n    ///   be no greater than the number returned by the function [`RawTableInner::buckets`].\n    ///\n    /// Calling this function on a table that has not been allocated results in [`undefined behavior`].\n    ///\n    /// Calling this function on a table with no elements is unspecified, but calling subsequent\n    /// functions is likely to result in [`undefined behavior`] due to overflow subtraction\n    /// (`self.items -= 1 cause overflow when self.items == 0`).\n    ///\n    /// See also [`Bucket::as_ptr`] method, for more information about of properly removing\n    /// or saving `data element` from / into the [`RawTable`] / [`RawTableInner`].\n    ///\n    /// [`RawTableInner::buckets`]: RawTableInner::buckets\n    /// [`Bucket::as_ptr`]: Bucket::as_ptr\n    /// [`undefined behavior`]: https://doc.rust-lang.org/reference/behavior-considered-undefined.html\n    #[inline]\n    unsafe fn erase(&mut self, index: usize) {\n        debug_assert!(self.is_bucket_full(index));\n\n        // This is the same as `index.wrapping_sub(Group::WIDTH) % self.buckets()` because\n        // the number of buckets is a power of two, and `self.bucket_mask = self.buckets() - 1`.\n        let index_before = index.wrapping_sub(Group::WIDTH) & self.bucket_mask;\n        // SAFETY:\n        // - The caller must uphold the safety contract for `erase` method;\n        // - `index_before` is guaranteed to be in range due to masking with `self.bucket_mask`\n        let empty_before = Group::load(self.ctrl(index_before)).match_empty();\n        let empty_after = Group::load(self.ctrl(index)).match_empty();\n\n        // Inserting and searching in the map is performed by two key functions:\n        //\n        // - The `find_insert_slot` function that looks up the index of any `Tag::EMPTY` or `Tag::DELETED`\n        //   slot in a group to be able to insert. If it doesn't find an `Tag::EMPTY` or `Tag::DELETED`\n        //   slot immediately in the first group, it jumps to the next `Group` looking for it,\n        //   and so on until it has gone through all the groups in the control bytes.\n        //\n        // - The `find_inner` function that looks for the index of the desired element by looking\n        //   at all the `FULL` bytes in the group. If it did not find the element right away, and\n        //   there is no `Tag::EMPTY` byte in the group, then this means that the `find_insert_slot`\n        //   function may have found a suitable slot in the next group. Therefore, `find_inner`\n        //   jumps further, and if it does not find the desired element and again there is no `Tag::EMPTY`\n        //   byte, then it jumps further, and so on. The search stops only if `find_inner` function\n        //   finds the desired element or hits an `Tag::EMPTY` slot/byte.\n        //\n        // Accordingly, this leads to two consequences:\n        //\n        // - The map must have `Tag::EMPTY` slots (bytes);\n        //\n        // - You can't just mark the byte to be erased as `Tag::EMPTY`, because otherwise the `find_inner`\n        //   function may stumble upon an `Tag::EMPTY` byte before finding the desired element and stop\n        //   searching.\n        //\n        // Thus it is necessary to check all bytes after and before the erased element. If we are in\n        // a contiguous `Group` of `FULL` or `Tag::DELETED` bytes (the number of `FULL` or `Tag::DELETED` bytes\n        // before and after is greater than or equal to `Group::WIDTH`), then we must mark our byte as\n        // `Tag::DELETED` in order for the `find_inner` function to go further. On the other hand, if there\n        // is at least one `Tag::EMPTY` slot in the `Group`, then the `find_inner` function will still stumble\n        // upon an `Tag::EMPTY` byte, so we can safely mark our erased byte as `Tag::EMPTY` as well.\n        //\n        // Finally, since `index_before == (index.wrapping_sub(Group::WIDTH) & self.bucket_mask) == index`\n        // and given all of the above, tables smaller than the group width (self.buckets() < Group::WIDTH)\n        // cannot have `Tag::DELETED` bytes.\n        //\n        // Note that in this context `leading_zeros` refers to the bytes at the end of a group, while\n        // `trailing_zeros` refers to the bytes at the beginning of a group.\n        let ctrl = if empty_before.leading_zeros() + empty_after.trailing_zeros() >= Group::WIDTH {\n            Tag::DELETED\n        } else {\n            self.growth_left += 1;\n            Tag::EMPTY\n        };\n        // SAFETY: the caller must uphold the safety contract for `erase` method.\n        self.set_ctrl(index, ctrl);\n        self.items -= 1;\n    }\n}",
            "impl RawTableInner {\n    const NEW: Self = RawTableInner::new();\n\n    /// Creates a new empty hash table without allocating any memory.\n    ///\n    /// In effect this returns a table with exactly 1 bucket. However we can\n    /// leave the data pointer dangling since that bucket is never accessed\n    /// due to our load factor forcing us to always have at least 1 free bucket.\n    #[inline]\n    const fn new() -> Self {\n        Self {\n            // Be careful to cast the entire slice to a raw pointer.\n            ctrl: unsafe {\n                NonNull::new_unchecked(Group::static_empty().as_ptr().cast_mut().cast())\n            },\n            bucket_mask: 0,\n            items: 0,\n            growth_left: 0,\n        }\n    }\n}"
        ],
        "raw::TableLayout": [
            "Clone",
            "Copy",
            "impl TableLayout {\n    #[inline]\n    const fn new<T>() -> Self {\n        let layout = Layout::new::<T>();\n        Self {\n            size: layout.size(),\n            ctrl_align: if layout.align() > Group::WIDTH {\n                layout.align()\n            } else {\n                Group::WIDTH\n            },\n        }\n    }\n\n    #[inline]\n    fn calculate_layout_for(self, buckets: usize) -> Option<(Layout, usize)> {\n        debug_assert!(buckets.is_power_of_two());\n\n        let TableLayout { size, ctrl_align } = self;\n        // Manual layout calculation since Layout methods are not yet stable.\n        let ctrl_offset =\n            size.checked_mul(buckets)?.checked_add(ctrl_align - 1)? & !(ctrl_align - 1);\n        let len = ctrl_offset.checked_add(buckets + Group::WIDTH)?;\n\n        // We need an additional check to ensure that the allocation doesn't\n        // exceed `isize::MAX` (https://github.com/rust-lang/rust/pull/95295).\n        if len > isize::MAX as usize - (ctrl_align - 1) {\n            return None;\n        }\n\n        Some((\n            unsafe { Layout::from_size_align_unchecked(len, ctrl_align) },\n            ctrl_offset,\n        ))\n    }\n}"
        ],
        "raw_entry::RawEntryBuilder": [
            "impl<'a, K, V, S, A: Allocator> RawEntryBuilder<'a, K, V, S, A> {\n    /// Access an immutable entry by key.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let map: HashMap<&str, u32> = [(\"a\", 100), (\"b\", 200)].into();\n    /// let key = \"a\";\n    /// assert_eq!(map.raw_entry().from_key(&key), Some((&\"a\", &100)));\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    #[allow(clippy::wrong_self_convention)]\n    pub fn from_key<Q>(self, k: &Q) -> Option<(&'a K, &'a V)>\n    where\n        S: BuildHasher,\n        Q: Hash + Equivalent<K> + ?Sized,\n    {\n        let hash = make_hash::<Q, S>(&self.map.hash_builder, k);\n        self.from_key_hashed_nocheck(hash, k)\n    }\n\n    /// Access an immutable entry by a key and its hash.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use core::hash::{BuildHasher, Hash};\n    /// use hashbrown::HashMap;\n    ///\n    /// fn compute_hash<K: Hash + ?Sized, S: BuildHasher>(hash_builder: &S, key: &K) -> u64 {\n    ///     use core::hash::Hasher;\n    ///     let mut state = hash_builder.build_hasher();\n    ///     key.hash(&mut state);\n    ///     state.finish()\n    /// }\n    ///\n    /// let map: HashMap<&str, u32> = [(\"a\", 100), (\"b\", 200)].into();\n    /// let key = \"a\";\n    /// let hash = compute_hash(map.hasher(), &key);\n    /// assert_eq!(map.raw_entry().from_key_hashed_nocheck(hash, &key), Some((&\"a\", &100)));\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    #[allow(clippy::wrong_self_convention)]\n    pub fn from_key_hashed_nocheck<Q>(self, hash: u64, k: &Q) -> Option<(&'a K, &'a V)>\n    where\n        Q: Equivalent<K> + ?Sized,\n    {\n        self.from_hash(hash, equivalent(k))\n    }\n\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn search<F>(self, hash: u64, mut is_match: F) -> Option<(&'a K, &'a V)>\n    where\n        F: FnMut(&K) -> bool,\n    {\n        match self.map.table.get(hash, |(k, _)| is_match(k)) {\n            Some((key, value)) => Some((key, value)),\n            None => None,\n        }\n    }\n\n    /// Access an immutable entry by hash and matching function.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use core::hash::{BuildHasher, Hash};\n    /// use hashbrown::HashMap;\n    ///\n    /// fn compute_hash<K: Hash + ?Sized, S: BuildHasher>(hash_builder: &S, key: &K) -> u64 {\n    ///     use core::hash::Hasher;\n    ///     let mut state = hash_builder.build_hasher();\n    ///     key.hash(&mut state);\n    ///     state.finish()\n    /// }\n    ///\n    /// let map: HashMap<&str, u32> = [(\"a\", 100), (\"b\", 200)].into();\n    /// let key = \"a\";\n    /// let hash = compute_hash(map.hasher(), &key);\n    /// assert_eq!(map.raw_entry().from_hash(hash, |k| k == &key), Some((&\"a\", &100)));\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    #[allow(clippy::wrong_self_convention)]\n    pub fn from_hash<F>(self, hash: u64, is_match: F) -> Option<(&'a K, &'a V)>\n    where\n        F: FnMut(&K) -> bool,\n    {\n        self.search(hash, is_match)\n    }\n}",
            "impl<K, V, S, A: Allocator> Debug for RawEntryBuilder<'_, K, V, S, A> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_struct(\"RawEntryBuilder\").finish()\n    }\n}"
        ],
        "raw_entry::RawEntryBuilderMut": [
            "impl<'a, K, V, S, A: Allocator> RawEntryBuilderMut<'a, K, V, S, A> {\n    /// Creates a `RawEntryMut` from the given hash and matching function.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use core::hash::{BuildHasher, Hash};\n    /// use hashbrown::hash_map::{HashMap, RawEntryMut};\n    ///\n    /// fn compute_hash<K: Hash + ?Sized, S: BuildHasher>(hash_builder: &S, key: &K) -> u64 {\n    ///     use core::hash::Hasher;\n    ///     let mut state = hash_builder.build_hasher();\n    ///     key.hash(&mut state);\n    ///     state.finish()\n    /// }\n    ///\n    /// let mut map: HashMap<&str, u32> = HashMap::new();\n    /// let key = \"a\";\n    /// let hash = compute_hash(map.hasher(), &key);\n    /// let entry: RawEntryMut<&str, u32, _> = map.raw_entry_mut().from_hash(hash, |k| k == &key);\n    /// entry.insert(key, 100);\n    /// assert_eq!(map[&\"a\"], 100);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    #[allow(clippy::wrong_self_convention)]\n    pub fn from_hash<F>(self, hash: u64, is_match: F) -> RawEntryMut<'a, K, V, S, A>\n    where\n        for<'b> F: FnMut(&'b K) -> bool,\n    {\n        self.search(hash, is_match)\n    }\n\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn search<F>(self, hash: u64, mut is_match: F) -> RawEntryMut<'a, K, V, S, A>\n    where\n        for<'b> F: FnMut(&'b K) -> bool,\n    {\n        match self.map.table.find(hash, |(k, _)| is_match(k)) {\n            Some(elem) => RawEntryMut::Occupied(RawOccupiedEntryMut {\n                elem,\n                table: &mut self.map.table,\n                hash_builder: &self.map.hash_builder,\n            }),\n            None => RawEntryMut::Vacant(RawVacantEntryMut {\n                table: &mut self.map.table,\n                hash_builder: &self.map.hash_builder,\n            }),\n        }\n    }\n}",
            "impl<'a, K, V, S, A: Allocator> RawEntryBuilderMut<'a, K, V, S, A> {\n    /// Creates a `RawEntryMut` from the given key.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::hash_map::{HashMap, RawEntryMut};\n    ///\n    /// let mut map: HashMap<&str, u32> = HashMap::new();\n    /// let key = \"a\";\n    /// let entry: RawEntryMut<&str, u32, _> = map.raw_entry_mut().from_key(&key);\n    /// entry.insert(key, 100);\n    /// assert_eq!(map[&\"a\"], 100);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    #[allow(clippy::wrong_self_convention)]\n    pub fn from_key<Q>(self, k: &Q) -> RawEntryMut<'a, K, V, S, A>\n    where\n        S: BuildHasher,\n        Q: Hash + Equivalent<K> + ?Sized,\n    {\n        let hash = make_hash::<Q, S>(&self.map.hash_builder, k);\n        self.from_key_hashed_nocheck(hash, k)\n    }\n\n    /// Creates a `RawEntryMut` from the given key and its hash.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use core::hash::{BuildHasher, Hash};\n    /// use hashbrown::hash_map::{HashMap, RawEntryMut};\n    ///\n    /// fn compute_hash<K: Hash + ?Sized, S: BuildHasher>(hash_builder: &S, key: &K) -> u64 {\n    ///     use core::hash::Hasher;\n    ///     let mut state = hash_builder.build_hasher();\n    ///     key.hash(&mut state);\n    ///     state.finish()\n    /// }\n    ///\n    /// let mut map: HashMap<&str, u32> = HashMap::new();\n    /// let key = \"a\";\n    /// let hash = compute_hash(map.hasher(), &key);\n    /// let entry: RawEntryMut<&str, u32, _> = map.raw_entry_mut().from_key_hashed_nocheck(hash, &key);\n    /// entry.insert(key, 100);\n    /// assert_eq!(map[&\"a\"], 100);\n    /// ```\n    #[inline]\n    #[allow(clippy::wrong_self_convention)]\n    pub fn from_key_hashed_nocheck<Q>(self, hash: u64, k: &Q) -> RawEntryMut<'a, K, V, S, A>\n    where\n        Q: Equivalent<K> + ?Sized,\n    {\n        self.from_hash(hash, equivalent(k))\n    }\n}",
            "impl<K, V, S, A: Allocator> Debug for RawEntryBuilderMut<'_, K, V, S, A> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_struct(\"RawEntryBuilder\").finish()\n    }\n}"
        ],
        "raw_entry::RawEntryMut": [
            "impl<'a, K, V, S, A: Allocator> RawEntryMut<'a, K, V, S, A> {\n    /// Sets the value of the entry, and returns a `RawOccupiedEntryMut`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut map: HashMap<&str, u32> = HashMap::new();\n    /// let entry = map.raw_entry_mut().from_key(\"horseyland\").insert(\"horseyland\", 37);\n    ///\n    /// assert_eq!(entry.remove_entry(), (\"horseyland\", 37));\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn insert(self, key: K, value: V) -> RawOccupiedEntryMut<'a, K, V, S, A>\n    where\n        K: Hash,\n        S: BuildHasher,\n    {\n        match self {\n            RawEntryMut::Occupied(mut entry) => {\n                entry.insert(value);\n                entry\n            }\n            RawEntryMut::Vacant(entry) => entry.insert_entry(key, value),\n        }\n    }\n\n    /// Ensures a value is in the entry by inserting the default if empty, and returns\n    /// mutable references to the key and value in the entry.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut map: HashMap<&str, u32> = HashMap::new();\n    ///\n    /// map.raw_entry_mut().from_key(\"poneyland\").or_insert(\"poneyland\", 3);\n    /// assert_eq!(map[\"poneyland\"], 3);\n    ///\n    /// *map.raw_entry_mut().from_key(\"poneyland\").or_insert(\"poneyland\", 10).1 *= 2;\n    /// assert_eq!(map[\"poneyland\"], 6);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn or_insert(self, default_key: K, default_val: V) -> (&'a mut K, &'a mut V)\n    where\n        K: Hash,\n        S: BuildHasher,\n    {\n        match self {\n            RawEntryMut::Occupied(entry) => entry.into_key_value(),\n            RawEntryMut::Vacant(entry) => entry.insert(default_key, default_val),\n        }\n    }\n\n    /// Ensures a value is in the entry by inserting the result of the default function if empty,\n    /// and returns mutable references to the key and value in the entry.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut map: HashMap<&str, String> = HashMap::new();\n    ///\n    /// map.raw_entry_mut().from_key(\"poneyland\").or_insert_with(|| {\n    ///     (\"poneyland\", \"hoho\".to_string())\n    /// });\n    ///\n    /// assert_eq!(map[\"poneyland\"], \"hoho\".to_string());\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn or_insert_with<F>(self, default: F) -> (&'a mut K, &'a mut V)\n    where\n        F: FnOnce() -> (K, V),\n        K: Hash,\n        S: BuildHasher,\n    {\n        match self {\n            RawEntryMut::Occupied(entry) => entry.into_key_value(),\n            RawEntryMut::Vacant(entry) => {\n                let (k, v) = default();\n                entry.insert(k, v)\n            }\n        }\n    }\n\n    /// Provides in-place mutable access to an occupied entry before any\n    /// potential inserts into the map.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    ///\n    /// let mut map: HashMap<&str, u32> = HashMap::new();\n    ///\n    /// map.raw_entry_mut()\n    ///    .from_key(\"poneyland\")\n    ///    .and_modify(|_k, v| { *v += 1 })\n    ///    .or_insert(\"poneyland\", 42);\n    /// assert_eq!(map[\"poneyland\"], 42);\n    ///\n    /// map.raw_entry_mut()\n    ///    .from_key(\"poneyland\")\n    ///    .and_modify(|_k, v| { *v += 1 })\n    ///    .or_insert(\"poneyland\", 0);\n    /// assert_eq!(map[\"poneyland\"], 43);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn and_modify<F>(self, f: F) -> Self\n    where\n        F: FnOnce(&mut K, &mut V),\n    {\n        match self {\n            RawEntryMut::Occupied(mut entry) => {\n                {\n                    let (k, v) = entry.get_key_value_mut();\n                    f(k, v);\n                }\n                RawEntryMut::Occupied(entry)\n            }\n            RawEntryMut::Vacant(entry) => RawEntryMut::Vacant(entry),\n        }\n    }\n\n    /// Provides shared access to the key and owned access to the value of\n    /// an occupied entry and allows to replace or remove it based on the\n    /// value of the returned option.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashMap;\n    /// use hashbrown::hash_map::RawEntryMut;\n    ///\n    /// let mut map: HashMap<&str, u32> = HashMap::new();\n    ///\n    /// let entry = map\n    ///     .raw_entry_mut()\n    ///     .from_key(\"poneyland\")\n    ///     .and_replace_entry_with(|_k, _v| panic!());\n    ///\n    /// match entry {\n    ///     RawEntryMut::Vacant(_) => {},\n    ///     RawEntryMut::Occupied(_) => panic!(),\n    /// }\n    ///\n    /// map.insert(\"poneyland\", 42);\n    ///\n    /// let entry = map\n    ///     .raw_entry_mut()\n    ///     .from_key(\"poneyland\")\n    ///     .and_replace_entry_with(|k, v| {\n    ///         assert_eq!(k, &\"poneyland\");\n    ///         assert_eq!(v, 42);\n    ///         Some(v + 1)\n    ///     });\n    ///\n    /// match entry {\n    ///     RawEntryMut::Occupied(e) => {\n    ///         assert_eq!(e.key(), &\"poneyland\");\n    ///         assert_eq!(e.get(), &43);\n    ///     },\n    ///     RawEntryMut::Vacant(_) => panic!(),\n    /// }\n    ///\n    /// assert_eq!(map[\"poneyland\"], 43);\n    ///\n    /// let entry = map\n    ///     .raw_entry_mut()\n    ///     .from_key(\"poneyland\")\n    ///     .and_replace_entry_with(|_k, _v| None);\n    ///\n    /// match entry {\n    ///     RawEntryMut::Vacant(_) => {},\n    ///     RawEntryMut::Occupied(_) => panic!(),\n    /// }\n    ///\n    /// assert!(!map.contains_key(\"poneyland\"));\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn and_replace_entry_with<F>(self, f: F) -> Self\n    where\n        F: FnOnce(&K, V) -> Option<V>,\n    {\n        match self {\n            RawEntryMut::Occupied(entry) => entry.replace_entry_with(f),\n            RawEntryMut::Vacant(_) => self,\n        }\n    }\n}",
            "impl<K: Debug, V: Debug, S, A: Allocator> Debug for RawEntryMut<'_, K, V, S, A> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        match *self {\n            RawEntryMut::Vacant(ref v) => f.debug_tuple(\"RawEntry\").field(v).finish(),\n            RawEntryMut::Occupied(ref o) => f.debug_tuple(\"RawEntry\").field(o).finish(),\n        }\n    }\n}"
        ],
        "raw_entry::RawOccupiedEntryMut": [
            "impl<'a, K, V, S, A: Allocator> RawOccupiedEntryMut<'a, K, V, S, A> {\n    /// Gets a reference to the key in the entry.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::hash_map::{HashMap, RawEntryMut};\n    ///\n    /// let mut map: HashMap<&str, u32> = [(\"a\", 100), (\"b\", 200)].into();\n    ///\n    /// match map.raw_entry_mut().from_key(&\"a\") {\n    ///     RawEntryMut::Vacant(_) => panic!(),\n    ///     RawEntryMut::Occupied(o) => assert_eq!(o.key(), &\"a\")\n    /// }\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn key(&self) -> &K {\n        unsafe { &self.elem.as_ref().0 }\n    }\n\n    /// Gets a mutable reference to the key in the entry.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::hash_map::{HashMap, RawEntryMut};\n    /// use std::rc::Rc;\n    ///\n    /// let key_one = Rc::new(\"a\");\n    /// let key_two = Rc::new(\"a\");\n    ///\n    /// let mut map: HashMap<Rc<&str>, u32> = HashMap::new();\n    /// map.insert(key_one.clone(), 10);\n    ///\n    /// assert_eq!(map[&key_one], 10);\n    /// assert!(Rc::strong_count(&key_one) == 2 && Rc::strong_count(&key_two) == 1);\n    ///\n    /// match map.raw_entry_mut().from_key(&key_one) {\n    ///     RawEntryMut::Vacant(_) => panic!(),\n    ///     RawEntryMut::Occupied(mut o) => {\n    ///         *o.key_mut() = key_two.clone();\n    ///     }\n    /// }\n    /// assert_eq!(map[&key_two], 10);\n    /// assert!(Rc::strong_count(&key_one) == 1 && Rc::strong_count(&key_two) == 2);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn key_mut(&mut self) -> &mut K {\n        unsafe { &mut self.elem.as_mut().0 }\n    }\n\n    /// Converts the entry into a mutable reference to the key in the entry\n    /// with a lifetime bound to the map itself.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::hash_map::{HashMap, RawEntryMut};\n    /// use std::rc::Rc;\n    ///\n    /// let key_one = Rc::new(\"a\");\n    /// let key_two = Rc::new(\"a\");\n    ///\n    /// let mut map: HashMap<Rc<&str>, u32> = HashMap::new();\n    /// map.insert(key_one.clone(), 10);\n    ///\n    /// assert_eq!(map[&key_one], 10);\n    /// assert!(Rc::strong_count(&key_one) == 2 && Rc::strong_count(&key_two) == 1);\n    ///\n    /// let inside_key: &mut Rc<&str>;\n    ///\n    /// match map.raw_entry_mut().from_key(&key_one) {\n    ///     RawEntryMut::Vacant(_) => panic!(),\n    ///     RawEntryMut::Occupied(o) => inside_key = o.into_key(),\n    /// }\n    /// *inside_key = key_two.clone();\n    ///\n    /// assert_eq!(map[&key_two], 10);\n    /// assert!(Rc::strong_count(&key_one) == 1 && Rc::strong_count(&key_two) == 2);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn into_key(self) -> &'a mut K {\n        unsafe { &mut self.elem.as_mut().0 }\n    }\n\n    /// Gets a reference to the value in the entry.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::hash_map::{HashMap, RawEntryMut};\n    ///\n    /// let mut map: HashMap<&str, u32> = [(\"a\", 100), (\"b\", 200)].into();\n    ///\n    /// match map.raw_entry_mut().from_key(&\"a\") {\n    ///     RawEntryMut::Vacant(_) => panic!(),\n    ///     RawEntryMut::Occupied(o) => assert_eq!(o.get(), &100),\n    /// }\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn get(&self) -> &V {\n        unsafe { &self.elem.as_ref().1 }\n    }\n\n    /// Converts the `OccupiedEntry` into a mutable reference to the value in the entry\n    /// with a lifetime bound to the map itself.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::hash_map::{HashMap, RawEntryMut};\n    ///\n    /// let mut map: HashMap<&str, u32> = [(\"a\", 100), (\"b\", 200)].into();\n    ///\n    /// let value: &mut u32;\n    ///\n    /// match map.raw_entry_mut().from_key(&\"a\") {\n    ///     RawEntryMut::Vacant(_) => panic!(),\n    ///     RawEntryMut::Occupied(o) => value = o.into_mut(),\n    /// }\n    /// *value += 900;\n    ///\n    /// assert_eq!(map[&\"a\"], 1000);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn into_mut(self) -> &'a mut V {\n        unsafe { &mut self.elem.as_mut().1 }\n    }\n\n    /// Gets a mutable reference to the value in the entry.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::hash_map::{HashMap, RawEntryMut};\n    ///\n    /// let mut map: HashMap<&str, u32> = [(\"a\", 100), (\"b\", 200)].into();\n    ///\n    /// match map.raw_entry_mut().from_key(&\"a\") {\n    ///     RawEntryMut::Vacant(_) => panic!(),\n    ///     RawEntryMut::Occupied(mut o) => *o.get_mut() += 900,\n    /// }\n    ///\n    /// assert_eq!(map[&\"a\"], 1000);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn get_mut(&mut self) -> &mut V {\n        unsafe { &mut self.elem.as_mut().1 }\n    }\n\n    /// Gets a reference to the key and value in the entry.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::hash_map::{HashMap, RawEntryMut};\n    ///\n    /// let mut map: HashMap<&str, u32> = [(\"a\", 100), (\"b\", 200)].into();\n    ///\n    /// match map.raw_entry_mut().from_key(&\"a\") {\n    ///     RawEntryMut::Vacant(_) => panic!(),\n    ///     RawEntryMut::Occupied(o) => assert_eq!(o.get_key_value(), (&\"a\", &100)),\n    /// }\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn get_key_value(&self) -> (&K, &V) {\n        unsafe {\n            let (key, value) = self.elem.as_ref();\n            (key, value)\n        }\n    }\n\n    /// Gets a mutable reference to the key and value in the entry.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::hash_map::{HashMap, RawEntryMut};\n    /// use std::rc::Rc;\n    ///\n    /// let key_one = Rc::new(\"a\");\n    /// let key_two = Rc::new(\"a\");\n    ///\n    /// let mut map: HashMap<Rc<&str>, u32> = HashMap::new();\n    /// map.insert(key_one.clone(), 10);\n    ///\n    /// assert_eq!(map[&key_one], 10);\n    /// assert!(Rc::strong_count(&key_one) == 2 && Rc::strong_count(&key_two) == 1);\n    ///\n    /// match map.raw_entry_mut().from_key(&key_one) {\n    ///     RawEntryMut::Vacant(_) => panic!(),\n    ///     RawEntryMut::Occupied(mut o) => {\n    ///         let (inside_key, inside_value) = o.get_key_value_mut();\n    ///         *inside_key = key_two.clone();\n    ///         *inside_value = 100;\n    ///     }\n    /// }\n    /// assert_eq!(map[&key_two], 100);\n    /// assert!(Rc::strong_count(&key_one) == 1 && Rc::strong_count(&key_two) == 2);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn get_key_value_mut(&mut self) -> (&mut K, &mut V) {\n        unsafe {\n            let &mut (ref mut key, ref mut value) = self.elem.as_mut();\n            (key, value)\n        }\n    }\n\n    /// Converts the `OccupiedEntry` into a mutable reference to the key and value in the entry\n    /// with a lifetime bound to the map itself.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::hash_map::{HashMap, RawEntryMut};\n    /// use std::rc::Rc;\n    ///\n    /// let key_one = Rc::new(\"a\");\n    /// let key_two = Rc::new(\"a\");\n    ///\n    /// let mut map: HashMap<Rc<&str>, u32> = HashMap::new();\n    /// map.insert(key_one.clone(), 10);\n    ///\n    /// assert_eq!(map[&key_one], 10);\n    /// assert!(Rc::strong_count(&key_one) == 2 && Rc::strong_count(&key_two) == 1);\n    ///\n    /// let inside_key: &mut Rc<&str>;\n    /// let inside_value: &mut u32;\n    /// match map.raw_entry_mut().from_key(&key_one) {\n    ///     RawEntryMut::Vacant(_) => panic!(),\n    ///     RawEntryMut::Occupied(o) => {\n    ///         let tuple = o.into_key_value();\n    ///         inside_key = tuple.0;\n    ///         inside_value = tuple.1;\n    ///     }\n    /// }\n    /// *inside_key = key_two.clone();\n    /// *inside_value = 100;\n    /// assert_eq!(map[&key_two], 100);\n    /// assert!(Rc::strong_count(&key_one) == 1 && Rc::strong_count(&key_two) == 2);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn into_key_value(self) -> (&'a mut K, &'a mut V) {\n        unsafe {\n            let &mut (ref mut key, ref mut value) = self.elem.as_mut();\n            (key, value)\n        }\n    }\n\n    /// Sets the value of the entry, and returns the entry's old value.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::hash_map::{HashMap, RawEntryMut};\n    ///\n    /// let mut map: HashMap<&str, u32> = [(\"a\", 100), (\"b\", 200)].into();\n    ///\n    /// match map.raw_entry_mut().from_key(&\"a\") {\n    ///     RawEntryMut::Vacant(_) => panic!(),\n    ///     RawEntryMut::Occupied(mut o) => assert_eq!(o.insert(1000), 100),\n    /// }\n    ///\n    /// assert_eq!(map[&\"a\"], 1000);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn insert(&mut self, value: V) -> V {\n        mem::replace(self.get_mut(), value)\n    }\n\n    /// Sets the value of the entry, and returns the entry's old value.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::hash_map::{HashMap, RawEntryMut};\n    /// use std::rc::Rc;\n    ///\n    /// let key_one = Rc::new(\"a\");\n    /// let key_two = Rc::new(\"a\");\n    ///\n    /// let mut map: HashMap<Rc<&str>, u32> = HashMap::new();\n    /// map.insert(key_one.clone(), 10);\n    ///\n    /// assert_eq!(map[&key_one], 10);\n    /// assert!(Rc::strong_count(&key_one) == 2 && Rc::strong_count(&key_two) == 1);\n    ///\n    /// match map.raw_entry_mut().from_key(&key_one) {\n    ///     RawEntryMut::Vacant(_) => panic!(),\n    ///     RawEntryMut::Occupied(mut o) => {\n    ///         let old_key = o.insert_key(key_two.clone());\n    ///         assert!(Rc::ptr_eq(&old_key, &key_one));\n    ///     }\n    /// }\n    /// assert_eq!(map[&key_two], 10);\n    /// assert!(Rc::strong_count(&key_one) == 1 && Rc::strong_count(&key_two) == 2);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn insert_key(&mut self, key: K) -> K {\n        mem::replace(self.key_mut(), key)\n    }\n\n    /// Takes the value out of the entry, and returns it.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::hash_map::{HashMap, RawEntryMut};\n    ///\n    /// let mut map: HashMap<&str, u32> = [(\"a\", 100), (\"b\", 200)].into();\n    ///\n    /// match map.raw_entry_mut().from_key(&\"a\") {\n    ///     RawEntryMut::Vacant(_) => panic!(),\n    ///     RawEntryMut::Occupied(o) => assert_eq!(o.remove(), 100),\n    /// }\n    /// assert_eq!(map.get(&\"a\"), None);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn remove(self) -> V {\n        self.remove_entry().1\n    }\n\n    /// Take the ownership of the key and value from the map.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::hash_map::{HashMap, RawEntryMut};\n    ///\n    /// let mut map: HashMap<&str, u32> = [(\"a\", 100), (\"b\", 200)].into();\n    ///\n    /// match map.raw_entry_mut().from_key(&\"a\") {\n    ///     RawEntryMut::Vacant(_) => panic!(),\n    ///     RawEntryMut::Occupied(o) => assert_eq!(o.remove_entry(), (\"a\", 100)),\n    /// }\n    /// assert_eq!(map.get(&\"a\"), None);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn remove_entry(self) -> (K, V) {\n        unsafe { self.table.remove(self.elem).0 }\n    }\n\n    /// Provides shared access to the key and owned access to the value of\n    /// the entry and allows to replace or remove it based on the\n    /// value of the returned option.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::hash_map::{HashMap, RawEntryMut};\n    ///\n    /// let mut map: HashMap<&str, u32> = [(\"a\", 100), (\"b\", 200)].into();\n    ///\n    /// let raw_entry = match map.raw_entry_mut().from_key(&\"a\") {\n    ///     RawEntryMut::Vacant(_) => panic!(),\n    ///     RawEntryMut::Occupied(o) => o.replace_entry_with(|k, v| {\n    ///         assert_eq!(k, &\"a\");\n    ///         assert_eq!(v, 100);\n    ///         Some(v + 900)\n    ///     }),\n    /// };\n    /// let raw_entry = match raw_entry {\n    ///     RawEntryMut::Vacant(_) => panic!(),\n    ///     RawEntryMut::Occupied(o) => o.replace_entry_with(|k, v| {\n    ///         assert_eq!(k, &\"a\");\n    ///         assert_eq!(v, 1000);\n    ///         None\n    ///     }),\n    /// };\n    /// match raw_entry {\n    ///     RawEntryMut::Vacant(_) => { },\n    ///     RawEntryMut::Occupied(_) => panic!(),\n    /// };\n    /// assert_eq!(map.get(&\"a\"), None);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn replace_entry_with<F>(self, f: F) -> RawEntryMut<'a, K, V, S, A>\n    where\n        F: FnOnce(&K, V) -> Option<V>,\n    {\n        unsafe {\n            let still_occupied = self\n                .table\n                .replace_bucket_with(self.elem.clone(), |(key, value)| {\n                    f(&key, value).map(|new_value| (key, new_value))\n                });\n\n            if still_occupied {\n                RawEntryMut::Occupied(self)\n            } else {\n                RawEntryMut::Vacant(RawVacantEntryMut {\n                    table: self.table,\n                    hash_builder: self.hash_builder,\n                })\n            }\n        }\n    }\n}",
            "impl<K: Debug, V: Debug, S, A: Allocator> Debug for RawOccupiedEntryMut<'_, K, V, S, A> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_struct(\"RawOccupiedEntryMut\")\n            .field(\"key\", self.key())\n            .field(\"value\", self.get())\n            .finish()\n    }\n}",
            "unsafe impl<K, V, S, A> Send for RawOccupiedEntryMut<'_, K, V, S, A>\nwhere\n    K: Send,\n    V: Send,\n    S: Send,\n    A: Send + Allocator,\n{\n}",
            "unsafe impl<K, V, S, A> Sync for RawOccupiedEntryMut<'_, K, V, S, A>\nwhere\n    K: Sync,\n    V: Sync,\n    S: Sync,\n    A: Sync + Allocator,\n{\n}"
        ],
        "raw_entry::RawVacantEntryMut": [
            "impl<'a, K, V, S, A: Allocator> RawVacantEntryMut<'a, K, V, S, A> {\n    /// Sets the value of the entry with the `VacantEntry`'s key,\n    /// and returns a mutable reference to it.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::hash_map::{HashMap, RawEntryMut};\n    ///\n    /// let mut map: HashMap<&str, u32> = [(\"a\", 100), (\"b\", 200)].into();\n    ///\n    /// match map.raw_entry_mut().from_key(&\"c\") {\n    ///     RawEntryMut::Occupied(_) => panic!(),\n    ///     RawEntryMut::Vacant(v) => assert_eq!(v.insert(\"c\", 300), (&mut \"c\", &mut 300)),\n    /// }\n    ///\n    /// assert_eq!(map[&\"c\"], 300);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn insert(self, key: K, value: V) -> (&'a mut K, &'a mut V)\n    where\n        K: Hash,\n        S: BuildHasher,\n    {\n        let hash = make_hash::<K, S>(self.hash_builder, &key);\n        self.insert_hashed_nocheck(hash, key, value)\n    }\n\n    /// Sets the value of the entry with the `VacantEntry`'s key,\n    /// and returns a mutable reference to it.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use core::hash::{BuildHasher, Hash};\n    /// use hashbrown::hash_map::{HashMap, RawEntryMut};\n    ///\n    /// fn compute_hash<K: Hash + ?Sized, S: BuildHasher>(hash_builder: &S, key: &K) -> u64 {\n    ///     use core::hash::Hasher;\n    ///     let mut state = hash_builder.build_hasher();\n    ///     key.hash(&mut state);\n    ///     state.finish()\n    /// }\n    ///\n    /// let mut map: HashMap<&str, u32> = [(\"a\", 100), (\"b\", 200)].into();\n    /// let key = \"c\";\n    /// let hash = compute_hash(map.hasher(), &key);\n    ///\n    /// match map.raw_entry_mut().from_key_hashed_nocheck(hash, &key) {\n    ///     RawEntryMut::Occupied(_) => panic!(),\n    ///     RawEntryMut::Vacant(v) => assert_eq!(\n    ///         v.insert_hashed_nocheck(hash, key, 300),\n    ///         (&mut \"c\", &mut 300)\n    ///     ),\n    /// }\n    ///\n    /// assert_eq!(map[&\"c\"], 300);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    #[allow(clippy::shadow_unrelated)]\n    pub fn insert_hashed_nocheck(self, hash: u64, key: K, value: V) -> (&'a mut K, &'a mut V)\n    where\n        K: Hash,\n        S: BuildHasher,\n    {\n        let &mut (ref mut k, ref mut v) = self.table.insert_entry(\n            hash,\n            (key, value),\n            make_hasher::<_, V, S>(self.hash_builder),\n        );\n        (k, v)\n    }\n\n    /// Set the value of an entry with a custom hasher function.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use core::hash::{BuildHasher, Hash};\n    /// use hashbrown::hash_map::{HashMap, RawEntryMut};\n    ///\n    /// fn make_hasher<K, S>(hash_builder: &S) -> impl Fn(&K) -> u64 + '_\n    /// where\n    ///     K: Hash + ?Sized,\n    ///     S: BuildHasher,\n    /// {\n    ///     move |key: &K| {\n    ///         use core::hash::Hasher;\n    ///         let mut state = hash_builder.build_hasher();\n    ///         key.hash(&mut state);\n    ///         state.finish()\n    ///     }\n    /// }\n    ///\n    /// let mut map: HashMap<&str, u32> = HashMap::new();\n    /// let key = \"a\";\n    /// let hash_builder = map.hasher().clone();\n    /// let hash = make_hasher(&hash_builder)(&key);\n    ///\n    /// match map.raw_entry_mut().from_hash(hash, |q| q == &key) {\n    ///     RawEntryMut::Occupied(_) => panic!(),\n    ///     RawEntryMut::Vacant(v) => assert_eq!(\n    ///         v.insert_with_hasher(hash, key, 100, make_hasher(&hash_builder)),\n    ///         (&mut \"a\", &mut 100)\n    ///     ),\n    /// }\n    /// map.extend([(\"b\", 200), (\"c\", 300), (\"d\", 400), (\"e\", 500), (\"f\", 600)]);\n    /// assert_eq!(map[&\"a\"], 100);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn insert_with_hasher<H>(\n        self,\n        hash: u64,\n        key: K,\n        value: V,\n        hasher: H,\n    ) -> (&'a mut K, &'a mut V)\n    where\n        H: Fn(&K) -> u64,\n    {\n        let &mut (ref mut k, ref mut v) = self\n            .table\n            .insert_entry(hash, (key, value), |x| hasher(&x.0));\n        (k, v)\n    }\n\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn insert_entry(self, key: K, value: V) -> RawOccupiedEntryMut<'a, K, V, S, A>\n    where\n        K: Hash,\n        S: BuildHasher,\n    {\n        let hash = make_hash::<K, S>(self.hash_builder, &key);\n        let elem = self.table.insert(\n            hash,\n            (key, value),\n            make_hasher::<_, V, S>(self.hash_builder),\n        );\n        RawOccupiedEntryMut {\n            elem,\n            table: self.table,\n            hash_builder: self.hash_builder,\n        }\n    }\n}",
            "impl<K, V, S, A: Allocator> Debug for RawVacantEntryMut<'_, K, V, S, A> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_struct(\"RawVacantEntryMut\").finish()\n    }\n}"
        ],
        "scopeguard::ScopeGuard": [
            "impl<T, F> Deref for ScopeGuard<T, F>\nwhere\n    F: FnMut(&mut T),\n{\n    type Target = T;\n    #[inline]\n    fn deref(&self) -> &T {\n        &self.value\n    }\n}",
            "impl<T, F> DerefMut for ScopeGuard<T, F>\nwhere\n    F: FnMut(&mut T),\n{\n    #[inline]\n    fn deref_mut(&mut self) -> &mut T {\n        &mut self.value\n    }\n}",
            "impl<T, F> Drop for ScopeGuard<T, F>\nwhere\n    F: FnMut(&mut T),\n{\n    #[inline]\n    fn drop(&mut self) {\n        (self.dropfn)(&mut self.value);\n    }\n}",
            "impl<T, F> ScopeGuard<T, F>\nwhere\n    F: FnMut(&mut T),\n{\n    #[inline]\n    pub fn into_inner(guard: Self) -> T {\n        // Cannot move out of Drop-implementing types, so\n        // ptr::read the value out of a ManuallyDrop<Self>\n        // Don't use mem::forget as that might invalidate value\n        let guard = ManuallyDrop::new(guard);\n        unsafe {\n            let value = ptr::read(&guard.value);\n            // read the closure so that it is dropped\n            let _ = ptr::read(&guard.dropfn);\n            value\n        }\n    }\n}"
        ],
        "set::Difference": [
            "impl<'a, T, S, A> Iterator for Difference<'a, T, S, A>\nwhere\n    T: Eq + Hash,\n    S: BuildHasher,\n    A: Allocator,\n{\n    type Item = &'a T;\n\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn next(&mut self) -> Option<&'a T> {\n        loop {\n            let elt = self.iter.next()?;\n            if !self.other.contains(elt) {\n                return Some(elt);\n            }\n        }\n    }\n\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        let (lower, upper) = self.iter.size_hint();\n        (lower.saturating_sub(self.other.len()), upper)\n    }\n\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn fold<B, F>(self, init: B, mut f: F) -> B\n    where\n        Self: Sized,\n        F: FnMut(B, Self::Item) -> B,\n    {\n        self.iter.fold(init, |acc, elt| {\n            if self.other.contains(elt) {\n                acc\n            } else {\n                f(acc, elt)\n            }\n        })\n    }\n}",
            "impl<T, S, A: Allocator> Clone for Difference<'_, T, S, A> {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn clone(&self) -> Self {\n        Difference {\n            iter: self.iter.clone(),\n            ..*self\n        }\n    }\n}",
            "impl<T, S, A> FusedIterator for Difference<'_, T, S, A>\nwhere\n    T: Eq + Hash,\n    S: BuildHasher,\n    A: Allocator,\n{\n}",
            "impl<T, S, A> fmt::Debug for Difference<'_, T, S, A>\nwhere\n    T: fmt::Debug + Eq + Hash,\n    S: BuildHasher,\n    A: Allocator,\n{\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_list().entries(self.clone()).finish()\n    }\n}"
        ],
        "set::Drain": [
            "impl<K, A: Allocator> ExactSizeIterator for Drain<'_, K, A> {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn len(&self) -> usize {\n        self.iter.len()\n    }\n}",
            "impl<K, A: Allocator> FusedIterator for Drain<'_, K, A> {}",
            "impl<K, A: Allocator> Iterator for Drain<'_, K, A> {\n    type Item = K;\n\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn next(&mut self) -> Option<K> {\n        // Avoid `Option::map` because it bloats LLVM IR.\n        match self.iter.next() {\n            Some((k, _)) => Some(k),\n            None => None,\n        }\n    }\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.iter.size_hint()\n    }\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn fold<B, F>(self, init: B, mut f: F) -> B\n    where\n        Self: Sized,\n        F: FnMut(B, Self::Item) -> B,\n    {\n        self.iter.fold(init, |acc, (k, ())| f(acc, k))\n    }\n}",
            "impl<K: fmt::Debug, A: Allocator> fmt::Debug for Drain<'_, K, A> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        let entries_iter = self.iter.iter().map(|(k, _)| k);\n        f.debug_list().entries(entries_iter).finish()\n    }\n}"
        ],
        "set::Entry": [
            "impl<'a, T, S, A: Allocator> Entry<'a, T, S, A> {\n    /// Sets the value of the entry, and returns an `OccupiedEntry`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    ///\n    /// let mut set: HashSet<&str> = HashSet::new();\n    /// let entry = set.entry(\"horseyland\").insert();\n    ///\n    /// assert_eq!(entry.get(), &\"horseyland\");\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn insert(self) -> OccupiedEntry<'a, T, S, A>\n    where\n        T: Hash,\n        S: BuildHasher,\n    {\n        match self {\n            Entry::Occupied(entry) => entry,\n            Entry::Vacant(entry) => entry.insert(),\n        }\n    }\n\n    /// Ensures a value is in the entry by inserting if it was vacant.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    ///\n    /// let mut set: HashSet<&str> = HashSet::new();\n    ///\n    /// // nonexistent key\n    /// set.entry(\"poneyland\").or_insert();\n    /// assert!(set.contains(\"poneyland\"));\n    ///\n    /// // existing key\n    /// set.entry(\"poneyland\").or_insert();\n    /// assert!(set.contains(\"poneyland\"));\n    /// assert_eq!(set.len(), 1);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn or_insert(self)\n    where\n        T: Hash,\n        S: BuildHasher,\n    {\n        if let Entry::Vacant(entry) = self {\n            entry.insert();\n        }\n    }\n\n    /// Returns a reference to this entry's value.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    ///\n    /// let mut set: HashSet<&str> = HashSet::new();\n    /// set.entry(\"poneyland\").or_insert();\n    /// // existing key\n    /// assert_eq!(set.entry(\"poneyland\").get(), &\"poneyland\");\n    /// // nonexistent key\n    /// assert_eq!(set.entry(\"horseland\").get(), &\"horseland\");\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn get(&self) -> &T {\n        match *self {\n            Entry::Occupied(ref entry) => entry.get(),\n            Entry::Vacant(ref entry) => entry.get(),\n        }\n    }\n}",
            "impl<T: fmt::Debug, S, A: Allocator> fmt::Debug for Entry<'_, T, S, A> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        match *self {\n            Entry::Vacant(ref v) => f.debug_tuple(\"Entry\").field(v).finish(),\n            Entry::Occupied(ref o) => f.debug_tuple(\"Entry\").field(o).finish(),\n        }\n    }\n}"
        ],
        "set::ExtractIf": [
            "impl<K, F, A: Allocator> FusedIterator for ExtractIf<'_, K, F, A> where F: FnMut(&K) -> bool {}",
            "impl<K, F, A: Allocator> Iterator for ExtractIf<'_, K, F, A>\nwhere\n    F: FnMut(&K) -> bool,\n{\n    type Item = K;\n\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn next(&mut self) -> Option<Self::Item> {\n        self.inner\n            .next(|&mut (ref k, ())| (self.f)(k))\n            .map(|(k, ())| k)\n    }\n\n    #[inline]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        (0, self.inner.iter.size_hint().1)\n    }\n}"
        ],
        "set::HashSet": [
            "impl<'a, T, S, A> Extend<&'a T> for HashSet<T, S, A>\nwhere\n    T: 'a + Eq + Hash + Copy,\n    S: BuildHasher,\n    A: Allocator,\n{\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn extend<I: IntoIterator<Item = &'a T>>(&mut self, iter: I) {\n        self.extend(iter.into_iter().copied());\n    }\n\n    #[inline]\n    #[cfg(feature = \"nightly\")]\n    fn extend_one(&mut self, k: &'a T) {\n        self.map.insert(*k, ());\n    }\n\n    #[inline]\n    #[cfg(feature = \"nightly\")]\n    fn extend_reserve(&mut self, additional: usize) {\n        Extend::<(T, ())>::extend_reserve(&mut self.map, additional);\n    }\n}",
            "impl<T, A, const N: usize> From<[T; N]> for HashSet<T, DefaultHashBuilder, A>\nwhere\n    T: Eq + Hash,\n    A: Default + Allocator,\n{\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    ///\n    /// let set1 = HashSet::from([1, 2, 3, 4]);\n    /// let set2: HashSet<_> = [1, 2, 3, 4].into();\n    /// assert_eq!(set1, set2);\n    /// ```\n    fn from(arr: [T; N]) -> Self {\n        arr.into_iter().collect()\n    }\n}",
            "impl<T, S, A: Allocator> HashSet<T, S, A> {\n    /// Returns the number of elements the set can hold without reallocating.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    /// let set: HashSet<i32> = HashSet::with_capacity(100);\n    /// assert!(set.capacity() >= 100);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn capacity(&self) -> usize {\n        self.map.capacity()\n    }\n\n    /// An iterator visiting all elements in arbitrary order.\n    /// The iterator element type is `&'a T`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    /// let mut set = HashSet::new();\n    /// set.insert(\"a\");\n    /// set.insert(\"b\");\n    ///\n    /// // Will print in an arbitrary order.\n    /// for x in set.iter() {\n    ///     println!(\"{}\", x);\n    /// }\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn iter(&self) -> Iter<'_, T> {\n        Iter {\n            iter: self.map.keys(),\n        }\n    }\n\n    /// Returns the number of elements in the set.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    ///\n    /// let mut v = HashSet::new();\n    /// assert_eq!(v.len(), 0);\n    /// v.insert(1);\n    /// assert_eq!(v.len(), 1);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn len(&self) -> usize {\n        self.map.len()\n    }\n\n    /// Returns `true` if the set contains no elements.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    ///\n    /// let mut v = HashSet::new();\n    /// assert!(v.is_empty());\n    /// v.insert(1);\n    /// assert!(!v.is_empty());\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn is_empty(&self) -> bool {\n        self.map.is_empty()\n    }\n\n    /// Clears the set, returning all elements in an iterator.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    ///\n    /// let mut set: HashSet<_> = [1, 2, 3].into_iter().collect();\n    /// assert!(!set.is_empty());\n    ///\n    /// // print 1, 2, 3 in an arbitrary order\n    /// for i in set.drain() {\n    ///     println!(\"{}\", i);\n    /// }\n    ///\n    /// assert!(set.is_empty());\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn drain(&mut self) -> Drain<'_, T, A> {\n        Drain {\n            iter: self.map.drain(),\n        }\n    }\n\n    /// Retains only the elements specified by the predicate.\n    ///\n    /// In other words, remove all elements `e` such that `f(&e)` returns `false`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    ///\n    /// let xs = [1,2,3,4,5,6];\n    /// let mut set: HashSet<i32> = xs.into_iter().collect();\n    /// set.retain(|&k| k % 2 == 0);\n    /// assert_eq!(set.len(), 3);\n    /// ```\n    pub fn retain<F>(&mut self, mut f: F)\n    where\n        F: FnMut(&T) -> bool,\n    {\n        self.map.retain(|k, _| f(k));\n    }\n\n    /// Drains elements which are true under the given predicate,\n    /// and returns an iterator over the removed items.\n    ///\n    /// In other words, move all elements `e` such that `f(&e)` returns `true` out\n    /// into another iterator.\n    ///\n    /// If the returned `ExtractIf` is not exhausted, e.g. because it is dropped without iterating\n    /// or the iteration short-circuits, then the remaining elements will be retained.\n    /// Use [`retain()`] with a negated predicate if you do not need the returned iterator.\n    ///\n    /// [`retain()`]: HashSet::retain\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    ///\n    /// let mut set: HashSet<i32> = (0..8).collect();\n    /// let drained: HashSet<i32> = set.extract_if(|v| v % 2 == 0).collect();\n    ///\n    /// let mut evens = drained.into_iter().collect::<Vec<_>>();\n    /// let mut odds = set.into_iter().collect::<Vec<_>>();\n    /// evens.sort();\n    /// odds.sort();\n    ///\n    /// assert_eq!(evens, vec![0, 2, 4, 6]);\n    /// assert_eq!(odds, vec![1, 3, 5, 7]);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn extract_if<F>(&mut self, f: F) -> ExtractIf<'_, T, F, A>\n    where\n        F: FnMut(&T) -> bool,\n    {\n        ExtractIf {\n            f,\n            inner: RawExtractIf {\n                iter: unsafe { self.map.table.iter() },\n                table: &mut self.map.table,\n            },\n        }\n    }\n\n    /// Clears the set, removing all values.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    ///\n    /// let mut v = HashSet::new();\n    /// v.insert(1);\n    /// v.clear();\n    /// assert!(v.is_empty());\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn clear(&mut self) {\n        self.map.clear();\n    }\n}",
            "impl<T, S, A: Allocator> IntoIterator for HashSet<T, S, A> {\n    type Item = T;\n    type IntoIter = IntoIter<T, A>;\n\n    /// Creates a consuming iterator, that is, one that moves each value out\n    /// of the set in arbitrary order. The set cannot be used after calling\n    /// this.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    /// let mut set = HashSet::new();\n    /// set.insert(\"a\".to_string());\n    /// set.insert(\"b\".to_string());\n    ///\n    /// // Not possible to collect to a Vec<String> with a regular `.iter()`.\n    /// let v: Vec<String> = set.into_iter().collect();\n    ///\n    /// // Will print in an arbitrary order.\n    /// for x in &v {\n    ///     println!(\"{}\", x);\n    /// }\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn into_iter(self) -> IntoIter<T, A> {\n        IntoIter {\n            iter: self.map.into_iter(),\n        }\n    }\n}",
            "impl<T, S, A> BitAndAssign<&HashSet<T, S, A>> for HashSet<T, S, A>\nwhere\n    T: Eq + Hash + Clone,\n    S: BuildHasher,\n    A: Allocator,\n{\n    /// Modifies this set to contain the intersection of `self` and `rhs`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    ///\n    /// let mut a: HashSet<_> = vec![1, 2, 3].into_iter().collect();\n    /// let b: HashSet<_> = vec![2, 3, 4].into_iter().collect();\n    ///\n    /// a &= &b;\n    ///\n    /// let mut i = 0;\n    /// let expected = [2, 3];\n    /// for x in &a {\n    ///     assert!(expected.contains(x));\n    ///     i += 1;\n    /// }\n    /// assert_eq!(i, expected.len());\n    /// ```\n    fn bitand_assign(&mut self, rhs: &HashSet<T, S, A>) {\n        self.retain(|item| rhs.contains(item));\n    }\n}",
            "impl<T, S, A> BitOrAssign<&HashSet<T, S, A>> for HashSet<T, S, A>\nwhere\n    T: Eq + Hash + Clone,\n    S: BuildHasher,\n    A: Allocator,\n{\n    /// Modifies this set to contain the union of `self` and `rhs`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    ///\n    /// let mut a: HashSet<_> = vec![1, 2, 3].into_iter().collect();\n    /// let b: HashSet<_> = vec![3, 4, 5].into_iter().collect();\n    ///\n    /// a |= &b;\n    ///\n    /// let mut i = 0;\n    /// let expected = [1, 2, 3, 4, 5];\n    /// for x in &a {\n    ///     assert!(expected.contains(x));\n    ///     i += 1;\n    /// }\n    /// assert_eq!(i, expected.len());\n    /// ```\n    fn bitor_assign(&mut self, rhs: &HashSet<T, S, A>) {\n        for item in rhs {\n            if !self.contains(item) {\n                self.insert(item.clone());\n            }\n        }\n    }\n}",
            "impl<T, S, A> BitXorAssign<&HashSet<T, S, A>> for HashSet<T, S, A>\nwhere\n    T: Eq + Hash + Clone,\n    S: BuildHasher,\n    A: Allocator,\n{\n    /// Modifies this set to contain the symmetric difference of `self` and `rhs`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    ///\n    /// let mut a: HashSet<_> = vec![1, 2, 3].into_iter().collect();\n    /// let b: HashSet<_> = vec![3, 4, 5].into_iter().collect();\n    ///\n    /// a ^= &b;\n    ///\n    /// let mut i = 0;\n    /// let expected = [1, 2, 4, 5];\n    /// for x in &a {\n    ///     assert!(expected.contains(x));\n    ///     i += 1;\n    /// }\n    /// assert_eq!(i, expected.len());\n    /// ```\n    fn bitxor_assign(&mut self, rhs: &HashSet<T, S, A>) {\n        for item in rhs {\n            let hash = make_hash(&self.map.hash_builder, item);\n            match self.map.find_or_find_insert_slot(hash, item) {\n                Ok(bucket) => unsafe {\n                    self.map.table.remove(bucket);\n                },\n                Err(slot) => unsafe {\n                    self.map\n                        .table\n                        .insert_in_slot(hash, slot, (item.clone(), ()));\n                },\n            }\n        }\n    }\n}",
            "impl<T, S, A> Default for HashSet<T, S, A>\nwhere\n    S: Default,\n    A: Default + Allocator,\n{\n    /// Creates an empty `HashSet<T, S>` with the `Default` value for the hasher.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn default() -> Self {\n        Self {\n            map: HashMap::default(),\n        }\n    }\n}",
            "impl<T, S, A> Eq for HashSet<T, S, A>\nwhere\n    T: Eq + Hash,\n    S: BuildHasher,\n    A: Allocator,\n{\n}",
            "impl<T, S, A> Extend<T> for HashSet<T, S, A>\nwhere\n    T: Eq + Hash,\n    S: BuildHasher,\n    A: Allocator,\n{\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn extend<I: IntoIterator<Item = T>>(&mut self, iter: I) {\n        self.map.extend(iter.into_iter().map(|k| (k, ())));\n    }\n\n    #[inline]\n    #[cfg(feature = \"nightly\")]\n    fn extend_one(&mut self, k: T) {\n        self.map.insert(k, ());\n    }\n\n    #[inline]\n    #[cfg(feature = \"nightly\")]\n    fn extend_reserve(&mut self, additional: usize) {\n        Extend::<(T, ())>::extend_reserve(&mut self.map, additional);\n    }\n}",
            "impl<T, S, A> From<HashMap<T, (), S, A>> for HashSet<T, S, A>\nwhere\n    A: Allocator,\n{\n    fn from(map: HashMap<T, (), S, A>) -> Self {\n        Self { map }\n    }\n}",
            "impl<T, S, A> FromIterator<T> for HashSet<T, S, A>\nwhere\n    T: Eq + Hash,\n    S: BuildHasher + Default,\n    A: Default + Allocator,\n{\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn from_iter<I: IntoIterator<Item = T>>(iter: I) -> Self {\n        let mut set = Self::with_hasher_in(Default::default(), Default::default());\n        set.extend(iter);\n        set\n    }\n}",
            "impl<T, S, A> HashSet<T, S, A>\nwhere\n    A: Allocator,\n{\n    /// Returns a reference to the underlying allocator.\n    #[inline]\n    pub fn allocator(&self) -> &A {\n        self.map.allocator()\n    }\n\n    /// Creates a new empty hash set which will use the given hasher to hash\n    /// keys.\n    ///\n    /// The hash set is initially created with a capacity of 0, so it will not\n    /// allocate until it is first inserted into.\n    ///\n    /// # HashDoS resistance\n    ///\n    /// The `hash_builder` normally use a fixed key by default and that does\n    /// not allow the `HashSet` to be protected against attacks such as [`HashDoS`].\n    /// Users who require HashDoS resistance should explicitly use\n    /// [`std::collections::hash_map::RandomState`]\n    /// as the hasher when creating a [`HashSet`].\n    ///\n    /// The `hash_builder` passed should implement the [`BuildHasher`] trait for\n    /// the `HashSet` to be useful, see its documentation for details.\n    ///\n    /// [`HashDoS`]: https://en.wikipedia.org/wiki/Collision_attack\n    /// [`std::collections::hash_map::RandomState`]: https://doc.rust-lang.org/std/collections/hash_map/struct.RandomState.html\n    /// [`BuildHasher`]: https://doc.rust-lang.org/std/hash/trait.BuildHasher.html\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    /// use hashbrown::DefaultHashBuilder;\n    ///\n    /// let s = DefaultHashBuilder::default();\n    /// let mut set = HashSet::with_hasher(s);\n    /// set.insert(2);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    #[cfg_attr(feature = \"rustc-dep-of-std\", rustc_const_stable_indirect)]\n    pub const fn with_hasher_in(hasher: S, alloc: A) -> Self {\n        Self {\n            map: HashMap::with_hasher_in(hasher, alloc),\n        }\n    }\n\n    /// Creates an empty `HashSet` with the specified capacity, using\n    /// `hasher` to hash the keys.\n    ///\n    /// The hash set will be able to hold at least `capacity` elements without\n    /// reallocating. If `capacity` is 0, the hash set will not allocate.\n    ///\n    /// # HashDoS resistance\n    ///\n    /// The `hash_builder` normally use a fixed key by default and that does\n    /// not allow the `HashSet` to be protected against attacks such as [`HashDoS`].\n    /// Users who require HashDoS resistance should explicitly use\n    /// [`std::collections::hash_map::RandomState`]\n    /// as the hasher when creating a [`HashSet`].\n    ///\n    /// The `hash_builder` passed should implement the [`BuildHasher`] trait for\n    /// the `HashSet` to be useful, see its documentation for details.\n    ///\n    /// [`HashDoS`]: https://en.wikipedia.org/wiki/Collision_attack\n    /// [`std::collections::hash_map::RandomState`]: https://doc.rust-lang.org/std/collections/hash_map/struct.RandomState.html\n    /// [`BuildHasher`]: https://doc.rust-lang.org/std/hash/trait.BuildHasher.html\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    /// use hashbrown::DefaultHashBuilder;\n    ///\n    /// let s = DefaultHashBuilder::default();\n    /// let mut set = HashSet::with_capacity_and_hasher(10, s);\n    /// set.insert(1);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn with_capacity_and_hasher_in(capacity: usize, hasher: S, alloc: A) -> Self {\n        Self {\n            map: HashMap::with_capacity_and_hasher_in(capacity, hasher, alloc),\n        }\n    }\n\n    /// Returns a reference to the set's [`BuildHasher`].\n    ///\n    /// [`BuildHasher`]: https://doc.rust-lang.org/std/hash/trait.BuildHasher.html\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    /// use hashbrown::DefaultHashBuilder;\n    ///\n    /// let hasher = DefaultHashBuilder::default();\n    /// let set: HashSet<i32> = HashSet::with_hasher(hasher);\n    /// let hasher: &DefaultHashBuilder = set.hasher();\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn hasher(&self) -> &S {\n        self.map.hasher()\n    }\n}",
            "impl<T, S, A> HashSet<T, S, A>\nwhere\n    T: Eq + Hash,\n    S: BuildHasher,\n    A: Allocator,\n{\n    /// Reserves capacity for at least `additional` more elements to be inserted\n    /// in the `HashSet`. The collection may reserve more space to avoid\n    /// frequent reallocations.\n    ///\n    /// # Panics\n    ///\n    /// Panics if the new capacity exceeds [`isize::MAX`] bytes and [`abort`] the program\n    /// in case of allocation error. Use [`try_reserve`](HashSet::try_reserve) instead\n    /// if you want to handle memory allocation failure.\n    ///\n    /// [`isize::MAX`]: https://doc.rust-lang.org/std/primitive.isize.html\n    /// [`abort`]: https://doc.rust-lang.org/alloc/alloc/fn.handle_alloc_error.html\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    /// let mut set: HashSet<i32> = HashSet::new();\n    /// set.reserve(10);\n    /// assert!(set.capacity() >= 10);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn reserve(&mut self, additional: usize) {\n        self.map.reserve(additional);\n    }\n\n    /// Tries to reserve capacity for at least `additional` more elements to be inserted\n    /// in the given `HashSet<K,V>`. The collection may reserve more space to avoid\n    /// frequent reallocations.\n    ///\n    /// # Errors\n    ///\n    /// If the capacity overflows, or the allocator reports a failure, then an error\n    /// is returned.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    /// let mut set: HashSet<i32> = HashSet::new();\n    /// set.try_reserve(10).expect(\"why is the test harness OOMing on 10 bytes?\");\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn try_reserve(&mut self, additional: usize) -> Result<(), TryReserveError> {\n        self.map.try_reserve(additional)\n    }\n\n    /// Shrinks the capacity of the set as much as possible. It will drop\n    /// down as much as possible while maintaining the internal rules\n    /// and possibly leaving some space in accordance with the resize policy.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    ///\n    /// let mut set = HashSet::with_capacity(100);\n    /// set.insert(1);\n    /// set.insert(2);\n    /// assert!(set.capacity() >= 100);\n    /// set.shrink_to_fit();\n    /// assert!(set.capacity() >= 2);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn shrink_to_fit(&mut self) {\n        self.map.shrink_to_fit();\n    }\n\n    /// Shrinks the capacity of the set with a lower limit. It will drop\n    /// down no lower than the supplied limit while maintaining the internal rules\n    /// and possibly leaving some space in accordance with the resize policy.\n    ///\n    /// Panics if the current capacity is smaller than the supplied\n    /// minimum capacity.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    ///\n    /// let mut set = HashSet::with_capacity(100);\n    /// set.insert(1);\n    /// set.insert(2);\n    /// assert!(set.capacity() >= 100);\n    /// set.shrink_to(10);\n    /// assert!(set.capacity() >= 10);\n    /// set.shrink_to(0);\n    /// assert!(set.capacity() >= 2);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn shrink_to(&mut self, min_capacity: usize) {\n        self.map.shrink_to(min_capacity);\n    }\n\n    /// Visits the values representing the difference,\n    /// i.e., the values that are in `self` but not in `other`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    /// let a: HashSet<_> = [1, 2, 3].into_iter().collect();\n    /// let b: HashSet<_> = [4, 2, 3, 4].into_iter().collect();\n    ///\n    /// // Can be seen as `a - b`.\n    /// for x in a.difference(&b) {\n    ///     println!(\"{}\", x); // Print 1\n    /// }\n    ///\n    /// let diff: HashSet<_> = a.difference(&b).collect();\n    /// assert_eq!(diff, [1].iter().collect());\n    ///\n    /// // Note that difference is not symmetric,\n    /// // and `b - a` means something else:\n    /// let diff: HashSet<_> = b.difference(&a).collect();\n    /// assert_eq!(diff, [4].iter().collect());\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn difference<'a>(&'a self, other: &'a Self) -> Difference<'a, T, S, A> {\n        Difference {\n            iter: self.iter(),\n            other,\n        }\n    }\n\n    /// Visits the values representing the symmetric difference,\n    /// i.e., the values that are in `self` or in `other` but not in both.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    /// let a: HashSet<_> = [1, 2, 3].into_iter().collect();\n    /// let b: HashSet<_> = [4, 2, 3, 4].into_iter().collect();\n    ///\n    /// // Print 1, 4 in arbitrary order.\n    /// for x in a.symmetric_difference(&b) {\n    ///     println!(\"{}\", x);\n    /// }\n    ///\n    /// let diff1: HashSet<_> = a.symmetric_difference(&b).collect();\n    /// let diff2: HashSet<_> = b.symmetric_difference(&a).collect();\n    ///\n    /// assert_eq!(diff1, diff2);\n    /// assert_eq!(diff1, [1, 4].iter().collect());\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn symmetric_difference<'a>(&'a self, other: &'a Self) -> SymmetricDifference<'a, T, S, A> {\n        SymmetricDifference {\n            iter: self.difference(other).chain(other.difference(self)),\n        }\n    }\n\n    /// Visits the values representing the intersection,\n    /// i.e., the values that are both in `self` and `other`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    /// let a: HashSet<_> = [1, 2, 3].into_iter().collect();\n    /// let b: HashSet<_> = [4, 2, 3, 4].into_iter().collect();\n    ///\n    /// // Print 2, 3 in arbitrary order.\n    /// for x in a.intersection(&b) {\n    ///     println!(\"{}\", x);\n    /// }\n    ///\n    /// let intersection: HashSet<_> = a.intersection(&b).collect();\n    /// assert_eq!(intersection, [2, 3].iter().collect());\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn intersection<'a>(&'a self, other: &'a Self) -> Intersection<'a, T, S, A> {\n        let (smaller, larger) = if self.len() <= other.len() {\n            (self, other)\n        } else {\n            (other, self)\n        };\n        Intersection {\n            iter: smaller.iter(),\n            other: larger,\n        }\n    }\n\n    /// Visits the values representing the union,\n    /// i.e., all the values in `self` or `other`, without duplicates.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    /// let a: HashSet<_> = [1, 2, 3].into_iter().collect();\n    /// let b: HashSet<_> = [4, 2, 3, 4].into_iter().collect();\n    ///\n    /// // Print 1, 2, 3, 4 in arbitrary order.\n    /// for x in a.union(&b) {\n    ///     println!(\"{}\", x);\n    /// }\n    ///\n    /// let union: HashSet<_> = a.union(&b).collect();\n    /// assert_eq!(union, [1, 2, 3, 4].iter().collect());\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn union<'a>(&'a self, other: &'a Self) -> Union<'a, T, S, A> {\n        // We'll iterate one set in full, and only the remaining difference from the other.\n        // Use the smaller set for the difference in order to reduce hash lookups.\n        let (smaller, larger) = if self.len() <= other.len() {\n            (self, other)\n        } else {\n            (other, self)\n        };\n        Union {\n            iter: larger.iter().chain(smaller.difference(larger)),\n        }\n    }\n\n    /// Returns `true` if the set contains a value.\n    ///\n    /// The value may be any borrowed form of the set's value type, but\n    /// [`Hash`] and [`Eq`] on the borrowed form *must* match those for\n    /// the value type.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    ///\n    /// let set: HashSet<_> = [1, 2, 3].into_iter().collect();\n    /// assert_eq!(set.contains(&1), true);\n    /// assert_eq!(set.contains(&4), false);\n    /// ```\n    ///\n    /// [`Eq`]: https://doc.rust-lang.org/std/cmp/trait.Eq.html\n    /// [`Hash`]: https://doc.rust-lang.org/std/hash/trait.Hash.html\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn contains<Q>(&self, value: &Q) -> bool\n    where\n        Q: Hash + Equivalent<T> + ?Sized,\n    {\n        self.map.contains_key(value)\n    }\n\n    /// Returns a reference to the value in the set, if any, that is equal to the given value.\n    ///\n    /// The value may be any borrowed form of the set's value type, but\n    /// [`Hash`] and [`Eq`] on the borrowed form *must* match those for\n    /// the value type.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    ///\n    /// let set: HashSet<_> = [1, 2, 3].into_iter().collect();\n    /// assert_eq!(set.get(&2), Some(&2));\n    /// assert_eq!(set.get(&4), None);\n    /// ```\n    ///\n    /// [`Eq`]: https://doc.rust-lang.org/std/cmp/trait.Eq.html\n    /// [`Hash`]: https://doc.rust-lang.org/std/hash/trait.Hash.html\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn get<Q>(&self, value: &Q) -> Option<&T>\n    where\n        Q: Hash + Equivalent<T> + ?Sized,\n    {\n        // Avoid `Option::map` because it bloats LLVM IR.\n        match self.map.get_key_value(value) {\n            Some((k, _)) => Some(k),\n            None => None,\n        }\n    }\n\n    /// Inserts the given `value` into the set if it is not present, then\n    /// returns a reference to the value in the set.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    ///\n    /// let mut set: HashSet<_> = [1, 2, 3].into_iter().collect();\n    /// assert_eq!(set.len(), 3);\n    /// assert_eq!(set.get_or_insert(2), &2);\n    /// assert_eq!(set.get_or_insert(100), &100);\n    /// assert_eq!(set.len(), 4); // 100 was inserted\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn get_or_insert(&mut self, value: T) -> &T {\n        let hash = make_hash(&self.map.hash_builder, &value);\n        let bucket = match self.map.find_or_find_insert_slot(hash, &value) {\n            Ok(bucket) => bucket,\n            Err(slot) => unsafe { self.map.table.insert_in_slot(hash, slot, (value, ())) },\n        };\n        unsafe { &bucket.as_ref().0 }\n    }\n\n    /// Inserts a value computed from `f` into the set if the given `value` is\n    /// not present, then returns a reference to the value in the set.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    ///\n    /// let mut set: HashSet<String> = [\"cat\", \"dog\", \"horse\"]\n    ///     .iter().map(|&pet| pet.to_owned()).collect();\n    ///\n    /// assert_eq!(set.len(), 3);\n    /// for &pet in &[\"cat\", \"dog\", \"fish\"] {\n    ///     let value = set.get_or_insert_with(pet, str::to_owned);\n    ///     assert_eq!(value, pet);\n    /// }\n    /// assert_eq!(set.len(), 4); // a new \"fish\" was inserted\n    /// ```\n    ///\n    /// The following example will panic because the new value doesn't match.\n    ///\n    /// ```should_panic\n    /// let mut set = hashbrown::HashSet::new();\n    /// set.get_or_insert_with(\"rust\", |_| String::new());\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn get_or_insert_with<Q, F>(&mut self, value: &Q, f: F) -> &T\n    where\n        Q: Hash + Equivalent<T> + ?Sized,\n        F: FnOnce(&Q) -> T,\n    {\n        let hash = make_hash(&self.map.hash_builder, value);\n        let bucket = match self.map.find_or_find_insert_slot(hash, value) {\n            Ok(bucket) => bucket,\n            Err(slot) => {\n                let new = f(value);\n                assert!(value.equivalent(&new), \"new value is not equivalent\");\n                unsafe { self.map.table.insert_in_slot(hash, slot, (new, ())) }\n            }\n        };\n        unsafe { &bucket.as_ref().0 }\n    }\n\n    /// Gets the given value's corresponding entry in the set for in-place manipulation.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    /// use hashbrown::hash_set::Entry::*;\n    ///\n    /// let mut singles = HashSet::new();\n    /// let mut dupes = HashSet::new();\n    ///\n    /// for ch in \"a short treatise on fungi\".chars() {\n    ///     if let Vacant(dupe_entry) = dupes.entry(ch) {\n    ///         // We haven't already seen a duplicate, so\n    ///         // check if we've at least seen it once.\n    ///         match singles.entry(ch) {\n    ///             Vacant(single_entry) => {\n    ///                 // We found a new character for the first time.\n    ///                 single_entry.insert();\n    ///             }\n    ///             Occupied(single_entry) => {\n    ///                 // We've already seen this once, \"move\" it to dupes.\n    ///                 single_entry.remove();\n    ///                 dupe_entry.insert();\n    ///             }\n    ///         }\n    ///     }\n    /// }\n    ///\n    /// assert!(!singles.contains(&'t') && dupes.contains(&'t'));\n    /// assert!(singles.contains(&'u') && !dupes.contains(&'u'));\n    /// assert!(!singles.contains(&'v') && !dupes.contains(&'v'));\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn entry(&mut self, value: T) -> Entry<'_, T, S, A> {\n        match self.map.entry(value) {\n            map::Entry::Occupied(entry) => Entry::Occupied(OccupiedEntry { inner: entry }),\n            map::Entry::Vacant(entry) => Entry::Vacant(VacantEntry { inner: entry }),\n        }\n    }\n\n    /// Returns `true` if `self` has no elements in common with `other`.\n    /// This is equivalent to checking for an empty intersection.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    ///\n    /// let a: HashSet<_> = [1, 2, 3].into_iter().collect();\n    /// let mut b = HashSet::new();\n    ///\n    /// assert_eq!(a.is_disjoint(&b), true);\n    /// b.insert(4);\n    /// assert_eq!(a.is_disjoint(&b), true);\n    /// b.insert(1);\n    /// assert_eq!(a.is_disjoint(&b), false);\n    /// ```\n    pub fn is_disjoint(&self, other: &Self) -> bool {\n        self.intersection(other).next().is_none()\n    }\n\n    /// Returns `true` if the set is a subset of another,\n    /// i.e., `other` contains at least all the values in `self`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    ///\n    /// let sup: HashSet<_> = [1, 2, 3].into_iter().collect();\n    /// let mut set = HashSet::new();\n    ///\n    /// assert_eq!(set.is_subset(&sup), true);\n    /// set.insert(2);\n    /// assert_eq!(set.is_subset(&sup), true);\n    /// set.insert(4);\n    /// assert_eq!(set.is_subset(&sup), false);\n    /// ```\n    pub fn is_subset(&self, other: &Self) -> bool {\n        self.len() <= other.len() && self.iter().all(|v| other.contains(v))\n    }\n\n    /// Returns `true` if the set is a superset of another,\n    /// i.e., `self` contains at least all the values in `other`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    ///\n    /// let sub: HashSet<_> = [1, 2].into_iter().collect();\n    /// let mut set = HashSet::new();\n    ///\n    /// assert_eq!(set.is_superset(&sub), false);\n    ///\n    /// set.insert(0);\n    /// set.insert(1);\n    /// assert_eq!(set.is_superset(&sub), false);\n    ///\n    /// set.insert(2);\n    /// assert_eq!(set.is_superset(&sub), true);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn is_superset(&self, other: &Self) -> bool {\n        other.is_subset(self)\n    }\n\n    /// Adds a value to the set.\n    ///\n    /// If the set did not have this value present, `true` is returned.\n    ///\n    /// If the set did have this value present, `false` is returned.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    ///\n    /// let mut set = HashSet::new();\n    ///\n    /// assert_eq!(set.insert(2), true);\n    /// assert_eq!(set.insert(2), false);\n    /// assert_eq!(set.len(), 1);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn insert(&mut self, value: T) -> bool {\n        self.map.insert(value, ()).is_none()\n    }\n\n    /// Insert a value the set without checking if the value already exists in the set.\n    ///\n    /// This operation is faster than regular insert, because it does not perform\n    /// lookup before insertion.\n    ///\n    /// This operation is useful during initial population of the set.\n    /// For example, when constructing a set from another set, we know\n    /// that values are unique.\n    ///\n    /// # Safety\n    ///\n    /// This operation is safe if a value does not exist in the set.\n    ///\n    /// However, if a value exists in the set already, the behavior is unspecified:\n    /// this operation may panic, loop forever, or any following operation with the set\n    /// may panic, loop forever or return arbitrary result.\n    ///\n    /// That said, this operation (and following operations) are guaranteed to\n    /// not violate memory safety.\n    ///\n    /// However this operation is still unsafe because the resulting `HashSet`\n    /// may be passed to unsafe code which does expect the set to behave\n    /// correctly, and would cause unsoundness as a result.\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub unsafe fn insert_unique_unchecked(&mut self, value: T) -> &T {\n        self.map.insert_unique_unchecked(value, ()).0\n    }\n\n    /// Adds a value to the set, replacing the existing value, if any, that is equal to the given\n    /// one. Returns the replaced value.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    ///\n    /// let mut set = HashSet::new();\n    /// set.insert(Vec::<i32>::new());\n    ///\n    /// assert_eq!(set.get(&[][..]).unwrap().capacity(), 0);\n    /// set.replace(Vec::with_capacity(10));\n    /// assert_eq!(set.get(&[][..]).unwrap().capacity(), 10);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn replace(&mut self, value: T) -> Option<T> {\n        let hash = make_hash(&self.map.hash_builder, &value);\n        match self.map.find_or_find_insert_slot(hash, &value) {\n            Ok(bucket) => Some(mem::replace(unsafe { &mut bucket.as_mut().0 }, value)),\n            Err(slot) => {\n                unsafe {\n                    self.map.table.insert_in_slot(hash, slot, (value, ()));\n                }\n                None\n            }\n        }\n    }\n\n    /// Removes a value from the set. Returns whether the value was\n    /// present in the set.\n    ///\n    /// The value may be any borrowed form of the set's value type, but\n    /// [`Hash`] and [`Eq`] on the borrowed form *must* match those for\n    /// the value type.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    ///\n    /// let mut set = HashSet::new();\n    ///\n    /// set.insert(2);\n    /// assert_eq!(set.remove(&2), true);\n    /// assert_eq!(set.remove(&2), false);\n    /// ```\n    ///\n    /// [`Eq`]: https://doc.rust-lang.org/std/cmp/trait.Eq.html\n    /// [`Hash`]: https://doc.rust-lang.org/std/hash/trait.Hash.html\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn remove<Q>(&mut self, value: &Q) -> bool\n    where\n        Q: Hash + Equivalent<T> + ?Sized,\n    {\n        self.map.remove(value).is_some()\n    }\n\n    /// Removes and returns the value in the set, if any, that is equal to the given one.\n    ///\n    /// The value may be any borrowed form of the set's value type, but\n    /// [`Hash`] and [`Eq`] on the borrowed form *must* match those for\n    /// the value type.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    ///\n    /// let mut set: HashSet<_> = [1, 2, 3].into_iter().collect();\n    /// assert_eq!(set.take(&2), Some(2));\n    /// assert_eq!(set.take(&2), None);\n    /// ```\n    ///\n    /// [`Eq`]: https://doc.rust-lang.org/std/cmp/trait.Eq.html\n    /// [`Hash`]: https://doc.rust-lang.org/std/hash/trait.Hash.html\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn take<Q>(&mut self, value: &Q) -> Option<T>\n    where\n        Q: Hash + Equivalent<T> + ?Sized,\n    {\n        // Avoid `Option::map` because it bloats LLVM IR.\n        match self.map.remove_entry(value) {\n            Some((k, _)) => Some(k),\n            None => None,\n        }\n    }\n\n    /// Returns the total amount of memory allocated internally by the hash\n    /// set, in bytes.\n    ///\n    /// The returned number is informational only. It is intended to be\n    /// primarily used for memory profiling.\n    #[inline]\n    pub fn allocation_size(&self) -> usize {\n        self.map.allocation_size()\n    }\n}",
            "impl<T, S, A> PartialEq for HashSet<T, S, A>\nwhere\n    T: Eq + Hash,\n    S: BuildHasher,\n    A: Allocator,\n{\n    fn eq(&self, other: &Self) -> bool {\n        if self.len() != other.len() {\n            return false;\n        }\n\n        self.iter().all(|key| other.contains(key))\n    }\n}",
            "impl<T, S, A> SubAssign<&HashSet<T, S, A>> for HashSet<T, S, A>\nwhere\n    T: Eq + Hash + Clone,\n    S: BuildHasher,\n    A: Allocator,\n{\n    /// Modifies this set to contain the difference of `self` and `rhs`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    ///\n    /// let mut a: HashSet<_> = vec![1, 2, 3].into_iter().collect();\n    /// let b: HashSet<_> = vec![3, 4, 5].into_iter().collect();\n    ///\n    /// a -= &b;\n    ///\n    /// let mut i = 0;\n    /// let expected = [1, 2];\n    /// for x in &a {\n    ///     assert!(expected.contains(x));\n    ///     i += 1;\n    /// }\n    /// assert_eq!(i, expected.len());\n    /// ```\n    fn sub_assign(&mut self, rhs: &HashSet<T, S, A>) {\n        if rhs.len() < self.len() {\n            for item in rhs {\n                self.remove(item);\n            }\n        } else {\n            self.retain(|item| !rhs.contains(item));\n        }\n    }\n}",
            "impl<T, S, A> fmt::Debug for HashSet<T, S, A>\nwhere\n    T: fmt::Debug,\n    A: Allocator,\n{\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_set().entries(self.iter()).finish()\n    }\n}",
            "impl<T, S> HashSet<T, S, Global> {\n    /// Creates a new empty hash set which will use the given hasher to hash\n    /// keys.\n    ///\n    /// The hash set is initially created with a capacity of 0, so it will not\n    /// allocate until it is first inserted into.\n    ///\n    /// # HashDoS resistance\n    ///\n    /// The `hash_builder` normally use a fixed key by default and that does\n    /// not allow the `HashSet` to be protected against attacks such as [`HashDoS`].\n    /// Users who require HashDoS resistance should explicitly use\n    /// [`std::collections::hash_map::RandomState`]\n    /// as the hasher when creating a [`HashSet`].\n    ///\n    /// The `hash_builder` passed should implement the [`BuildHasher`] trait for\n    /// the `HashSet` to be useful, see its documentation for details.\n    ///\n    /// [`HashDoS`]: https://en.wikipedia.org/wiki/Collision_attack\n    /// [`std::collections::hash_map::RandomState`]: https://doc.rust-lang.org/std/collections/hash_map/struct.RandomState.html\n    /// [`BuildHasher`]: https://doc.rust-lang.org/std/hash/trait.BuildHasher.html\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    /// use hashbrown::DefaultHashBuilder;\n    ///\n    /// let s = DefaultHashBuilder::default();\n    /// let mut set = HashSet::with_hasher(s);\n    /// set.insert(2);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    #[cfg_attr(feature = \"rustc-dep-of-std\", rustc_const_stable_indirect)]\n    pub const fn with_hasher(hasher: S) -> Self {\n        Self {\n            map: HashMap::with_hasher(hasher),\n        }\n    }\n\n    /// Creates an empty `HashSet` with the specified capacity, using\n    /// `hasher` to hash the keys.\n    ///\n    /// The hash set will be able to hold at least `capacity` elements without\n    /// reallocating. If `capacity` is 0, the hash set will not allocate.\n    ///\n    /// # HashDoS resistance\n    ///\n    /// The `hash_builder` normally use a fixed key by default and that does\n    /// not allow the `HashSet` to be protected against attacks such as [`HashDoS`].\n    /// Users who require HashDoS resistance should explicitly use\n    /// [`std::collections::hash_map::RandomState`]\n    /// as the hasher when creating a [`HashSet`].\n    ///\n    /// The `hash_builder` passed should implement the [`BuildHasher`] trait for\n    /// the `HashSet` to be useful, see its documentation for details.\n    ///\n    /// [`HashDoS`]: https://en.wikipedia.org/wiki/Collision_attack\n    /// [`std::collections::hash_map::RandomState`]: https://doc.rust-lang.org/std/collections/hash_map/struct.RandomState.html\n    /// [`BuildHasher`]: https://doc.rust-lang.org/std/hash/trait.BuildHasher.html\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    /// use hashbrown::DefaultHashBuilder;\n    ///\n    /// let s = DefaultHashBuilder::default();\n    /// let mut set = HashSet::with_capacity_and_hasher(10, s);\n    /// set.insert(1);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn with_capacity_and_hasher(capacity: usize, hasher: S) -> Self {\n        Self {\n            map: HashMap::with_capacity_and_hasher(capacity, hasher),\n        }\n    }\n}",
            "impl<T: Clone, S: Clone, A: Allocator + Clone> Clone for HashSet<T, S, A> {\n    fn clone(&self) -> Self {\n        HashSet {\n            map: self.map.clone(),\n        }\n    }\n\n    fn clone_from(&mut self, source: &Self) {\n        self.map.clone_from(&source.map);\n    }\n}",
            "impl<T: Hash + Eq, A: Allocator> HashSet<T, DefaultHashBuilder, A> {\n    /// Creates an empty `HashSet`.\n    ///\n    /// The hash set is initially created with a capacity of 0, so it will not allocate until it\n    /// is first inserted into.\n    ///\n    /// # HashDoS resistance\n    ///\n    /// The `hash_builder` normally use a fixed key by default and that does\n    /// not allow the `HashSet` to be protected against attacks such as [`HashDoS`].\n    /// Users who require HashDoS resistance should explicitly use\n    /// [`std::collections::hash_map::RandomState`]\n    /// as the hasher when creating a [`HashSet`], for example with\n    /// [`with_hasher_in`](HashSet::with_hasher_in) method.\n    ///\n    /// [`HashDoS`]: https://en.wikipedia.org/wiki/Collision_attack\n    /// [`std::collections::hash_map::RandomState`]: https://doc.rust-lang.org/std/collections/hash_map/struct.RandomState.html\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    /// let set: HashSet<i32> = HashSet::new();\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn new_in(alloc: A) -> Self {\n        Self {\n            map: HashMap::new_in(alloc),\n        }\n    }\n\n    /// Creates an empty `HashSet` with the specified capacity.\n    ///\n    /// The hash set will be able to hold at least `capacity` elements without\n    /// reallocating. If `capacity` is 0, the hash set will not allocate.\n    ///\n    /// # HashDoS resistance\n    ///\n    /// The `hash_builder` normally use a fixed key by default and that does\n    /// not allow the `HashSet` to be protected against attacks such as [`HashDoS`].\n    /// Users who require HashDoS resistance should explicitly use\n    /// [`std::collections::hash_map::RandomState`]\n    /// as the hasher when creating a [`HashSet`], for example with\n    /// [`with_capacity_and_hasher_in`](HashSet::with_capacity_and_hasher_in) method.\n    ///\n    /// [`HashDoS`]: https://en.wikipedia.org/wiki/Collision_attack\n    /// [`std::collections::hash_map::RandomState`]: https://doc.rust-lang.org/std/collections/hash_map/struct.RandomState.html\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    /// let set: HashSet<i32> = HashSet::with_capacity(10);\n    /// assert!(set.capacity() >= 10);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn with_capacity_in(capacity: usize, alloc: A) -> Self {\n        Self {\n            map: HashMap::with_capacity_in(capacity, alloc),\n        }\n    }\n}",
            "impl<T> HashSet<T, DefaultHashBuilder> {\n    /// Creates an empty `HashSet`.\n    ///\n    /// The hash set is initially created with a capacity of 0, so it will not allocate until it\n    /// is first inserted into.\n    ///\n    /// # HashDoS resistance\n    ///\n    /// The `hash_builder` normally use a fixed key by default and that does\n    /// not allow the `HashSet` to be protected against attacks such as [`HashDoS`].\n    /// Users who require HashDoS resistance should explicitly use\n    /// [`std::collections::hash_map::RandomState`]\n    /// as the hasher when creating a [`HashSet`], for example with\n    /// [`with_hasher`](HashSet::with_hasher) method.\n    ///\n    /// [`HashDoS`]: https://en.wikipedia.org/wiki/Collision_attack\n    /// [`std::collections::hash_map::RandomState`]: https://doc.rust-lang.org/std/collections/hash_map/struct.RandomState.html\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    /// let set: HashSet<i32> = HashSet::new();\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn new() -> Self {\n        Self {\n            map: HashMap::new(),\n        }\n    }\n\n    /// Creates an empty `HashSet` with the specified capacity.\n    ///\n    /// The hash set will be able to hold at least `capacity` elements without\n    /// reallocating. If `capacity` is 0, the hash set will not allocate.\n    ///\n    /// # HashDoS resistance\n    ///\n    /// The `hash_builder` normally use a fixed key by default and that does\n    /// not allow the `HashSet` to be protected against attacks such as [`HashDoS`].\n    /// Users who require HashDoS resistance should explicitly use\n    /// [`std::collections::hash_map::RandomState`]\n    /// as the hasher when creating a [`HashSet`], for example with\n    /// [`with_capacity_and_hasher`](HashSet::with_capacity_and_hasher) method.\n    ///\n    /// [`HashDoS`]: https://en.wikipedia.org/wiki/Collision_attack\n    /// [`std::collections::hash_map::RandomState`]: https://doc.rust-lang.org/std/collections/hash_map/struct.RandomState.html\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    /// let set: HashSet<i32> = HashSet::with_capacity(10);\n    /// assert!(set.capacity() >= 10);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn with_capacity(capacity: usize) -> Self {\n        Self {\n            map: HashMap::with_capacity(capacity),\n        }\n    }\n}"
        ],
        "set::Intersection": [
            "impl<'a, T, S, A> Iterator for Intersection<'a, T, S, A>\nwhere\n    T: Eq + Hash,\n    S: BuildHasher,\n    A: Allocator,\n{\n    type Item = &'a T;\n\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn next(&mut self) -> Option<&'a T> {\n        loop {\n            let elt = self.iter.next()?;\n            if self.other.contains(elt) {\n                return Some(elt);\n            }\n        }\n    }\n\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        let (_, upper) = self.iter.size_hint();\n        (0, upper)\n    }\n\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn fold<B, F>(self, init: B, mut f: F) -> B\n    where\n        Self: Sized,\n        F: FnMut(B, Self::Item) -> B,\n    {\n        self.iter.fold(init, |acc, elt| {\n            if self.other.contains(elt) {\n                f(acc, elt)\n            } else {\n                acc\n            }\n        })\n    }\n}",
            "impl<T, S, A: Allocator> Clone for Intersection<'_, T, S, A> {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn clone(&self) -> Self {\n        Intersection {\n            iter: self.iter.clone(),\n            ..*self\n        }\n    }\n}",
            "impl<T, S, A> FusedIterator for Intersection<'_, T, S, A>\nwhere\n    T: Eq + Hash,\n    S: BuildHasher,\n    A: Allocator,\n{\n}",
            "impl<T, S, A> fmt::Debug for Intersection<'_, T, S, A>\nwhere\n    T: fmt::Debug + Eq + Hash,\n    S: BuildHasher,\n    A: Allocator,\n{\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_list().entries(self.clone()).finish()\n    }\n}"
        ],
        "set::IntoIter": [
            "impl<K, A: Allocator> Default for IntoIter<K, A> {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn default() -> Self {\n        IntoIter {\n            iter: Default::default(),\n        }\n    }\n}",
            "impl<K, A: Allocator> ExactSizeIterator for IntoIter<K, A> {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn len(&self) -> usize {\n        self.iter.len()\n    }\n}",
            "impl<K, A: Allocator> FusedIterator for IntoIter<K, A> {}",
            "impl<K, A: Allocator> Iterator for IntoIter<K, A> {\n    type Item = K;\n\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn next(&mut self) -> Option<K> {\n        // Avoid `Option::map` because it bloats LLVM IR.\n        match self.iter.next() {\n            Some((k, _)) => Some(k),\n            None => None,\n        }\n    }\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.iter.size_hint()\n    }\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn fold<B, F>(self, init: B, mut f: F) -> B\n    where\n        Self: Sized,\n        F: FnMut(B, Self::Item) -> B,\n    {\n        self.iter.fold(init, |acc, (k, ())| f(acc, k))\n    }\n}",
            "impl<K: fmt::Debug, A: Allocator> fmt::Debug for IntoIter<K, A> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        let entries_iter = self.iter.iter().map(|(k, _)| k);\n        f.debug_list().entries(entries_iter).finish()\n    }\n}"
        ],
        "set::Iter": [
            "impl<'a, K> Iterator for Iter<'a, K> {\n    type Item = &'a K;\n\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn next(&mut self) -> Option<&'a K> {\n        self.iter.next()\n    }\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.iter.size_hint()\n    }\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn fold<B, F>(self, init: B, f: F) -> B\n    where\n        Self: Sized,\n        F: FnMut(B, Self::Item) -> B,\n    {\n        self.iter.fold(init, f)\n    }\n}",
            "impl<K: fmt::Debug> fmt::Debug for Iter<'_, K> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_list().entries(self.clone()).finish()\n    }\n}",
            "impl<K> Clone for Iter<'_, K> {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn clone(&self) -> Self {\n        Iter {\n            iter: self.iter.clone(),\n        }\n    }\n}",
            "impl<K> Default for Iter<'_, K> {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn default() -> Self {\n        Iter {\n            iter: Default::default(),\n        }\n    }\n}",
            "impl<K> ExactSizeIterator for Iter<'_, K> {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn len(&self) -> usize {\n        self.iter.len()\n    }\n}",
            "impl<K> FusedIterator for Iter<'_, K> {}"
        ],
        "set::OccupiedEntry": [
            "impl<T, S, A: Allocator> OccupiedEntry<'_, T, S, A> {\n    /// Gets a reference to the value in the entry.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::hash_set::{Entry, HashSet};\n    ///\n    /// let mut set: HashSet<&str> = HashSet::new();\n    /// set.entry(\"poneyland\").or_insert();\n    ///\n    /// match set.entry(\"poneyland\") {\n    ///     Entry::Vacant(_) => panic!(),\n    ///     Entry::Occupied(entry) => assert_eq!(entry.get(), &\"poneyland\"),\n    /// }\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn get(&self) -> &T {\n        self.inner.key()\n    }\n\n    /// Takes the value out of the entry, and returns it.\n    /// Keeps the allocated memory for reuse.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    /// use hashbrown::hash_set::Entry;\n    ///\n    /// let mut set: HashSet<&str> = HashSet::new();\n    /// // The set is empty\n    /// assert!(set.is_empty() && set.capacity() == 0);\n    ///\n    /// set.entry(\"poneyland\").or_insert();\n    /// let capacity_before_remove = set.capacity();\n    ///\n    /// if let Entry::Occupied(o) = set.entry(\"poneyland\") {\n    ///     assert_eq!(o.remove(), \"poneyland\");\n    /// }\n    ///\n    /// assert_eq!(set.contains(\"poneyland\"), false);\n    /// // Now set hold none elements but capacity is equal to the old one\n    /// assert!(set.len() == 0 && set.capacity() == capacity_before_remove);\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn remove(self) -> T {\n        self.inner.remove_entry().0\n    }\n}",
            "impl<T: fmt::Debug, S, A: Allocator> fmt::Debug for OccupiedEntry<'_, T, S, A> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_struct(\"OccupiedEntry\")\n            .field(\"value\", self.get())\n            .finish()\n    }\n}"
        ],
        "set::SymmetricDifference": [
            "impl<'a, T, S, A> Iterator for SymmetricDifference<'a, T, S, A>\nwhere\n    T: Eq + Hash,\n    S: BuildHasher,\n    A: Allocator,\n{\n    type Item = &'a T;\n\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn next(&mut self) -> Option<&'a T> {\n        self.iter.next()\n    }\n\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.iter.size_hint()\n    }\n\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn fold<B, F>(self, init: B, f: F) -> B\n    where\n        Self: Sized,\n        F: FnMut(B, Self::Item) -> B,\n    {\n        self.iter.fold(init, f)\n    }\n}",
            "impl<T, S, A: Allocator> Clone for SymmetricDifference<'_, T, S, A> {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn clone(&self) -> Self {\n        SymmetricDifference {\n            iter: self.iter.clone(),\n        }\n    }\n}",
            "impl<T, S, A> FusedIterator for SymmetricDifference<'_, T, S, A>\nwhere\n    T: Eq + Hash,\n    S: BuildHasher,\n    A: Allocator,\n{\n}",
            "impl<T, S, A> fmt::Debug for SymmetricDifference<'_, T, S, A>\nwhere\n    T: fmt::Debug + Eq + Hash,\n    S: BuildHasher,\n    A: Allocator,\n{\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_list().entries(self.clone()).finish()\n    }\n}"
        ],
        "set::Union": [
            "impl<'a, T, S, A> Iterator for Union<'a, T, S, A>\nwhere\n    T: Eq + Hash,\n    S: BuildHasher,\n    A: Allocator,\n{\n    type Item = &'a T;\n\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn next(&mut self) -> Option<&'a T> {\n        self.iter.next()\n    }\n\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.iter.size_hint()\n    }\n\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn fold<B, F>(self, init: B, f: F) -> B\n    where\n        Self: Sized,\n        F: FnMut(B, Self::Item) -> B,\n    {\n        self.iter.fold(init, f)\n    }\n}",
            "impl<T, S, A: Allocator> Clone for Union<'_, T, S, A> {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn clone(&self) -> Self {\n        Union {\n            iter: self.iter.clone(),\n        }\n    }\n}",
            "impl<T, S, A> FusedIterator for Union<'_, T, S, A>\nwhere\n    T: Eq + Hash,\n    S: BuildHasher,\n    A: Allocator,\n{\n}",
            "impl<T, S, A> fmt::Debug for Union<'_, T, S, A>\nwhere\n    T: fmt::Debug + Eq + Hash,\n    S: BuildHasher,\n    A: Allocator,\n{\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_list().entries(self.clone()).finish()\n    }\n}"
        ],
        "set::VacantEntry": [
            "impl<'a, T, S, A: Allocator> VacantEntry<'a, T, S, A> {\n    /// Gets a reference to the value that would be used when inserting\n    /// through the `VacantEntry`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    ///\n    /// let mut set: HashSet<&str> = HashSet::new();\n    /// assert_eq!(set.entry(\"poneyland\").get(), &\"poneyland\");\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn get(&self) -> &T {\n        self.inner.key()\n    }\n\n    /// Take ownership of the value.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::hash_set::{Entry, HashSet};\n    ///\n    /// let mut set: HashSet<&str> = HashSet::new();\n    ///\n    /// match set.entry(\"poneyland\") {\n    ///     Entry::Occupied(_) => panic!(),\n    ///     Entry::Vacant(v) => assert_eq!(v.into_value(), \"poneyland\"),\n    /// }\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn into_value(self) -> T {\n        self.inner.into_key()\n    }\n\n    /// Sets the value of the entry with the `VacantEntry`'s value.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashSet;\n    /// use hashbrown::hash_set::Entry;\n    ///\n    /// let mut set: HashSet<&str> = HashSet::new();\n    ///\n    /// if let Entry::Vacant(o) = set.entry(\"poneyland\") {\n    ///     o.insert();\n    /// }\n    /// assert!(set.contains(\"poneyland\"));\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn insert(self) -> OccupiedEntry<'a, T, S, A>\n    where\n        T: Hash,\n        S: BuildHasher,\n    {\n        OccupiedEntry {\n            inner: self.inner.insert_entry(()),\n        }\n    }\n}",
            "impl<T: fmt::Debug, S, A: Allocator> fmt::Debug for VacantEntry<'_, T, S, A> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_tuple(\"VacantEntry\").field(self.get()).finish()\n    }\n}"
        ],
        "table::AbsentEntry": [
            "impl<'a, T, A> AbsentEntry<'a, T, A>\nwhere\n    A: Allocator,\n{\n    /// Converts the `AbsentEntry` into a mutable reference to the underlying\n    /// table.\n    pub fn into_table(self) -> &'a mut HashTable<T, A> {\n        self.table\n    }\n}",
            "impl<T: fmt::Debug, A: Allocator> fmt::Debug for AbsentEntry<'_, T, A> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.write_str(\"AbsentEntry\")\n    }\n}"
        ],
        "table::Drain": [
            "impl<T, A: Allocator> ExactSizeIterator for Drain<'_, T, A> {\n    fn len(&self) -> usize {\n        self.inner.len()\n    }\n}",
            "impl<T, A: Allocator> FusedIterator for Drain<'_, T, A> {}",
            "impl<T, A: Allocator> Iterator for Drain<'_, T, A> {\n    type Item = T;\n\n    fn next(&mut self) -> Option<T> {\n        self.inner.next()\n    }\n\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.inner.size_hint()\n    }\n\n    fn fold<B, F>(self, init: B, f: F) -> B\n    where\n        Self: Sized,\n        F: FnMut(B, Self::Item) -> B,\n    {\n        self.inner.fold(init, f)\n    }\n}",
            "impl<T: fmt::Debug, A: Allocator> fmt::Debug for Drain<'_, T, A> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_list()\n            .entries(Iter {\n                inner: self.inner.iter(),\n                marker: PhantomData,\n            })\n            .finish()\n    }\n}"
        ],
        "table::Entry": [
            "impl<'a, T, A> Entry<'a, T, A>\nwhere\n    A: Allocator,\n{\n    /// Sets the value of the entry, replacing any existing value if there is\n    /// one, and returns an [`OccupiedEntry`].\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// # #[cfg(feature = \"nightly\")]\n    /// # fn test() {\n    /// use hashbrown::{HashTable, DefaultHashBuilder};\n    /// use std::hash::BuildHasher;\n    ///\n    /// let mut table: HashTable<&str> = HashTable::new();\n    /// let hasher = DefaultHashBuilder::default();\n    /// let hasher = |val: &_| hasher.hash_one(val);\n    ///\n    /// let entry = table\n    ///     .entry(hasher(&\"horseyland\"), |&x| x == \"horseyland\", hasher)\n    ///     .insert(\"horseyland\");\n    ///\n    /// assert_eq!(entry.get(), &\"horseyland\");\n    /// # }\n    /// # fn main() {\n    /// #     #[cfg(feature = \"nightly\")]\n    /// #     test()\n    /// # }\n    /// ```\n    pub fn insert(self, value: T) -> OccupiedEntry<'a, T, A> {\n        match self {\n            Entry::Occupied(mut entry) => {\n                *entry.get_mut() = value;\n                entry\n            }\n            Entry::Vacant(entry) => entry.insert(value),\n        }\n    }\n\n    /// Ensures a value is in the entry by inserting if it was vacant.\n    ///\n    /// Returns an [`OccupiedEntry`] pointing to the now-occupied entry.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// # #[cfg(feature = \"nightly\")]\n    /// # fn test() {\n    /// use hashbrown::{HashTable, DefaultHashBuilder};\n    /// use std::hash::BuildHasher;\n    ///\n    /// let mut table: HashTable<&str> = HashTable::new();\n    /// let hasher = DefaultHashBuilder::default();\n    /// let hasher = |val: &_| hasher.hash_one(val);\n    ///\n    /// // nonexistent key\n    /// table\n    ///     .entry(hasher(&\"poneyland\"), |&x| x == \"poneyland\", hasher)\n    ///     .or_insert(\"poneyland\");\n    /// assert!(table\n    ///     .find(hasher(&\"poneyland\"), |&x| x == \"poneyland\")\n    ///     .is_some());\n    ///\n    /// // existing key\n    /// table\n    ///     .entry(hasher(&\"poneyland\"), |&x| x == \"poneyland\", hasher)\n    ///     .or_insert(\"poneyland\");\n    /// assert!(table\n    ///     .find(hasher(&\"poneyland\"), |&x| x == \"poneyland\")\n    ///     .is_some());\n    /// assert_eq!(table.len(), 1);\n    /// # }\n    /// # fn main() {\n    /// #     #[cfg(feature = \"nightly\")]\n    /// #     test()\n    /// # }\n    /// ```\n    pub fn or_insert(self, default: T) -> OccupiedEntry<'a, T, A> {\n        match self {\n            Entry::Occupied(entry) => entry,\n            Entry::Vacant(entry) => entry.insert(default),\n        }\n    }\n\n    /// Ensures a value is in the entry by inserting the result of the default function if empty..\n    ///\n    /// Returns an [`OccupiedEntry`] pointing to the now-occupied entry.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// # #[cfg(feature = \"nightly\")]\n    /// # fn test() {\n    /// use hashbrown::{HashTable, DefaultHashBuilder};\n    /// use std::hash::BuildHasher;\n    ///\n    /// let mut table: HashTable<String> = HashTable::new();\n    /// let hasher = DefaultHashBuilder::default();\n    /// let hasher = |val: &_| hasher.hash_one(val);\n    ///\n    /// table\n    ///     .entry(hasher(\"poneyland\"), |x| x == \"poneyland\", |val| hasher(val))\n    ///     .or_insert_with(|| \"poneyland\".to_string());\n    ///\n    /// assert!(table\n    ///     .find(hasher(&\"poneyland\"), |x| x == \"poneyland\")\n    ///     .is_some());\n    /// # }\n    /// # fn main() {\n    /// #     #[cfg(feature = \"nightly\")]\n    /// #     test()\n    /// # }\n    /// ```\n    pub fn or_insert_with(self, default: impl FnOnce() -> T) -> OccupiedEntry<'a, T, A> {\n        match self {\n            Entry::Occupied(entry) => entry,\n            Entry::Vacant(entry) => entry.insert(default()),\n        }\n    }\n\n    /// Provides in-place mutable access to an occupied entry before any\n    /// potential inserts into the table.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// # #[cfg(feature = \"nightly\")]\n    /// # fn test() {\n    /// use hashbrown::{HashTable, DefaultHashBuilder};\n    /// use std::hash::BuildHasher;\n    ///\n    /// let mut table: HashTable<(&str, u32)> = HashTable::new();\n    /// let hasher = DefaultHashBuilder::default();\n    /// let hasher = |val: &_| hasher.hash_one(val);\n    ///\n    /// table\n    ///     .entry(\n    ///         hasher(&\"poneyland\"),\n    ///         |&(x, _)| x == \"poneyland\",\n    ///         |(k, _)| hasher(&k),\n    ///     )\n    ///     .and_modify(|(_, v)| *v += 1)\n    ///     .or_insert((\"poneyland\", 42));\n    /// assert_eq!(\n    ///     table.find(hasher(&\"poneyland\"), |&(k, _)| k == \"poneyland\"),\n    ///     Some(&(\"poneyland\", 42))\n    /// );\n    ///\n    /// table\n    ///     .entry(\n    ///         hasher(&\"poneyland\"),\n    ///         |&(x, _)| x == \"poneyland\",\n    ///         |(k, _)| hasher(&k),\n    ///     )\n    ///     .and_modify(|(_, v)| *v += 1)\n    ///     .or_insert((\"poneyland\", 42));\n    /// assert_eq!(\n    ///     table.find(hasher(&\"poneyland\"), |&(k, _)| k == \"poneyland\"),\n    ///     Some(&(\"poneyland\", 43))\n    /// );\n    /// # }\n    /// # fn main() {\n    /// #     #[cfg(feature = \"nightly\")]\n    /// #     test()\n    /// # }\n    /// ```\n    pub fn and_modify(self, f: impl FnOnce(&mut T)) -> Self {\n        match self {\n            Entry::Occupied(mut entry) => {\n                f(entry.get_mut());\n                Entry::Occupied(entry)\n            }\n            Entry::Vacant(entry) => Entry::Vacant(entry),\n        }\n    }\n}",
            "impl<T: fmt::Debug, A: Allocator> fmt::Debug for Entry<'_, T, A> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        match *self {\n            Entry::Vacant(ref v) => f.debug_tuple(\"Entry\").field(v).finish(),\n            Entry::Occupied(ref o) => f.debug_tuple(\"Entry\").field(o).finish(),\n        }\n    }\n}"
        ],
        "table::ExtractIf": [
            "impl<T, F, A: Allocator> FusedIterator for ExtractIf<'_, T, F, A> where F: FnMut(&mut T) -> bool {}",
            "impl<T, F, A: Allocator> Iterator for ExtractIf<'_, T, F, A>\nwhere\n    F: FnMut(&mut T) -> bool,\n{\n    type Item = T;\n\n    #[inline]\n    fn next(&mut self) -> Option<Self::Item> {\n        self.inner.next(|val| (self.f)(val))\n    }\n\n    #[inline]\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        (0, self.inner.iter.size_hint().1)\n    }\n}"
        ],
        "table::HashTable": [
            "impl<T, A> Clone for HashTable<T, A>\nwhere\n    T: Clone,\n    A: Allocator + Clone,\n{\n    fn clone(&self) -> Self {\n        Self {\n            raw: self.raw.clone(),\n        }\n    }\n}",
            "impl<T, A> Default for HashTable<T, A>\nwhere\n    A: Allocator + Default,\n{\n    fn default() -> Self {\n        Self {\n            raw: Default::default(),\n        }\n    }\n}",
            "impl<T, A> HashTable<T, A>\nwhere\n    A: Allocator,\n{\n    /// Creates an empty `HashTable` using the given allocator.\n    ///\n    /// The hash table is initially created with a capacity of 0, so it will not allocate until it\n    /// is first inserted into.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// # #[cfg(feature = \"nightly\")]\n    /// # fn test() {\n    /// use bumpalo::Bump;\n    /// use hashbrown::{HashTable, DefaultHashBuilder};\n    /// use std::hash::BuildHasher;\n    ///\n    /// let bump = Bump::new();\n    /// let mut table = HashTable::new_in(&bump);\n    /// let hasher = DefaultHashBuilder::default();\n    /// let hasher = |val: &_| hasher.hash_one(val);\n    ///\n    /// // The created HashTable holds none elements\n    /// assert_eq!(table.len(), 0);\n    ///\n    /// // The created HashTable also doesn't allocate memory\n    /// assert_eq!(table.capacity(), 0);\n    ///\n    /// // Now we insert element inside created HashTable\n    /// table.insert_unique(hasher(&\"One\"), \"One\", hasher);\n    /// // We can see that the HashTable holds 1 element\n    /// assert_eq!(table.len(), 1);\n    /// // And it also allocates some capacity\n    /// assert!(table.capacity() > 1);\n    /// # }\n    /// # fn main() {\n    /// #     #[cfg(feature = \"nightly\")]\n    /// #     test()\n    /// # }\n    /// ```\n    pub const fn new_in(alloc: A) -> Self {\n        Self {\n            raw: RawTable::new_in(alloc),\n        }\n    }\n\n    /// Creates an empty `HashTable` with the specified capacity using the given allocator.\n    ///\n    /// The hash table will be able to hold at least `capacity` elements without\n    /// reallocating. If `capacity` is 0, the hash table will not allocate.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// # #[cfg(feature = \"nightly\")]\n    /// # fn test() {\n    /// use bumpalo::Bump;\n    /// use hashbrown::{HashTable, DefaultHashBuilder};\n    /// use std::hash::BuildHasher;\n    ///\n    /// let bump = Bump::new();\n    /// let mut table = HashTable::with_capacity_in(5, &bump);\n    /// let hasher = DefaultHashBuilder::default();\n    /// let hasher = |val: &_| hasher.hash_one(val);\n    ///\n    /// // The created HashTable holds none elements\n    /// assert_eq!(table.len(), 0);\n    /// // But it can hold at least 5 elements without reallocating\n    /// let empty_map_capacity = table.capacity();\n    /// assert!(empty_map_capacity >= 5);\n    ///\n    /// // Now we insert some 5 elements inside created HashTable\n    /// table.insert_unique(hasher(&\"One\"), \"One\", hasher);\n    /// table.insert_unique(hasher(&\"Two\"), \"Two\", hasher);\n    /// table.insert_unique(hasher(&\"Three\"), \"Three\", hasher);\n    /// table.insert_unique(hasher(&\"Four\"), \"Four\", hasher);\n    /// table.insert_unique(hasher(&\"Five\"), \"Five\", hasher);\n    ///\n    /// // We can see that the HashTable holds 5 elements\n    /// assert_eq!(table.len(), 5);\n    /// // But its capacity isn't changed\n    /// assert_eq!(table.capacity(), empty_map_capacity)\n    /// # }\n    /// # fn main() {\n    /// #     #[cfg(feature = \"nightly\")]\n    /// #     test()\n    /// # }\n    /// ```\n    pub fn with_capacity_in(capacity: usize, alloc: A) -> Self {\n        Self {\n            raw: RawTable::with_capacity_in(capacity, alloc),\n        }\n    }\n\n    /// Returns a reference to the underlying allocator.\n    pub fn allocator(&self) -> &A {\n        self.raw.allocator()\n    }\n\n    /// Returns a reference to an entry in the table with the given hash and\n    /// which satisfies the equality function passed.\n    ///\n    /// This method will call `eq` for all entries with the given hash, but may\n    /// also call it for entries with a different hash. `eq` should only return\n    /// true for the desired entry, at which point the search is stopped.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// # #[cfg(feature = \"nightly\")]\n    /// # fn test() {\n    /// use hashbrown::{HashTable, DefaultHashBuilder};\n    /// use std::hash::BuildHasher;\n    ///\n    /// let mut table = HashTable::new();\n    /// let hasher = DefaultHashBuilder::default();\n    /// let hasher = |val: &_| hasher.hash_one(val);\n    /// table.insert_unique(hasher(&1), 1, hasher);\n    /// table.insert_unique(hasher(&2), 2, hasher);\n    /// table.insert_unique(hasher(&3), 3, hasher);\n    /// assert_eq!(table.find(hasher(&2), |&val| val == 2), Some(&2));\n    /// assert_eq!(table.find(hasher(&4), |&val| val == 4), None);\n    /// # }\n    /// # fn main() {\n    /// #     #[cfg(feature = \"nightly\")]\n    /// #     test()\n    /// # }\n    /// ```\n    pub fn find(&self, hash: u64, eq: impl FnMut(&T) -> bool) -> Option<&T> {\n        self.raw.get(hash, eq)\n    }\n\n    /// Returns a mutable reference to an entry in the table with the given hash\n    /// and which satisfies the equality function passed.\n    ///\n    /// This method will call `eq` for all entries with the given hash, but may\n    /// also call it for entries with a different hash. `eq` should only return\n    /// true for the desired entry, at which point the search is stopped.\n    ///\n    /// When mutating an entry, you should ensure that it still retains the same\n    /// hash value as when it was inserted, otherwise lookups of that entry may\n    /// fail to find it.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// # #[cfg(feature = \"nightly\")]\n    /// # fn test() {\n    /// use hashbrown::{HashTable, DefaultHashBuilder};\n    /// use std::hash::BuildHasher;\n    ///\n    /// let mut table = HashTable::new();\n    /// let hasher = DefaultHashBuilder::default();\n    /// let hasher = |val: &_| hasher.hash_one(val);\n    /// table.insert_unique(hasher(&1), (1, \"a\"), |val| hasher(&val.0));\n    /// if let Some(val) = table.find_mut(hasher(&1), |val| val.0 == 1) {\n    ///     val.1 = \"b\";\n    /// }\n    /// assert_eq!(table.find(hasher(&1), |val| val.0 == 1), Some(&(1, \"b\")));\n    /// assert_eq!(table.find(hasher(&2), |val| val.0 == 2), None);\n    /// # }\n    /// # fn main() {\n    /// #     #[cfg(feature = \"nightly\")]\n    /// #     test()\n    /// # }\n    /// ```\n    pub fn find_mut(&mut self, hash: u64, eq: impl FnMut(&T) -> bool) -> Option<&mut T> {\n        self.raw.get_mut(hash, eq)\n    }\n\n    /// Returns an `OccupiedEntry` for an entry in the table with the given hash\n    /// and which satisfies the equality function passed.\n    ///\n    /// This can be used to remove the entry from the table. Call\n    /// [`HashTable::entry`] instead if you wish to insert an entry if the\n    /// lookup fails.\n    ///\n    /// This method will call `eq` for all entries with the given hash, but may\n    /// also call it for entries with a different hash. `eq` should only return\n    /// true for the desired entry, at which point the search is stopped.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// # #[cfg(feature = \"nightly\")]\n    /// # fn test() {\n    /// use hashbrown::{HashTable, DefaultHashBuilder};\n    /// use std::hash::BuildHasher;\n    ///\n    /// let mut table = HashTable::new();\n    /// let hasher = DefaultHashBuilder::default();\n    /// let hasher = |val: &_| hasher.hash_one(val);\n    /// table.insert_unique(hasher(&1), (1, \"a\"), |val| hasher(&val.0));\n    /// if let Ok(entry) = table.find_entry(hasher(&1), |val| val.0 == 1) {\n    ///     entry.remove();\n    /// }\n    /// assert_eq!(table.find(hasher(&1), |val| val.0 == 1), None);\n    /// # }\n    /// # fn main() {\n    /// #     #[cfg(feature = \"nightly\")]\n    /// #     test()\n    /// # }\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn find_entry(\n        &mut self,\n        hash: u64,\n        eq: impl FnMut(&T) -> bool,\n    ) -> Result<OccupiedEntry<'_, T, A>, AbsentEntry<'_, T, A>> {\n        match self.raw.find(hash, eq) {\n            Some(bucket) => Ok(OccupiedEntry {\n                hash,\n                bucket,\n                table: self,\n            }),\n            None => Err(AbsentEntry { table: self }),\n        }\n    }\n\n    /// Returns an `Entry` for an entry in the table with the given hash\n    /// and which satisfies the equality function passed.\n    ///\n    /// This can be used to remove the entry from the table, or insert a new\n    /// entry with the given hash if one doesn't already exist.\n    ///\n    /// This method will call `eq` for all entries with the given hash, but may\n    /// also call it for entries with a different hash. `eq` should only return\n    /// true for the desired entry, at which point the search is stopped.\n    ///\n    /// This method may grow the table in preparation for an insertion. Call\n    /// [`HashTable::find_entry`] if this is undesirable.\n    ///\n    /// `hasher` is called if entries need to be moved or copied to a new table.\n    /// This must return the same hash value that each entry was inserted with.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// # #[cfg(feature = \"nightly\")]\n    /// # fn test() {\n    /// use hashbrown::hash_table::Entry;\n    /// use hashbrown::{HashTable, DefaultHashBuilder};\n    /// use std::hash::BuildHasher;\n    ///\n    /// let mut table = HashTable::new();\n    /// let hasher = DefaultHashBuilder::default();\n    /// let hasher = |val: &_| hasher.hash_one(val);\n    /// table.insert_unique(hasher(&1), (1, \"a\"), |val| hasher(&val.0));\n    /// if let Entry::Occupied(entry) = table.entry(hasher(&1), |val| val.0 == 1, |val| hasher(&val.0))\n    /// {\n    ///     entry.remove();\n    /// }\n    /// if let Entry::Vacant(entry) = table.entry(hasher(&2), |val| val.0 == 2, |val| hasher(&val.0)) {\n    ///     entry.insert((2, \"b\"));\n    /// }\n    /// assert_eq!(table.find(hasher(&1), |val| val.0 == 1), None);\n    /// assert_eq!(table.find(hasher(&2), |val| val.0 == 2), Some(&(2, \"b\")));\n    /// # }\n    /// # fn main() {\n    /// #     #[cfg(feature = \"nightly\")]\n    /// #     test()\n    /// # }\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn entry(\n        &mut self,\n        hash: u64,\n        eq: impl FnMut(&T) -> bool,\n        hasher: impl Fn(&T) -> u64,\n    ) -> Entry<'_, T, A> {\n        match self.raw.find_or_find_insert_slot(hash, eq, hasher) {\n            Ok(bucket) => Entry::Occupied(OccupiedEntry {\n                hash,\n                bucket,\n                table: self,\n            }),\n            Err(insert_slot) => Entry::Vacant(VacantEntry {\n                hash,\n                insert_slot,\n                table: self,\n            }),\n        }\n    }\n\n    /// Inserts an element into the `HashTable` with the given hash value, but\n    /// without checking whether an equivalent element already exists within the\n    /// table.\n    ///\n    /// `hasher` is called if entries need to be moved or copied to a new table.\n    /// This must return the same hash value that each entry was inserted with.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// # #[cfg(feature = \"nightly\")]\n    /// # fn test() {\n    /// use hashbrown::{HashTable, DefaultHashBuilder};\n    /// use std::hash::BuildHasher;\n    ///\n    /// let mut v = HashTable::new();\n    /// let hasher = DefaultHashBuilder::default();\n    /// let hasher = |val: &_| hasher.hash_one(val);\n    /// v.insert_unique(hasher(&1), 1, hasher);\n    /// # }\n    /// # fn main() {\n    /// #     #[cfg(feature = \"nightly\")]\n    /// #     test()\n    /// # }\n    /// ```\n    pub fn insert_unique(\n        &mut self,\n        hash: u64,\n        value: T,\n        hasher: impl Fn(&T) -> u64,\n    ) -> OccupiedEntry<'_, T, A> {\n        let bucket = self.raw.insert(hash, value, hasher);\n        OccupiedEntry {\n            hash,\n            bucket,\n            table: self,\n        }\n    }\n\n    /// Clears the table, removing all values.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// # #[cfg(feature = \"nightly\")]\n    /// # fn test() {\n    /// use hashbrown::{HashTable, DefaultHashBuilder};\n    /// use std::hash::BuildHasher;\n    ///\n    /// let mut v = HashTable::new();\n    /// let hasher = DefaultHashBuilder::default();\n    /// let hasher = |val: &_| hasher.hash_one(val);\n    /// v.insert_unique(hasher(&1), 1, hasher);\n    /// v.clear();\n    /// assert!(v.is_empty());\n    /// # }\n    /// # fn main() {\n    /// #     #[cfg(feature = \"nightly\")]\n    /// #     test()\n    /// # }\n    /// ```\n    pub fn clear(&mut self) {\n        self.raw.clear();\n    }\n\n    /// Shrinks the capacity of the table as much as possible. It will drop\n    /// down as much as possible while maintaining the internal rules\n    /// and possibly leaving some space in accordance with the resize policy.\n    ///\n    /// `hasher` is called if entries need to be moved or copied to a new table.\n    /// This must return the same hash value that each entry was inserted with.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// # #[cfg(feature = \"nightly\")]\n    /// # fn test() {\n    /// use hashbrown::{HashTable, DefaultHashBuilder};\n    /// use std::hash::BuildHasher;\n    ///\n    /// let mut table = HashTable::with_capacity(100);\n    /// let hasher = DefaultHashBuilder::default();\n    /// let hasher = |val: &_| hasher.hash_one(val);\n    /// table.insert_unique(hasher(&1), 1, hasher);\n    /// table.insert_unique(hasher(&2), 2, hasher);\n    /// assert!(table.capacity() >= 100);\n    /// table.shrink_to_fit(hasher);\n    /// assert!(table.capacity() >= 2);\n    /// # }\n    /// # fn main() {\n    /// #     #[cfg(feature = \"nightly\")]\n    /// #     test()\n    /// # }\n    /// ```\n    pub fn shrink_to_fit(&mut self, hasher: impl Fn(&T) -> u64) {\n        self.raw.shrink_to(self.len(), hasher)\n    }\n\n    /// Shrinks the capacity of the table with a lower limit. It will drop\n    /// down no lower than the supplied limit while maintaining the internal rules\n    /// and possibly leaving some space in accordance with the resize policy.\n    ///\n    /// `hasher` is called if entries need to be moved or copied to a new table.\n    /// This must return the same hash value that each entry was inserted with.\n    ///\n    /// Panics if the current capacity is smaller than the supplied\n    /// minimum capacity.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// # #[cfg(feature = \"nightly\")]\n    /// # fn test() {\n    /// use hashbrown::{HashTable, DefaultHashBuilder};\n    /// use std::hash::BuildHasher;\n    ///\n    /// let mut table = HashTable::with_capacity(100);\n    /// let hasher = DefaultHashBuilder::default();\n    /// let hasher = |val: &_| hasher.hash_one(val);\n    /// table.insert_unique(hasher(&1), 1, hasher);\n    /// table.insert_unique(hasher(&2), 2, hasher);\n    /// assert!(table.capacity() >= 100);\n    /// table.shrink_to(10, hasher);\n    /// assert!(table.capacity() >= 10);\n    /// table.shrink_to(0, hasher);\n    /// assert!(table.capacity() >= 2);\n    /// # }\n    /// # fn main() {\n    /// #     #[cfg(feature = \"nightly\")]\n    /// #     test()\n    /// # }\n    /// ```\n    pub fn shrink_to(&mut self, min_capacity: usize, hasher: impl Fn(&T) -> u64) {\n        self.raw.shrink_to(min_capacity, hasher);\n    }\n\n    /// Reserves capacity for at least `additional` more elements to be inserted\n    /// in the `HashTable`. The collection may reserve more space to avoid\n    /// frequent reallocations.\n    ///\n    /// `hasher` is called if entries need to be moved or copied to a new table.\n    /// This must return the same hash value that each entry was inserted with.\n    ///\n    /// # Panics\n    ///\n    /// Panics if the new capacity exceeds [`isize::MAX`] bytes and [`abort`] the program\n    /// in case of allocation error. Use [`try_reserve`](HashTable::try_reserve) instead\n    /// if you want to handle memory allocation failure.\n    ///\n    /// [`isize::MAX`]: https://doc.rust-lang.org/std/primitive.isize.html\n    /// [`abort`]: https://doc.rust-lang.org/alloc/alloc/fn.handle_alloc_error.html\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// # #[cfg(feature = \"nightly\")]\n    /// # fn test() {\n    /// use hashbrown::{HashTable, DefaultHashBuilder};\n    /// use std::hash::BuildHasher;\n    ///\n    /// let mut table: HashTable<i32> = HashTable::new();\n    /// let hasher = DefaultHashBuilder::default();\n    /// let hasher = |val: &_| hasher.hash_one(val);\n    /// table.reserve(10, hasher);\n    /// assert!(table.capacity() >= 10);\n    /// # }\n    /// # fn main() {\n    /// #     #[cfg(feature = \"nightly\")]\n    /// #     test()\n    /// # }\n    /// ```\n    pub fn reserve(&mut self, additional: usize, hasher: impl Fn(&T) -> u64) {\n        self.raw.reserve(additional, hasher)\n    }\n\n    /// Tries to reserve capacity for at least `additional` more elements to be inserted\n    /// in the given `HashTable`. The collection may reserve more space to avoid\n    /// frequent reallocations.\n    ///\n    /// `hasher` is called if entries need to be moved or copied to a new table.\n    /// This must return the same hash value that each entry was inserted with.\n    ///\n    /// # Errors\n    ///\n    /// If the capacity overflows, or the allocator reports a failure, then an error\n    /// is returned.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// # #[cfg(feature = \"nightly\")]\n    /// # fn test() {\n    /// use hashbrown::{HashTable, DefaultHashBuilder};\n    /// use std::hash::BuildHasher;\n    ///\n    /// let mut table: HashTable<i32> = HashTable::new();\n    /// let hasher = DefaultHashBuilder::default();\n    /// let hasher = |val: &_| hasher.hash_one(val);\n    /// table\n    ///     .try_reserve(10, hasher)\n    ///     .expect(\"why is the test harness OOMing on 10 bytes?\");\n    /// # }\n    /// # fn main() {\n    /// #     #[cfg(feature = \"nightly\")]\n    /// #     test()\n    /// # }\n    /// ```\n    pub fn try_reserve(\n        &mut self,\n        additional: usize,\n        hasher: impl Fn(&T) -> u64,\n    ) -> Result<(), TryReserveError> {\n        self.raw.try_reserve(additional, hasher)\n    }\n\n    /// Returns the number of elements the table can hold without reallocating.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashTable;\n    /// let table: HashTable<i32> = HashTable::with_capacity(100);\n    /// assert!(table.capacity() >= 100);\n    /// ```\n    pub fn capacity(&self) -> usize {\n        self.raw.capacity()\n    }\n\n    /// Returns the number of elements in the table.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// # #[cfg(feature = \"nightly\")]\n    /// # fn test() {\n    /// use hashbrown::{HashTable, DefaultHashBuilder};\n    /// use std::hash::BuildHasher;\n    ///\n    /// let hasher = DefaultHashBuilder::default();\n    /// let hasher = |val: &_| hasher.hash_one(val);\n    /// let mut v = HashTable::new();\n    /// assert_eq!(v.len(), 0);\n    /// v.insert_unique(hasher(&1), 1, hasher);\n    /// assert_eq!(v.len(), 1);\n    /// # }\n    /// # fn main() {\n    /// #     #[cfg(feature = \"nightly\")]\n    /// #     test()\n    /// # }\n    /// ```\n    pub fn len(&self) -> usize {\n        self.raw.len()\n    }\n\n    /// Returns `true` if the set contains no elements.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// # #[cfg(feature = \"nightly\")]\n    /// # fn test() {\n    /// use hashbrown::{HashTable, DefaultHashBuilder};\n    /// use std::hash::BuildHasher;\n    ///\n    /// let hasher = DefaultHashBuilder::default();\n    /// let hasher = |val: &_| hasher.hash_one(val);\n    /// let mut v = HashTable::new();\n    /// assert!(v.is_empty());\n    /// v.insert_unique(hasher(&1), 1, hasher);\n    /// assert!(!v.is_empty());\n    /// # }\n    /// # fn main() {\n    /// #     #[cfg(feature = \"nightly\")]\n    /// #     test()\n    /// # }\n    /// ```\n    pub fn is_empty(&self) -> bool {\n        self.raw.is_empty()\n    }\n\n    /// An iterator visiting all elements in arbitrary order.\n    /// The iterator element type is `&'a T`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// # #[cfg(feature = \"nightly\")]\n    /// # fn test() {\n    /// use hashbrown::{HashTable, DefaultHashBuilder};\n    /// use std::hash::BuildHasher;\n    ///\n    /// let mut table = HashTable::new();\n    /// let hasher = DefaultHashBuilder::default();\n    /// let hasher = |val: &_| hasher.hash_one(val);\n    /// table.insert_unique(hasher(&\"a\"), \"b\", hasher);\n    /// table.insert_unique(hasher(&\"b\"), \"b\", hasher);\n    ///\n    /// // Will print in an arbitrary order.\n    /// for x in table.iter() {\n    ///     println!(\"{}\", x);\n    /// }\n    /// # }\n    /// # fn main() {\n    /// #     #[cfg(feature = \"nightly\")]\n    /// #     test()\n    /// # }\n    /// ```\n    pub fn iter(&self) -> Iter<'_, T> {\n        Iter {\n            inner: unsafe { self.raw.iter() },\n            marker: PhantomData,\n        }\n    }\n\n    /// An iterator visiting all elements in arbitrary order,\n    /// with mutable references to the elements.\n    /// The iterator element type is `&'a mut T`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// # #[cfg(feature = \"nightly\")]\n    /// # fn test() {\n    /// use hashbrown::{HashTable, DefaultHashBuilder};\n    /// use std::hash::BuildHasher;\n    ///\n    /// let mut table = HashTable::new();\n    /// let hasher = DefaultHashBuilder::default();\n    /// let hasher = |val: &_| hasher.hash_one(val);\n    /// table.insert_unique(hasher(&1), 1, hasher);\n    /// table.insert_unique(hasher(&2), 2, hasher);\n    /// table.insert_unique(hasher(&3), 3, hasher);\n    ///\n    /// // Update all values\n    /// for val in table.iter_mut() {\n    ///     *val *= 2;\n    /// }\n    ///\n    /// assert_eq!(table.len(), 3);\n    /// let mut vec: Vec<i32> = Vec::new();\n    ///\n    /// for val in &table {\n    ///     println!(\"val: {}\", val);\n    ///     vec.push(*val);\n    /// }\n    ///\n    /// // The `Iter` iterator produces items in arbitrary order, so the\n    /// // items must be sorted to test them against a sorted array.\n    /// vec.sort_unstable();\n    /// assert_eq!(vec, [2, 4, 6]);\n    ///\n    /// assert_eq!(table.len(), 3);\n    /// # }\n    /// # fn main() {\n    /// #     #[cfg(feature = \"nightly\")]\n    /// #     test()\n    /// # }\n    /// ```\n    pub fn iter_mut(&mut self) -> IterMut<'_, T> {\n        IterMut {\n            inner: unsafe { self.raw.iter() },\n            marker: PhantomData,\n        }\n    }\n\n    /// An iterator visiting all elements which may match a hash.\n    /// The iterator element type is `&'a T`.\n    ///\n    /// This iterator may return elements from the table that have a hash value\n    /// different than the one provided. You should always validate the returned\n    /// values before using them.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// # #[cfg(feature = \"nightly\")]\n    /// # fn test() {\n    /// use hashbrown::{HashTable, DefaultHashBuilder};\n    /// use std::hash::BuildHasher;\n    ///\n    /// let mut table = HashTable::new();\n    /// let hasher = DefaultHashBuilder::default();\n    /// let hasher = |val: &_| hasher.hash_one(val);\n    /// table.insert_unique(hasher(&\"a\"), \"a\", hasher);\n    /// table.insert_unique(hasher(&\"a\"), \"b\", hasher);\n    /// table.insert_unique(hasher(&\"b\"), \"c\", hasher);\n    ///\n    /// // Will print \"a\" and \"b\" (and possibly \"c\") in an arbitrary order.\n    /// for x in table.iter_hash(hasher(&\"a\")) {\n    ///     println!(\"{}\", x);\n    /// }\n    /// # }\n    /// # fn main() {\n    /// #     #[cfg(feature = \"nightly\")]\n    /// #     test()\n    /// # }\n    /// ```\n    pub fn iter_hash(&self, hash: u64) -> IterHash<'_, T> {\n        IterHash {\n            inner: unsafe { self.raw.iter_hash(hash) },\n            marker: PhantomData,\n        }\n    }\n\n    /// A mutable iterator visiting all elements which may match a hash.\n    /// The iterator element type is `&'a mut T`.\n    ///\n    /// This iterator may return elements from the table that have a hash value\n    /// different than the one provided. You should always validate the returned\n    /// values before using them.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// # #[cfg(feature = \"nightly\")]\n    /// # fn test() {\n    /// use hashbrown::{HashTable, DefaultHashBuilder};\n    /// use std::hash::BuildHasher;\n    ///\n    /// let mut table = HashTable::new();\n    /// let hasher = DefaultHashBuilder::default();\n    /// let hasher = |val: &_| hasher.hash_one(val);\n    /// table.insert_unique(hasher(&1), 2, hasher);\n    /// table.insert_unique(hasher(&1), 3, hasher);\n    /// table.insert_unique(hasher(&2), 5, hasher);\n    ///\n    /// // Update matching values\n    /// for val in table.iter_hash_mut(hasher(&1)) {\n    ///     *val *= 2;\n    /// }\n    ///\n    /// assert_eq!(table.len(), 3);\n    /// let mut vec: Vec<i32> = Vec::new();\n    ///\n    /// for val in &table {\n    ///     println!(\"val: {}\", val);\n    ///     vec.push(*val);\n    /// }\n    ///\n    /// // The values will contain 4 and 6 and may contain either 5 or 10.\n    /// assert!(vec.contains(&4));\n    /// assert!(vec.contains(&6));\n    ///\n    /// assert_eq!(table.len(), 3);\n    /// # }\n    /// # fn main() {\n    /// #     #[cfg(feature = \"nightly\")]\n    /// #     test()\n    /// # }\n    /// ```\n    pub fn iter_hash_mut(&mut self, hash: u64) -> IterHashMut<'_, T> {\n        IterHashMut {\n            inner: unsafe { self.raw.iter_hash(hash) },\n            marker: PhantomData,\n        }\n    }\n\n    /// Retains only the elements specified by the predicate.\n    ///\n    /// In other words, remove all elements `e` such that `f(&e)` returns `false`.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// # #[cfg(feature = \"nightly\")]\n    /// # fn test() {\n    /// use hashbrown::{HashTable, DefaultHashBuilder};\n    /// use std::hash::BuildHasher;\n    ///\n    /// let mut table = HashTable::new();\n    /// let hasher = DefaultHashBuilder::default();\n    /// let hasher = |val: &_| hasher.hash_one(val);\n    /// for x in 1..=6 {\n    ///     table.insert_unique(hasher(&x), x, hasher);\n    /// }\n    /// table.retain(|&mut x| x % 2 == 0);\n    /// assert_eq!(table.len(), 3);\n    /// # }\n    /// # fn main() {\n    /// #     #[cfg(feature = \"nightly\")]\n    /// #     test()\n    /// # }\n    /// ```\n    pub fn retain(&mut self, mut f: impl FnMut(&mut T) -> bool) {\n        // Here we only use `iter` as a temporary, preventing use-after-free\n        unsafe {\n            for item in self.raw.iter() {\n                if !f(item.as_mut()) {\n                    self.raw.erase(item);\n                }\n            }\n        }\n    }\n\n    /// Clears the set, returning all elements in an iterator.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// # #[cfg(feature = \"nightly\")]\n    /// # fn test() {\n    /// use hashbrown::{HashTable, DefaultHashBuilder};\n    /// use std::hash::BuildHasher;\n    ///\n    /// let mut table = HashTable::new();\n    /// let hasher = DefaultHashBuilder::default();\n    /// let hasher = |val: &_| hasher.hash_one(val);\n    /// for x in 1..=3 {\n    ///     table.insert_unique(hasher(&x), x, hasher);\n    /// }\n    /// assert!(!table.is_empty());\n    ///\n    /// // print 1, 2, 3 in an arbitrary order\n    /// for i in table.drain() {\n    ///     println!(\"{}\", i);\n    /// }\n    ///\n    /// assert!(table.is_empty());\n    /// # }\n    /// # fn main() {\n    /// #     #[cfg(feature = \"nightly\")]\n    /// #     test()\n    /// # }\n    /// ```\n    pub fn drain(&mut self) -> Drain<'_, T, A> {\n        Drain {\n            inner: self.raw.drain(),\n        }\n    }\n\n    /// Drains elements which are true under the given predicate,\n    /// and returns an iterator over the removed items.\n    ///\n    /// In other words, move all elements `e` such that `f(&e)` returns `true` out\n    /// into another iterator.\n    ///\n    /// If the returned `ExtractIf` is not exhausted, e.g. because it is dropped without iterating\n    /// or the iteration short-circuits, then the remaining elements will be retained.\n    /// Use [`retain()`] with a negated predicate if you do not need the returned iterator.\n    ///\n    /// [`retain()`]: HashTable::retain\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// # #[cfg(feature = \"nightly\")]\n    /// # fn test() {\n    /// use hashbrown::{HashTable, DefaultHashBuilder};\n    /// use std::hash::BuildHasher;\n    ///\n    /// let mut table = HashTable::new();\n    /// let hasher = DefaultHashBuilder::default();\n    /// let hasher = |val: &_| hasher.hash_one(val);\n    /// for x in 0..8 {\n    ///     table.insert_unique(hasher(&x), x, hasher);\n    /// }\n    /// let drained: Vec<i32> = table.extract_if(|&mut v| v % 2 == 0).collect();\n    ///\n    /// let mut evens = drained.into_iter().collect::<Vec<_>>();\n    /// let mut odds = table.into_iter().collect::<Vec<_>>();\n    /// evens.sort();\n    /// odds.sort();\n    ///\n    /// assert_eq!(evens, vec![0, 2, 4, 6]);\n    /// assert_eq!(odds, vec![1, 3, 5, 7]);\n    /// # }\n    /// # fn main() {\n    /// #     #[cfg(feature = \"nightly\")]\n    /// #     test()\n    /// # }\n    /// ```\n    pub fn extract_if<F>(&mut self, f: F) -> ExtractIf<'_, T, F, A>\n    where\n        F: FnMut(&mut T) -> bool,\n    {\n        ExtractIf {\n            f,\n            inner: RawExtractIf {\n                iter: unsafe { self.raw.iter() },\n                table: &mut self.raw,\n            },\n        }\n    }\n\n    /// Attempts to get mutable references to `N` values in the map at once.\n    ///\n    /// The `eq` argument should be a closure such that `eq(i, k)` returns true if `k` is equal to\n    /// the `i`th key to be looked up.\n    ///\n    /// Returns an array of length `N` with the results of each query. For soundness, at most one\n    /// mutable reference will be returned to any value. `None` will be used if the key is missing.\n    ///\n    /// # Panics\n    ///\n    /// Panics if any keys are overlapping.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// # #[cfg(feature = \"nightly\")]\n    /// # fn test() {\n    /// use hashbrown::hash_table::Entry;\n    /// use hashbrown::{HashTable, DefaultHashBuilder};\n    /// use std::hash::BuildHasher;\n    ///\n    /// let mut libraries: HashTable<(&str, u32)> = HashTable::new();\n    /// let hasher = DefaultHashBuilder::default();\n    /// let hasher = |val: &_| hasher.hash_one(val);\n    /// for (k, v) in [\n    ///     (\"Bodleian Library\", 1602),\n    ///     (\"Athenum\", 1807),\n    ///     (\"Herzogin-Anna-Amalia-Bibliothek\", 1691),\n    ///     (\"Library of Congress\", 1800),\n    /// ] {\n    ///     libraries.insert_unique(hasher(&k), (k, v), |(k, _)| hasher(&k));\n    /// }\n    ///\n    /// let keys = [\"Athenum\", \"Library of Congress\"];\n    /// let got = libraries.get_many_mut(keys.map(|k| hasher(&k)), |i, val| keys[i] == val.0);\n    /// assert_eq!(\n    ///     got,\n    ///     [Some(&mut (\"Athenum\", 1807)), Some(&mut (\"Library of Congress\", 1800))],\n    /// );\n    ///\n    /// // Missing keys result in None\n    /// let keys = [\"Athenum\", \"New York Public Library\"];\n    /// let got = libraries.get_many_mut(keys.map(|k| hasher(&k)), |i, val| keys[i] == val.0);\n    /// assert_eq!(got, [Some(&mut (\"Athenum\", 1807)), None]);\n    /// # }\n    /// # fn main() {\n    /// #     #[cfg(feature = \"nightly\")]\n    /// #     test()\n    /// # }\n    /// ```\n    ///\n    /// ```should_panic\n    /// # #[cfg(feature = \"nightly\")]\n    /// # fn test() {\n    /// # use hashbrown::{HashTable, DefaultHashBuilder};\n    /// # use std::hash::BuildHasher;\n    ///\n    /// let mut libraries: HashTable<(&str, u32)> = HashTable::new();\n    /// let hasher = DefaultHashBuilder::default();\n    /// let hasher = |val: &_| hasher.hash_one(val);\n    /// for (k, v) in [\n    ///     (\"Athenum\", 1807),\n    ///     (\"Library of Congress\", 1800),\n    /// ] {\n    ///     libraries.insert_unique(hasher(&k), (k, v), |(k, _)| hasher(&k));\n    /// }\n    ///\n    /// // Duplicate keys result in a panic!\n    /// let keys = [\"Athenum\", \"Athenum\"];\n    /// let got = libraries.get_many_mut(keys.map(|k| hasher(&k)), |i, val| keys[i] == val.0);\n    /// # }\n    /// # fn main() {\n    /// #     #[cfg(feature = \"nightly\")]\n    /// #     test();\n    /// #     #[cfg(not(feature = \"nightly\"))]\n    /// #     panic!();\n    /// # }\n    /// ```\n    pub fn get_many_mut<const N: usize>(\n        &mut self,\n        hashes: [u64; N],\n        eq: impl FnMut(usize, &T) -> bool,\n    ) -> [Option<&'_ mut T>; N] {\n        self.raw.get_many_mut(hashes, eq)\n    }\n\n    /// Attempts to get mutable references to `N` values in the map at once, without validating that\n    /// the values are unique.\n    ///\n    /// The `eq` argument should be a closure such that `eq(i, k)` returns true if `k` is equal to\n    /// the `i`th key to be looked up.\n    ///\n    /// Returns an array of length `N` with the results of each query. `None` will be returned if\n    /// any of the keys are missing.\n    ///\n    /// For a safe alternative see [`get_many_mut`](`HashTable::get_many_mut`).\n    ///\n    /// # Safety\n    ///\n    /// Calling this method with overlapping keys is *[undefined behavior]* even if the resulting\n    /// references are not used.\n    ///\n    /// [undefined behavior]: https://doc.rust-lang.org/reference/behavior-considered-undefined.html\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// # #[cfg(feature = \"nightly\")]\n    /// # fn test() {\n    /// use hashbrown::hash_table::Entry;\n    /// use hashbrown::{HashTable, DefaultHashBuilder};\n    /// use std::hash::BuildHasher;\n    ///\n    /// let mut libraries: HashTable<(&str, u32)> = HashTable::new();\n    /// let hasher = DefaultHashBuilder::default();\n    /// let hasher = |val: &_| hasher.hash_one(val);\n    /// for (k, v) in [\n    ///     (\"Bodleian Library\", 1602),\n    ///     (\"Athenum\", 1807),\n    ///     (\"Herzogin-Anna-Amalia-Bibliothek\", 1691),\n    ///     (\"Library of Congress\", 1800),\n    /// ] {\n    ///     libraries.insert_unique(hasher(&k), (k, v), |(k, _)| hasher(&k));\n    /// }\n    ///\n    /// let keys = [\"Athenum\", \"Library of Congress\"];\n    /// let got = libraries.get_many_mut(keys.map(|k| hasher(&k)), |i, val| keys[i] == val.0);\n    /// assert_eq!(\n    ///     got,\n    ///     [Some(&mut (\"Athenum\", 1807)), Some(&mut (\"Library of Congress\", 1800))],\n    /// );\n    ///\n    /// // Missing keys result in None\n    /// let keys = [\"Athenum\", \"New York Public Library\"];\n    /// let got = libraries.get_many_mut(keys.map(|k| hasher(&k)), |i, val| keys[i] == val.0);\n    /// assert_eq!(got, [Some(&mut (\"Athenum\", 1807)), None]);\n    /// # }\n    /// # fn main() {\n    /// #     #[cfg(feature = \"nightly\")]\n    /// #     test()\n    /// # }\n    /// ```\n    pub unsafe fn get_many_unchecked_mut<const N: usize>(\n        &mut self,\n        hashes: [u64; N],\n        eq: impl FnMut(usize, &T) -> bool,\n    ) -> [Option<&'_ mut T>; N] {\n        self.raw.get_many_unchecked_mut(hashes, eq)\n    }\n\n    /// Returns the total amount of memory allocated internally by the hash\n    /// table, in bytes.\n    ///\n    /// The returned number is informational only. It is intended to be\n    /// primarily used for memory profiling.\n    #[inline]\n    pub fn allocation_size(&self) -> usize {\n        self.raw.allocation_size()\n    }\n}",
            "impl<T, A> IntoIterator for HashTable<T, A>\nwhere\n    A: Allocator,\n{\n    type Item = T;\n    type IntoIter = IntoIter<T, A>;\n\n    fn into_iter(self) -> IntoIter<T, A> {\n        IntoIter {\n            inner: self.raw.into_iter(),\n        }\n    }\n}",
            "impl<T, A> fmt::Debug for HashTable<T, A>\nwhere\n    T: fmt::Debug,\n    A: Allocator,\n{\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_set().entries(self.iter()).finish()\n    }\n}",
            "impl<T> HashTable<T, Global> {\n    /// Creates an empty `HashTable`.\n    ///\n    /// The hash table is initially created with a capacity of 0, so it will not allocate until it\n    /// is first inserted into.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashTable;\n    /// let mut table: HashTable<&str> = HashTable::new();\n    /// assert_eq!(table.len(), 0);\n    /// assert_eq!(table.capacity(), 0);\n    /// ```\n    pub const fn new() -> Self {\n        Self {\n            raw: RawTable::new(),\n        }\n    }\n\n    /// Creates an empty `HashTable` with the specified capacity.\n    ///\n    /// The hash table will be able to hold at least `capacity` elements without\n    /// reallocating. If `capacity` is 0, the hash table will not allocate.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::HashTable;\n    /// let mut table: HashTable<&str> = HashTable::with_capacity(10);\n    /// assert_eq!(table.len(), 0);\n    /// assert!(table.capacity() >= 10);\n    /// ```\n    pub fn with_capacity(capacity: usize) -> Self {\n        Self {\n            raw: RawTable::with_capacity(capacity),\n        }\n    }\n}"
        ],
        "table::IntoIter": [
            "impl<T, A: Allocator> Default for IntoIter<T, A> {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn default() -> Self {\n        IntoIter {\n            inner: Default::default(),\n        }\n    }\n}",
            "impl<T, A> ExactSizeIterator for IntoIter<T, A>\nwhere\n    A: Allocator,\n{\n    fn len(&self) -> usize {\n        self.inner.len()\n    }\n}",
            "impl<T, A> FusedIterator for IntoIter<T, A> where A: Allocator {}",
            "impl<T, A> Iterator for IntoIter<T, A>\nwhere\n    A: Allocator,\n{\n    type Item = T;\n\n    fn next(&mut self) -> Option<Self::Item> {\n        self.inner.next()\n    }\n\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.inner.size_hint()\n    }\n\n    fn fold<B, F>(self, init: B, f: F) -> B\n    where\n        Self: Sized,\n        F: FnMut(B, Self::Item) -> B,\n    {\n        self.inner.fold(init, f)\n    }\n}",
            "impl<T, A> fmt::Debug for IntoIter<T, A>\nwhere\n    T: fmt::Debug,\n    A: Allocator,\n{\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_list()\n            .entries(Iter {\n                inner: self.inner.iter(),\n                marker: PhantomData,\n            })\n            .finish()\n    }\n}"
        ],
        "table::Iter": [
            "impl<'a, T> Clone for Iter<'a, T> {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn clone(&self) -> Iter<'a, T> {\n        Iter {\n            inner: self.inner.clone(),\n            marker: PhantomData,\n        }\n    }\n}",
            "impl<'a, T> Iterator for Iter<'a, T> {\n    type Item = &'a T;\n\n    fn next(&mut self) -> Option<Self::Item> {\n        // Avoid `Option::map` because it bloats LLVM IR.\n        match self.inner.next() {\n            Some(bucket) => Some(unsafe { bucket.as_ref() }),\n            None => None,\n        }\n    }\n\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.inner.size_hint()\n    }\n\n    fn fold<B, F>(self, init: B, mut f: F) -> B\n    where\n        Self: Sized,\n        F: FnMut(B, Self::Item) -> B,\n    {\n        self.inner\n            .fold(init, |acc, bucket| unsafe { f(acc, bucket.as_ref()) })\n    }\n}",
            "impl<T: fmt::Debug> fmt::Debug for Iter<'_, T> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_list().entries(self.clone()).finish()\n    }\n}",
            "impl<T> Default for Iter<'_, T> {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn default() -> Self {\n        Iter {\n            inner: Default::default(),\n            marker: PhantomData,\n        }\n    }\n}",
            "impl<T> ExactSizeIterator for Iter<'_, T> {\n    fn len(&self) -> usize {\n        self.inner.len()\n    }\n}",
            "impl<T> FusedIterator for Iter<'_, T> {}"
        ],
        "table::IterHash": [
            "impl<'a, T> Clone for IterHash<'a, T> {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn clone(&self) -> IterHash<'a, T> {\n        IterHash {\n            inner: self.inner.clone(),\n            marker: PhantomData,\n        }\n    }\n}",
            "impl<'a, T> Iterator for IterHash<'a, T> {\n    type Item = &'a T;\n\n    fn next(&mut self) -> Option<Self::Item> {\n        // Avoid `Option::map` because it bloats LLVM IR.\n        match self.inner.next() {\n            Some(bucket) => Some(unsafe { bucket.as_ref() }),\n            None => None,\n        }\n    }\n\n    fn fold<B, F>(self, init: B, mut f: F) -> B\n    where\n        Self: Sized,\n        F: FnMut(B, Self::Item) -> B,\n    {\n        self.inner\n            .fold(init, |acc, bucket| unsafe { f(acc, bucket.as_ref()) })\n    }\n}",
            "impl<T> Default for IterHash<'_, T> {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn default() -> Self {\n        IterHash {\n            inner: Default::default(),\n            marker: PhantomData,\n        }\n    }\n}",
            "impl<T> FusedIterator for IterHash<'_, T> {}",
            "impl<T> fmt::Debug for IterHash<'_, T>\nwhere\n    T: fmt::Debug,\n{\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_list().entries(self.clone()).finish()\n    }\n}"
        ],
        "table::IterHashMut": [
            "impl<'a, T> Iterator for IterHashMut<'a, T> {\n    type Item = &'a mut T;\n\n    fn next(&mut self) -> Option<Self::Item> {\n        // Avoid `Option::map` because it bloats LLVM IR.\n        match self.inner.next() {\n            Some(bucket) => Some(unsafe { bucket.as_mut() }),\n            None => None,\n        }\n    }\n\n    fn fold<B, F>(self, init: B, mut f: F) -> B\n    where\n        Self: Sized,\n        F: FnMut(B, Self::Item) -> B,\n    {\n        self.inner\n            .fold(init, |acc, bucket| unsafe { f(acc, bucket.as_mut()) })\n    }\n}",
            "impl<T> Default for IterHashMut<'_, T> {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn default() -> Self {\n        IterHashMut {\n            inner: Default::default(),\n            marker: PhantomData,\n        }\n    }\n}",
            "impl<T> FusedIterator for IterHashMut<'_, T> {}",
            "impl<T> fmt::Debug for IterHashMut<'_, T>\nwhere\n    T: fmt::Debug,\n{\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_list()\n            .entries(IterHash {\n                inner: self.inner.clone(),\n                marker: PhantomData,\n            })\n            .finish()\n    }\n}"
        ],
        "table::IterMut": [
            "impl<'a, T> Iterator for IterMut<'a, T> {\n    type Item = &'a mut T;\n\n    fn next(&mut self) -> Option<Self::Item> {\n        // Avoid `Option::map` because it bloats LLVM IR.\n        match self.inner.next() {\n            Some(bucket) => Some(unsafe { bucket.as_mut() }),\n            None => None,\n        }\n    }\n\n    fn size_hint(&self) -> (usize, Option<usize>) {\n        self.inner.size_hint()\n    }\n\n    fn fold<B, F>(self, init: B, mut f: F) -> B\n    where\n        Self: Sized,\n        F: FnMut(B, Self::Item) -> B,\n    {\n        self.inner\n            .fold(init, |acc, bucket| unsafe { f(acc, bucket.as_mut()) })\n    }\n}",
            "impl<T> Default for IterMut<'_, T> {\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    fn default() -> Self {\n        IterMut {\n            inner: Default::default(),\n            marker: PhantomData,\n        }\n    }\n}",
            "impl<T> ExactSizeIterator for IterMut<'_, T> {\n    fn len(&self) -> usize {\n        self.inner.len()\n    }\n}",
            "impl<T> FusedIterator for IterMut<'_, T> {}",
            "impl<T> fmt::Debug for IterMut<'_, T>\nwhere\n    T: fmt::Debug,\n{\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_list()\n            .entries(Iter {\n                inner: self.inner.clone(),\n                marker: PhantomData,\n            })\n            .finish()\n    }\n}"
        ],
        "table::OccupiedEntry": [
            "impl<'a, T, A> OccupiedEntry<'a, T, A>\nwhere\n    A: Allocator,\n{\n    /// Takes the value out of the entry, and returns it along with a\n    /// `VacantEntry` that can be used to insert another value with the same\n    /// hash as the one that was just removed.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// # #[cfg(feature = \"nightly\")]\n    /// # fn test() {\n    /// use hashbrown::hash_table::Entry;\n    /// use hashbrown::{HashTable, DefaultHashBuilder};\n    /// use std::hash::BuildHasher;\n    ///\n    /// let mut table: HashTable<&str> = HashTable::new();\n    /// let hasher = DefaultHashBuilder::default();\n    /// let hasher = |val: &_| hasher.hash_one(val);\n    /// // The table is empty\n    /// assert!(table.is_empty() && table.capacity() == 0);\n    ///\n    /// table.insert_unique(hasher(&\"poneyland\"), \"poneyland\", hasher);\n    /// let capacity_before_remove = table.capacity();\n    ///\n    /// if let Entry::Occupied(o) = table.entry(hasher(&\"poneyland\"), |&x| x == \"poneyland\", hasher) {\n    ///     assert_eq!(o.remove().0, \"poneyland\");\n    /// }\n    ///\n    /// assert!(table\n    ///     .find(hasher(&\"poneyland\"), |&x| x == \"poneyland\")\n    ///     .is_none());\n    /// // Now table hold none elements but capacity is equal to the old one\n    /// assert!(table.len() == 0 && table.capacity() == capacity_before_remove);\n    /// # }\n    /// # fn main() {\n    /// #     #[cfg(feature = \"nightly\")]\n    /// #     test()\n    /// # }\n    /// ```\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub fn remove(self) -> (T, VacantEntry<'a, T, A>) {\n        let (val, slot) = unsafe { self.table.raw.remove(self.bucket) };\n        (\n            val,\n            VacantEntry {\n                hash: self.hash,\n                insert_slot: slot,\n                table: self.table,\n            },\n        )\n    }\n\n    /// Gets a reference to the value in the entry.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// # #[cfg(feature = \"nightly\")]\n    /// # fn test() {\n    /// use hashbrown::hash_table::Entry;\n    /// use hashbrown::{HashTable, DefaultHashBuilder};\n    /// use std::hash::BuildHasher;\n    ///\n    /// let mut table: HashTable<&str> = HashTable::new();\n    /// let hasher = DefaultHashBuilder::default();\n    /// let hasher = |val: &_| hasher.hash_one(val);\n    /// table.insert_unique(hasher(&\"poneyland\"), \"poneyland\", hasher);\n    ///\n    /// match table.entry(hasher(&\"poneyland\"), |&x| x == \"poneyland\", hasher) {\n    ///     Entry::Vacant(_) => panic!(),\n    ///     Entry::Occupied(entry) => assert_eq!(entry.get(), &\"poneyland\"),\n    /// }\n    /// # }\n    /// # fn main() {\n    /// #     #[cfg(feature = \"nightly\")]\n    /// #     test()\n    /// # }\n    /// ```\n    #[inline]\n    pub fn get(&self) -> &T {\n        unsafe { self.bucket.as_ref() }\n    }\n\n    /// Gets a mutable reference to the value in the entry.\n    ///\n    /// If you need a reference to the `OccupiedEntry` which may outlive the\n    /// destruction of the `Entry` value, see [`into_mut`].\n    ///\n    /// [`into_mut`]: #method.into_mut\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// # #[cfg(feature = \"nightly\")]\n    /// # fn test() {\n    /// use hashbrown::hash_table::Entry;\n    /// use hashbrown::{HashTable, DefaultHashBuilder};\n    /// use std::hash::BuildHasher;\n    ///\n    /// let mut table: HashTable<(&str, u32)> = HashTable::new();\n    /// let hasher = DefaultHashBuilder::default();\n    /// let hasher = |val: &_| hasher.hash_one(val);\n    /// table.insert_unique(hasher(&\"poneyland\"), (\"poneyland\", 12), |(k, _)| hasher(&k));\n    ///\n    /// assert_eq!(\n    ///     table.find(hasher(&\"poneyland\"), |&(x, _)| x == \"poneyland\",),\n    ///     Some(&(\"poneyland\", 12))\n    /// );\n    ///\n    /// if let Entry::Occupied(mut o) = table.entry(\n    ///     hasher(&\"poneyland\"),\n    ///     |&(x, _)| x == \"poneyland\",\n    ///     |(k, _)| hasher(&k),\n    /// ) {\n    ///     o.get_mut().1 += 10;\n    ///     assert_eq!(o.get().1, 22);\n    ///\n    ///     // We can use the same Entry multiple times.\n    ///     o.get_mut().1 += 2;\n    /// }\n    ///\n    /// assert_eq!(\n    ///     table.find(hasher(&\"poneyland\"), |&(x, _)| x == \"poneyland\",),\n    ///     Some(&(\"poneyland\", 24))\n    /// );\n    /// # }\n    /// # fn main() {\n    /// #     #[cfg(feature = \"nightly\")]\n    /// #     test()\n    /// # }\n    /// ```\n    #[inline]\n    pub fn get_mut(&mut self) -> &mut T {\n        unsafe { self.bucket.as_mut() }\n    }\n\n    /// Converts the `OccupiedEntry` into a mutable reference to the value in the entry\n    /// with a lifetime bound to the table itself.\n    ///\n    /// If you need multiple references to the `OccupiedEntry`, see [`get_mut`].\n    ///\n    /// [`get_mut`]: #method.get_mut\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// # #[cfg(feature = \"nightly\")]\n    /// # fn test() {\n    /// use hashbrown::hash_table::Entry;\n    /// use hashbrown::{HashTable, DefaultHashBuilder};\n    /// use std::hash::BuildHasher;\n    ///\n    /// let mut table: HashTable<(&str, u32)> = HashTable::new();\n    /// let hasher = DefaultHashBuilder::default();\n    /// let hasher = |val: &_| hasher.hash_one(val);\n    /// table.insert_unique(hasher(&\"poneyland\"), (\"poneyland\", 12), |(k, _)| hasher(&k));\n    ///\n    /// assert_eq!(\n    ///     table.find(hasher(&\"poneyland\"), |&(x, _)| x == \"poneyland\",),\n    ///     Some(&(\"poneyland\", 12))\n    /// );\n    ///\n    /// let value: &mut (&str, u32);\n    /// match table.entry(\n    ///     hasher(&\"poneyland\"),\n    ///     |&(x, _)| x == \"poneyland\",\n    ///     |(k, _)| hasher(&k),\n    /// ) {\n    ///     Entry::Occupied(entry) => value = entry.into_mut(),\n    ///     Entry::Vacant(_) => panic!(),\n    /// }\n    /// value.1 += 10;\n    ///\n    /// assert_eq!(\n    ///     table.find(hasher(&\"poneyland\"), |&(x, _)| x == \"poneyland\",),\n    ///     Some(&(\"poneyland\", 22))\n    /// );\n    /// # }\n    /// # fn main() {\n    /// #     #[cfg(feature = \"nightly\")]\n    /// #     test()\n    /// # }\n    /// ```\n    pub fn into_mut(self) -> &'a mut T {\n        unsafe { self.bucket.as_mut() }\n    }\n\n    /// Converts the `OccupiedEntry` into a mutable reference to the underlying\n    /// table.\n    pub fn into_table(self) -> &'a mut HashTable<T, A> {\n        self.table\n    }\n}",
            "impl<T: fmt::Debug, A: Allocator> fmt::Debug for OccupiedEntry<'_, T, A> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.debug_struct(\"OccupiedEntry\")\n            .field(\"value\", self.get())\n            .finish()\n    }\n}",
            "unsafe impl<T, A> Send for OccupiedEntry<'_, T, A>\nwhere\n    T: Send,\n    A: Send + Allocator,\n{\n}",
            "unsafe impl<T, A> Sync for OccupiedEntry<'_, T, A>\nwhere\n    T: Sync,\n    A: Sync + Allocator,\n{\n}"
        ],
        "table::VacantEntry": [
            "impl<'a, T, A> VacantEntry<'a, T, A>\nwhere\n    A: Allocator,\n{\n    /// Inserts a new element into the table with the hash that was used to\n    /// obtain the `VacantEntry`.\n    ///\n    /// An `OccupiedEntry` is returned for the newly inserted element.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// # #[cfg(feature = \"nightly\")]\n    /// # fn test() {\n    /// use hashbrown::hash_table::Entry;\n    /// use hashbrown::{HashTable, DefaultHashBuilder};\n    /// use std::hash::BuildHasher;\n    ///\n    /// let mut table: HashTable<&str> = HashTable::new();\n    /// let hasher = DefaultHashBuilder::default();\n    /// let hasher = |val: &_| hasher.hash_one(val);\n    ///\n    /// if let Entry::Vacant(o) = table.entry(hasher(&\"poneyland\"), |&x| x == \"poneyland\", hasher) {\n    ///     o.insert(\"poneyland\");\n    /// }\n    /// assert_eq!(\n    ///     table.find(hasher(&\"poneyland\"), |&x| x == \"poneyland\"),\n    ///     Some(&\"poneyland\")\n    /// );\n    /// # }\n    /// # fn main() {\n    /// #     #[cfg(feature = \"nightly\")]\n    /// #     test()\n    /// # }\n    /// ```\n    #[inline]\n    pub fn insert(self, value: T) -> OccupiedEntry<'a, T, A> {\n        let bucket = unsafe {\n            self.table\n                .raw\n                .insert_in_slot(self.hash, self.insert_slot, value)\n        };\n        OccupiedEntry {\n            hash: self.hash,\n            bucket,\n            table: self.table,\n        }\n    }\n\n    /// Converts the `VacantEntry` into a mutable reference to the underlying\n    /// table.\n    pub fn into_table(self) -> &'a mut HashTable<T, A> {\n        self.table\n    }\n}",
            "impl<T: fmt::Debug, A: Allocator> fmt::Debug for VacantEntry<'_, T, A> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        f.write_str(\"VacantEntry\")\n    }\n}"
        ]
    },
    "single_path_import": {
        "allocator_api2::alloc::Allocator": "raw::alloc::inner::Allocator",
        "allocator_api2::alloc::Global": "raw::alloc::inner::Global",
        "equivalent::Equivalent": "Equivalent",
        "map::HashMap": "HashMap",
        "set::HashSet": "HashSet",
        "table::HashTable": "HashTable"
    },
    "srcs": {
        "<&'a map::HashMap<K, V, S, A> as core::iter::IntoIterator>::into_iter": [
            "/// Creates an iterator over the entries of a `HashMap` in arbitrary order.\n/// The iterator element type is `(&'a K, &'a V)`.\n///\n/// Return the same `Iter` struct as by the [`iter`] method on [`HashMap`].\n///\n/// [`iter`]: struct.HashMap.html#method.iter\n/// [`HashMap`]: struct.HashMap.html\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n/// let map_one: HashMap<_, _> = [(1, \"a\"), (2, \"b\"), (3, \"c\")].into();\n/// let mut map_two = HashMap::new();\n///\n/// for (key, value) in &map_one {\n///     println!(\"Key: {}, Value: {}\", key, value);\n///     map_two.insert(*key, *value);\n/// }\n///\n/// assert_eq!(map_one, map_two);\n/// ```\ninline\nfn into_iter(self) -> Iter<'a, K, V>{\n        self.iter()\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "<&'a mut map::HashMap<K, V, S, A> as core::iter::IntoIterator>::into_iter": [
            "/// Creates an iterator over the entries of a `HashMap` in arbitrary order\n/// with mutable references to the values. The iterator element type is\n/// `(&'a K, &'a mut V)`.\n///\n/// Return the same `IterMut` struct as by the [`iter_mut`] method on\n/// [`HashMap`].\n///\n/// [`iter_mut`]: struct.HashMap.html#method.iter_mut\n/// [`HashMap`]: struct.HashMap.html\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n/// let mut map: HashMap<_, _> = [(\"a\", 1), (\"b\", 2), (\"c\", 3)].into();\n///\n/// for (key, value) in &mut map {\n///     println!(\"Key: {}, Value: {}\", key, value);\n///     *value *= 2;\n/// }\n///\n/// let mut vec = map.iter().collect::<Vec<_>>();\n/// // The `Iter` iterator produces items in arbitrary order, so the\n/// // items must be sorted to test them against a sorted array.\n/// vec.sort_unstable();\n/// assert_eq!(vec, [(&\"a\", &2), (&\"b\", &4), (&\"c\", &6)]);\n/// ```\ninline\nfn into_iter(self) -> IterMut<'a, K, V>{\n        self.iter_mut()\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "<&'a mut table::HashTable<T, A> as core::iter::IntoIterator>::into_iter": [
            "fn into_iter(self) -> IterMut<'a, T>{\n        self.iter_mut()\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "<&'a set::HashSet<T, S, A> as core::iter::IntoIterator>::into_iter": [
            "inline\nfn into_iter(self) -> Iter<'a, T>{\n        self.iter()\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "<&'a table::HashTable<T, A> as core::iter::IntoIterator>::into_iter": [
            "fn into_iter(self) -> Iter<'a, T>{\n        self.iter()\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "<&set::HashSet<T, S, A> as core::ops::BitAnd<&set::HashSet<T, S, A>>>::bitand": [
            "/// Returns the intersection of `self` and `rhs` as a new `HashSet<T, S>`.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n///\n/// let a: HashSet<_> = vec![1, 2, 3].into_iter().collect();\n/// let b: HashSet<_> = vec![2, 3, 4].into_iter().collect();\n///\n/// let set = &a & &b;\n///\n/// let mut i = 0;\n/// let expected = [2, 3];\n/// for x in &set {\n///     assert!(expected.contains(x));\n///     i += 1;\n/// }\n/// assert_eq!(i, expected.len());\n/// ```\nfn bitand(self, rhs: &HashSet<T, S, A>) -> HashSet<T, S, A>{\n        self.intersection(rhs).cloned().collect()\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "<&set::HashSet<T, S, A> as core::ops::BitOr<&set::HashSet<T, S, A>>>::bitor": [
            "/// Returns the union of `self` and `rhs` as a new `HashSet<T, S>`.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n///\n/// let a: HashSet<_> = vec![1, 2, 3].into_iter().collect();\n/// let b: HashSet<_> = vec![3, 4, 5].into_iter().collect();\n///\n/// let set = &a | &b;\n///\n/// let mut i = 0;\n/// let expected = [1, 2, 3, 4, 5];\n/// for x in &set {\n///     assert!(expected.contains(x));\n///     i += 1;\n/// }\n/// assert_eq!(i, expected.len());\n/// ```\nfn bitor(self, rhs: &HashSet<T, S, A>) -> HashSet<T, S, A>{\n        self.union(rhs).cloned().collect()\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "<&set::HashSet<T, S, A> as core::ops::BitXor<&set::HashSet<T, S, A>>>::bitxor": [
            "/// Returns the symmetric difference of `self` and `rhs` as a new `HashSet<T, S>`.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n///\n/// let a: HashSet<_> = vec![1, 2, 3].into_iter().collect();\n/// let b: HashSet<_> = vec![3, 4, 5].into_iter().collect();\n///\n/// let set = &a ^ &b;\n///\n/// let mut i = 0;\n/// let expected = [1, 2, 4, 5];\n/// for x in &set {\n///     assert!(expected.contains(x));\n///     i += 1;\n/// }\n/// assert_eq!(i, expected.len());\n/// ```\nfn bitxor(self, rhs: &HashSet<T, S, A>) -> HashSet<T, S, A>{\n        self.symmetric_difference(rhs).cloned().collect()\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "<&set::HashSet<T, S, A> as core::ops::Sub<&set::HashSet<T, S, A>>>::sub": [
            "/// Returns the difference of `self` and `rhs` as a new `HashSet<T, S>`.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n///\n/// let a: HashSet<_> = vec![1, 2, 3].into_iter().collect();\n/// let b: HashSet<_> = vec![3, 4, 5].into_iter().collect();\n///\n/// let set = &a - &b;\n///\n/// let mut i = 0;\n/// let expected = [1, 2];\n/// for x in &set {\n///     assert!(expected.contains(x));\n///     i += 1;\n/// }\n/// assert_eq!(i, expected.len());\n/// ```\nfn sub(self, rhs: &HashSet<T, S, A>) -> HashSet<T, S, A>{\n        self.difference(rhs).cloned().collect()\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "<[control::tag::Tag] as control::tag::TagSliceExt>::fill_tag": [
            "#[inline]\nfn fill_tag(&mut self, tag: Tag){\n        // SAFETY: We have access to the entire slice, so, we can write to the entire slice.\n        unsafe { self.as_mut_ptr().write_bytes(tag.0, self.len()) }\n    }",
            "Real(LocalPath(\"src/control/tag.rs\"))"
        ],
        "<control::bitmask::BitMask as core::iter::IntoIterator>::into_iter": [
            "#[inline]\nfn into_iter(self) -> BitMaskIter{\n        // A BitMask only requires each element (group of bits) to be non-zero.\n        // However for iteration we need each element to only contain 1 bit.\n        BitMaskIter(BitMask(self.0 & BITMASK_ITER_MASK))\n    }",
            "Real(LocalPath(\"src/control/bitmask.rs\"))"
        ],
        "<control::bitmask::BitMaskIter as core::iter::Iterator>::next": [
            "#[inline]\nfn next(&mut self) -> Option<usize>{\n        let bit = self.0.lowest_set_bit()?;\n        self.0 = self.0.remove_lowest_bit();\n        Some(bit)\n    }",
            "Real(LocalPath(\"src/control/bitmask.rs\"))"
        ],
        "<control::tag::Tag as core::fmt::Debug>::fmt": [
            "fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result{\n        if self.is_special() {\n            if self.special_is_empty() {\n                f.pad(\"EMPTY\")\n            } else {\n                f.pad(\"DELETED\")\n            }\n        } else {\n            f.debug_tuple(\"full\").field(&(self.0 & 0x7F)).finish()\n        }\n    }",
            "Real(LocalPath(\"src/control/tag.rs\"))"
        ],
        "<map::Drain<'_, K, V, A> as core::fmt::Debug>::fmt": [
            "fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result{\n        f.debug_list().entries(self.iter()).finish()\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "<map::Drain<'_, K, V, A> as core::iter::ExactSizeIterator>::len": [
            "inline\nfn len(&self) -> usize{\n        self.inner.len()\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "<map::Drain<'_, K, V, A> as core::iter::Iterator>::fold": [
            "inline\nfn fold<B, F>(self, init: B, f: F) -> B\n    where\n        Self: Sized,\n        F: FnMut(B, Self::Item) -> B,{\n        self.inner.fold(init, f)\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "<map::Drain<'_, K, V, A> as core::iter::Iterator>::next": [
            "inline\nfn next(&mut self) -> Option<(K, V)>{\n        self.inner.next()\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "<map::Drain<'_, K, V, A> as core::iter::Iterator>::size_hint": [
            "inline\nfn size_hint(&self) -> (usize, Option<usize>){\n        self.inner.size_hint()\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "<map::Entry<'_, K, V, S, A> as core::fmt::Debug>::fmt": [
            "fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result{\n        match *self {\n            Entry::Vacant(ref v) => f.debug_tuple(\"Entry\").field(v).finish(),\n            Entry::Occupied(ref o) => f.debug_tuple(\"Entry\").field(o).finish(),\n        }\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "<map::EntryRef<'_, '_, K, Q, V, S, A> as core::fmt::Debug>::fmt": [
            "fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result{\n        match *self {\n            EntryRef::Vacant(ref v) => f.debug_tuple(\"EntryRef\").field(v).finish(),\n            EntryRef::Occupied(ref o) => f.debug_tuple(\"EntryRef\").field(o).finish(),\n        }\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "<map::ExtractIf<'_, K, V, F, A> as core::iter::Iterator>::next": [
            "inline\nfn next(&mut self) -> Option<Self::Item>{\n        self.inner.next(|&mut (ref k, ref mut v)| (self.f)(k, v))\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "<map::ExtractIf<'_, K, V, F, A> as core::iter::Iterator>::size_hint": [
            "#[inline]\nfn size_hint(&self) -> (usize, Option<usize>){\n        (0, self.inner.iter.size_hint().1)\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "<map::HashMap<K, V, S, A> as core::clone::Clone>::clone": [
            "fn clone(&self) -> Self{\n        HashMap {\n            hash_builder: self.hash_builder.clone(),\n            table: self.table.clone(),\n        }\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "<map::HashMap<K, V, S, A> as core::clone::Clone>::clone_from": [
            "fn clone_from(&mut self, source: &Self){\n        self.table.clone_from(&source.table);\n\n        // Update hash_builder only if we successfully cloned all elements.\n        self.hash_builder.clone_from(&source.hash_builder);\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "<map::HashMap<K, V, S, A> as core::cmp::PartialEq>::eq": [
            "fn eq(&self, other: &Self) -> bool{\n        if self.len() != other.len() {\n            return false;\n        }\n\n        self.iter()\n            .all(|(key, value)| other.get(key).map_or(false, |v| *value == *v))\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "<map::HashMap<K, V, S, A> as core::default::Default>::default": [
            "/// Creates an empty `HashMap<K, V, S, A>`, with the `Default` value for the hasher and allocator.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n/// use std::collections::hash_map::RandomState;\n///\n/// // You can specify all types of HashMap, including hasher and allocator.\n/// // Created map is empty and don't allocate memory\n/// let map: HashMap<u32, String> = Default::default();\n/// assert_eq!(map.capacity(), 0);\n/// let map: HashMap<u32, String, RandomState> = HashMap::default();\n/// assert_eq!(map.capacity(), 0);\n/// ```\ninline\nfn default() -> Self{\n        Self::with_hasher_in(Default::default(), Default::default())\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "<map::HashMap<K, V, S, A> as core::fmt::Debug>::fmt": [
            "fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result{\n        f.debug_map().entries(self.iter()).finish()\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "<map::HashMap<K, V, S, A> as core::iter::Extend<&'a (K, V)>>::extend": [
            "/// Inserts all new key-values from the iterator to existing `HashMap<K, V, S, A>`.\n/// Replace values with existing keys with new values returned from the iterator.\n/// The keys and values must implement [`Copy`] trait.\n///\n/// [`Copy`]: https://doc.rust-lang.org/core/marker/trait.Copy.html\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::hash_map::HashMap;\n///\n/// let mut map = HashMap::new();\n/// map.insert(1, 100);\n///\n/// let arr = [(1, 1), (2, 2)];\n/// let some_iter = arr.iter();\n/// map.extend(some_iter);\n/// // Replace values with existing keys with new values returned from the iterator.\n/// // So that the map.get(&1) doesn't return Some(&100).\n/// assert_eq!(map.get(&1), Some(&1));\n///\n/// let some_vec: Vec<_> = vec![(3, 3), (4, 4)];\n/// map.extend(&some_vec);\n///\n/// let some_arr = [(5, 5), (6, 6)];\n/// map.extend(&some_arr);\n///\n/// let mut vec: Vec<_> = map.into_iter().collect();\n/// // The `IntoIter` iterator produces items in arbitrary order, so the\n/// // items must be sorted to test them against a sorted array.\n/// vec.sort_unstable();\n/// assert_eq!(vec, [(1, 1), (2, 2), (3, 3), (4, 4), (5, 5), (6, 6)]);\n/// ```\ninline\nfn extend<T: IntoIterator<Item = &'a (K, V)>>(&mut self, iter: T){\n        self.extend(iter.into_iter().map(|&(key, value)| (key, value)));\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "<map::HashMap<K, V, S, A> as core::iter::Extend<(&'a K, &'a V)>>::extend": [
            "/// Inserts all new key-values from the iterator to existing `HashMap<K, V, S, A>`.\n/// Replace values with existing keys with new values returned from the iterator.\n/// The keys and values must implement [`Copy`] trait.\n///\n/// [`Copy`]: https://doc.rust-lang.org/core/marker/trait.Copy.html\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::hash_map::HashMap;\n///\n/// let mut map = HashMap::new();\n/// map.insert(1, 100);\n///\n/// let arr = [(1, 1), (2, 2)];\n/// let some_iter = arr.iter().map(|(k, v)| (k, v));\n/// map.extend(some_iter);\n/// // Replace values with existing keys with new values returned from the iterator.\n/// // So that the map.get(&1) doesn't return Some(&100).\n/// assert_eq!(map.get(&1), Some(&1));\n///\n/// let some_vec: Vec<_> = vec![(3, 3), (4, 4)];\n/// map.extend(some_vec.iter().map(|(k, v)| (k, v)));\n///\n/// let some_arr = [(5, 5), (6, 6)];\n/// map.extend(some_arr.iter().map(|(k, v)| (k, v)));\n///\n/// // You can also extend from another HashMap\n/// let mut new_map = HashMap::new();\n/// new_map.extend(&map);\n/// assert_eq!(new_map, map);\n///\n/// let mut vec: Vec<_> = new_map.into_iter().collect();\n/// // The `IntoIter` iterator produces items in arbitrary order, so the\n/// // items must be sorted to test them against a sorted array.\n/// vec.sort_unstable();\n/// assert_eq!(vec, [(1, 1), (2, 2), (3, 3), (4, 4), (5, 5), (6, 6)]);\n/// ```\ninline\nfn extend<T: IntoIterator<Item = (&'a K, &'a V)>>(&mut self, iter: T){\n        self.extend(iter.into_iter().map(|(&key, &value)| (key, value)));\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "<map::HashMap<K, V, S, A> as core::iter::Extend<(K, V)>>::extend": [
            "/// Inserts all new key-values from the iterator to existing `HashMap<K, V, S, A>`.\n/// Replace values with existing keys with new values returned from the iterator.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::hash_map::HashMap;\n///\n/// let mut map = HashMap::new();\n/// map.insert(1, 100);\n///\n/// let some_iter = [(1, 1), (2, 2)].into_iter();\n/// map.extend(some_iter);\n/// // Replace values with existing keys with new values returned from the iterator.\n/// // So that the map.get(&1) doesn't return Some(&100).\n/// assert_eq!(map.get(&1), Some(&1));\n///\n/// let some_vec: Vec<_> = vec![(3, 3), (4, 4)];\n/// map.extend(some_vec);\n///\n/// let some_arr = [(5, 5), (6, 6)];\n/// map.extend(some_arr);\n/// let old_map_len = map.len();\n///\n/// // You can also extend from another HashMap\n/// let mut new_map = HashMap::new();\n/// new_map.extend(map);\n/// assert_eq!(new_map.len(), old_map_len);\n///\n/// let mut vec: Vec<_> = new_map.into_iter().collect();\n/// // The `IntoIter` iterator produces items in arbitrary order, so the\n/// // items must be sorted to test them against a sorted array.\n/// vec.sort_unstable();\n/// assert_eq!(vec, [(1, 1), (2, 2), (3, 3), (4, 4), (5, 5), (6, 6)]);\n/// ```\ninline\nfn extend<T: IntoIterator<Item = (K, V)>>(&mut self, iter: T){\n        // Keys may be already present or show multiple times in the iterator.\n        // Reserve the entire hint lower bound if the map is empty.\n        // Otherwise reserve half the hint (rounded up), so the map\n        // will only resize twice in the worst case.\n        let iter = iter.into_iter();\n        let reserve = if self.is_empty() {\n            iter.size_hint().0\n        } else {\n            (iter.size_hint().0 + 1) / 2\n        };\n        self.reserve(reserve);\n        iter.for_each(move |(k, v)| {\n            self.insert(k, v);\n        });\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "<map::HashMap<K, V, S, A> as core::iter::FromIterator<(K, V)>>::from_iter": [
            "inline\nfn from_iter<T: IntoIterator<Item = (K, V)>>(iter: T) -> Self{\n        let iter = iter.into_iter();\n        let mut map =\n            Self::with_capacity_and_hasher_in(iter.size_hint().0, S::default(), A::default());\n        iter.for_each(|(k, v)| {\n            map.insert(k, v);\n        });\n        map\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "<map::HashMap<K, V, S, A> as core::iter::IntoIterator>::into_iter": [
            "/// Creates a consuming iterator, that is, one that moves each key-value\n/// pair out of the map in arbitrary order. The map cannot be used after\n/// calling this.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let map: HashMap<_, _> = [(\"a\", 1), (\"b\", 2), (\"c\", 3)].into();\n///\n/// // Not possible with .iter()\n/// let mut vec: Vec<(&str, i32)> = map.into_iter().collect();\n/// // The `IntoIter` iterator produces items in arbitrary order, so\n/// // the items must be sorted to test them against a sorted array.\n/// vec.sort_unstable();\n/// assert_eq!(vec, [(\"a\", 1), (\"b\", 2), (\"c\", 3)]);\n/// ```\ninline\nfn into_iter(self) -> IntoIter<K, V, A>{\n        IntoIter {\n            inner: self.table.into_iter(),\n        }\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "<map::HashMap<K, V, S, A> as core::ops::Index<&Q>>::index": [
            "/// Returns a reference to the value corresponding to the supplied key.\n///\n/// # Panics\n///\n/// Panics if the key is not present in the `HashMap`.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let map: HashMap<_, _> = [(\"a\", \"One\"), (\"b\", \"Two\")].into();\n///\n/// assert_eq!(map[&\"a\"], \"One\");\n/// assert_eq!(map[&\"b\"], \"Two\");\n/// ```\ninline\nfn index(&self, key: &Q) -> &V{\n        self.get(key).expect(\"no entry found for key\")\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "<map::HashMap<K, V, foldhash::fast::RandomState, A> as core::convert::From<[(K, V); N]>>::from": [
            "/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let map1 = HashMap::from([(1, 2), (3, 4)]);\n/// let map2: HashMap<_, _> = [(1, 2), (3, 4)].into();\n/// assert_eq!(map1, map2);\n/// ```\nfn from(arr: [(K, V); N]) -> Self{\n        arr.into_iter().collect()\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "<map::IntoIter<K, V, A> as core::default::Default>::default": [
            "inline\nfn default() -> Self{\n        Self {\n            inner: Default::default(),\n        }\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "<map::IntoIter<K, V, A> as core::fmt::Debug>::fmt": [
            "fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result{\n        f.debug_list().entries(self.iter()).finish()\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "<map::IntoIter<K, V, A> as core::iter::ExactSizeIterator>::len": [
            "inline\nfn len(&self) -> usize{\n        self.inner.len()\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "<map::IntoIter<K, V, A> as core::iter::Iterator>::fold": [
            "inline\nfn fold<B, F>(self, init: B, f: F) -> B\n    where\n        Self: Sized,\n        F: FnMut(B, Self::Item) -> B,{\n        self.inner.fold(init, f)\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "<map::IntoIter<K, V, A> as core::iter::Iterator>::next": [
            "inline\nfn next(&mut self) -> Option<(K, V)>{\n        self.inner.next()\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "<map::IntoIter<K, V, A> as core::iter::Iterator>::size_hint": [
            "inline\nfn size_hint(&self) -> (usize, Option<usize>){\n        self.inner.size_hint()\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "<map::IntoKeys<K, V, A> as core::default::Default>::default": [
            "inline\nfn default() -> Self{\n        Self {\n            inner: Default::default(),\n        }\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "<map::IntoKeys<K, V, A> as core::fmt::Debug>::fmt": [
            "fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result{\n        f.debug_list()\n            .entries(self.inner.iter().map(|(k, _)| k))\n            .finish()\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "<map::IntoKeys<K, V, A> as core::iter::ExactSizeIterator>::len": [
            "#[inline]\nfn len(&self) -> usize{\n        self.inner.len()\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "<map::IntoKeys<K, V, A> as core::iter::Iterator>::fold": [
            "#[inline]\nfn fold<B, F>(self, init: B, mut f: F) -> B\n    where\n        Self: Sized,\n        F: FnMut(B, Self::Item) -> B,{\n        self.inner.fold(init, |acc, (k, _)| f(acc, k))\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "<map::IntoKeys<K, V, A> as core::iter::Iterator>::next": [
            "#[inline]\nfn next(&mut self) -> Option<K>{\n        self.inner.next().map(|(k, _)| k)\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "<map::IntoKeys<K, V, A> as core::iter::Iterator>::size_hint": [
            "#[inline]\nfn size_hint(&self) -> (usize, Option<usize>){\n        self.inner.size_hint()\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "<map::IntoValues<K, V, A> as core::default::Default>::default": [
            "inline\nfn default() -> Self{\n        Self {\n            inner: Default::default(),\n        }\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "<map::IntoValues<K, V, A> as core::fmt::Debug>::fmt": [
            "fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result{\n        f.debug_list()\n            .entries(self.inner.iter().map(|(_, v)| v))\n            .finish()\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "<map::IntoValues<K, V, A> as core::iter::ExactSizeIterator>::len": [
            "#[inline]\nfn len(&self) -> usize{\n        self.inner.len()\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "<map::IntoValues<K, V, A> as core::iter::Iterator>::fold": [
            "#[inline]\nfn fold<B, F>(self, init: B, mut f: F) -> B\n    where\n        Self: Sized,\n        F: FnMut(B, Self::Item) -> B,{\n        self.inner.fold(init, |acc, (_, v)| f(acc, v))\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "<map::IntoValues<K, V, A> as core::iter::Iterator>::next": [
            "#[inline]\nfn next(&mut self) -> Option<V>{\n        self.inner.next().map(|(_, v)| v)\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "<map::IntoValues<K, V, A> as core::iter::Iterator>::size_hint": [
            "#[inline]\nfn size_hint(&self) -> (usize, Option<usize>){\n        self.inner.size_hint()\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "<map::Iter<'_, K, V> as core::clone::Clone>::clone": [
            "inline\nfn clone(&self) -> Self{\n        Iter {\n            inner: self.inner.clone(),\n            marker: PhantomData,\n        }\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "<map::Iter<'_, K, V> as core::default::Default>::default": [
            "inline\nfn default() -> Self{\n        Self {\n            inner: Default::default(),\n            marker: PhantomData,\n        }\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "<map::Iter<'_, K, V> as core::fmt::Debug>::fmt": [
            "fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result{\n        f.debug_list().entries(self.clone()).finish()\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "<map::Iter<'_, K, V> as core::iter::ExactSizeIterator>::len": [
            "inline\nfn len(&self) -> usize{\n        self.inner.len()\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "<map::Iter<'a, K, V> as core::iter::Iterator>::fold": [
            "inline\nfn fold<B, F>(self, init: B, mut f: F) -> B\n    where\n        Self: Sized,\n        F: FnMut(B, Self::Item) -> B,{\n        self.inner.fold(init, |acc, x| unsafe {\n            let (k, v) = x.as_ref();\n            f(acc, (k, v))\n        })\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "<map::Iter<'a, K, V> as core::iter::Iterator>::next": [
            "inline\nfn next(&mut self) -> Option<(&'a K, &'a V)>{\n        // Avoid `Option::map` because it bloats LLVM IR.\n        match self.inner.next() {\n            Some(x) => unsafe {\n                let r = x.as_ref();\n                Some((&r.0, &r.1))\n            },\n            None => None,\n        }\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "<map::Iter<'a, K, V> as core::iter::Iterator>::size_hint": [
            "inline\nfn size_hint(&self) -> (usize, Option<usize>){\n        self.inner.size_hint()\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "<map::IterMut<'_, K, V> as core::default::Default>::default": [
            "inline\nfn default() -> Self{\n        Self {\n            inner: Default::default(),\n            marker: PhantomData,\n        }\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "<map::IterMut<'_, K, V> as core::fmt::Debug>::fmt": [
            "fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result{\n        f.debug_list().entries(self.iter()).finish()\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "<map::IterMut<'_, K, V> as core::iter::ExactSizeIterator>::len": [
            "inline\nfn len(&self) -> usize{\n        self.inner.len()\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "<map::IterMut<'a, K, V> as core::iter::Iterator>::fold": [
            "inline\nfn fold<B, F>(self, init: B, mut f: F) -> B\n    where\n        Self: Sized,\n        F: FnMut(B, Self::Item) -> B,{\n        self.inner.fold(init, |acc, x| unsafe {\n            let (k, v) = x.as_mut();\n            f(acc, (k, v))\n        })\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "<map::IterMut<'a, K, V> as core::iter::Iterator>::next": [
            "inline\nfn next(&mut self) -> Option<(&'a K, &'a mut V)>{\n        // Avoid `Option::map` because it bloats LLVM IR.\n        match self.inner.next() {\n            Some(x) => unsafe {\n                let r = x.as_mut();\n                Some((&r.0, &mut r.1))\n            },\n            None => None,\n        }\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "<map::IterMut<'a, K, V> as core::iter::Iterator>::size_hint": [
            "inline\nfn size_hint(&self) -> (usize, Option<usize>){\n        self.inner.size_hint()\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "<map::Keys<'_, K, V> as core::clone::Clone>::clone": [
            "inline\nfn clone(&self) -> Self{\n        Keys {\n            inner: self.inner.clone(),\n        }\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "<map::Keys<'_, K, V> as core::default::Default>::default": [
            "inline\nfn default() -> Self{\n        Self {\n            inner: Default::default(),\n        }\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "<map::Keys<'_, K, V> as core::fmt::Debug>::fmt": [
            "fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result{\n        f.debug_list().entries(self.clone()).finish()\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "<map::Keys<'_, K, V> as core::iter::ExactSizeIterator>::len": [
            "inline\nfn len(&self) -> usize{\n        self.inner.len()\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "<map::Keys<'a, K, V> as core::iter::Iterator>::fold": [
            "inline\nfn fold<B, F>(self, init: B, mut f: F) -> B\n    where\n        Self: Sized,\n        F: FnMut(B, Self::Item) -> B,{\n        self.inner.fold(init, |acc, (k, _)| f(acc, k))\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "<map::Keys<'a, K, V> as core::iter::Iterator>::next": [
            "inline\nfn next(&mut self) -> Option<&'a K>{\n        // Avoid `Option::map` because it bloats LLVM IR.\n        match self.inner.next() {\n            Some((k, _)) => Some(k),\n            None => None,\n        }\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "<map::Keys<'a, K, V> as core::iter::Iterator>::size_hint": [
            "inline\nfn size_hint(&self) -> (usize, Option<usize>){\n        self.inner.size_hint()\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "<map::OccupiedEntry<'_, K, V, S, A> as core::fmt::Debug>::fmt": [
            "fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result{\n        f.debug_struct(\"OccupiedEntry\")\n            .field(\"key\", self.key())\n            .field(\"value\", self.get())\n            .finish()\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "<map::OccupiedError<'_, K, V, S, A> as core::fmt::Debug>::fmt": [
            "fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result{\n        f.debug_struct(\"OccupiedError\")\n            .field(\"key\", self.entry.key())\n            .field(\"old_value\", self.entry.get())\n            .field(\"new_value\", &self.value)\n            .finish()\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "<map::OccupiedError<'_, K, V, S, A> as core::fmt::Display>::fmt": [
            "fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result{\n        write!(\n            f,\n            \"failed to insert {:?}, key {:?} already exists with value {:?}\",\n            self.value,\n            self.entry.key(),\n            self.entry.get(),\n        )\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "<map::VacantEntry<'_, K, V, S, A> as core::fmt::Debug>::fmt": [
            "fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result{\n        f.debug_tuple(\"VacantEntry\").field(self.key()).finish()\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "<map::VacantEntryRef<'_, '_, K, Q, V, S, A> as core::fmt::Debug>::fmt": [
            "fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result{\n        f.debug_tuple(\"VacantEntryRef\").field(&self.key()).finish()\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "<map::Values<'_, K, V> as core::clone::Clone>::clone": [
            "inline\nfn clone(&self) -> Self{\n        Values {\n            inner: self.inner.clone(),\n        }\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "<map::Values<'_, K, V> as core::default::Default>::default": [
            "inline\nfn default() -> Self{\n        Self {\n            inner: Default::default(),\n        }\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "<map::Values<'_, K, V> as core::fmt::Debug>::fmt": [
            "fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result{\n        f.debug_list().entries(self.clone()).finish()\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "<map::Values<'_, K, V> as core::iter::ExactSizeIterator>::len": [
            "inline\nfn len(&self) -> usize{\n        self.inner.len()\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "<map::Values<'a, K, V> as core::iter::Iterator>::fold": [
            "inline\nfn fold<B, F>(self, init: B, mut f: F) -> B\n    where\n        Self: Sized,\n        F: FnMut(B, Self::Item) -> B,{\n        self.inner.fold(init, |acc, (_, v)| f(acc, v))\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "<map::Values<'a, K, V> as core::iter::Iterator>::next": [
            "inline\nfn next(&mut self) -> Option<&'a V>{\n        // Avoid `Option::map` because it bloats LLVM IR.\n        match self.inner.next() {\n            Some((_, v)) => Some(v),\n            None => None,\n        }\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "<map::Values<'a, K, V> as core::iter::Iterator>::size_hint": [
            "inline\nfn size_hint(&self) -> (usize, Option<usize>){\n        self.inner.size_hint()\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "<map::ValuesMut<'_, K, V> as core::default::Default>::default": [
            "inline\nfn default() -> Self{\n        Self {\n            inner: Default::default(),\n        }\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "<map::ValuesMut<'_, K, V> as core::fmt::Debug>::fmt": [
            "fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result{\n        f.debug_list()\n            .entries(self.inner.iter().map(|(_, val)| val))\n            .finish()\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "<map::ValuesMut<'_, K, V> as core::iter::ExactSizeIterator>::len": [
            "inline\nfn len(&self) -> usize{\n        self.inner.len()\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "<map::ValuesMut<'a, K, V> as core::iter::Iterator>::fold": [
            "inline\nfn fold<B, F>(self, init: B, mut f: F) -> B\n    where\n        Self: Sized,\n        F: FnMut(B, Self::Item) -> B,{\n        self.inner.fold(init, |acc, (_, v)| f(acc, v))\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "<map::ValuesMut<'a, K, V> as core::iter::Iterator>::next": [
            "inline\nfn next(&mut self) -> Option<&'a mut V>{\n        // Avoid `Option::map` because it bloats LLVM IR.\n        match self.inner.next() {\n            Some((_, v)) => Some(v),\n            None => None,\n        }\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "<map::ValuesMut<'a, K, V> as core::iter::Iterator>::size_hint": [
            "inline\nfn size_hint(&self) -> (usize, Option<usize>){\n        self.inner.size_hint()\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "<raw::Bucket<T> as core::clone::Clone>::clone": [
            "#[inline]\nfn clone(&self) -> Self{\n        Self { ptr: self.ptr }\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "<raw::FullBucketsIndices as core::iter::Iterator>::next": [
            "/// Advances the iterator and returns the next value. It is up to\n/// the caller to ensure that the `RawTable` outlives the `FullBucketsIndices`,\n/// because we cannot make the `next` method unsafe.\n#[inline(always)]\nfn next(&mut self) -> Option<usize>{\n        // Return if we already yielded all items.\n        if self.items == 0 {\n            return None;\n        }\n\n        let nxt = unsafe {\n            // SAFETY:\n            // 1. We check number of items to yield using `items` field.\n            // 2. The caller ensures that the table is alive and has not moved.\n            self.next_impl()\n        };\n\n        debug_assert!(nxt.is_some());\n        self.items -= 1;\n\n        nxt\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "<raw::FullBucketsIndices as core::iter::Iterator>::size_hint": [
            "#[inline(always)]\nfn size_hint(&self) -> (usize, Option<usize>){\n        (self.items, Some(self.items))\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "<raw::RawDrain<'_, T, A> as core::iter::Iterator>::next": [
            "inline\nfn next(&mut self) -> Option<T>{\n        unsafe {\n            let item = self.iter.next()?;\n            Some(item.read())\n        }\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "<raw::RawDrain<'_, T, A> as core::iter::Iterator>::size_hint": [
            "#[inline]\nfn size_hint(&self) -> (usize, Option<usize>){\n        self.iter.size_hint()\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "<raw::RawDrain<'_, T, A> as core::ops::Drop>::drop": [
            "inline\nfn drop(&mut self){\n        unsafe {\n            // Drop all remaining elements. Note that this may panic.\n            self.iter.drop_elements();\n\n            // Reset the contents of the table now that all elements have been\n            // dropped.\n            self.table.clear_no_drop();\n\n            // Move the now empty table back to its original location.\n            self.orig_table\n                .as_ptr()\n                .copy_from_nonoverlapping(&self.table, 1);\n        }\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "<raw::RawIntoIter<T, A> as core::default::Default>::default": [
            "fn default() -> Self{\n        Self {\n            iter: Default::default(),\n            allocation: None,\n            marker: PhantomData,\n        }\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "<raw::RawIntoIter<T, A> as core::iter::Iterator>::next": [
            "inline\nfn next(&mut self) -> Option<T>{\n        unsafe { Some(self.iter.next()?.read()) }\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "<raw::RawIntoIter<T, A> as core::iter::Iterator>::size_hint": [
            "#[inline]\nfn size_hint(&self) -> (usize, Option<usize>){\n        self.iter.size_hint()\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "<raw::RawIntoIter<T, A> as core::ops::Drop>::drop": [
            "inline\nfn drop(&mut self){\n        unsafe {\n            // Drop all remaining elements\n            self.iter.drop_elements();\n\n            // Free the table\n            if let Some((ptr, layout, ref alloc)) = self.allocation {\n                alloc.deallocate(ptr, layout);\n            }\n        }\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "<raw::RawIter<T> as core::clone::Clone>::clone": [
            "inline\nfn clone(&self) -> Self{\n        Self {\n            iter: self.iter.clone(),\n            items: self.items,\n        }\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "<raw::RawIter<T> as core::default::Default>::default": [
            "inline\nfn default() -> Self{\n        // SAFETY: Because the table is static, it always outlives the iter.\n        unsafe { RawTableInner::NEW.iter() }\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "<raw::RawIter<T> as core::iter::Iterator>::fold": [
            "#[inline]\nfn fold<B, F>(self, init: B, f: F) -> B\n    where\n        Self: Sized,\n        F: FnMut(B, Self::Item) -> B,{\n        unsafe { self.iter.fold_impl(self.items, init, f) }\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "<raw::RawIter<T> as core::iter::Iterator>::next": [
            "inline\nfn next(&mut self) -> Option<Bucket<T>>{\n        // Inner iterator iterates over buckets\n        // so it can do unnecessary work if we already yielded all items.\n        if self.items == 0 {\n            return None;\n        }\n\n        let nxt = unsafe {\n            // SAFETY: We check number of items to yield using `items` field.\n            self.iter.next_impl::<false>()\n        };\n\n        debug_assert!(nxt.is_some());\n        self.items -= 1;\n\n        nxt\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "<raw::RawIter<T> as core::iter::Iterator>::size_hint": [
            "#[inline]\nfn size_hint(&self) -> (usize, Option<usize>){\n        (self.items, Some(self.items))\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "<raw::RawIterHash<T> as core::clone::Clone>::clone": [
            "inline\nfn clone(&self) -> Self{\n        Self {\n            inner: self.inner.clone(),\n            _marker: PhantomData,\n        }\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "<raw::RawIterHash<T> as core::default::Default>::default": [
            "inline\nfn default() -> Self{\n        Self {\n            // SAFETY: Because the table is static, it always outlives the iter.\n            inner: unsafe { RawIterHashInner::new(&RawTableInner::NEW, 0) },\n            _marker: PhantomData,\n        }\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "<raw::RawIterHash<T> as core::iter::Iterator>::next": [
            "fn next(&mut self) -> Option<Bucket<T>>{\n        unsafe {\n            match self.inner.next() {\n                Some(index) => {\n                    // Can't use `RawTable::bucket` here as we don't have\n                    // an actual `RawTable` reference to use.\n                    debug_assert!(index <= self.inner.bucket_mask);\n                    let bucket = Bucket::from_base_index(self.inner.ctrl.cast(), index);\n                    Some(bucket)\n                }\n                None => None,\n            }\n        }\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "<raw::RawIterHashInner as core::iter::Iterator>::next": [
            "fn next(&mut self) -> Option<Self::Item>{\n        unsafe {\n            loop {\n                if let Some(bit) = self.bitmask.next() {\n                    let index = (self.probe_seq.pos + bit) & self.bucket_mask;\n                    return Some(index);\n                }\n                if likely(self.group.match_empty().any_bit_set()) {\n                    return None;\n                }\n                self.probe_seq.move_next(self.bucket_mask);\n\n                // Can't use `RawTableInner::ctrl` here as we don't have\n                // an actual `RawTableInner` reference to use.\n                let index = self.probe_seq.pos;\n                debug_assert!(index < self.bucket_mask + 1 + Group::WIDTH);\n                let group_ctrl = self.ctrl.as_ptr().add(index).cast();\n\n                self.group = Group::load(group_ctrl);\n                self.bitmask = self.group.match_tag(self.tag_hash).into_iter();\n            }\n        }\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "<raw::RawIterRange<T> as core::clone::Clone>::clone": [
            "inline\nfn clone(&self) -> Self{\n        Self {\n            data: self.data.clone(),\n            next_ctrl: self.next_ctrl,\n            current_group: self.current_group.clone(),\n            end: self.end,\n        }\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "<raw::RawIterRange<T> as core::iter::Iterator>::next": [
            "inline\nfn next(&mut self) -> Option<Bucket<T>>{\n        unsafe {\n            // SAFETY: We set checker flag to true.\n            self.next_impl::<true>()\n        }\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "<raw::RawIterRange<T> as core::iter::Iterator>::size_hint": [
            "#[inline]\nfn size_hint(&self) -> (usize, Option<usize>){\n        // We don't have an item count, so just guess based on the range size.\n        let remaining_buckets = if self.end > self.next_ctrl {\n            unsafe { offset_from(self.end, self.next_ctrl) }\n        } else {\n            0\n        };\n\n        // Add a group width to include the group we are currently processing.\n        (0, Some(Group::WIDTH + remaining_buckets))\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "<raw::RawTable<T, A> as core::clone::Clone>::clone": [
            "fn clone(&self) -> Self{\n        if self.table.is_empty_singleton() {\n            Self::new_in(self.alloc.clone())\n        } else {\n            unsafe {\n                // Avoid `Result::ok_or_else` because it bloats LLVM IR.\n                //\n                // SAFETY: This is safe as we are taking the size of an already allocated table\n                // and therefore capacity overflow cannot occur, `self.table.buckets()` is power\n                // of two and all allocator errors will be caught inside `RawTableInner::new_uninitialized`.\n                let mut new_table = match Self::new_uninitialized(\n                    self.alloc.clone(),\n                    self.table.buckets(),\n                    Fallibility::Infallible,\n                ) {\n                    Ok(table) => table,\n                    Err(_) => hint::unreachable_unchecked(),\n                };\n\n                // Cloning elements may fail (the clone function may panic). But we don't\n                // need to worry about uninitialized control bits, since:\n                // 1. The number of items (elements) in the table is zero, which means that\n                //    the control bits will not be read by Drop function.\n                // 2. The `clone_from_spec` method will first copy all control bits from\n                //    `self` (thus initializing them). But this will not affect the `Drop`\n                //    function, since the `clone_from_spec` function sets `items` only after\n                //    successfully cloning all elements.\n                new_table.clone_from_spec(self);\n                new_table\n            }\n        }\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "<raw::RawTable<T, A> as core::clone::Clone>::clone_from": [
            "fn clone_from(&mut self, source: &Self){\n        if source.table.is_empty_singleton() {\n            let mut old_inner = mem::replace(&mut self.table, RawTableInner::NEW);\n            unsafe {\n                // SAFETY:\n                // 1. We call the function only once;\n                // 2. We know for sure that `alloc` and `table_layout` matches the [`Allocator`]\n                //    and [`TableLayout`] that were used to allocate this table.\n                // 3. If any elements' drop function panics, then there will only be a memory leak,\n                //    because we have replaced the inner table with a new one.\n                old_inner.drop_inner_table::<T, _>(&self.alloc, Self::TABLE_LAYOUT);\n            }\n        } else {\n            unsafe {\n                // Make sure that if any panics occurs, we clear the table and\n                // leave it in an empty state.\n                let mut self_ = guard(self, |self_| {\n                    self_.clear_no_drop();\n                });\n\n                // First, drop all our elements without clearing the control\n                // bytes. If this panics then the scope guard will clear the\n                // table, leaking any elements that were not dropped yet.\n                //\n                // This leak is unavoidable: we can't try dropping more elements\n                // since this could lead to another panic and abort the process.\n                //\n                // SAFETY: If something gets wrong we clear our table right after\n                // dropping the elements, so there is no double drop, since `items`\n                // will be equal to zero.\n                self_.table.drop_elements::<T>();\n\n                // If necessary, resize our table to match the source.\n                if self_.buckets() != source.buckets() {\n                    let new_inner = match RawTableInner::new_uninitialized(\n                        &self_.alloc,\n                        Self::TABLE_LAYOUT,\n                        source.buckets(),\n                        Fallibility::Infallible,\n                    ) {\n                        Ok(table) => table,\n                        Err(_) => hint::unreachable_unchecked(),\n                    };\n                    // Replace the old inner with new uninitialized one. It's ok, since if something gets\n                    // wrong `ScopeGuard` will initialize all control bytes and leave empty table.\n                    let mut old_inner = mem::replace(&mut self_.table, new_inner);\n                    if !old_inner.is_empty_singleton() {\n                        // SAFETY:\n                        // 1. We have checked that our table is allocated.\n                        // 2. We know for sure that `alloc` and `table_layout` matches\n                        // the [`Allocator`] and [`TableLayout`] that were used to allocate this table.\n                        old_inner.free_buckets(&self_.alloc, Self::TABLE_LAYOUT);\n                    }\n                }\n\n                // Cloning elements may fail (the clone function may panic), but the `ScopeGuard`\n                // inside the `clone_from_impl` function will take care of that, dropping all\n                // cloned elements if necessary. Our `ScopeGuard` will clear the table.\n                self_.clone_from_spec(source);\n\n                // Disarm the scope guard if cloning was successful.\n                ScopeGuard::into_inner(self_);\n            }\n        }\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "<raw::RawTable<T, A> as core::default::Default>::default": [
            "#[inline]\nfn default() -> Self{\n        Self::new_in(Default::default())\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "<raw::RawTable<T, A> as core::iter::IntoIterator>::into_iter": [
            "inline\nfn into_iter(self) -> RawIntoIter<T, A>{\n        unsafe {\n            let iter = self.iter();\n            self.into_iter_from(iter)\n        }\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "<raw::RawTable<T, A> as core::ops::Drop>::drop": [
            "inline\nfn drop(&mut self){\n        unsafe {\n            // SAFETY:\n            // 1. We call the function only once;\n            // 2. We know for sure that `alloc` and `table_layout` matches the [`Allocator`]\n            //    and [`TableLayout`] that were used to allocate this table.\n            // 3. If the drop function of any elements fails, then only a memory leak will occur,\n            //    and we don't care because we are inside the `Drop` function of the `RawTable`,\n            //    so there won't be any table left in an inconsistent state.\n            self.table\n                .drop_inner_table::<T, _>(&self.alloc, Self::TABLE_LAYOUT);\n        }\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "<raw::RawTable<T, A> as raw::RawTableClone>::clone_from_spec": [
            "inline\nunsafe fn clone_from_spec(&mut self, source: &Self){\n            self.clone_from_impl(source);\n        }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "<raw_entry::RawEntryBuilder<'_, K, V, S, A> as core::fmt::Debug>::fmt": [
            "fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result{\n        f.debug_struct(\"RawEntryBuilder\").finish()\n    }",
            "Real(LocalPath(\"src/raw_entry.rs\"))"
        ],
        "<raw_entry::RawEntryBuilderMut<'_, K, V, S, A> as core::fmt::Debug>::fmt": [
            "fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result{\n        f.debug_struct(\"RawEntryBuilder\").finish()\n    }",
            "Real(LocalPath(\"src/raw_entry.rs\"))"
        ],
        "<raw_entry::RawEntryMut<'_, K, V, S, A> as core::fmt::Debug>::fmt": [
            "fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result{\n        match *self {\n            RawEntryMut::Vacant(ref v) => f.debug_tuple(\"RawEntry\").field(v).finish(),\n            RawEntryMut::Occupied(ref o) => f.debug_tuple(\"RawEntry\").field(o).finish(),\n        }\n    }",
            "Real(LocalPath(\"src/raw_entry.rs\"))"
        ],
        "<raw_entry::RawOccupiedEntryMut<'_, K, V, S, A> as core::fmt::Debug>::fmt": [
            "fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result{\n        f.debug_struct(\"RawOccupiedEntryMut\")\n            .field(\"key\", self.key())\n            .field(\"value\", self.get())\n            .finish()\n    }",
            "Real(LocalPath(\"src/raw_entry.rs\"))"
        ],
        "<raw_entry::RawVacantEntryMut<'_, K, V, S, A> as core::fmt::Debug>::fmt": [
            "fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result{\n        f.debug_struct(\"RawVacantEntryMut\").finish()\n    }",
            "Real(LocalPath(\"src/raw_entry.rs\"))"
        ],
        "<scopeguard::ScopeGuard<T, F> as core::ops::Deref>::deref": [
            "#[inline]\nfn deref(&self) -> &T{\n        &self.value\n    }",
            "Real(LocalPath(\"src/scopeguard.rs\"))"
        ],
        "<scopeguard::ScopeGuard<T, F> as core::ops::DerefMut>::deref_mut": [
            "#[inline]\nfn deref_mut(&mut self) -> &mut T{\n        &mut self.value\n    }",
            "Real(LocalPath(\"src/scopeguard.rs\"))"
        ],
        "<scopeguard::ScopeGuard<T, F> as core::ops::Drop>::drop": [
            "#[inline]\nfn drop(&mut self){\n        (self.dropfn)(&mut self.value);\n    }",
            "Real(LocalPath(\"src/scopeguard.rs\"))"
        ],
        "<set::Difference<'_, T, S, A> as core::clone::Clone>::clone": [
            "inline\nfn clone(&self) -> Self{\n        Difference {\n            iter: self.iter.clone(),\n            ..*self\n        }\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "<set::Difference<'_, T, S, A> as core::fmt::Debug>::fmt": [
            "fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result{\n        f.debug_list().entries(self.clone()).finish()\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "<set::Difference<'a, T, S, A> as core::iter::Iterator>::fold": [
            "inline\nfn fold<B, F>(self, init: B, mut f: F) -> B\n    where\n        Self: Sized,\n        F: FnMut(B, Self::Item) -> B,{\n        self.iter.fold(init, |acc, elt| {\n            if self.other.contains(elt) {\n                acc\n            } else {\n                f(acc, elt)\n            }\n        })\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "<set::Difference<'a, T, S, A> as core::iter::Iterator>::next": [
            "inline\nfn next(&mut self) -> Option<&'a T>{\n        loop {\n            let elt = self.iter.next()?;\n            if !self.other.contains(elt) {\n                return Some(elt);\n            }\n        }\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "<set::Difference<'a, T, S, A> as core::iter::Iterator>::size_hint": [
            "inline\nfn size_hint(&self) -> (usize, Option<usize>){\n        let (lower, upper) = self.iter.size_hint();\n        (lower.saturating_sub(self.other.len()), upper)\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "<set::Drain<'_, K, A> as core::fmt::Debug>::fmt": [
            "fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result{\n        let entries_iter = self.iter.iter().map(|(k, _)| k);\n        f.debug_list().entries(entries_iter).finish()\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "<set::Drain<'_, K, A> as core::iter::ExactSizeIterator>::len": [
            "inline\nfn len(&self) -> usize{\n        self.iter.len()\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "<set::Drain<'_, K, A> as core::iter::Iterator>::fold": [
            "inline\nfn fold<B, F>(self, init: B, mut f: F) -> B\n    where\n        Self: Sized,\n        F: FnMut(B, Self::Item) -> B,{\n        self.iter.fold(init, |acc, (k, ())| f(acc, k))\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "<set::Drain<'_, K, A> as core::iter::Iterator>::next": [
            "inline\nfn next(&mut self) -> Option<K>{\n        // Avoid `Option::map` because it bloats LLVM IR.\n        match self.iter.next() {\n            Some((k, _)) => Some(k),\n            None => None,\n        }\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "<set::Drain<'_, K, A> as core::iter::Iterator>::size_hint": [
            "inline\nfn size_hint(&self) -> (usize, Option<usize>){\n        self.iter.size_hint()\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "<set::Entry<'_, T, S, A> as core::fmt::Debug>::fmt": [
            "fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result{\n        match *self {\n            Entry::Vacant(ref v) => f.debug_tuple(\"Entry\").field(v).finish(),\n            Entry::Occupied(ref o) => f.debug_tuple(\"Entry\").field(o).finish(),\n        }\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "<set::ExtractIf<'_, K, F, A> as core::iter::Iterator>::next": [
            "inline\nfn next(&mut self) -> Option<Self::Item>{\n        self.inner\n            .next(|&mut (ref k, ())| (self.f)(k))\n            .map(|(k, ())| k)\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "<set::ExtractIf<'_, K, F, A> as core::iter::Iterator>::size_hint": [
            "#[inline]\nfn size_hint(&self) -> (usize, Option<usize>){\n        (0, self.inner.iter.size_hint().1)\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "<set::HashSet<T, S, A> as core::clone::Clone>::clone": [
            "fn clone(&self) -> Self{\n        HashSet {\n            map: self.map.clone(),\n        }\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "<set::HashSet<T, S, A> as core::clone::Clone>::clone_from": [
            "fn clone_from(&mut self, source: &Self){\n        self.map.clone_from(&source.map);\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "<set::HashSet<T, S, A> as core::cmp::PartialEq>::eq": [
            "fn eq(&self, other: &Self) -> bool{\n        if self.len() != other.len() {\n            return false;\n        }\n\n        self.iter().all(|key| other.contains(key))\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "<set::HashSet<T, S, A> as core::convert::From<map::HashMap<T, (), S, A>>>::from": [
            "fn from(map: HashMap<T, (), S, A>) -> Self{\n        Self { map }\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "<set::HashSet<T, S, A> as core::default::Default>::default": [
            "/// Creates an empty `HashSet<T, S>` with the `Default` value for the hasher.\ninline\nfn default() -> Self{\n        Self {\n            map: HashMap::default(),\n        }\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "<set::HashSet<T, S, A> as core::fmt::Debug>::fmt": [
            "fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result{\n        f.debug_set().entries(self.iter()).finish()\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "<set::HashSet<T, S, A> as core::iter::Extend<&'a T>>::extend": [
            "inline\nfn extend<I: IntoIterator<Item = &'a T>>(&mut self, iter: I){\n        self.extend(iter.into_iter().copied());\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "<set::HashSet<T, S, A> as core::iter::Extend<T>>::extend": [
            "inline\nfn extend<I: IntoIterator<Item = T>>(&mut self, iter: I){\n        self.map.extend(iter.into_iter().map(|k| (k, ())));\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "<set::HashSet<T, S, A> as core::iter::FromIterator<T>>::from_iter": [
            "inline\nfn from_iter<I: IntoIterator<Item = T>>(iter: I) -> Self{\n        let mut set = Self::with_hasher_in(Default::default(), Default::default());\n        set.extend(iter);\n        set\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "<set::HashSet<T, S, A> as core::iter::IntoIterator>::into_iter": [
            "/// Creates a consuming iterator, that is, one that moves each value out\n/// of the set in arbitrary order. The set cannot be used after calling\n/// this.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n/// let mut set = HashSet::new();\n/// set.insert(\"a\".to_string());\n/// set.insert(\"b\".to_string());\n///\n/// // Not possible to collect to a Vec<String> with a regular `.iter()`.\n/// let v: Vec<String> = set.into_iter().collect();\n///\n/// // Will print in an arbitrary order.\n/// for x in &v {\n///     println!(\"{}\", x);\n/// }\n/// ```\ninline\nfn into_iter(self) -> IntoIter<T, A>{\n        IntoIter {\n            iter: self.map.into_iter(),\n        }\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "<set::HashSet<T, S, A> as core::ops::BitAndAssign<&set::HashSet<T, S, A>>>::bitand_assign": [
            "/// Modifies this set to contain the intersection of `self` and `rhs`.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n///\n/// let mut a: HashSet<_> = vec![1, 2, 3].into_iter().collect();\n/// let b: HashSet<_> = vec![2, 3, 4].into_iter().collect();\n///\n/// a &= &b;\n///\n/// let mut i = 0;\n/// let expected = [2, 3];\n/// for x in &a {\n///     assert!(expected.contains(x));\n///     i += 1;\n/// }\n/// assert_eq!(i, expected.len());\n/// ```\nfn bitand_assign(&mut self, rhs: &HashSet<T, S, A>){\n        self.retain(|item| rhs.contains(item));\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "<set::HashSet<T, S, A> as core::ops::BitOrAssign<&set::HashSet<T, S, A>>>::bitor_assign": [
            "/// Modifies this set to contain the union of `self` and `rhs`.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n///\n/// let mut a: HashSet<_> = vec![1, 2, 3].into_iter().collect();\n/// let b: HashSet<_> = vec![3, 4, 5].into_iter().collect();\n///\n/// a |= &b;\n///\n/// let mut i = 0;\n/// let expected = [1, 2, 3, 4, 5];\n/// for x in &a {\n///     assert!(expected.contains(x));\n///     i += 1;\n/// }\n/// assert_eq!(i, expected.len());\n/// ```\nfn bitor_assign(&mut self, rhs: &HashSet<T, S, A>){\n        for item in rhs {\n            if !self.contains(item) {\n                self.insert(item.clone());\n            }\n        }\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "<set::HashSet<T, S, A> as core::ops::BitXorAssign<&set::HashSet<T, S, A>>>::bitxor_assign": [
            "/// Modifies this set to contain the symmetric difference of `self` and `rhs`.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n///\n/// let mut a: HashSet<_> = vec![1, 2, 3].into_iter().collect();\n/// let b: HashSet<_> = vec![3, 4, 5].into_iter().collect();\n///\n/// a ^= &b;\n///\n/// let mut i = 0;\n/// let expected = [1, 2, 4, 5];\n/// for x in &a {\n///     assert!(expected.contains(x));\n///     i += 1;\n/// }\n/// assert_eq!(i, expected.len());\n/// ```\nfn bitxor_assign(&mut self, rhs: &HashSet<T, S, A>){\n        for item in rhs {\n            let hash = make_hash(&self.map.hash_builder, item);\n            match self.map.find_or_find_insert_slot(hash, item) {\n                Ok(bucket) => unsafe {\n                    self.map.table.remove(bucket);\n                },\n                Err(slot) => unsafe {\n                    self.map\n                        .table\n                        .insert_in_slot(hash, slot, (item.clone(), ()));\n                },\n            }\n        }\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "<set::HashSet<T, S, A> as core::ops::SubAssign<&set::HashSet<T, S, A>>>::sub_assign": [
            "/// Modifies this set to contain the difference of `self` and `rhs`.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n///\n/// let mut a: HashSet<_> = vec![1, 2, 3].into_iter().collect();\n/// let b: HashSet<_> = vec![3, 4, 5].into_iter().collect();\n///\n/// a -= &b;\n///\n/// let mut i = 0;\n/// let expected = [1, 2];\n/// for x in &a {\n///     assert!(expected.contains(x));\n///     i += 1;\n/// }\n/// assert_eq!(i, expected.len());\n/// ```\nfn sub_assign(&mut self, rhs: &HashSet<T, S, A>){\n        if rhs.len() < self.len() {\n            for item in rhs {\n                self.remove(item);\n            }\n        } else {\n            self.retain(|item| !rhs.contains(item));\n        }\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "<set::HashSet<T, foldhash::fast::RandomState, A> as core::convert::From<[T; N]>>::from": [
            "/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n///\n/// let set1 = HashSet::from([1, 2, 3, 4]);\n/// let set2: HashSet<_> = [1, 2, 3, 4].into();\n/// assert_eq!(set1, set2);\n/// ```\nfn from(arr: [T; N]) -> Self{\n        arr.into_iter().collect()\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "<set::Intersection<'_, T, S, A> as core::clone::Clone>::clone": [
            "inline\nfn clone(&self) -> Self{\n        Intersection {\n            iter: self.iter.clone(),\n            ..*self\n        }\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "<set::Intersection<'_, T, S, A> as core::fmt::Debug>::fmt": [
            "fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result{\n        f.debug_list().entries(self.clone()).finish()\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "<set::Intersection<'a, T, S, A> as core::iter::Iterator>::fold": [
            "inline\nfn fold<B, F>(self, init: B, mut f: F) -> B\n    where\n        Self: Sized,\n        F: FnMut(B, Self::Item) -> B,{\n        self.iter.fold(init, |acc, elt| {\n            if self.other.contains(elt) {\n                f(acc, elt)\n            } else {\n                acc\n            }\n        })\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "<set::Intersection<'a, T, S, A> as core::iter::Iterator>::next": [
            "inline\nfn next(&mut self) -> Option<&'a T>{\n        loop {\n            let elt = self.iter.next()?;\n            if self.other.contains(elt) {\n                return Some(elt);\n            }\n        }\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "<set::Intersection<'a, T, S, A> as core::iter::Iterator>::size_hint": [
            "inline\nfn size_hint(&self) -> (usize, Option<usize>){\n        let (_, upper) = self.iter.size_hint();\n        (0, upper)\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "<set::IntoIter<K, A> as core::default::Default>::default": [
            "inline\nfn default() -> Self{\n        IntoIter {\n            iter: Default::default(),\n        }\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "<set::IntoIter<K, A> as core::fmt::Debug>::fmt": [
            "fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result{\n        let entries_iter = self.iter.iter().map(|(k, _)| k);\n        f.debug_list().entries(entries_iter).finish()\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "<set::IntoIter<K, A> as core::iter::ExactSizeIterator>::len": [
            "inline\nfn len(&self) -> usize{\n        self.iter.len()\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "<set::IntoIter<K, A> as core::iter::Iterator>::fold": [
            "inline\nfn fold<B, F>(self, init: B, mut f: F) -> B\n    where\n        Self: Sized,\n        F: FnMut(B, Self::Item) -> B,{\n        self.iter.fold(init, |acc, (k, ())| f(acc, k))\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "<set::IntoIter<K, A> as core::iter::Iterator>::next": [
            "inline\nfn next(&mut self) -> Option<K>{\n        // Avoid `Option::map` because it bloats LLVM IR.\n        match self.iter.next() {\n            Some((k, _)) => Some(k),\n            None => None,\n        }\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "<set::IntoIter<K, A> as core::iter::Iterator>::size_hint": [
            "inline\nfn size_hint(&self) -> (usize, Option<usize>){\n        self.iter.size_hint()\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "<set::Iter<'_, K> as core::clone::Clone>::clone": [
            "inline\nfn clone(&self) -> Self{\n        Iter {\n            iter: self.iter.clone(),\n        }\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "<set::Iter<'_, K> as core::default::Default>::default": [
            "inline\nfn default() -> Self{\n        Iter {\n            iter: Default::default(),\n        }\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "<set::Iter<'_, K> as core::fmt::Debug>::fmt": [
            "fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result{\n        f.debug_list().entries(self.clone()).finish()\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "<set::Iter<'_, K> as core::iter::ExactSizeIterator>::len": [
            "inline\nfn len(&self) -> usize{\n        self.iter.len()\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "<set::Iter<'a, K> as core::iter::Iterator>::fold": [
            "inline\nfn fold<B, F>(self, init: B, f: F) -> B\n    where\n        Self: Sized,\n        F: FnMut(B, Self::Item) -> B,{\n        self.iter.fold(init, f)\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "<set::Iter<'a, K> as core::iter::Iterator>::next": [
            "inline\nfn next(&mut self) -> Option<&'a K>{\n        self.iter.next()\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "<set::Iter<'a, K> as core::iter::Iterator>::size_hint": [
            "inline\nfn size_hint(&self) -> (usize, Option<usize>){\n        self.iter.size_hint()\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "<set::OccupiedEntry<'_, T, S, A> as core::fmt::Debug>::fmt": [
            "fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result{\n        f.debug_struct(\"OccupiedEntry\")\n            .field(\"value\", self.get())\n            .finish()\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "<set::SymmetricDifference<'_, T, S, A> as core::clone::Clone>::clone": [
            "inline\nfn clone(&self) -> Self{\n        SymmetricDifference {\n            iter: self.iter.clone(),\n        }\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "<set::SymmetricDifference<'_, T, S, A> as core::fmt::Debug>::fmt": [
            "fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result{\n        f.debug_list().entries(self.clone()).finish()\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "<set::SymmetricDifference<'a, T, S, A> as core::iter::Iterator>::fold": [
            "inline\nfn fold<B, F>(self, init: B, f: F) -> B\n    where\n        Self: Sized,\n        F: FnMut(B, Self::Item) -> B,{\n        self.iter.fold(init, f)\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "<set::SymmetricDifference<'a, T, S, A> as core::iter::Iterator>::next": [
            "inline\nfn next(&mut self) -> Option<&'a T>{\n        self.iter.next()\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "<set::SymmetricDifference<'a, T, S, A> as core::iter::Iterator>::size_hint": [
            "inline\nfn size_hint(&self) -> (usize, Option<usize>){\n        self.iter.size_hint()\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "<set::Union<'_, T, S, A> as core::clone::Clone>::clone": [
            "inline\nfn clone(&self) -> Self{\n        Union {\n            iter: self.iter.clone(),\n        }\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "<set::Union<'_, T, S, A> as core::fmt::Debug>::fmt": [
            "fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result{\n        f.debug_list().entries(self.clone()).finish()\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "<set::Union<'a, T, S, A> as core::iter::Iterator>::fold": [
            "inline\nfn fold<B, F>(self, init: B, f: F) -> B\n    where\n        Self: Sized,\n        F: FnMut(B, Self::Item) -> B,{\n        self.iter.fold(init, f)\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "<set::Union<'a, T, S, A> as core::iter::Iterator>::next": [
            "inline\nfn next(&mut self) -> Option<&'a T>{\n        self.iter.next()\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "<set::Union<'a, T, S, A> as core::iter::Iterator>::size_hint": [
            "inline\nfn size_hint(&self) -> (usize, Option<usize>){\n        self.iter.size_hint()\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "<set::VacantEntry<'_, T, S, A> as core::fmt::Debug>::fmt": [
            "fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result{\n        f.debug_tuple(\"VacantEntry\").field(self.get()).finish()\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "<table::AbsentEntry<'_, T, A> as core::fmt::Debug>::fmt": [
            "fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result{\n        f.write_str(\"AbsentEntry\")\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "<table::Drain<'_, T, A> as core::fmt::Debug>::fmt": [
            "fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result{\n        f.debug_list()\n            .entries(Iter {\n                inner: self.inner.iter(),\n                marker: PhantomData,\n            })\n            .finish()\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "<table::Drain<'_, T, A> as core::iter::ExactSizeIterator>::len": [
            "fn len(&self) -> usize{\n        self.inner.len()\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "<table::Drain<'_, T, A> as core::iter::Iterator>::fold": [
            "fn fold<B, F>(self, init: B, f: F) -> B\n    where\n        Self: Sized,\n        F: FnMut(B, Self::Item) -> B,{\n        self.inner.fold(init, f)\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "<table::Drain<'_, T, A> as core::iter::Iterator>::next": [
            "fn next(&mut self) -> Option<T>{\n        self.inner.next()\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "<table::Drain<'_, T, A> as core::iter::Iterator>::size_hint": [
            "fn size_hint(&self) -> (usize, Option<usize>){\n        self.inner.size_hint()\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "<table::Entry<'_, T, A> as core::fmt::Debug>::fmt": [
            "fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result{\n        match *self {\n            Entry::Vacant(ref v) => f.debug_tuple(\"Entry\").field(v).finish(),\n            Entry::Occupied(ref o) => f.debug_tuple(\"Entry\").field(o).finish(),\n        }\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "<table::ExtractIf<'_, T, F, A> as core::iter::Iterator>::next": [
            "#[inline]\nfn next(&mut self) -> Option<Self::Item>{\n        self.inner.next(|val| (self.f)(val))\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "<table::ExtractIf<'_, T, F, A> as core::iter::Iterator>::size_hint": [
            "#[inline]\nfn size_hint(&self) -> (usize, Option<usize>){\n        (0, self.inner.iter.size_hint().1)\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "<table::HashTable<T, A> as core::clone::Clone>::clone": [
            "fn clone(&self) -> Self{\n        Self {\n            raw: self.raw.clone(),\n        }\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "<table::HashTable<T, A> as core::default::Default>::default": [
            "fn default() -> Self{\n        Self {\n            raw: Default::default(),\n        }\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "<table::HashTable<T, A> as core::fmt::Debug>::fmt": [
            "fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result{\n        f.debug_set().entries(self.iter()).finish()\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "<table::HashTable<T, A> as core::iter::IntoIterator>::into_iter": [
            "fn into_iter(self) -> IntoIter<T, A>{\n        IntoIter {\n            inner: self.raw.into_iter(),\n        }\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "<table::IntoIter<T, A> as core::default::Default>::default": [
            "inline\nfn default() -> Self{\n        IntoIter {\n            inner: Default::default(),\n        }\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "<table::IntoIter<T, A> as core::fmt::Debug>::fmt": [
            "fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result{\n        f.debug_list()\n            .entries(Iter {\n                inner: self.inner.iter(),\n                marker: PhantomData,\n            })\n            .finish()\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "<table::IntoIter<T, A> as core::iter::ExactSizeIterator>::len": [
            "fn len(&self) -> usize{\n        self.inner.len()\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "<table::IntoIter<T, A> as core::iter::Iterator>::fold": [
            "fn fold<B, F>(self, init: B, f: F) -> B\n    where\n        Self: Sized,\n        F: FnMut(B, Self::Item) -> B,{\n        self.inner.fold(init, f)\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "<table::IntoIter<T, A> as core::iter::Iterator>::next": [
            "fn next(&mut self) -> Option<Self::Item>{\n        self.inner.next()\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "<table::IntoIter<T, A> as core::iter::Iterator>::size_hint": [
            "fn size_hint(&self) -> (usize, Option<usize>){\n        self.inner.size_hint()\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "<table::Iter<'_, T> as core::default::Default>::default": [
            "inline\nfn default() -> Self{\n        Iter {\n            inner: Default::default(),\n            marker: PhantomData,\n        }\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "<table::Iter<'_, T> as core::fmt::Debug>::fmt": [
            "fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result{\n        f.debug_list().entries(self.clone()).finish()\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "<table::Iter<'_, T> as core::iter::ExactSizeIterator>::len": [
            "fn len(&self) -> usize{\n        self.inner.len()\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "<table::Iter<'a, T> as core::clone::Clone>::clone": [
            "inline\nfn clone(&self) -> Iter<'a, T>{\n        Iter {\n            inner: self.inner.clone(),\n            marker: PhantomData,\n        }\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "<table::Iter<'a, T> as core::iter::Iterator>::fold": [
            "fn fold<B, F>(self, init: B, mut f: F) -> B\n    where\n        Self: Sized,\n        F: FnMut(B, Self::Item) -> B,{\n        self.inner\n            .fold(init, |acc, bucket| unsafe { f(acc, bucket.as_ref()) })\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "<table::Iter<'a, T> as core::iter::Iterator>::next": [
            "fn next(&mut self) -> Option<Self::Item>{\n        // Avoid `Option::map` because it bloats LLVM IR.\n        match self.inner.next() {\n            Some(bucket) => Some(unsafe { bucket.as_ref() }),\n            None => None,\n        }\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "<table::Iter<'a, T> as core::iter::Iterator>::size_hint": [
            "fn size_hint(&self) -> (usize, Option<usize>){\n        self.inner.size_hint()\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "<table::IterHash<'_, T> as core::default::Default>::default": [
            "inline\nfn default() -> Self{\n        IterHash {\n            inner: Default::default(),\n            marker: PhantomData,\n        }\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "<table::IterHash<'_, T> as core::fmt::Debug>::fmt": [
            "fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result{\n        f.debug_list().entries(self.clone()).finish()\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "<table::IterHash<'a, T> as core::clone::Clone>::clone": [
            "inline\nfn clone(&self) -> IterHash<'a, T>{\n        IterHash {\n            inner: self.inner.clone(),\n            marker: PhantomData,\n        }\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "<table::IterHash<'a, T> as core::iter::Iterator>::fold": [
            "fn fold<B, F>(self, init: B, mut f: F) -> B\n    where\n        Self: Sized,\n        F: FnMut(B, Self::Item) -> B,{\n        self.inner\n            .fold(init, |acc, bucket| unsafe { f(acc, bucket.as_ref()) })\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "<table::IterHash<'a, T> as core::iter::Iterator>::next": [
            "fn next(&mut self) -> Option<Self::Item>{\n        // Avoid `Option::map` because it bloats LLVM IR.\n        match self.inner.next() {\n            Some(bucket) => Some(unsafe { bucket.as_ref() }),\n            None => None,\n        }\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "<table::IterHashMut<'_, T> as core::default::Default>::default": [
            "inline\nfn default() -> Self{\n        IterHashMut {\n            inner: Default::default(),\n            marker: PhantomData,\n        }\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "<table::IterHashMut<'_, T> as core::fmt::Debug>::fmt": [
            "fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result{\n        f.debug_list()\n            .entries(IterHash {\n                inner: self.inner.clone(),\n                marker: PhantomData,\n            })\n            .finish()\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "<table::IterHashMut<'a, T> as core::iter::Iterator>::fold": [
            "fn fold<B, F>(self, init: B, mut f: F) -> B\n    where\n        Self: Sized,\n        F: FnMut(B, Self::Item) -> B,{\n        self.inner\n            .fold(init, |acc, bucket| unsafe { f(acc, bucket.as_mut()) })\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "<table::IterHashMut<'a, T> as core::iter::Iterator>::next": [
            "fn next(&mut self) -> Option<Self::Item>{\n        // Avoid `Option::map` because it bloats LLVM IR.\n        match self.inner.next() {\n            Some(bucket) => Some(unsafe { bucket.as_mut() }),\n            None => None,\n        }\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "<table::IterMut<'_, T> as core::default::Default>::default": [
            "inline\nfn default() -> Self{\n        IterMut {\n            inner: Default::default(),\n            marker: PhantomData,\n        }\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "<table::IterMut<'_, T> as core::fmt::Debug>::fmt": [
            "fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result{\n        f.debug_list()\n            .entries(Iter {\n                inner: self.inner.clone(),\n                marker: PhantomData,\n            })\n            .finish()\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "<table::IterMut<'_, T> as core::iter::ExactSizeIterator>::len": [
            "fn len(&self) -> usize{\n        self.inner.len()\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "<table::IterMut<'a, T> as core::iter::Iterator>::fold": [
            "fn fold<B, F>(self, init: B, mut f: F) -> B\n    where\n        Self: Sized,\n        F: FnMut(B, Self::Item) -> B,{\n        self.inner\n            .fold(init, |acc, bucket| unsafe { f(acc, bucket.as_mut()) })\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "<table::IterMut<'a, T> as core::iter::Iterator>::next": [
            "fn next(&mut self) -> Option<Self::Item>{\n        // Avoid `Option::map` because it bloats LLVM IR.\n        match self.inner.next() {\n            Some(bucket) => Some(unsafe { bucket.as_mut() }),\n            None => None,\n        }\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "<table::IterMut<'a, T> as core::iter::Iterator>::size_hint": [
            "fn size_hint(&self) -> (usize, Option<usize>){\n        self.inner.size_hint()\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "<table::OccupiedEntry<'_, T, A> as core::fmt::Debug>::fmt": [
            "fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result{\n        f.debug_struct(\"OccupiedEntry\")\n            .field(\"value\", self.get())\n            .finish()\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "<table::VacantEntry<'_, T, A> as core::fmt::Debug>::fmt": [
            "fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result{\n        f.write_str(\"VacantEntry\")\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "TryReserveError": [
            "/// The error type for `try_reserve` methods.\npub enum TryReserveError {\n    /// Error due to the computed capacity exceeding the collection's maximum\n    /// (usually `isize::MAX` bytes).\n    CapacityOverflow,\n\n    /// The memory allocator returned an error\n    AllocError {\n        /// The layout of the allocation request that failed.\n        layout: alloc::alloc::Layout,\n    },\n}",
            "Real(LocalPath(\"src/lib.rs\"))"
        ],
        "control::bitmask::BitMask": [
            "/// A bit mask which contains the result of a `Match` operation on a `Group` and\n/// allows iterating through them.\n///\n/// The bit mask is arranged so that low-order bits represent lower memory\n/// addresses for group match results.\n///\n/// For implementation reasons, the bits in the set may be sparsely packed with\n/// groups of 8 bits representing one element. If any of these bits are non-zero\n/// then this element is considered to true in the mask. If this is the\n/// case, `BITMASK_STRIDE` will be 8 to indicate a divide-by-8 should be\n/// performed on counts/indices to normalize this difference. `BITMASK_MASK` is\n/// similarly a mask of all the actually-used bits.\n///\n/// To iterate over a bit mask, it must be converted to a form where only 1 bit\n/// is set per element. This is done by applying `BITMASK_ITER_MASK` on the\n/// mask bits.\npub(crate) struct BitMask(pub(crate) BitMaskWord);",
            "Real(LocalPath(\"src/control/bitmask.rs\"))"
        ],
        "control::bitmask::BitMask::any_bit_set": [
            "/// Returns whether the `BitMask` has at least one set bit.\n#[inline]\npub(crate) fn any_bit_set(self) -> bool{\n        self.0 != 0\n    }",
            "Real(LocalPath(\"src/control/bitmask.rs\"))"
        ],
        "control::bitmask::BitMask::invert": [
            "/// Returns a new `BitMask` with all bits inverted.\n#[inline]\n#[must_use]\n#[allow(dead_code)]\npub(crate) fn invert(self) -> Self{\n        BitMask(self.0 ^ BITMASK_MASK)\n    }",
            "Real(LocalPath(\"src/control/bitmask.rs\"))"
        ],
        "control::bitmask::BitMask::leading_zeros": [
            "/// Returns the number of leading zeroes in the `BitMask`.\n#[inline]\npub(crate) fn leading_zeros(self) -> usize{\n        self.0.leading_zeros() as usize / BITMASK_STRIDE\n    }",
            "Real(LocalPath(\"src/control/bitmask.rs\"))"
        ],
        "control::bitmask::BitMask::lowest_set_bit": [
            "/// Returns the first set bit in the `BitMask`, if there is one.\n#[inline]\npub(crate) fn lowest_set_bit(self) -> Option<usize>{\n        if let Some(nonzero) = NonZeroBitMaskWord::new(self.0) {\n            Some(Self::nonzero_trailing_zeros(nonzero))\n        } else {\n            None\n        }\n    }",
            "Real(LocalPath(\"src/control/bitmask.rs\"))"
        ],
        "control::bitmask::BitMask::nonzero_trailing_zeros": [
            "/// Same as above but takes a `NonZeroBitMaskWord`.\n#[inline]\nfn nonzero_trailing_zeros(nonzero: NonZeroBitMaskWord) -> usize{\n        if cfg!(target_arch = \"arm\") && BITMASK_STRIDE % 8 == 0 {\n            // SAFETY: A byte-swapped non-zero value is still non-zero.\n            let swapped = unsafe { NonZeroBitMaskWord::new_unchecked(nonzero.get().swap_bytes()) };\n            swapped.leading_zeros() as usize / BITMASK_STRIDE\n        } else {\n            nonzero.trailing_zeros() as usize / BITMASK_STRIDE\n        }\n    }",
            "Real(LocalPath(\"src/control/bitmask.rs\"))"
        ],
        "control::bitmask::BitMask::remove_lowest_bit": [
            "/// Returns a new `BitMask` with the lowest bit removed.\n#[inline]\n#[must_use]\nfn remove_lowest_bit(self) -> Self{\n        BitMask(self.0 & (self.0 - 1))\n    }",
            "Real(LocalPath(\"src/control/bitmask.rs\"))"
        ],
        "control::bitmask::BitMask::trailing_zeros": [
            "/// Returns the number of trailing zeroes in the `BitMask`.\n#[inline]\npub(crate) fn trailing_zeros(self) -> usize{\n        // ARM doesn't have a trailing_zeroes instruction, and instead uses\n        // reverse_bits (RBIT) + leading_zeroes (CLZ). However older ARM\n        // versions (pre-ARMv7) don't have RBIT and need to emulate it\n        // instead. Since we only have 1 bit set in each byte on ARM, we can\n        // use swap_bytes (REV) + leading_zeroes instead.\n        if cfg!(target_arch = \"arm\") && BITMASK_STRIDE % 8 == 0 {\n            self.0.swap_bytes().leading_zeros() as usize / BITMASK_STRIDE\n        } else {\n            self.0.trailing_zeros() as usize / BITMASK_STRIDE\n        }\n    }",
            "Real(LocalPath(\"src/control/bitmask.rs\"))"
        ],
        "control::bitmask::BitMaskIter": [
            "/// Iterator over the contents of a `BitMask`, returning the indices of set\n/// bits.\npub(crate) struct BitMaskIter(pub(crate) BitMask);",
            "Real(LocalPath(\"src/control/bitmask.rs\"))"
        ],
        "control::group::sse2::Group": [
            "/// Abstraction over a group of control tags which can be scanned in\n/// parallel.\n///\n/// This implementation uses a 128-bit SSE value.\npub(crate) struct Group(x86::__m128i);",
            "Real(LocalPath(\"src/control/group/sse2.rs\"))"
        ],
        "control::group::sse2::Group::convert_special_to_empty_and_full_to_deleted": [
            "/// Performs the following transformation on all tags in the group:\n/// - `EMPTY => EMPTY`\n/// - `DELETED => EMPTY`\n/// - `FULL => DELETED`\n#[inline]\npub(crate) fn convert_special_to_empty_and_full_to_deleted(self) -> Self{\n        // Map high_bit = 1 (EMPTY or DELETED) to 1111_1111\n        // and high_bit = 0 (FULL) to 1000_0000\n        //\n        // Here's this logic expanded to concrete values:\n        //   let special = 0 > tag = 1111_1111 (true) or 0000_0000 (false)\n        //   1111_1111 | 1000_0000 = 1111_1111\n        //   0000_0000 | 1000_0000 = 1000_0000\n        #[allow(\n            clippy::cast_possible_wrap, // tag: Tag::DELETED.0 as i8\n        )]\n        unsafe {\n            let zero = x86::_mm_setzero_si128();\n            let special = x86::_mm_cmpgt_epi8(zero, self.0);\n            Group(x86::_mm_or_si128(\n                special,\n                x86::_mm_set1_epi8(Tag::DELETED.0 as i8),\n            ))\n        }\n    }",
            "Real(LocalPath(\"src/control/group/sse2.rs\"))"
        ],
        "control::group::sse2::Group::load": [
            "/// Loads a group of tags starting at the given address.\n#[inline]\n#[allow(clippy::cast_ptr_alignment)]\npub(crate) unsafe fn load(ptr: *const Tag) -> Self{\n        Group(x86::_mm_loadu_si128(ptr.cast()))\n    }",
            "Real(LocalPath(\"src/control/group/sse2.rs\"))"
        ],
        "control::group::sse2::Group::load_aligned": [
            "/// Loads a group of tags starting at the given address, which must be\n/// aligned to `mem::align_of::<Group>()`.\n#[inline]\n#[allow(clippy::cast_ptr_alignment)]\npub(crate) unsafe fn load_aligned(ptr: *const Tag) -> Self{\n        debug_assert_eq!(ptr.align_offset(mem::align_of::<Self>()), 0);\n        Group(x86::_mm_load_si128(ptr.cast()))\n    }",
            "Real(LocalPath(\"src/control/group/sse2.rs\"))"
        ],
        "control::group::sse2::Group::match_empty": [
            "/// Returns a `BitMask` indicating all tags in the group which are\n/// `EMPTY`.\n#[inline]\npub(crate) fn match_empty(self) -> BitMask{\n        self.match_tag(Tag::EMPTY)\n    }",
            "Real(LocalPath(\"src/control/group/sse2.rs\"))"
        ],
        "control::group::sse2::Group::match_empty_or_deleted": [
            "/// Returns a `BitMask` indicating all tags in the group which are\n/// `EMPTY` or `DELETED`.\n#[inline]\npub(crate) fn match_empty_or_deleted(self) -> BitMask{\n        #[allow(\n            // tag: i32 as u16\n            //   note: _mm_movemask_epi8 returns a 16-bit mask in a i32, the\n            //   upper 16-bits of the i32 are zeroed:\n            clippy::cast_sign_loss,\n            clippy::cast_possible_truncation\n        )]\n        unsafe {\n            // A tag is EMPTY or DELETED iff the high bit is set\n            BitMask(x86::_mm_movemask_epi8(self.0) as u16)\n        }\n    }",
            "Real(LocalPath(\"src/control/group/sse2.rs\"))"
        ],
        "control::group::sse2::Group::match_full": [
            "/// Returns a `BitMask` indicating all tags in the group which are full.\n#[inline]\npub(crate) fn match_full(&self) -> BitMask{\n        self.match_empty_or_deleted().invert()\n    }",
            "Real(LocalPath(\"src/control/group/sse2.rs\"))"
        ],
        "control::group::sse2::Group::match_tag": [
            "/// Returns a `BitMask` indicating all tags in the group which have\n/// the given value.\n#[inline]\npub(crate) fn match_tag(self, tag: Tag) -> BitMask{\n        #[allow(\n            clippy::cast_possible_wrap, // tag.0: Tag as i8\n            // tag: i32 as u16\n            //   note: _mm_movemask_epi8 returns a 16-bit mask in a i32, the\n            //   upper 16-bits of the i32 are zeroed:\n            clippy::cast_sign_loss,\n            clippy::cast_possible_truncation\n        )]\n        unsafe {\n            let cmp = x86::_mm_cmpeq_epi8(self.0, x86::_mm_set1_epi8(tag.0 as i8));\n            BitMask(x86::_mm_movemask_epi8(cmp) as u16)\n        }\n    }",
            "Real(LocalPath(\"src/control/group/sse2.rs\"))"
        ],
        "control::group::sse2::Group::static_empty": [
            "/// Returns a full group of empty tags, suitable for use as the initial\n/// value for an empty hash table.\n///\n/// This is guaranteed to be aligned to the group size.\n#[inline]\n#[allow(clippy::items_after_statements)]\npub(crate) const fn static_empty() -> &'static [Tag; Group::WIDTH]{\n        #[repr(C)]\n        struct AlignedTags {\n            _align: [Group; 0],\n            tags: [Tag; Group::WIDTH],\n        }\n        const ALIGNED_TAGS: AlignedTags = AlignedTags {\n            _align: [],\n            tags: [Tag::EMPTY; Group::WIDTH],\n        };\n        &ALIGNED_TAGS.tags\n    }",
            "Real(LocalPath(\"src/control/group/sse2.rs\"))"
        ],
        "control::group::sse2::Group::static_empty::AlignedTags": [
            "#[repr(C)]\nstruct AlignedTags {\n            _align: [Group; 0],\n            tags: [Tag; Group::WIDTH],\n        }",
            "Real(LocalPath(\"src/control/group/sse2.rs\"))"
        ],
        "control::group::sse2::Group::store_aligned": [
            "/// Stores the group of tags to the given address, which must be\n/// aligned to `mem::align_of::<Group>()`.\n#[inline]\n#[allow(clippy::cast_ptr_alignment)]\npub(crate) unsafe fn store_aligned(self, ptr: *mut Tag){\n        debug_assert_eq!(ptr.align_offset(mem::align_of::<Self>()), 0);\n        x86::_mm_store_si128(ptr.cast(), self.0);\n    }",
            "Real(LocalPath(\"src/control/group/sse2.rs\"))"
        ],
        "control::tag::Tag": [
            "/// Single tag in a control group.\n#[repr(transparent)]\npub(crate) struct Tag(pub(super) u8);",
            "Real(LocalPath(\"src/control/tag.rs\"))"
        ],
        "control::tag::Tag::full": [
            "/// Creates a control tag representing a full bucket with the given hash.\n#[inline]\n#[allow(clippy::cast_possible_truncation)]\npub(crate) const fn full(hash: u64) -> Tag{\n        // Constant for function that grabs the top 7 bits of the hash.\n        const MIN_HASH_LEN: usize = if mem::size_of::<usize>() < mem::size_of::<u64>() {\n            mem::size_of::<usize>()\n        } else {\n            mem::size_of::<u64>()\n        };\n\n        // Grab the top 7 bits of the hash. While the hash is normally a full 64-bit\n        // value, some hash functions (such as FxHash) produce a usize result\n        // instead, which means that the top 32 bits are 0 on 32-bit platforms.\n        // So we use MIN_HASH_LEN constant to handle this.\n        let top7 = hash >> (MIN_HASH_LEN * 8 - 7);\n        Tag((top7 & 0x7f) as u8) // truncation\n    }",
            "Real(LocalPath(\"src/control/tag.rs\"))"
        ],
        "control::tag::Tag::is_full": [
            "/// Checks whether a control tag represents a full bucket (top bit is clear).\n#[inline]\npub(crate) const fn is_full(self) -> bool{\n        self.0 & 0x80 == 0\n    }",
            "Real(LocalPath(\"src/control/tag.rs\"))"
        ],
        "control::tag::Tag::is_special": [
            "/// Checks whether a control tag represents a special value (top bit is set).\n#[inline]\npub(crate) const fn is_special(self) -> bool{\n        self.0 & 0x80 != 0\n    }",
            "Real(LocalPath(\"src/control/tag.rs\"))"
        ],
        "control::tag::Tag::special_is_empty": [
            "/// Checks whether a special control value is EMPTY (just check 1 bit).\n#[inline]\npub(crate) const fn special_is_empty(self) -> bool{\n        debug_assert!(self.is_special());\n        self.0 & 0x01 != 0\n    }",
            "Real(LocalPath(\"src/control/tag.rs\"))"
        ],
        "control::tag::TagSliceExt": [
            "/// Extension trait for slices of tags.\npub(crate) trait TagSliceExt {\n    /// Fills the control with the given tag.\n    fn fill_tag(&mut self, tag: Tag);\n\n    /// Clears out the control.\n    #[inline]\n    fn fill_empty(&mut self) {\n        self.fill_tag(Tag::EMPTY)\n    }\n}",
            "Real(LocalPath(\"src/control/tag.rs\"))"
        ],
        "control::tag::TagSliceExt::fill_empty": [
            "/// Clears out the control.\n#[inline]\nfn fill_empty(&mut self){\n        self.fill_tag(Tag::EMPTY)\n    }",
            "Real(LocalPath(\"src/control/tag.rs\"))"
        ],
        "map::Drain": [
            "/// A draining iterator over the entries of a `HashMap` in arbitrary\n/// order. The iterator element type is `(K, V)`.\n///\n/// This `struct` is created by the [`drain`] method on [`HashMap`]. See its\n/// documentation for more.\n///\n/// [`drain`]: struct.HashMap.html#method.drain\n/// [`HashMap`]: struct.HashMap.html\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut map: HashMap<_, _> = [(1, \"a\"), (2, \"b\"), (3, \"c\")].into();\n///\n/// let mut drain_iter = map.drain();\n/// let mut vec = vec![drain_iter.next(), drain_iter.next(), drain_iter.next()];\n///\n/// // The `Drain` iterator produces items in arbitrary order, so the\n/// // items must be sorted to test them against a sorted array.\n/// vec.sort_unstable();\n/// assert_eq!(vec, [Some((1, \"a\")), Some((2, \"b\")), Some((3, \"c\"))]);\n///\n/// // It is fused iterator\n/// assert_eq!(drain_iter.next(), None);\n/// assert_eq!(drain_iter.next(), None);\n/// ```\npub struct Drain<'a, K, V, A: Allocator = Global> {\n    inner: RawDrain<'a, (K, V), A>,\n}",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::Drain::<'_, K, V, A>::iter": [
            "/// Returns a iterator of references over the remaining items.\ninline\npub(super) fn iter(&self) -> Iter<'_, K, V>{\n        Iter {\n            inner: self.inner.iter(),\n            marker: PhantomData,\n        }\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::Entry": [
            "/// A view into a single entry in a map, which may either be vacant or occupied.\n///\n/// This `enum` is constructed from the [`entry`] method on [`HashMap`].\n///\n/// [`HashMap`]: struct.HashMap.html\n/// [`entry`]: struct.HashMap.html#method.entry\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::hash_map::{Entry, HashMap, OccupiedEntry};\n///\n/// let mut map = HashMap::new();\n/// map.extend([(\"a\", 10), (\"b\", 20), (\"c\", 30)]);\n/// assert_eq!(map.len(), 3);\n///\n/// // Existing key (insert)\n/// let entry: Entry<_, _, _> = map.entry(\"a\");\n/// let _raw_o: OccupiedEntry<_, _, _> = entry.insert(1);\n/// assert_eq!(map.len(), 3);\n/// // Nonexistent key (insert)\n/// map.entry(\"d\").insert(4);\n///\n/// // Existing key (or_insert)\n/// let v = map.entry(\"b\").or_insert(2);\n/// assert_eq!(std::mem::replace(v, 2), 20);\n/// // Nonexistent key (or_insert)\n/// map.entry(\"e\").or_insert(5);\n///\n/// // Existing key (or_insert_with)\n/// let v = map.entry(\"c\").or_insert_with(|| 3);\n/// assert_eq!(std::mem::replace(v, 3), 30);\n/// // Nonexistent key (or_insert_with)\n/// map.entry(\"f\").or_insert_with(|| 6);\n///\n/// println!(\"Our HashMap: {:?}\", map);\n///\n/// let mut vec: Vec<_> = map.iter().map(|(&k, &v)| (k, v)).collect();\n/// // The `Iter` iterator produces items in arbitrary order, so the\n/// // items must be sorted to test them against a sorted array.\n/// vec.sort_unstable();\n/// assert_eq!(vec, [(\"a\", 1), (\"b\", 2), (\"c\", 3), (\"d\", 4), (\"e\", 5), (\"f\", 6)]);\n/// ```\npub enum Entry<'a, K, V, S, A = Global>\nwhere\n    A: Allocator,\n{\n    /// An occupied entry.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::hash_map::{Entry, HashMap};\n    /// let mut map: HashMap<_, _> = [(\"a\", 100), (\"b\", 200)].into();\n    ///\n    /// match map.entry(\"a\") {\n    ///     Entry::Vacant(_) => unreachable!(),\n    ///     Entry::Occupied(_) => { }\n    /// }\n    /// ```\n    Occupied(OccupiedEntry<'a, K, V, S, A>),\n\n    /// A vacant entry.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::hash_map::{Entry, HashMap};\n    /// let mut map: HashMap<&str, i32> = HashMap::new();\n    ///\n    /// match map.entry(\"a\") {\n    ///     Entry::Occupied(_) => unreachable!(),\n    ///     Entry::Vacant(_) => { }\n    /// }\n    /// ```\n    Vacant(VacantEntry<'a, K, V, S, A>),\n}",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::Entry::<'a, K, V, S, A>::and_modify": [
            "/// Provides in-place mutable access to an occupied entry before any\n/// potential inserts into the map.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut map: HashMap<&str, u32> = HashMap::new();\n///\n/// map.entry(\"poneyland\")\n///    .and_modify(|e| { *e += 1 })\n///    .or_insert(42);\n/// assert_eq!(map[\"poneyland\"], 42);\n///\n/// map.entry(\"poneyland\")\n///    .and_modify(|e| { *e += 1 })\n///    .or_insert(42);\n/// assert_eq!(map[\"poneyland\"], 43);\n/// ```\ninline\npub fn and_modify<F>(self, f: F) -> Self\n    where\n        F: FnOnce(&mut V),{\n        match self {\n            Entry::Occupied(mut entry) => {\n                f(entry.get_mut());\n                Entry::Occupied(entry)\n            }\n            Entry::Vacant(entry) => Entry::Vacant(entry),\n        }\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::Entry::<'a, K, V, S, A>::and_replace_entry_with": [
            "/// Provides shared access to the key and owned access to the value of\n/// an occupied entry and allows to replace or remove it based on the\n/// value of the returned option.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n/// use hashbrown::hash_map::Entry;\n///\n/// let mut map: HashMap<&str, u32> = HashMap::new();\n///\n/// let entry = map\n///     .entry(\"poneyland\")\n///     .and_replace_entry_with(|_k, _v| panic!());\n///\n/// match entry {\n///     Entry::Vacant(e) => {\n///         assert_eq!(e.key(), &\"poneyland\");\n///     }\n///     Entry::Occupied(_) => panic!(),\n/// }\n///\n/// map.insert(\"poneyland\", 42);\n///\n/// let entry = map\n///     .entry(\"poneyland\")\n///     .and_replace_entry_with(|k, v| {\n///         assert_eq!(k, &\"poneyland\");\n///         assert_eq!(v, 42);\n///         Some(v + 1)\n///     });\n///\n/// match entry {\n///     Entry::Occupied(e) => {\n///         assert_eq!(e.key(), &\"poneyland\");\n///         assert_eq!(e.get(), &43);\n///     }\n///     Entry::Vacant(_) => panic!(),\n/// }\n///\n/// assert_eq!(map[\"poneyland\"], 43);\n///\n/// let entry = map\n///     .entry(\"poneyland\")\n///     .and_replace_entry_with(|_k, _v| None);\n///\n/// match entry {\n///     Entry::Vacant(e) => assert_eq!(e.key(), &\"poneyland\"),\n///     Entry::Occupied(_) => panic!(),\n/// }\n///\n/// assert!(!map.contains_key(\"poneyland\"));\n/// ```\ninline\npub fn and_replace_entry_with<F>(self, f: F) -> Self\n    where\n        F: FnOnce(&K, V) -> Option<V>,{\n        match self {\n            Entry::Occupied(entry) => entry.replace_entry_with(f),\n            Entry::Vacant(_) => self,\n        }\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::Entry::<'a, K, V, S, A>::insert": [
            "/// Sets the value of the entry, and returns an `OccupiedEntry`.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut map: HashMap<&str, u32> = HashMap::new();\n/// let entry = map.entry(\"horseyland\").insert(37);\n///\n/// assert_eq!(entry.key(), &\"horseyland\");\n/// ```\ninline\npub fn insert(self, value: V) -> OccupiedEntry<'a, K, V, S, A>\n    where\n        K: Hash,\n        S: BuildHasher,{\n        match self {\n            Entry::Occupied(mut entry) => {\n                entry.insert(value);\n                entry\n            }\n            Entry::Vacant(entry) => entry.insert_entry(value),\n        }\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::Entry::<'a, K, V, S, A>::key": [
            "/// Returns a reference to this entry's key.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut map: HashMap<&str, u32> = HashMap::new();\n/// map.entry(\"poneyland\").or_insert(3);\n/// // existing key\n/// assert_eq!(map.entry(\"poneyland\").key(), &\"poneyland\");\n/// // nonexistent key\n/// assert_eq!(map.entry(\"horseland\").key(), &\"horseland\");\n/// ```\ninline\npub fn key(&self) -> &K{\n        match *self {\n            Entry::Occupied(ref entry) => entry.key(),\n            Entry::Vacant(ref entry) => entry.key(),\n        }\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::Entry::<'a, K, V, S, A>::or_default": [
            "/// Ensures a value is in the entry by inserting the default value if empty,\n/// and returns a mutable reference to the value in the entry.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut map: HashMap<&str, Option<u32>> = HashMap::new();\n///\n/// // nonexistent key\n/// map.entry(\"poneyland\").or_default();\n/// assert_eq!(map[\"poneyland\"], None);\n///\n/// map.insert(\"horseland\", Some(3));\n///\n/// // existing key\n/// assert_eq!(map.entry(\"horseland\").or_default(), &mut Some(3));\n/// ```\ninline\npub fn or_default(self) -> &'a mut V\n    where\n        K: Hash,\n        S: BuildHasher,{\n        match self {\n            Entry::Occupied(entry) => entry.into_mut(),\n            Entry::Vacant(entry) => entry.insert(Default::default()),\n        }\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::Entry::<'a, K, V, S, A>::or_insert": [
            "/// Ensures a value is in the entry by inserting the default if empty, and returns\n/// a mutable reference to the value in the entry.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut map: HashMap<&str, u32> = HashMap::new();\n///\n/// // nonexistent key\n/// map.entry(\"poneyland\").or_insert(3);\n/// assert_eq!(map[\"poneyland\"], 3);\n///\n/// // existing key\n/// *map.entry(\"poneyland\").or_insert(10) *= 2;\n/// assert_eq!(map[\"poneyland\"], 6);\n/// ```\ninline\npub fn or_insert(self, default: V) -> &'a mut V\n    where\n        K: Hash,\n        S: BuildHasher,{\n        match self {\n            Entry::Occupied(entry) => entry.into_mut(),\n            Entry::Vacant(entry) => entry.insert(default),\n        }\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::Entry::<'a, K, V, S, A>::or_insert_with": [
            "/// Ensures a value is in the entry by inserting the result of the default function if empty,\n/// and returns a mutable reference to the value in the entry.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut map: HashMap<&str, u32> = HashMap::new();\n///\n/// // nonexistent key\n/// map.entry(\"poneyland\").or_insert_with(|| 3);\n/// assert_eq!(map[\"poneyland\"], 3);\n///\n/// // existing key\n/// *map.entry(\"poneyland\").or_insert_with(|| 10) *= 2;\n/// assert_eq!(map[\"poneyland\"], 6);\n/// ```\ninline\npub fn or_insert_with<F: FnOnce() -> V>(self, default: F) -> &'a mut V\n    where\n        K: Hash,\n        S: BuildHasher,{\n        match self {\n            Entry::Occupied(entry) => entry.into_mut(),\n            Entry::Vacant(entry) => entry.insert(default()),\n        }\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::Entry::<'a, K, V, S, A>::or_insert_with_key": [
            "/// Ensures a value is in the entry by inserting, if empty, the result of the default function.\n/// This method allows for generating key-derived values for insertion by providing the default\n/// function a reference to the key that was moved during the `.entry(key)` method call.\n///\n/// The reference to the moved key is provided so that cloning or copying the key is\n/// unnecessary, unlike with `.or_insert_with(|| ... )`.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut map: HashMap<&str, usize> = HashMap::new();\n///\n/// // nonexistent key\n/// map.entry(\"poneyland\").or_insert_with_key(|key| key.chars().count());\n/// assert_eq!(map[\"poneyland\"], 9);\n///\n/// // existing key\n/// *map.entry(\"poneyland\").or_insert_with_key(|key| key.chars().count() * 10) *= 2;\n/// assert_eq!(map[\"poneyland\"], 18);\n/// ```\ninline\npub fn or_insert_with_key<F: FnOnce(&K) -> V>(self, default: F) -> &'a mut V\n    where\n        K: Hash,\n        S: BuildHasher,{\n        match self {\n            Entry::Occupied(entry) => entry.into_mut(),\n            Entry::Vacant(entry) => {\n                let value = default(entry.key());\n                entry.insert(value)\n            }\n        }\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::EntryRef": [
            "/// A view into a single entry in a map, which may either be vacant or occupied,\n/// with any borrowed form of the map's key type.\n///\n///\n/// This `enum` is constructed from the [`entry_ref`] method on [`HashMap`].\n///\n/// [`Hash`] and [`Eq`] on the borrowed form of the map's key type *must* match those\n/// for the key type. It also require that key may be constructed from the borrowed\n/// form through the [`From`] trait.\n///\n/// [`HashMap`]: struct.HashMap.html\n/// [`entry_ref`]: struct.HashMap.html#method.entry_ref\n/// [`Eq`]: https://doc.rust-lang.org/std/cmp/trait.Eq.html\n/// [`Hash`]: https://doc.rust-lang.org/std/hash/trait.Hash.html\n/// [`From`]: https://doc.rust-lang.org/std/convert/trait.From.html\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::hash_map::{EntryRef, HashMap, OccupiedEntry};\n///\n/// let mut map = HashMap::new();\n/// map.extend([(\"a\".to_owned(), 10), (\"b\".into(), 20), (\"c\".into(), 30)]);\n/// assert_eq!(map.len(), 3);\n///\n/// // Existing key (insert)\n/// let key = String::from(\"a\");\n/// let entry: EntryRef<_, _, _, _> = map.entry_ref(&key);\n/// let _raw_o: OccupiedEntry<_, _, _, _> = entry.insert(1);\n/// assert_eq!(map.len(), 3);\n/// // Nonexistent key (insert)\n/// map.entry_ref(\"d\").insert(4);\n///\n/// // Existing key (or_insert)\n/// let v = map.entry_ref(\"b\").or_insert(2);\n/// assert_eq!(std::mem::replace(v, 2), 20);\n/// // Nonexistent key (or_insert)\n/// map.entry_ref(\"e\").or_insert(5);\n///\n/// // Existing key (or_insert_with)\n/// let v = map.entry_ref(\"c\").or_insert_with(|| 3);\n/// assert_eq!(std::mem::replace(v, 3), 30);\n/// // Nonexistent key (or_insert_with)\n/// map.entry_ref(\"f\").or_insert_with(|| 6);\n///\n/// println!(\"Our HashMap: {:?}\", map);\n///\n/// for (key, value) in [\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"].into_iter().zip(1..=6) {\n///     assert_eq!(map[key], value)\n/// }\n/// assert_eq!(map.len(), 6);\n/// ```\npub enum EntryRef<'a, 'b, K, Q: ?Sized, V, S, A = Global>\nwhere\n    A: Allocator,\n{\n    /// An occupied entry.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::hash_map::{EntryRef, HashMap};\n    /// let mut map: HashMap<_, _> = [(\"a\".to_owned(), 100), (\"b\".into(), 200)].into();\n    ///\n    /// match map.entry_ref(\"a\") {\n    ///     EntryRef::Vacant(_) => unreachable!(),\n    ///     EntryRef::Occupied(_) => { }\n    /// }\n    /// ```\n    Occupied(OccupiedEntry<'a, K, V, S, A>),\n\n    /// A vacant entry.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::hash_map::{EntryRef, HashMap};\n    /// let mut map: HashMap<String, i32> = HashMap::new();\n    ///\n    /// match map.entry_ref(\"a\") {\n    ///     EntryRef::Occupied(_) => unreachable!(),\n    ///     EntryRef::Vacant(_) => { }\n    /// }\n    /// ```\n    Vacant(VacantEntryRef<'a, 'b, K, Q, V, S, A>),\n}",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::EntryRef::<'a, 'b, K, Q, V, S, A>::and_modify": [
            "/// Provides in-place mutable access to an occupied entry before any\n/// potential inserts into the map.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut map: HashMap<String, u32> = HashMap::new();\n///\n/// map.entry_ref(\"poneyland\")\n///    .and_modify(|e| { *e += 1 })\n///    .or_insert(42);\n/// assert_eq!(map[\"poneyland\"], 42);\n///\n/// map.entry_ref(\"poneyland\")\n///    .and_modify(|e| { *e += 1 })\n///    .or_insert(42);\n/// assert_eq!(map[\"poneyland\"], 43);\n/// ```\ninline\npub fn and_modify<F>(self, f: F) -> Self\n    where\n        F: FnOnce(&mut V),{\n        match self {\n            EntryRef::Occupied(mut entry) => {\n                f(entry.get_mut());\n                EntryRef::Occupied(entry)\n            }\n            EntryRef::Vacant(entry) => EntryRef::Vacant(entry),\n        }\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::EntryRef::<'a, 'b, K, Q, V, S, A>::insert": [
            "/// Sets the value of the entry, and returns an `OccupiedEntry`.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut map: HashMap<String, u32> = HashMap::new();\n/// let entry = map.entry_ref(\"horseyland\").insert(37);\n///\n/// assert_eq!(entry.key(), \"horseyland\");\n/// ```\ninline\npub fn insert(self, value: V) -> OccupiedEntry<'a, K, V, S, A>\n    where\n        K: Hash,\n        &'b Q: Into<K>,\n        S: BuildHasher,{\n        match self {\n            EntryRef::Occupied(mut entry) => {\n                entry.insert(value);\n                entry\n            }\n            EntryRef::Vacant(entry) => entry.insert_entry(value),\n        }\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::EntryRef::<'a, 'b, K, Q, V, S, A>::key": [
            "/// Returns a reference to this entry's key.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut map: HashMap<String, u32> = HashMap::new();\n/// map.entry_ref(\"poneyland\").or_insert(3);\n/// // existing key\n/// assert_eq!(map.entry_ref(\"poneyland\").key(), \"poneyland\");\n/// // nonexistent key\n/// assert_eq!(map.entry_ref(\"horseland\").key(), \"horseland\");\n/// ```\ninline\npub fn key(&self) -> &Q\n    where\n        K: Borrow<Q>,{\n        match *self {\n            EntryRef::Occupied(ref entry) => entry.key().borrow(),\n            EntryRef::Vacant(ref entry) => entry.key(),\n        }\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::EntryRef::<'a, 'b, K, Q, V, S, A>::or_default": [
            "/// Ensures a value is in the entry by inserting the default value if empty,\n/// and returns a mutable reference to the value in the entry.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut map: HashMap<String, Option<u32>> = HashMap::new();\n///\n/// // nonexistent key\n/// map.entry_ref(\"poneyland\").or_default();\n/// assert_eq!(map[\"poneyland\"], None);\n///\n/// map.insert(\"horseland\".to_string(), Some(3));\n///\n/// // existing key\n/// assert_eq!(map.entry_ref(\"horseland\").or_default(), &mut Some(3));\n/// ```\ninline\npub fn or_default(self) -> &'a mut V\n    where\n        K: Hash,\n        &'b Q: Into<K>,\n        S: BuildHasher,{\n        match self {\n            EntryRef::Occupied(entry) => entry.into_mut(),\n            EntryRef::Vacant(entry) => entry.insert(Default::default()),\n        }\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::EntryRef::<'a, 'b, K, Q, V, S, A>::or_insert": [
            "/// Ensures a value is in the entry by inserting the default if empty, and returns\n/// a mutable reference to the value in the entry.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut map: HashMap<String, u32> = HashMap::new();\n///\n/// // nonexistent key\n/// map.entry_ref(\"poneyland\").or_insert(3);\n/// assert_eq!(map[\"poneyland\"], 3);\n///\n/// // existing key\n/// *map.entry_ref(\"poneyland\").or_insert(10) *= 2;\n/// assert_eq!(map[\"poneyland\"], 6);\n/// ```\ninline\npub fn or_insert(self, default: V) -> &'a mut V\n    where\n        K: Hash,\n        &'b Q: Into<K>,\n        S: BuildHasher,{\n        match self {\n            EntryRef::Occupied(entry) => entry.into_mut(),\n            EntryRef::Vacant(entry) => entry.insert(default),\n        }\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::EntryRef::<'a, 'b, K, Q, V, S, A>::or_insert_with": [
            "/// Ensures a value is in the entry by inserting the result of the default function if empty,\n/// and returns a mutable reference to the value in the entry.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut map: HashMap<String, u32> = HashMap::new();\n///\n/// // nonexistent key\n/// map.entry_ref(\"poneyland\").or_insert_with(|| 3);\n/// assert_eq!(map[\"poneyland\"], 3);\n///\n/// // existing key\n/// *map.entry_ref(\"poneyland\").or_insert_with(|| 10) *= 2;\n/// assert_eq!(map[\"poneyland\"], 6);\n/// ```\ninline\npub fn or_insert_with<F: FnOnce() -> V>(self, default: F) -> &'a mut V\n    where\n        K: Hash,\n        &'b Q: Into<K>,\n        S: BuildHasher,{\n        match self {\n            EntryRef::Occupied(entry) => entry.into_mut(),\n            EntryRef::Vacant(entry) => entry.insert(default()),\n        }\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::EntryRef::<'a, 'b, K, Q, V, S, A>::or_insert_with_key": [
            "/// Ensures a value is in the entry by inserting, if empty, the result of the default function.\n/// This method allows for generating key-derived values for insertion by providing the default\n/// function an access to the borrower form of the key.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut map: HashMap<String, usize> = HashMap::new();\n///\n/// // nonexistent key\n/// map.entry_ref(\"poneyland\").or_insert_with_key(|key| key.chars().count());\n/// assert_eq!(map[\"poneyland\"], 9);\n///\n/// // existing key\n/// *map.entry_ref(\"poneyland\").or_insert_with_key(|key| key.chars().count() * 10) *= 2;\n/// assert_eq!(map[\"poneyland\"], 18);\n/// ```\ninline\npub fn or_insert_with_key<F: FnOnce(&Q) -> V>(self, default: F) -> &'a mut V\n    where\n        K: Hash + Borrow<Q>,\n        &'b Q: Into<K>,\n        S: BuildHasher,{\n        match self {\n            EntryRef::Occupied(entry) => entry.into_mut(),\n            EntryRef::Vacant(entry) => {\n                let value = default(entry.key);\n                entry.insert(value)\n            }\n        }\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::ExtractIf": [
            "/// A draining iterator over entries of a `HashMap` which don't satisfy the predicate\n/// `f(&k, &mut v)` in arbitrary order. The iterator element type is `(K, V)`.\n///\n/// This `struct` is created by the [`extract_if`] method on [`HashMap`]. See its\n/// documentation for more.\n///\n/// [`extract_if`]: struct.HashMap.html#method.extract_if\n/// [`HashMap`]: struct.HashMap.html\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut map: HashMap<i32, &str> = [(1, \"a\"), (2, \"b\"), (3, \"c\")].into();\n///\n/// let mut extract_if = map.extract_if(|k, _v| k % 2 != 0);\n/// let mut vec = vec![extract_if.next(), extract_if.next()];\n///\n/// // The `ExtractIf` iterator produces items in arbitrary order, so the\n/// // items must be sorted to test them against a sorted array.\n/// vec.sort_unstable();\n/// assert_eq!(vec, [Some((1, \"a\")),Some((3, \"c\"))]);\n///\n/// // It is fused iterator\n/// assert_eq!(extract_if.next(), None);\n/// assert_eq!(extract_if.next(), None);\n/// drop(extract_if);\n///\n/// assert_eq!(map.len(), 1);\n/// ```\n#[must_use = \"Iterators are lazy unless consumed\"]\npub struct ExtractIf<'a, K, V, F, A: Allocator = Global> {\n    f: F,\n    inner: RawExtractIf<'a, (K, V), A>,\n}",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::HashMap": [
            "/// A hash map implemented with quadratic probing and SIMD lookup.\n///\n/// The default hashing algorithm is currently [`foldhash`], though this is\n/// subject to change at any point in the future. This hash function is very\n/// fast for all types of keys, but this algorithm will typically *not* protect\n/// against attacks such as HashDoS.\n///\n/// The hashing algorithm can be replaced on a per-`HashMap` basis using the\n/// [`default`], [`with_hasher`], and [`with_capacity_and_hasher`] methods. Many\n/// alternative algorithms are available on crates.io, such as the [`fnv`] crate.\n///\n/// It is required that the keys implement the [`Eq`] and [`Hash`] traits, although\n/// this can frequently be achieved by using `#[derive(PartialEq, Eq, Hash)]`.\n/// If you implement these yourself, it is important that the following\n/// property holds:\n///\n/// ```text\n/// k1 == k2 -> hash(k1) == hash(k2)\n/// ```\n///\n/// In other words, if two keys are equal, their hashes must be equal.\n///\n/// It is a logic error for a key to be modified in such a way that the key's\n/// hash, as determined by the [`Hash`] trait, or its equality, as determined by\n/// the [`Eq`] trait, changes while it is in the map. This is normally only\n/// possible through [`Cell`], [`RefCell`], global state, I/O, or unsafe code.\n///\n/// It is also a logic error for the [`Hash`] implementation of a key to panic.\n/// This is generally only possible if the trait is implemented manually. If a\n/// panic does occur then the contents of the `HashMap` may become corrupted and\n/// some items may be dropped from the table.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// // Type inference lets us omit an explicit type signature (which\n/// // would be `HashMap<String, String>` in this example).\n/// let mut book_reviews = HashMap::new();\n///\n/// // Review some books.\n/// book_reviews.insert(\n///     \"Adventures of Huckleberry Finn\".to_string(),\n///     \"My favorite book.\".to_string(),\n/// );\n/// book_reviews.insert(\n///     \"Grimms' Fairy Tales\".to_string(),\n///     \"Masterpiece.\".to_string(),\n/// );\n/// book_reviews.insert(\n///     \"Pride and Prejudice\".to_string(),\n///     \"Very enjoyable.\".to_string(),\n/// );\n/// book_reviews.insert(\n///     \"The Adventures of Sherlock Holmes\".to_string(),\n///     \"Eye lyked it alot.\".to_string(),\n/// );\n///\n/// // Check for a specific one.\n/// // When collections store owned values (String), they can still be\n/// // queried using references (&str).\n/// if !book_reviews.contains_key(\"Les Misrables\") {\n///     println!(\"We've got {} reviews, but Les Misrables ain't one.\",\n///              book_reviews.len());\n/// }\n///\n/// // oops, this review has a lot of spelling mistakes, let's delete it.\n/// book_reviews.remove(\"The Adventures of Sherlock Holmes\");\n///\n/// // Look up the values associated with some keys.\n/// let to_find = [\"Pride and Prejudice\", \"Alice's Adventure in Wonderland\"];\n/// for &book in &to_find {\n///     match book_reviews.get(book) {\n///         Some(review) => println!(\"{}: {}\", book, review),\n///         None => println!(\"{} is unreviewed.\", book)\n///     }\n/// }\n///\n/// // Look up the value for a key (will panic if the key is not found).\n/// println!(\"Review for Jane: {}\", book_reviews[\"Pride and Prejudice\"]);\n///\n/// // Iterate over everything.\n/// for (book, review) in &book_reviews {\n///     println!(\"{}: \\\"{}\\\"\", book, review);\n/// }\n/// ```\n///\n/// `HashMap` also implements an [`Entry API`](#method.entry), which allows\n/// for more complex methods of getting, setting, updating and removing keys and\n/// their values:\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// // type inference lets us omit an explicit type signature (which\n/// // would be `HashMap<&str, u8>` in this example).\n/// let mut player_stats = HashMap::new();\n///\n/// fn random_stat_buff() -> u8 {\n///     // could actually return some random value here - let's just return\n///     // some fixed value for now\n///     42\n/// }\n///\n/// // insert a key only if it doesn't already exist\n/// player_stats.entry(\"health\").or_insert(100);\n///\n/// // insert a key using a function that provides a new value only if it\n/// // doesn't already exist\n/// player_stats.entry(\"defence\").or_insert_with(random_stat_buff);\n///\n/// // update a key, guarding against the key possibly not being set\n/// let stat = player_stats.entry(\"attack\").or_insert(100);\n/// *stat += random_stat_buff();\n/// ```\n///\n/// The easiest way to use `HashMap` with a custom key type is to derive [`Eq`] and [`Hash`].\n/// We must also derive [`PartialEq`].\n///\n/// [`Eq`]: https://doc.rust-lang.org/std/cmp/trait.Eq.html\n/// [`Hash`]: https://doc.rust-lang.org/std/hash/trait.Hash.html\n/// [`PartialEq`]: https://doc.rust-lang.org/std/cmp/trait.PartialEq.html\n/// [`RefCell`]: https://doc.rust-lang.org/std/cell/struct.RefCell.html\n/// [`Cell`]: https://doc.rust-lang.org/std/cell/struct.Cell.html\n/// [`default`]: #method.default\n/// [`with_hasher`]: #method.with_hasher\n/// [`with_capacity_and_hasher`]: #method.with_capacity_and_hasher\n/// [`fnv`]: https://crates.io/crates/fnv\n/// [`foldhash`]: https://crates.io/crates/foldhash\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// #[derive(Hash, Eq, PartialEq, Debug)]\n/// struct Viking {\n///     name: String,\n///     country: String,\n/// }\n///\n/// impl Viking {\n///     /// Creates a new Viking.\n///     fn new(name: &str, country: &str) -> Viking {\n///         Viking { name: name.to_string(), country: country.to_string() }\n///     }\n/// }\n///\n/// // Use a HashMap to store the vikings' health points.\n/// let mut vikings = HashMap::new();\n///\n/// vikings.insert(Viking::new(\"Einar\", \"Norway\"), 25);\n/// vikings.insert(Viking::new(\"Olaf\", \"Denmark\"), 24);\n/// vikings.insert(Viking::new(\"Harald\", \"Iceland\"), 12);\n///\n/// // Use derived implementation to print the status of the vikings.\n/// for (viking, health) in &vikings {\n///     println!(\"{:?} has {} hp\", viking, health);\n/// }\n/// ```\n///\n/// A `HashMap` with fixed list of elements can be initialized from an array:\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let timber_resources: HashMap<&str, i32> = [(\"Norway\", 100), (\"Denmark\", 50), (\"Iceland\", 10)]\n///     .into_iter().collect();\n/// // use the values stored in map\n/// ```\npub struct HashMap<K, V, S = DefaultHashBuilder, A: Allocator = Global> {\n    pub(crate) hash_builder: S,\n    pub(crate) table: RawTable<(K, V), A>,\n}",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::HashMap::<K, V, S, A>::allocation_size": [
            "/// Returns the total amount of memory allocated internally by the hash\n/// set, in bytes.\n///\n/// The returned number is informational only. It is intended to be\n/// primarily used for memory profiling.\n#[inline]\npub fn allocation_size(&self) -> usize{\n        self.table.allocation_size()\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::HashMap::<K, V, S, A>::allocator": [
            "/// Returns a reference to the underlying allocator.\n#[inline]\npub fn allocator(&self) -> &A{\n        self.table.allocator()\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::HashMap::<K, V, S, A>::build_hashes_inner": [
            "fn build_hashes_inner<Q, const N: usize>(&self, ks: [&Q; N]) -> [u64; N]\n    where\n        Q: Hash + Equivalent<K> + ?Sized,{\n        let mut hashes = [0_u64; N];\n        for i in 0..N {\n            hashes[i] = make_hash::<Q, S>(&self.hash_builder, ks[i]);\n        }\n        hashes\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::HashMap::<K, V, S, A>::capacity": [
            "/// Returns the number of elements the map can hold without reallocating.\n///\n/// This number is a lower bound; the `HashMap<K, V>` might be able to hold\n/// more, but is guaranteed to be able to hold at least this many.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n/// let map: HashMap<i32, i32> = HashMap::with_capacity(100);\n/// assert_eq!(map.len(), 0);\n/// assert!(map.capacity() >= 100);\n/// ```\ninline\npub fn capacity(&self) -> usize{\n        self.table.capacity()\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::HashMap::<K, V, S, A>::clear": [
            "/// Clears the map, removing all key-value pairs. Keeps the allocated memory\n/// for reuse.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut a = HashMap::new();\n/// a.insert(1, \"a\");\n/// let capacity_before_clear = a.capacity();\n///\n/// a.clear();\n///\n/// // Map is empty.\n/// assert!(a.is_empty());\n/// // But map capacity is equal to old one.\n/// assert_eq!(a.capacity(), capacity_before_clear);\n/// ```\ninline\npub fn clear(&mut self){\n        self.table.clear();\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::HashMap::<K, V, S, A>::contains_key": [
            "/// Returns `true` if the map contains a value for the specified key.\n///\n/// The key may be any borrowed form of the map's key type, but\n/// [`Hash`] and [`Eq`] on the borrowed form *must* match those for\n/// the key type.\n///\n/// [`Eq`]: https://doc.rust-lang.org/std/cmp/trait.Eq.html\n/// [`Hash`]: https://doc.rust-lang.org/std/hash/trait.Hash.html\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut map = HashMap::new();\n/// map.insert(1, \"a\");\n/// assert_eq!(map.contains_key(&1), true);\n/// assert_eq!(map.contains_key(&2), false);\n/// ```\ninline\npub fn contains_key<Q>(&self, k: &Q) -> bool\n    where\n        Q: Hash + Equivalent<K> + ?Sized,{\n        self.get_inner(k).is_some()\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::HashMap::<K, V, S, A>::drain": [
            "/// Clears the map, returning all key-value pairs as an iterator. Keeps the\n/// allocated memory for reuse.\n///\n/// If the returned iterator is dropped before being fully consumed, it\n/// drops the remaining key-value pairs. The returned iterator keeps a\n/// mutable borrow on the vector to optimize its implementation.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut a = HashMap::new();\n/// a.insert(1, \"a\");\n/// a.insert(2, \"b\");\n/// let capacity_before_drain = a.capacity();\n///\n/// for (k, v) in a.drain().take(1) {\n///     assert!(k == 1 || k == 2);\n///     assert!(v == \"a\" || v == \"b\");\n/// }\n///\n/// // As we can see, the map is empty and contains no element.\n/// assert!(a.is_empty() && a.len() == 0);\n/// // But map capacity is equal to old one.\n/// assert_eq!(a.capacity(), capacity_before_drain);\n///\n/// let mut a = HashMap::new();\n/// a.insert(1, \"a\");\n/// a.insert(2, \"b\");\n///\n/// {   // Iterator is dropped without being consumed.\n///     let d = a.drain();\n/// }\n///\n/// // But the map is empty even if we do not use Drain iterator.\n/// assert!(a.is_empty());\n/// ```\ninline\npub fn drain(&mut self) -> Drain<'_, K, V, A>{\n        Drain {\n            inner: self.table.drain(),\n        }\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::HashMap::<K, V, S, A>::entry": [
            "/// Gets the given key's corresponding entry in the map for in-place manipulation.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut letters = HashMap::new();\n///\n/// for ch in \"a short treatise on fungi\".chars() {\n///     let counter = letters.entry(ch).or_insert(0);\n///     *counter += 1;\n/// }\n///\n/// assert_eq!(letters[&'s'], 2);\n/// assert_eq!(letters[&'t'], 3);\n/// assert_eq!(letters[&'u'], 1);\n/// assert_eq!(letters.get(&'y'), None);\n/// ```\ninline\npub fn entry(&mut self, key: K) -> Entry<'_, K, V, S, A>{\n        let hash = make_hash::<K, S>(&self.hash_builder, &key);\n        if let Some(elem) = self.table.find(hash, equivalent_key(&key)) {\n            Entry::Occupied(OccupiedEntry {\n                hash,\n                elem,\n                table: self,\n            })\n        } else {\n            Entry::Vacant(VacantEntry {\n                hash,\n                key,\n                table: self,\n            })\n        }\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::HashMap::<K, V, S, A>::entry_ref": [
            "/// Gets the given key's corresponding entry by reference in the map for in-place manipulation.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut words: HashMap<String, usize> = HashMap::new();\n/// let source = [\"poneyland\", \"horseyland\", \"poneyland\", \"poneyland\"];\n/// for (i, &s) in source.iter().enumerate() {\n///     let counter = words.entry_ref(s).or_insert(0);\n///     *counter += 1;\n/// }\n///\n/// assert_eq!(words[\"poneyland\"], 3);\n/// assert_eq!(words[\"horseyland\"], 1);\n/// ```\ninline\npub fn entry_ref<'a, 'b, Q>(&'a mut self, key: &'b Q) -> EntryRef<'a, 'b, K, Q, V, S, A>\n    where\n        Q: Hash + Equivalent<K> + ?Sized,{\n        let hash = make_hash::<Q, S>(&self.hash_builder, key);\n        if let Some(elem) = self.table.find(hash, equivalent_key(key)) {\n            EntryRef::Occupied(OccupiedEntry {\n                hash,\n                elem,\n                table: self,\n            })\n        } else {\n            EntryRef::Vacant(VacantEntryRef {\n                hash,\n                key,\n                table: self,\n            })\n        }\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::HashMap::<K, V, S, A>::extract_if": [
            "/// Drains elements which are true under the given predicate,\n/// and returns an iterator over the removed items.\n///\n/// In other words, move all pairs `(k, v)` such that `f(&k, &mut v)` returns `true` out\n/// into another iterator.\n///\n/// Note that `extract_if` lets you mutate every value in the filter closure, regardless of\n/// whether you choose to keep or remove it.\n///\n/// If the returned `ExtractIf` is not exhausted, e.g. because it is dropped without iterating\n/// or the iteration short-circuits, then the remaining elements will be retained.\n/// Use [`retain()`] with a negated predicate if you do not need the returned iterator.\n///\n/// Keeps the allocated memory for reuse.\n///\n/// [`retain()`]: HashMap::retain\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut map: HashMap<i32, i32> = (0..8).map(|x| (x, x)).collect();\n///\n/// let drained: HashMap<i32, i32> = map.extract_if(|k, _v| k % 2 == 0).collect();\n///\n/// let mut evens = drained.keys().cloned().collect::<Vec<_>>();\n/// let mut odds = map.keys().cloned().collect::<Vec<_>>();\n/// evens.sort();\n/// odds.sort();\n///\n/// assert_eq!(evens, vec![0, 2, 4, 6]);\n/// assert_eq!(odds, vec![1, 3, 5, 7]);\n///\n/// let mut map: HashMap<i32, i32> = (0..8).map(|x| (x, x)).collect();\n///\n/// {   // Iterator is dropped without being consumed.\n///     let d = map.extract_if(|k, _v| k % 2 != 0);\n/// }\n///\n/// // ExtractIf was not exhausted, therefore no elements were drained.\n/// assert_eq!(map.len(), 8);\n/// ```\ninline\npub fn extract_if<F>(&mut self, f: F) -> ExtractIf<'_, K, V, F, A>\n    where\n        F: FnMut(&K, &mut V) -> bool,{\n        ExtractIf {\n            f,\n            inner: RawExtractIf {\n                iter: unsafe { self.table.iter() },\n                table: &mut self.table,\n            },\n        }\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::HashMap::<K, V, S, A>::find_or_find_insert_slot": [
            "inline\npub(crate) fn find_or_find_insert_slot<Q>(\n        &mut self,\n        hash: u64,\n        key: &Q,\n    ) -> Result<Bucket<(K, V)>, crate::raw::InsertSlot>\n    where\n        Q: Equivalent<K> + ?Sized,{\n        self.table.find_or_find_insert_slot(\n            hash,\n            equivalent_key(key),\n            make_hasher(&self.hash_builder),\n        )\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::HashMap::<K, V, S, A>::get": [
            "/// Returns a reference to the value corresponding to the key.\n///\n/// The key may be any borrowed form of the map's key type, but\n/// [`Hash`] and [`Eq`] on the borrowed form *must* match those for\n/// the key type.\n///\n/// [`Eq`]: https://doc.rust-lang.org/std/cmp/trait.Eq.html\n/// [`Hash`]: https://doc.rust-lang.org/std/hash/trait.Hash.html\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut map = HashMap::new();\n/// map.insert(1, \"a\");\n/// assert_eq!(map.get(&1), Some(&\"a\"));\n/// assert_eq!(map.get(&2), None);\n/// ```\n#[inline]\npub fn get<Q>(&self, k: &Q) -> Option<&V>\n    where\n        Q: Hash + Equivalent<K> + ?Sized,{\n        // Avoid `Option::map` because it bloats LLVM IR.\n        match self.get_inner(k) {\n            Some((_, v)) => Some(v),\n            None => None,\n        }\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::HashMap::<K, V, S, A>::get_inner": [
            "#[inline]\nfn get_inner<Q>(&self, k: &Q) -> Option<&(K, V)>\n    where\n        Q: Hash + Equivalent<K> + ?Sized,{\n        if self.table.is_empty() {\n            None\n        } else {\n            let hash = make_hash::<Q, S>(&self.hash_builder, k);\n            self.table.get(hash, equivalent_key(k))\n        }\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::HashMap::<K, V, S, A>::get_inner_mut": [
            "#[inline]\nfn get_inner_mut<Q>(&mut self, k: &Q) -> Option<&mut (K, V)>\n    where\n        Q: Hash + Equivalent<K> + ?Sized,{\n        if self.table.is_empty() {\n            None\n        } else {\n            let hash = make_hash::<Q, S>(&self.hash_builder, k);\n            self.table.get_mut(hash, equivalent_key(k))\n        }\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::HashMap::<K, V, S, A>::get_key_value": [
            "/// Returns the key-value pair corresponding to the supplied key.\n///\n/// The supplied key may be any borrowed form of the map's key type, but\n/// [`Hash`] and [`Eq`] on the borrowed form *must* match those for\n/// the key type.\n///\n/// [`Eq`]: https://doc.rust-lang.org/std/cmp/trait.Eq.html\n/// [`Hash`]: https://doc.rust-lang.org/std/hash/trait.Hash.html\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut map = HashMap::new();\n/// map.insert(1, \"a\");\n/// assert_eq!(map.get_key_value(&1), Some((&1, &\"a\")));\n/// assert_eq!(map.get_key_value(&2), None);\n/// ```\n#[inline]\npub fn get_key_value<Q>(&self, k: &Q) -> Option<(&K, &V)>\n    where\n        Q: Hash + Equivalent<K> + ?Sized,{\n        // Avoid `Option::map` because it bloats LLVM IR.\n        match self.get_inner(k) {\n            Some((key, value)) => Some((key, value)),\n            None => None,\n        }\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::HashMap::<K, V, S, A>::get_key_value_mut": [
            "/// Returns the key-value pair corresponding to the supplied key, with a mutable reference to value.\n///\n/// The supplied key may be any borrowed form of the map's key type, but\n/// [`Hash`] and [`Eq`] on the borrowed form *must* match those for\n/// the key type.\n///\n/// [`Eq`]: https://doc.rust-lang.org/std/cmp/trait.Eq.html\n/// [`Hash`]: https://doc.rust-lang.org/std/hash/trait.Hash.html\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut map = HashMap::new();\n/// map.insert(1, \"a\");\n/// let (k, v) = map.get_key_value_mut(&1).unwrap();\n/// assert_eq!(k, &1);\n/// assert_eq!(v, &mut \"a\");\n/// *v = \"b\";\n/// assert_eq!(map.get_key_value_mut(&1), Some((&1, &mut \"b\")));\n/// assert_eq!(map.get_key_value_mut(&2), None);\n/// ```\n#[inline]\npub fn get_key_value_mut<Q>(&mut self, k: &Q) -> Option<(&K, &mut V)>\n    where\n        Q: Hash + Equivalent<K> + ?Sized,{\n        // Avoid `Option::map` because it bloats LLVM IR.\n        match self.get_inner_mut(k) {\n            Some(&mut (ref key, ref mut value)) => Some((key, value)),\n            None => None,\n        }\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::HashMap::<K, V, S, A>::get_many_key_value_mut": [
            "/// Attempts to get mutable references to `N` values in the map at once, with immutable\n/// references to the corresponding keys.\n///\n/// Returns an array of length `N` with the results of each query. For soundness, at most one\n/// mutable reference will be returned to any value. `None` will be used if the key is missing.\n///\n/// # Panics\n///\n/// Panics if any keys are overlapping.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut libraries = HashMap::new();\n/// libraries.insert(\"Bodleian Library\".to_string(), 1602);\n/// libraries.insert(\"Athenum\".to_string(), 1807);\n/// libraries.insert(\"Herzogin-Anna-Amalia-Bibliothek\".to_string(), 1691);\n/// libraries.insert(\"Library of Congress\".to_string(), 1800);\n///\n/// let got = libraries.get_many_key_value_mut([\n///     \"Bodleian Library\",\n///     \"Herzogin-Anna-Amalia-Bibliothek\",\n/// ]);\n/// assert_eq!(\n///     got,\n///     [\n///         Some((&\"Bodleian Library\".to_string(), &mut 1602)),\n///         Some((&\"Herzogin-Anna-Amalia-Bibliothek\".to_string(), &mut 1691)),\n///     ],\n/// );\n/// // Missing keys result in None\n/// let got = libraries.get_many_key_value_mut([\n///     \"Bodleian Library\",\n///     \"Gewandhaus\",\n/// ]);\n/// assert_eq!(got, [Some((&\"Bodleian Library\".to_string(), &mut 1602)), None]);\n/// ```\n///\n/// ```should_panic\n/// use hashbrown::HashMap;\n///\n/// let mut libraries = HashMap::new();\n/// libraries.insert(\"Bodleian Library\".to_string(), 1602);\n/// libraries.insert(\"Herzogin-Anna-Amalia-Bibliothek\".to_string(), 1691);\n///\n/// // Duplicate keys result in panic!\n/// let got = libraries.get_many_key_value_mut([\n///     \"Bodleian Library\",\n///     \"Herzogin-Anna-Amalia-Bibliothek\",\n///     \"Herzogin-Anna-Amalia-Bibliothek\",\n/// ]);\n/// ```\npub fn get_many_key_value_mut<Q, const N: usize>(\n        &mut self,\n        ks: [&Q; N],\n    ) -> [Option<(&'_ K, &'_ mut V)>; N]\n    where\n        Q: Hash + Equivalent<K> + ?Sized,{\n        self.get_many_mut_inner(ks)\n            .map(|res| res.map(|(k, v)| (&*k, v)))\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::HashMap::<K, V, S, A>::get_many_key_value_unchecked_mut": [
            "/// Attempts to get mutable references to `N` values in the map at once, with immutable\n/// references to the corresponding keys, without validating that the values are unique.\n///\n/// Returns an array of length `N` with the results of each query. `None` will be returned if\n/// any of the keys are missing.\n///\n/// For a safe alternative see [`get_many_key_value_mut`](`HashMap::get_many_key_value_mut`).\n///\n/// # Safety\n///\n/// Calling this method with overlapping keys is *[undefined behavior]* even if the resulting\n/// references are not used.\n///\n/// [undefined behavior]: https://doc.rust-lang.org/reference/behavior-considered-undefined.html\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut libraries = HashMap::new();\n/// libraries.insert(\"Bodleian Library\".to_string(), 1602);\n/// libraries.insert(\"Athenum\".to_string(), 1807);\n/// libraries.insert(\"Herzogin-Anna-Amalia-Bibliothek\".to_string(), 1691);\n/// libraries.insert(\"Library of Congress\".to_string(), 1800);\n///\n/// let got = libraries.get_many_key_value_mut([\n///     \"Bodleian Library\",\n///     \"Herzogin-Anna-Amalia-Bibliothek\",\n/// ]);\n/// assert_eq!(\n///     got,\n///     [\n///         Some((&\"Bodleian Library\".to_string(), &mut 1602)),\n///         Some((&\"Herzogin-Anna-Amalia-Bibliothek\".to_string(), &mut 1691)),\n///     ],\n/// );\n/// // Missing keys result in None\n/// let got = libraries.get_many_key_value_mut([\n///     \"Bodleian Library\",\n///     \"Gewandhaus\",\n/// ]);\n/// assert_eq!(\n///     got,\n///     [\n///         Some((&\"Bodleian Library\".to_string(), &mut 1602)),\n///         None,\n///     ],\n/// );\n/// ```\npub unsafe fn get_many_key_value_unchecked_mut<Q, const N: usize>(\n        &mut self,\n        ks: [&Q; N],\n    ) -> [Option<(&'_ K, &'_ mut V)>; N]\n    where\n        Q: Hash + Equivalent<K> + ?Sized,{\n        self.get_many_unchecked_mut_inner(ks)\n            .map(|res| res.map(|(k, v)| (&*k, v)))\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::HashMap::<K, V, S, A>::get_many_mut": [
            "/// Attempts to get mutable references to `N` values in the map at once.\n///\n/// Returns an array of length `N` with the results of each query. For soundness, at most one\n/// mutable reference will be returned to any value. `None` will be used if the key is missing.\n///\n/// # Panics\n///\n/// Panics if any keys are overlapping.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut libraries = HashMap::new();\n/// libraries.insert(\"Bodleian Library\".to_string(), 1602);\n/// libraries.insert(\"Athenum\".to_string(), 1807);\n/// libraries.insert(\"Herzogin-Anna-Amalia-Bibliothek\".to_string(), 1691);\n/// libraries.insert(\"Library of Congress\".to_string(), 1800);\n///\n/// // Get Athenum and Bodleian Library\n/// let [Some(a), Some(b)] = libraries.get_many_mut([\n///     \"Athenum\",\n///     \"Bodleian Library\",\n/// ]) else { panic!() };\n///\n/// // Assert values of Athenum and Library of Congress\n/// let got = libraries.get_many_mut([\n///     \"Athenum\",\n///     \"Library of Congress\",\n/// ]);\n/// assert_eq!(\n///     got,\n///     [\n///         Some(&mut 1807),\n///         Some(&mut 1800),\n///     ],\n/// );\n///\n/// // Missing keys result in None\n/// let got = libraries.get_many_mut([\n///     \"Athenum\",\n///     \"New York Public Library\",\n/// ]);\n/// assert_eq!(\n///     got,\n///     [\n///         Some(&mut 1807),\n///         None\n///     ]\n/// );\n/// ```\n///\n/// ```should_panic\n/// use hashbrown::HashMap;\n///\n/// let mut libraries = HashMap::new();\n/// libraries.insert(\"Athenum\".to_string(), 1807);\n///\n/// // Duplicate keys panic!\n/// let got = libraries.get_many_mut([\n///     \"Athenum\",\n///     \"Athenum\",\n/// ]);\n/// ```\npub fn get_many_mut<Q, const N: usize>(&mut self, ks: [&Q; N]) -> [Option<&'_ mut V>; N]\n    where\n        Q: Hash + Equivalent<K> + ?Sized,{\n        self.get_many_mut_inner(ks).map(|res| res.map(|(_, v)| v))\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::HashMap::<K, V, S, A>::get_many_mut_inner": [
            "fn get_many_mut_inner<Q, const N: usize>(&mut self, ks: [&Q; N]) -> [Option<&'_ mut (K, V)>; N]\n    where\n        Q: Hash + Equivalent<K> + ?Sized,{\n        let hashes = self.build_hashes_inner(ks);\n        self.table\n            .get_many_mut(hashes, |i, (k, _)| ks[i].equivalent(k))\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::HashMap::<K, V, S, A>::get_many_unchecked_mut": [
            "/// Attempts to get mutable references to `N` values in the map at once, without validating that\n/// the values are unique.\n///\n/// Returns an array of length `N` with the results of each query. `None` will be used if\n/// the key is missing.\n///\n/// For a safe alternative see [`get_many_mut`](`HashMap::get_many_mut`).\n///\n/// # Safety\n///\n/// Calling this method with overlapping keys is *[undefined behavior]* even if the resulting\n/// references are not used.\n///\n/// [undefined behavior]: https://doc.rust-lang.org/reference/behavior-considered-undefined.html\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut libraries = HashMap::new();\n/// libraries.insert(\"Bodleian Library\".to_string(), 1602);\n/// libraries.insert(\"Athenum\".to_string(), 1807);\n/// libraries.insert(\"Herzogin-Anna-Amalia-Bibliothek\".to_string(), 1691);\n/// libraries.insert(\"Library of Congress\".to_string(), 1800);\n///\n/// // SAFETY: The keys do not overlap.\n/// let [Some(a), Some(b)] = (unsafe { libraries.get_many_unchecked_mut([\n///     \"Athenum\",\n///     \"Bodleian Library\",\n/// ]) }) else { panic!() };\n///\n/// // SAFETY: The keys do not overlap.\n/// let got = unsafe { libraries.get_many_unchecked_mut([\n///     \"Athenum\",\n///     \"Library of Congress\",\n/// ]) };\n/// assert_eq!(\n///     got,\n///     [\n///         Some(&mut 1807),\n///         Some(&mut 1800),\n///     ],\n/// );\n///\n/// // SAFETY: The keys do not overlap.\n/// let got = unsafe { libraries.get_many_unchecked_mut([\n///     \"Athenum\",\n///     \"New York Public Library\",\n/// ]) };\n/// // Missing keys result in None\n/// assert_eq!(got, [Some(&mut 1807), None]);\n/// ```\npub unsafe fn get_many_unchecked_mut<Q, const N: usize>(\n        &mut self,\n        ks: [&Q; N],\n    ) -> [Option<&'_ mut V>; N]\n    where\n        Q: Hash + Equivalent<K> + ?Sized,{\n        self.get_many_unchecked_mut_inner(ks)\n            .map(|res| res.map(|(_, v)| v))\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::HashMap::<K, V, S, A>::get_many_unchecked_mut_inner": [
            "unsafe fn get_many_unchecked_mut_inner<Q, const N: usize>(\n        &mut self,\n        ks: [&Q; N],\n    ) -> [Option<&'_ mut (K, V)>; N]\n    where\n        Q: Hash + Equivalent<K> + ?Sized,{\n        let hashes = self.build_hashes_inner(ks);\n        self.table\n            .get_many_unchecked_mut(hashes, |i, (k, _)| ks[i].equivalent(k))\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::HashMap::<K, V, S, A>::get_mut": [
            "/// Returns a mutable reference to the value corresponding to the key.\n///\n/// The key may be any borrowed form of the map's key type, but\n/// [`Hash`] and [`Eq`] on the borrowed form *must* match those for\n/// the key type.\n///\n/// [`Eq`]: https://doc.rust-lang.org/std/cmp/trait.Eq.html\n/// [`Hash`]: https://doc.rust-lang.org/std/hash/trait.Hash.html\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut map = HashMap::new();\n/// map.insert(1, \"a\");\n/// if let Some(x) = map.get_mut(&1) {\n///     *x = \"b\";\n/// }\n/// assert_eq!(map[&1], \"b\");\n///\n/// assert_eq!(map.get_mut(&2), None);\n/// ```\ninline\npub fn get_mut<Q>(&mut self, k: &Q) -> Option<&mut V>\n    where\n        Q: Hash + Equivalent<K> + ?Sized,{\n        // Avoid `Option::map` because it bloats LLVM IR.\n        match self.get_inner_mut(k) {\n            Some(&mut (_, ref mut v)) => Some(v),\n            None => None,\n        }\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::HashMap::<K, V, S, A>::hasher": [
            "/// Returns a reference to the map's [`BuildHasher`].\n///\n/// [`BuildHasher`]: https://doc.rust-lang.org/std/hash/trait.BuildHasher.html\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n/// use hashbrown::DefaultHashBuilder;\n///\n/// let hasher = DefaultHashBuilder::default();\n/// let map: HashMap<i32, i32> = HashMap::with_hasher(hasher);\n/// let hasher: &DefaultHashBuilder = map.hasher();\n/// ```\ninline\npub fn hasher(&self) -> &S{\n        &self.hash_builder\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::HashMap::<K, V, S, A>::insert": [
            "/// Inserts a key-value pair into the map.\n///\n/// If the map did not have this key present, [`None`] is returned.\n///\n/// If the map did have this key present, the value is updated, and the old\n/// value is returned. The key is not updated, though; this matters for\n/// types that can be `==` without being identical. See the [`std::collections`]\n/// [module-level documentation] for more.\n///\n/// [`None`]: https://doc.rust-lang.org/std/option/enum.Option.html#variant.None\n/// [`std::collections`]: https://doc.rust-lang.org/std/collections/index.html\n/// [module-level documentation]: https://doc.rust-lang.org/std/collections/index.html#insert-and-complex-keys\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut map = HashMap::new();\n/// assert_eq!(map.insert(37, \"a\"), None);\n/// assert_eq!(map.is_empty(), false);\n///\n/// map.insert(37, \"b\");\n/// assert_eq!(map.insert(37, \"c\"), Some(\"b\"));\n/// assert_eq!(map[&37], \"c\");\n/// ```\ninline\npub fn insert(&mut self, k: K, v: V) -> Option<V>{\n        let hash = make_hash::<K, S>(&self.hash_builder, &k);\n        match self.find_or_find_insert_slot(hash, &k) {\n            Ok(bucket) => Some(mem::replace(unsafe { &mut bucket.as_mut().1 }, v)),\n            Err(slot) => {\n                unsafe {\n                    self.table.insert_in_slot(hash, slot, (k, v));\n                }\n                None\n            }\n        }\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::HashMap::<K, V, S, A>::insert_unique_unchecked": [
            "/// Insert a key-value pair into the map without checking\n/// if the key already exists in the map.\n///\n/// This operation is faster than regular insert, because it does not perform\n/// lookup before insertion.\n///\n/// This operation is useful during initial population of the map.\n/// For example, when constructing a map from another map, we know\n/// that keys are unique.\n///\n/// Returns a reference to the key and value just inserted.\n///\n/// # Safety\n///\n/// This operation is safe if a key does not exist in the map.\n///\n/// However, if a key exists in the map already, the behavior is unspecified:\n/// this operation may panic, loop forever, or any following operation with the map\n/// may panic, loop forever or return arbitrary result.\n///\n/// That said, this operation (and following operations) are guaranteed to\n/// not violate memory safety.\n///\n/// However this operation is still unsafe because the resulting `HashMap`\n/// may be passed to unsafe code which does expect the map to behave\n/// correctly, and would cause unsoundness as a result.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut map1 = HashMap::new();\n/// assert_eq!(map1.insert(1, \"a\"), None);\n/// assert_eq!(map1.insert(2, \"b\"), None);\n/// assert_eq!(map1.insert(3, \"c\"), None);\n/// assert_eq!(map1.len(), 3);\n///\n/// let mut map2 = HashMap::new();\n///\n/// for (key, value) in map1.into_iter() {\n///     unsafe {\n///         map2.insert_unique_unchecked(key, value);\n///     }\n/// }\n///\n/// let (key, value) = unsafe { map2.insert_unique_unchecked(4, \"d\") };\n/// assert_eq!(key, &4);\n/// assert_eq!(value, &mut \"d\");\n/// *value = \"e\";\n///\n/// assert_eq!(map2[&1], \"a\");\n/// assert_eq!(map2[&2], \"b\");\n/// assert_eq!(map2[&3], \"c\");\n/// assert_eq!(map2[&4], \"e\");\n/// assert_eq!(map2.len(), 4);\n/// ```\ninline\npub unsafe fn insert_unique_unchecked(&mut self, k: K, v: V) -> (&K, &mut V){\n        let hash = make_hash::<K, S>(&self.hash_builder, &k);\n        let bucket = self\n            .table\n            .insert(hash, (k, v), make_hasher::<_, V, S>(&self.hash_builder));\n        let (k_ref, v_ref) = unsafe { bucket.as_mut() };\n        (k_ref, v_ref)\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::HashMap::<K, V, S, A>::into_keys": [
            "/// Creates a consuming iterator visiting all the keys in arbitrary order.\n/// The map cannot be used after calling this.\n/// The iterator element type is `K`.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut map = HashMap::new();\n/// map.insert(\"a\", 1);\n/// map.insert(\"b\", 2);\n/// map.insert(\"c\", 3);\n///\n/// let mut vec: Vec<&str> = map.into_keys().collect();\n///\n/// // The `IntoKeys` iterator produces keys in arbitrary order, so the\n/// // keys must be sorted to test them against a sorted array.\n/// vec.sort_unstable();\n/// assert_eq!(vec, [\"a\", \"b\", \"c\"]);\n/// ```\n#[inline]\npub fn into_keys(self) -> IntoKeys<K, V, A>{\n        IntoKeys {\n            inner: self.into_iter(),\n        }\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::HashMap::<K, V, S, A>::into_values": [
            "/// Creates a consuming iterator visiting all the values in arbitrary order.\n/// The map cannot be used after calling this.\n/// The iterator element type is `V`.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut map = HashMap::new();\n/// map.insert(\"a\", 1);\n/// map.insert(\"b\", 2);\n/// map.insert(\"c\", 3);\n///\n/// let mut vec: Vec<i32> = map.into_values().collect();\n///\n/// // The `IntoValues` iterator produces values in arbitrary order, so\n/// // the values must be sorted to test them against a sorted array.\n/// vec.sort_unstable();\n/// assert_eq!(vec, [1, 2, 3]);\n/// ```\n#[inline]\npub fn into_values(self) -> IntoValues<K, V, A>{\n        IntoValues {\n            inner: self.into_iter(),\n        }\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::HashMap::<K, V, S, A>::is_empty": [
            "/// Returns `true` if the map contains no elements.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut a = HashMap::new();\n/// assert!(a.is_empty());\n/// a.insert(1, \"a\");\n/// assert!(!a.is_empty());\n/// ```\ninline\npub fn is_empty(&self) -> bool{\n        self.len() == 0\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::HashMap::<K, V, S, A>::iter": [
            "/// An iterator visiting all key-value pairs in arbitrary order.\n/// The iterator element type is `(&'a K, &'a V)`.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut map = HashMap::new();\n/// map.insert(\"a\", 1);\n/// map.insert(\"b\", 2);\n/// map.insert(\"c\", 3);\n/// assert_eq!(map.len(), 3);\n/// let mut vec: Vec<(&str, i32)> = Vec::new();\n///\n/// for (key, val) in map.iter() {\n///     println!(\"key: {} val: {}\", key, val);\n///     vec.push((*key, *val));\n/// }\n///\n/// // The `Iter` iterator produces items in arbitrary order, so the\n/// // items must be sorted to test them against a sorted array.\n/// vec.sort_unstable();\n/// assert_eq!(vec, [(\"a\", 1), (\"b\", 2), (\"c\", 3)]);\n///\n/// assert_eq!(map.len(), 3);\n/// ```\ninline\npub fn iter(&self) -> Iter<'_, K, V>{\n        // Here we tie the lifetime of self to the iter.\n        unsafe {\n            Iter {\n                inner: self.table.iter(),\n                marker: PhantomData,\n            }\n        }\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::HashMap::<K, V, S, A>::iter_mut": [
            "/// An iterator visiting all key-value pairs in arbitrary order,\n/// with mutable references to the values.\n/// The iterator element type is `(&'a K, &'a mut V)`.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut map = HashMap::new();\n/// map.insert(\"a\", 1);\n/// map.insert(\"b\", 2);\n/// map.insert(\"c\", 3);\n///\n/// // Update all values\n/// for (_, val) in map.iter_mut() {\n///     *val *= 2;\n/// }\n///\n/// assert_eq!(map.len(), 3);\n/// let mut vec: Vec<(&str, i32)> = Vec::new();\n///\n/// for (key, val) in &map {\n///     println!(\"key: {} val: {}\", key, val);\n///     vec.push((*key, *val));\n/// }\n///\n/// // The `Iter` iterator produces items in arbitrary order, so the\n/// // items must be sorted to test them against a sorted array.\n/// vec.sort_unstable();\n/// assert_eq!(vec, [(\"a\", 2), (\"b\", 4), (\"c\", 6)]);\n///\n/// assert_eq!(map.len(), 3);\n/// ```\ninline\npub fn iter_mut(&mut self) -> IterMut<'_, K, V>{\n        // Here we tie the lifetime of self to the iter.\n        unsafe {\n            IterMut {\n                inner: self.table.iter(),\n                marker: PhantomData,\n            }\n        }\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::HashMap::<K, V, S, A>::keys": [
            "/// An iterator visiting all keys in arbitrary order.\n/// The iterator element type is `&'a K`.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut map = HashMap::new();\n/// map.insert(\"a\", 1);\n/// map.insert(\"b\", 2);\n/// map.insert(\"c\", 3);\n/// assert_eq!(map.len(), 3);\n/// let mut vec: Vec<&str> = Vec::new();\n///\n/// for key in map.keys() {\n///     println!(\"{}\", key);\n///     vec.push(*key);\n/// }\n///\n/// // The `Keys` iterator produces keys in arbitrary order, so the\n/// // keys must be sorted to test them against a sorted array.\n/// vec.sort_unstable();\n/// assert_eq!(vec, [\"a\", \"b\", \"c\"]);\n///\n/// assert_eq!(map.len(), 3);\n/// ```\ninline\npub fn keys(&self) -> Keys<'_, K, V>{\n        Keys { inner: self.iter() }\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::HashMap::<K, V, S, A>::len": [
            "/// Returns the number of elements in the map.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut a = HashMap::new();\n/// assert_eq!(a.len(), 0);\n/// a.insert(1, \"a\");\n/// assert_eq!(a.len(), 1);\n/// ```\ninline\npub fn len(&self) -> usize{\n        self.table.len()\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::HashMap::<K, V, S, A>::remove": [
            "/// Removes a key from the map, returning the value at the key if the key\n/// was previously in the map. Keeps the allocated memory for reuse.\n///\n/// The key may be any borrowed form of the map's key type, but\n/// [`Hash`] and [`Eq`] on the borrowed form *must* match those for\n/// the key type.\n///\n/// [`Eq`]: https://doc.rust-lang.org/std/cmp/trait.Eq.html\n/// [`Hash`]: https://doc.rust-lang.org/std/hash/trait.Hash.html\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut map = HashMap::new();\n/// // The map is empty\n/// assert!(map.is_empty() && map.capacity() == 0);\n///\n/// map.insert(1, \"a\");\n///\n/// assert_eq!(map.remove(&1), Some(\"a\"));\n/// assert_eq!(map.remove(&1), None);\n///\n/// // Now map holds none elements\n/// assert!(map.is_empty());\n/// ```\ninline\npub fn remove<Q>(&mut self, k: &Q) -> Option<V>\n    where\n        Q: Hash + Equivalent<K> + ?Sized,{\n        // Avoid `Option::map` because it bloats LLVM IR.\n        match self.remove_entry(k) {\n            Some((_, v)) => Some(v),\n            None => None,\n        }\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::HashMap::<K, V, S, A>::remove_entry": [
            "/// Removes a key from the map, returning the stored key and value if the\n/// key was previously in the map. Keeps the allocated memory for reuse.\n///\n/// The key may be any borrowed form of the map's key type, but\n/// [`Hash`] and [`Eq`] on the borrowed form *must* match those for\n/// the key type.\n///\n/// [`Eq`]: https://doc.rust-lang.org/std/cmp/trait.Eq.html\n/// [`Hash`]: https://doc.rust-lang.org/std/hash/trait.Hash.html\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut map = HashMap::new();\n/// // The map is empty\n/// assert!(map.is_empty() && map.capacity() == 0);\n///\n/// map.insert(1, \"a\");\n///\n/// assert_eq!(map.remove_entry(&1), Some((1, \"a\")));\n/// assert_eq!(map.remove(&1), None);\n///\n/// // Now map hold none elements\n/// assert!(map.is_empty());\n/// ```\ninline\npub fn remove_entry<Q>(&mut self, k: &Q) -> Option<(K, V)>\n    where\n        Q: Hash + Equivalent<K> + ?Sized,{\n        let hash = make_hash::<Q, S>(&self.hash_builder, k);\n        self.table.remove_entry(hash, equivalent_key(k))\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::HashMap::<K, V, S, A>::reserve": [
            "/// Reserves capacity for at least `additional` more elements to be inserted\n/// in the `HashMap`. The collection may reserve more space to avoid\n/// frequent reallocations.\n///\n/// # Panics\n///\n/// Panics if the new capacity exceeds [`isize::MAX`] bytes and [`abort`] the program\n/// in case of allocation error. Use [`try_reserve`](HashMap::try_reserve) instead\n/// if you want to handle memory allocation failure.\n///\n/// [`isize::MAX`]: https://doc.rust-lang.org/std/primitive.isize.html\n/// [`abort`]: https://doc.rust-lang.org/alloc/alloc/fn.handle_alloc_error.html\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n/// let mut map: HashMap<&str, i32> = HashMap::new();\n/// // Map is empty and doesn't allocate memory\n/// assert_eq!(map.capacity(), 0);\n///\n/// map.reserve(10);\n///\n/// // And now map can hold at least 10 elements\n/// assert!(map.capacity() >= 10);\n/// ```\ninline\npub fn reserve(&mut self, additional: usize){\n        self.table\n            .reserve(additional, make_hasher::<_, V, S>(&self.hash_builder));\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::HashMap::<K, V, S, A>::retain": [
            "/// Retains only the elements specified by the predicate. Keeps the\n/// allocated memory for reuse.\n///\n/// In other words, remove all pairs `(k, v)` such that `f(&k, &mut v)` returns `false`.\n/// The elements are visited in unsorted (and unspecified) order.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut map: HashMap<i32, i32> = (0..8).map(|x|(x, x*10)).collect();\n/// assert_eq!(map.len(), 8);\n///\n/// map.retain(|&k, _| k % 2 == 0);\n///\n/// // We can see, that the number of elements inside map is changed.\n/// assert_eq!(map.len(), 4);\n///\n/// let mut vec: Vec<(i32, i32)> = map.iter().map(|(&k, &v)| (k, v)).collect();\n/// vec.sort_unstable();\n/// assert_eq!(vec, [(0, 0), (2, 20), (4, 40), (6, 60)]);\n/// ```\npub fn retain<F>(&mut self, mut f: F)\n    where\n        F: FnMut(&K, &mut V) -> bool,{\n        // Here we only use `iter` as a temporary, preventing use-after-free\n        unsafe {\n            for item in self.table.iter() {\n                let &mut (ref key, ref mut value) = item.as_mut();\n                if !f(key, value) {\n                    self.table.erase(item);\n                }\n            }\n        }\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::HashMap::<K, V, S, A>::shrink_to": [
            "/// Shrinks the capacity of the map with a lower limit. It will drop\n/// down no lower than the supplied limit while maintaining the internal rules\n/// and possibly leaving some space in accordance with the resize policy.\n///\n/// This function does nothing if the current capacity is smaller than the\n/// supplied minimum capacity.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut map: HashMap<i32, i32> = HashMap::with_capacity(100);\n/// map.insert(1, 2);\n/// map.insert(3, 4);\n/// assert!(map.capacity() >= 100);\n/// map.shrink_to(10);\n/// assert!(map.capacity() >= 10);\n/// map.shrink_to(0);\n/// assert!(map.capacity() >= 2);\n/// map.shrink_to(10);\n/// assert!(map.capacity() >= 2);\n/// ```\ninline\npub fn shrink_to(&mut self, min_capacity: usize){\n        self.table\n            .shrink_to(min_capacity, make_hasher::<_, V, S>(&self.hash_builder));\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::HashMap::<K, V, S, A>::shrink_to_fit": [
            "/// Shrinks the capacity of the map as much as possible. It will drop\n/// down as much as possible while maintaining the internal rules\n/// and possibly leaving some space in accordance with the resize policy.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut map: HashMap<i32, i32> = HashMap::with_capacity(100);\n/// map.insert(1, 2);\n/// map.insert(3, 4);\n/// assert!(map.capacity() >= 100);\n/// map.shrink_to_fit();\n/// assert!(map.capacity() >= 2);\n/// ```\ninline\npub fn shrink_to_fit(&mut self){\n        self.table\n            .shrink_to(0, make_hasher::<_, V, S>(&self.hash_builder));\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::HashMap::<K, V, S, A>::try_insert": [
            "/// Tries to insert a key-value pair into the map, and returns\n/// a mutable reference to the value in the entry.\n///\n/// # Errors\n///\n/// If the map already had this key present, nothing is updated, and\n/// an error containing the occupied entry and the value is returned.\n///\n/// # Examples\n///\n/// Basic usage:\n///\n/// ```\n/// use hashbrown::HashMap;\n/// use hashbrown::hash_map::OccupiedError;\n///\n/// let mut map = HashMap::new();\n/// assert_eq!(map.try_insert(37, \"a\").unwrap(), &\"a\");\n///\n/// match map.try_insert(37, \"b\") {\n///     Err(OccupiedError { entry, value }) => {\n///         assert_eq!(entry.key(), &37);\n///         assert_eq!(entry.get(), &\"a\");\n///         assert_eq!(value, \"b\");\n///     }\n///     _ => panic!()\n/// }\n/// ```\ninline\npub fn try_insert(\n        &mut self,\n        key: K,\n        value: V,\n    ) -> Result<&mut V, OccupiedError<'_, K, V, S, A>>{\n        match self.entry(key) {\n            Entry::Occupied(entry) => Err(OccupiedError { entry, value }),\n            Entry::Vacant(entry) => Ok(entry.insert(value)),\n        }\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::HashMap::<K, V, S, A>::try_reserve": [
            "/// Tries to reserve capacity for at least `additional` more elements to be inserted\n/// in the given `HashMap<K,V>`. The collection may reserve more space to avoid\n/// frequent reallocations.\n///\n/// # Errors\n///\n/// If the capacity overflows, or the allocator reports a failure, then an error\n/// is returned.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut map: HashMap<&str, isize> = HashMap::new();\n/// // Map is empty and doesn't allocate memory\n/// assert_eq!(map.capacity(), 0);\n///\n/// map.try_reserve(10).expect(\"why is the test harness OOMing on 10 bytes?\");\n///\n/// // And now map can hold at least 10 elements\n/// assert!(map.capacity() >= 10);\n/// ```\n/// If the capacity overflows, or the allocator reports a failure, then an error\n/// is returned:\n/// ```\n/// # fn test() {\n/// use hashbrown::HashMap;\n/// use hashbrown::TryReserveError;\n/// let mut map: HashMap<i32, i32> = HashMap::new();\n///\n/// match map.try_reserve(usize::MAX) {\n///     Err(error) => match error {\n///         TryReserveError::CapacityOverflow => {}\n///         _ => panic!(\"TryReserveError::AllocError ?\"),\n///     },\n///     _ => panic!(),\n/// }\n/// # }\n/// # fn main() {\n/// #     #[cfg(not(miri))]\n/// #     test()\n/// # }\n/// ```\ninline\npub fn try_reserve(&mut self, additional: usize) -> Result<(), TryReserveError>{\n        self.table\n            .try_reserve(additional, make_hasher::<_, V, S>(&self.hash_builder))\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::HashMap::<K, V, S, A>::values": [
            "/// An iterator visiting all values in arbitrary order.\n/// The iterator element type is `&'a V`.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut map = HashMap::new();\n/// map.insert(\"a\", 1);\n/// map.insert(\"b\", 2);\n/// map.insert(\"c\", 3);\n/// assert_eq!(map.len(), 3);\n/// let mut vec: Vec<i32> = Vec::new();\n///\n/// for val in map.values() {\n///     println!(\"{}\", val);\n///     vec.push(*val);\n/// }\n///\n/// // The `Values` iterator produces values in arbitrary order, so the\n/// // values must be sorted to test them against a sorted array.\n/// vec.sort_unstable();\n/// assert_eq!(vec, [1, 2, 3]);\n///\n/// assert_eq!(map.len(), 3);\n/// ```\ninline\npub fn values(&self) -> Values<'_, K, V>{\n        Values { inner: self.iter() }\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::HashMap::<K, V, S, A>::values_mut": [
            "/// An iterator visiting all values mutably in arbitrary order.\n/// The iterator element type is `&'a mut V`.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut map = HashMap::new();\n///\n/// map.insert(\"a\", 1);\n/// map.insert(\"b\", 2);\n/// map.insert(\"c\", 3);\n///\n/// for val in map.values_mut() {\n///     *val = *val + 10;\n/// }\n///\n/// assert_eq!(map.len(), 3);\n/// let mut vec: Vec<i32> = Vec::new();\n///\n/// for val in map.values() {\n///     println!(\"{}\", val);\n///     vec.push(*val);\n/// }\n///\n/// // The `Values` iterator produces values in arbitrary order, so the\n/// // values must be sorted to test them against a sorted array.\n/// vec.sort_unstable();\n/// assert_eq!(vec, [11, 12, 13]);\n///\n/// assert_eq!(map.len(), 3);\n/// ```\ninline\npub fn values_mut(&mut self) -> ValuesMut<'_, K, V>{\n        ValuesMut {\n            inner: self.iter_mut(),\n        }\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::HashMap::<K, V, S, A>::with_capacity_and_hasher_in": [
            "/// Creates an empty `HashMap` with the specified capacity, using `hash_builder`\n/// to hash the keys. It will be allocated with the given allocator.\n///\n/// The hash map will be able to hold at least `capacity` elements without\n/// reallocating. If `capacity` is 0, the hash map will not allocate.\n///\n/// # HashDoS resistance\n///\n/// The `hash_builder` normally use a fixed key by default and that does\n/// not allow the `HashMap` to be protected against attacks such as [`HashDoS`].\n/// Users who require HashDoS resistance should explicitly use\n/// [`std::collections::hash_map::RandomState`]\n/// as the hasher when creating a [`HashMap`].\n///\n/// [`HashDoS`]: https://en.wikipedia.org/wiki/Collision_attack\n/// [`std::collections::hash_map::RandomState`]: https://doc.rust-lang.org/std/collections/hash_map/struct.RandomState.html\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n/// use hashbrown::DefaultHashBuilder;\n///\n/// let s = DefaultHashBuilder::default();\n/// let mut map = HashMap::with_capacity_and_hasher(10, s);\n/// map.insert(1, 2);\n/// ```\ninline\npub fn with_capacity_and_hasher_in(capacity: usize, hash_builder: S, alloc: A) -> Self{\n        Self {\n            hash_builder,\n            table: RawTable::with_capacity_in(capacity, alloc),\n        }\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::HashMap::<K, V, S, A>::with_hasher_in": [
            "/// Creates an empty `HashMap` which will use the given hash builder to hash\n/// keys. It will be allocated with the given allocator.\n///\n/// The hash map is initially created with a capacity of 0, so it will not allocate until it\n/// is first inserted into.\n///\n/// # HashDoS resistance\n///\n/// The `hash_builder` normally use a fixed key by default and that does\n/// not allow the `HashMap` to be protected against attacks such as [`HashDoS`].\n/// Users who require HashDoS resistance should explicitly use\n/// [`std::collections::hash_map::RandomState`]\n/// as the hasher when creating a [`HashMap`].\n///\n/// [`HashDoS`]: https://en.wikipedia.org/wiki/Collision_attack\n/// [`std::collections::hash_map::RandomState`]: https://doc.rust-lang.org/std/collections/hash_map/struct.RandomState.html\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n/// use hashbrown::DefaultHashBuilder;\n///\n/// let s = DefaultHashBuilder::default();\n/// let mut map = HashMap::with_hasher(s);\n/// map.insert(1, 2);\n/// ```\ninline\npub const fn with_hasher_in(hash_builder: S, alloc: A) -> Self{\n        Self {\n            hash_builder,\n            table: RawTable::new_in(alloc),\n        }\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::HashMap::<K, V, S>::with_capacity_and_hasher": [
            "/// Creates an empty `HashMap` with the specified capacity, using `hash_builder`\n/// to hash the keys.\n///\n/// The hash map will be able to hold at least `capacity` elements without\n/// reallocating. If `capacity` is 0, the hash map will not allocate.\n///\n/// # HashDoS resistance\n///\n/// The `hash_builder` normally use a fixed key by default and that does\n/// not allow the `HashMap` to be protected against attacks such as [`HashDoS`].\n/// Users who require HashDoS resistance should explicitly use\n/// [`std::collections::hash_map::RandomState`]\n/// as the hasher when creating a [`HashMap`].\n///\n/// The `hash_builder` passed should implement the [`BuildHasher`] trait for\n/// the `HashMap` to be useful, see its documentation for details.\n///\n/// [`HashDoS`]: https://en.wikipedia.org/wiki/Collision_attack\n/// [`std::collections::hash_map::RandomState`]: https://doc.rust-lang.org/std/collections/hash_map/struct.RandomState.html\n/// [`BuildHasher`]: https://doc.rust-lang.org/std/hash/trait.BuildHasher.html\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n/// use hashbrown::DefaultHashBuilder;\n///\n/// let s = DefaultHashBuilder::default();\n/// let mut map = HashMap::with_capacity_and_hasher(10, s);\n/// assert_eq!(map.len(), 0);\n/// assert!(map.capacity() >= 10);\n///\n/// map.insert(1, 2);\n/// ```\ninline\npub fn with_capacity_and_hasher(capacity: usize, hash_builder: S) -> Self{\n        Self {\n            hash_builder,\n            table: RawTable::with_capacity(capacity),\n        }\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::HashMap::<K, V, S>::with_hasher": [
            "/// Creates an empty `HashMap` which will use the given hash builder to hash\n/// keys.\n///\n/// The hash map is initially created with a capacity of 0, so it will not\n/// allocate until it is first inserted into.\n///\n/// # HashDoS resistance\n///\n/// The `hash_builder` normally use a fixed key by default and that does\n/// not allow the `HashMap` to be protected against attacks such as [`HashDoS`].\n/// Users who require HashDoS resistance should explicitly use\n/// [`std::collections::hash_map::RandomState`]\n/// as the hasher when creating a [`HashMap`].\n///\n/// The `hash_builder` passed should implement the [`BuildHasher`] trait for\n/// the `HashMap` to be useful, see its documentation for details.\n///\n/// [`HashDoS`]: https://en.wikipedia.org/wiki/Collision_attack\n/// [`std::collections::hash_map::RandomState`]: https://doc.rust-lang.org/std/collections/hash_map/struct.RandomState.html\n/// [`BuildHasher`]: https://doc.rust-lang.org/std/hash/trait.BuildHasher.html\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n/// use hashbrown::DefaultHashBuilder;\n///\n/// let s = DefaultHashBuilder::default();\n/// let mut map = HashMap::with_hasher(s);\n/// assert_eq!(map.len(), 0);\n/// assert_eq!(map.capacity(), 0);\n///\n/// map.insert(1, 2);\n/// ```\ninline\npub const fn with_hasher(hash_builder: S) -> Self{\n        Self {\n            hash_builder,\n            table: RawTable::new(),\n        }\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::HashMap::<K, V, foldhash::fast::RandomState, A>::new_in": [
            "/// Creates an empty `HashMap` using the given allocator.\n///\n/// The hash map is initially created with a capacity of 0, so it will not allocate until it\n/// is first inserted into.\n///\n/// # HashDoS resistance\n///\n/// The `hash_builder` normally use a fixed key by default and that does\n/// not allow the `HashMap` to be protected against attacks such as [`HashDoS`].\n/// Users who require HashDoS resistance should explicitly use\n/// [`std::collections::hash_map::RandomState`]\n/// as the hasher when creating a [`HashMap`], for example with\n/// [`with_hasher_in`](HashMap::with_hasher_in) method.\n///\n/// [`HashDoS`]: https://en.wikipedia.org/wiki/Collision_attack\n/// [`std::collections::hash_map::RandomState`]: https://doc.rust-lang.org/std/collections/hash_map/struct.RandomState.html\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n/// use bumpalo::Bump;\n///\n/// let bump = Bump::new();\n/// let mut map = HashMap::new_in(&bump);\n///\n/// // The created HashMap holds none elements\n/// assert_eq!(map.len(), 0);\n///\n/// // The created HashMap also doesn't allocate memory\n/// assert_eq!(map.capacity(), 0);\n///\n/// // Now we insert element inside created HashMap\n/// map.insert(\"One\", 1);\n/// // We can see that the HashMap holds 1 element\n/// assert_eq!(map.len(), 1);\n/// // And it also allocates some capacity\n/// assert!(map.capacity() > 1);\n/// ```\ninline\npub fn new_in(alloc: A) -> Self{\n        Self::with_hasher_in(DefaultHashBuilder::default(), alloc)\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::HashMap::<K, V, foldhash::fast::RandomState, A>::with_capacity_in": [
            "/// Creates an empty `HashMap` with the specified capacity using the given allocator.\n///\n/// The hash map will be able to hold at least `capacity` elements without\n/// reallocating. If `capacity` is 0, the hash map will not allocate.\n///\n/// # HashDoS resistance\n///\n/// The `hash_builder` normally use a fixed key by default and that does\n/// not allow the `HashMap` to be protected against attacks such as [`HashDoS`].\n/// Users who require HashDoS resistance should explicitly use\n/// [`std::collections::hash_map::RandomState`]\n/// as the hasher when creating a [`HashMap`], for example with\n/// [`with_capacity_and_hasher_in`](HashMap::with_capacity_and_hasher_in) method.\n///\n/// [`HashDoS`]: https://en.wikipedia.org/wiki/Collision_attack\n/// [`std::collections::hash_map::RandomState`]: https://doc.rust-lang.org/std/collections/hash_map/struct.RandomState.html\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n/// use bumpalo::Bump;\n///\n/// let bump = Bump::new();\n/// let mut map = HashMap::with_capacity_in(5, &bump);\n///\n/// // The created HashMap holds none elements\n/// assert_eq!(map.len(), 0);\n/// // But it can hold at least 5 elements without reallocating\n/// let empty_map_capacity = map.capacity();\n/// assert!(empty_map_capacity >= 5);\n///\n/// // Now we insert some 5 elements inside created HashMap\n/// map.insert(\"One\",   1);\n/// map.insert(\"Two\",   2);\n/// map.insert(\"Three\", 3);\n/// map.insert(\"Four\",  4);\n/// map.insert(\"Five\",  5);\n///\n/// // We can see that the HashMap holds 5 elements\n/// assert_eq!(map.len(), 5);\n/// // But its capacity isn't changed\n/// assert_eq!(map.capacity(), empty_map_capacity)\n/// ```\ninline\npub fn with_capacity_in(capacity: usize, alloc: A) -> Self{\n        Self::with_capacity_and_hasher_in(capacity, DefaultHashBuilder::default(), alloc)\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::HashMap::<K, V>::new": [
            "/// Creates an empty `HashMap`.\n///\n/// The hash map is initially created with a capacity of 0, so it will not allocate until it\n/// is first inserted into.\n///\n/// # HashDoS resistance\n///\n/// The `hash_builder` normally use a fixed key by default and that does\n/// not allow the `HashMap` to be protected against attacks such as [`HashDoS`].\n/// Users who require HashDoS resistance should explicitly use\n/// [`std::collections::hash_map::RandomState`]\n/// as the hasher when creating a [`HashMap`], for example with\n/// [`with_hasher`](HashMap::with_hasher) method.\n///\n/// [`HashDoS`]: https://en.wikipedia.org/wiki/Collision_attack\n/// [`std::collections::hash_map::RandomState`]: https://doc.rust-lang.org/std/collections/hash_map/struct.RandomState.html\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n/// let mut map: HashMap<&str, i32> = HashMap::new();\n/// assert_eq!(map.len(), 0);\n/// assert_eq!(map.capacity(), 0);\n/// ```\ninline\npub fn new() -> Self{\n        Self::default()\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::HashMap::<K, V>::with_capacity": [
            "/// Creates an empty `HashMap` with the specified capacity.\n///\n/// The hash map will be able to hold at least `capacity` elements without\n/// reallocating. If `capacity` is 0, the hash map will not allocate.\n///\n/// # HashDoS resistance\n///\n/// The `hash_builder` normally use a fixed key by default and that does\n/// not allow the `HashMap` to be protected against attacks such as [`HashDoS`].\n/// Users who require HashDoS resistance should explicitly use\n/// [`std::collections::hash_map::RandomState`]\n/// as the hasher when creating a [`HashMap`], for example with\n/// [`with_capacity_and_hasher`](HashMap::with_capacity_and_hasher) method.\n///\n/// [`HashDoS`]: https://en.wikipedia.org/wiki/Collision_attack\n/// [`std::collections::hash_map::RandomState`]: https://doc.rust-lang.org/std/collections/hash_map/struct.RandomState.html\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n/// let mut map: HashMap<&str, i32> = HashMap::with_capacity(10);\n/// assert_eq!(map.len(), 0);\n/// assert!(map.capacity() >= 10);\n/// ```\ninline\npub fn with_capacity(capacity: usize) -> Self{\n        Self::with_capacity_and_hasher(capacity, DefaultHashBuilder::default())\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::IntoIter": [
            "/// An owning iterator over the entries of a `HashMap` in arbitrary order.\n/// The iterator element type is `(K, V)`.\n///\n/// This `struct` is created by the [`into_iter`] method on [`HashMap`]\n/// (provided by the [`IntoIterator`] trait). See its documentation for more.\n/// The map cannot be used after calling that method.\n///\n/// [`into_iter`]: struct.HashMap.html#method.into_iter\n/// [`HashMap`]: struct.HashMap.html\n/// [`IntoIterator`]: https://doc.rust-lang.org/core/iter/trait.IntoIterator.html\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let map: HashMap<_, _> = [(1, \"a\"), (2, \"b\"), (3, \"c\")].into();\n///\n/// let mut iter = map.into_iter();\n/// let mut vec = vec![iter.next(), iter.next(), iter.next()];\n///\n/// // The `IntoIter` iterator produces items in arbitrary order, so the\n/// // items must be sorted to test them against a sorted array.\n/// vec.sort_unstable();\n/// assert_eq!(vec, [Some((1, \"a\")), Some((2, \"b\")), Some((3, \"c\"))]);\n///\n/// // It is fused iterator\n/// assert_eq!(iter.next(), None);\n/// assert_eq!(iter.next(), None);\n/// ```\npub struct IntoIter<K, V, A: Allocator = Global> {\n    inner: RawIntoIter<(K, V), A>,\n}",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::IntoIter::<K, V, A>::iter": [
            "/// Returns a iterator of references over the remaining items.\ninline\npub(super) fn iter(&self) -> Iter<'_, K, V>{\n        Iter {\n            inner: self.inner.iter(),\n            marker: PhantomData,\n        }\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::IntoKeys": [
            "/// An owning iterator over the keys of a `HashMap` in arbitrary order.\n/// The iterator element type is `K`.\n///\n/// This `struct` is created by the [`into_keys`] method on [`HashMap`].\n/// See its documentation for more.\n/// The map cannot be used after calling that method.\n///\n/// [`into_keys`]: struct.HashMap.html#method.into_keys\n/// [`HashMap`]: struct.HashMap.html\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let map: HashMap<_, _> = [(1, \"a\"), (2, \"b\"), (3, \"c\")].into();\n///\n/// let mut keys = map.into_keys();\n/// let mut vec = vec![keys.next(), keys.next(), keys.next()];\n///\n/// // The `IntoKeys` iterator produces keys in arbitrary order, so the\n/// // keys must be sorted to test them against a sorted array.\n/// vec.sort_unstable();\n/// assert_eq!(vec, [Some(1), Some(2), Some(3)]);\n///\n/// // It is fused iterator\n/// assert_eq!(keys.next(), None);\n/// assert_eq!(keys.next(), None);\n/// ```\npub struct IntoKeys<K, V, A: Allocator = Global> {\n    inner: IntoIter<K, V, A>,\n}",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::IntoValues": [
            "/// An owning iterator over the values of a `HashMap` in arbitrary order.\n/// The iterator element type is `V`.\n///\n/// This `struct` is created by the [`into_values`] method on [`HashMap`].\n/// See its documentation for more. The map cannot be used after calling that method.\n///\n/// [`into_values`]: struct.HashMap.html#method.into_values\n/// [`HashMap`]: struct.HashMap.html\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let map: HashMap<_, _> = [(1, \"a\"), (2, \"b\"), (3, \"c\")].into();\n///\n/// let mut values = map.into_values();\n/// let mut vec = vec![values.next(), values.next(), values.next()];\n///\n/// // The `IntoValues` iterator produces values in arbitrary order, so\n/// // the values must be sorted to test them against a sorted array.\n/// vec.sort_unstable();\n/// assert_eq!(vec, [Some(\"a\"), Some(\"b\"), Some(\"c\")]);\n///\n/// // It is fused iterator\n/// assert_eq!(values.next(), None);\n/// assert_eq!(values.next(), None);\n/// ```\npub struct IntoValues<K, V, A: Allocator = Global> {\n    inner: IntoIter<K, V, A>,\n}",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::Iter": [
            "/// An iterator over the entries of a `HashMap` in arbitrary order.\n/// The iterator element type is `(&'a K, &'a V)`.\n///\n/// This `struct` is created by the [`iter`] method on [`HashMap`]. See its\n/// documentation for more.\n///\n/// [`iter`]: struct.HashMap.html#method.iter\n/// [`HashMap`]: struct.HashMap.html\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let map: HashMap<_, _> = [(1, \"a\"), (2, \"b\"), (3, \"c\")].into();\n///\n/// let mut iter = map.iter();\n/// let mut vec = vec![iter.next(), iter.next(), iter.next()];\n///\n/// // The `Iter` iterator produces items in arbitrary order, so the\n/// // items must be sorted to test them against a sorted array.\n/// vec.sort_unstable();\n/// assert_eq!(vec, [Some((&1, &\"a\")), Some((&2, &\"b\")), Some((&3, &\"c\"))]);\n///\n/// // It is fused iterator\n/// assert_eq!(iter.next(), None);\n/// assert_eq!(iter.next(), None);\n/// ```\npub struct Iter<'a, K, V> {\n    inner: RawIter<(K, V)>,\n    marker: PhantomData<(&'a K, &'a V)>,\n}",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::IterMut": [
            "/// A mutable iterator over the entries of a `HashMap` in arbitrary order.\n/// The iterator element type is `(&'a K, &'a mut V)`.\n///\n/// This `struct` is created by the [`iter_mut`] method on [`HashMap`]. See its\n/// documentation for more.\n///\n/// [`iter_mut`]: struct.HashMap.html#method.iter_mut\n/// [`HashMap`]: struct.HashMap.html\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut map: HashMap<_, _> = [(1, \"One\".to_owned()), (2, \"Two\".into())].into();\n///\n/// let mut iter = map.iter_mut();\n/// iter.next().map(|(_, v)| v.push_str(\" Mississippi\"));\n/// iter.next().map(|(_, v)| v.push_str(\" Mississippi\"));\n///\n/// // It is fused iterator\n/// assert_eq!(iter.next(), None);\n/// assert_eq!(iter.next(), None);\n///\n/// assert_eq!(map.get(&1).unwrap(), &\"One Mississippi\".to_owned());\n/// assert_eq!(map.get(&2).unwrap(), &\"Two Mississippi\".to_owned());\n/// ```\npub struct IterMut<'a, K, V> {\n    inner: RawIter<(K, V)>,\n    // To ensure invariance with respect to V\n    marker: PhantomData<(&'a K, &'a mut V)>,\n}",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::IterMut::<'_, K, V>::iter": [
            "/// Returns a iterator of references over the remaining items.\ninline\npub(super) fn iter(&self) -> Iter<'_, K, V>{\n        Iter {\n            inner: self.inner.clone(),\n            marker: PhantomData,\n        }\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::Keys": [
            "/// An iterator over the keys of a `HashMap` in arbitrary order.\n/// The iterator element type is `&'a K`.\n///\n/// This `struct` is created by the [`keys`] method on [`HashMap`]. See its\n/// documentation for more.\n///\n/// [`keys`]: struct.HashMap.html#method.keys\n/// [`HashMap`]: struct.HashMap.html\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let map: HashMap<_, _> = [(1, \"a\"), (2, \"b\"), (3, \"c\")].into();\n///\n/// let mut keys = map.keys();\n/// let mut vec = vec![keys.next(), keys.next(), keys.next()];\n///\n/// // The `Keys` iterator produces keys in arbitrary order, so the\n/// // keys must be sorted to test them against a sorted array.\n/// vec.sort_unstable();\n/// assert_eq!(vec, [Some(&1), Some(&2), Some(&3)]);\n///\n/// // It is fused iterator\n/// assert_eq!(keys.next(), None);\n/// assert_eq!(keys.next(), None);\n/// ```\npub struct Keys<'a, K, V> {\n    inner: Iter<'a, K, V>,\n}",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::OccupiedEntry": [
            "/// A view into an occupied entry in a [`HashMap`].\n/// It is part of the [`Entry`] and [`EntryRef`] enums.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::hash_map::{Entry, HashMap, OccupiedEntry};\n///\n/// let mut map = HashMap::new();\n/// map.extend([(\"a\", 10), (\"b\", 20), (\"c\", 30)]);\n///\n/// let _entry_o: OccupiedEntry<_, _, _> = map.entry(\"a\").insert(100);\n/// assert_eq!(map.len(), 3);\n///\n/// // Existing key (insert and update)\n/// match map.entry(\"a\") {\n///     Entry::Vacant(_) => unreachable!(),\n///     Entry::Occupied(mut view) => {\n///         assert_eq!(view.get(), &100);\n///         let v = view.get_mut();\n///         *v *= 10;\n///         assert_eq!(view.insert(1111), 1000);\n///     }\n/// }\n///\n/// assert_eq!(map[&\"a\"], 1111);\n/// assert_eq!(map.len(), 3);\n///\n/// // Existing key (take)\n/// match map.entry(\"c\") {\n///     Entry::Vacant(_) => unreachable!(),\n///     Entry::Occupied(view) => {\n///         assert_eq!(view.remove_entry(), (\"c\", 30));\n///     }\n/// }\n/// assert_eq!(map.get(&\"c\"), None);\n/// assert_eq!(map.len(), 2);\n/// ```\npub struct OccupiedEntry<'a, K, V, S = DefaultHashBuilder, A: Allocator = Global> {\n    hash: u64,\n    elem: Bucket<(K, V)>,\n    table: &'a mut HashMap<K, V, S, A>,\n}",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::OccupiedEntry::<'a, K, V, S, A>::get": [
            "/// Gets a reference to the value in the entry.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n/// use hashbrown::hash_map::Entry;\n///\n/// let mut map: HashMap<&str, u32> = HashMap::new();\n/// map.entry(\"poneyland\").or_insert(12);\n///\n/// match map.entry(\"poneyland\") {\n///     Entry::Vacant(_) => panic!(),\n///     Entry::Occupied(entry) => assert_eq!(entry.get(), &12),\n/// }\n/// ```\ninline\npub fn get(&self) -> &V{\n        unsafe { &self.elem.as_ref().1 }\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::OccupiedEntry::<'a, K, V, S, A>::get_mut": [
            "/// Gets a mutable reference to the value in the entry.\n///\n/// If you need a reference to the `OccupiedEntry` which may outlive the\n/// destruction of the `Entry` value, see [`into_mut`].\n///\n/// [`into_mut`]: #method.into_mut\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n/// use hashbrown::hash_map::Entry;\n///\n/// let mut map: HashMap<&str, u32> = HashMap::new();\n/// map.entry(\"poneyland\").or_insert(12);\n///\n/// assert_eq!(map[\"poneyland\"], 12);\n/// if let Entry::Occupied(mut o) = map.entry(\"poneyland\") {\n///     *o.get_mut() += 10;\n///     assert_eq!(*o.get(), 22);\n///\n///     // We can use the same Entry multiple times.\n///     *o.get_mut() += 2;\n/// }\n///\n/// assert_eq!(map[\"poneyland\"], 24);\n/// ```\ninline\npub fn get_mut(&mut self) -> &mut V{\n        unsafe { &mut self.elem.as_mut().1 }\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::OccupiedEntry::<'a, K, V, S, A>::insert": [
            "/// Sets the value of the entry, and returns the entry's old value.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n/// use hashbrown::hash_map::Entry;\n///\n/// let mut map: HashMap<&str, u32> = HashMap::new();\n/// map.entry(\"poneyland\").or_insert(12);\n///\n/// if let Entry::Occupied(mut o) = map.entry(\"poneyland\") {\n///     assert_eq!(o.insert(15), 12);\n/// }\n///\n/// assert_eq!(map[\"poneyland\"], 15);\n/// ```\ninline\npub fn insert(&mut self, value: V) -> V{\n        mem::replace(self.get_mut(), value)\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::OccupiedEntry::<'a, K, V, S, A>::into_mut": [
            "/// Converts the `OccupiedEntry` into a mutable reference to the value in the entry\n/// with a lifetime bound to the map itself.\n///\n/// If you need multiple references to the `OccupiedEntry`, see [`get_mut`].\n///\n/// [`get_mut`]: #method.get_mut\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::hash_map::{Entry, HashMap};\n///\n/// let mut map: HashMap<&str, u32> = HashMap::new();\n/// map.entry(\"poneyland\").or_insert(12);\n///\n/// assert_eq!(map[\"poneyland\"], 12);\n///\n/// let value: &mut u32;\n/// match map.entry(\"poneyland\") {\n///     Entry::Occupied(entry) => value = entry.into_mut(),\n///     Entry::Vacant(_) => panic!(),\n/// }\n/// *value += 10;\n///\n/// assert_eq!(map[\"poneyland\"], 22);\n/// ```\ninline\npub fn into_mut(self) -> &'a mut V{\n        unsafe { &mut self.elem.as_mut().1 }\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::OccupiedEntry::<'a, K, V, S, A>::key": [
            "/// Gets a reference to the key in the entry.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::hash_map::{Entry, HashMap};\n///\n/// let mut map: HashMap<&str, u32> = HashMap::new();\n/// map.entry(\"poneyland\").or_insert(12);\n///\n/// match map.entry(\"poneyland\") {\n///     Entry::Vacant(_) => panic!(),\n///     Entry::Occupied(entry) => assert_eq!(entry.key(), &\"poneyland\"),\n/// }\n/// ```\ninline\npub fn key(&self) -> &K{\n        unsafe { &self.elem.as_ref().0 }\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::OccupiedEntry::<'a, K, V, S, A>::remove": [
            "/// Takes the value out of the entry, and returns it.\n/// Keeps the allocated memory for reuse.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n/// use hashbrown::hash_map::Entry;\n///\n/// let mut map: HashMap<&str, u32> = HashMap::new();\n/// // The map is empty\n/// assert!(map.is_empty() && map.capacity() == 0);\n///\n/// map.entry(\"poneyland\").or_insert(12);\n///\n/// if let Entry::Occupied(o) = map.entry(\"poneyland\") {\n///     assert_eq!(o.remove(), 12);\n/// }\n///\n/// assert_eq!(map.contains_key(\"poneyland\"), false);\n/// // Now map hold none elements\n/// assert!(map.is_empty());\n/// ```\ninline\npub fn remove(self) -> V{\n        self.remove_entry().1\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::OccupiedEntry::<'a, K, V, S, A>::remove_entry": [
            "/// Take the ownership of the key and value from the map.\n/// Keeps the allocated memory for reuse.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n/// use hashbrown::hash_map::Entry;\n///\n/// let mut map: HashMap<&str, u32> = HashMap::new();\n/// // The map is empty\n/// assert!(map.is_empty() && map.capacity() == 0);\n///\n/// map.entry(\"poneyland\").or_insert(12);\n///\n/// if let Entry::Occupied(o) = map.entry(\"poneyland\") {\n///     // We delete the entry from the map.\n///     assert_eq!(o.remove_entry(), (\"poneyland\", 12));\n/// }\n///\n/// assert_eq!(map.contains_key(\"poneyland\"), false);\n/// // Now map hold none elements\n/// assert!(map.is_empty());\n/// ```\ninline\npub fn remove_entry(self) -> (K, V){\n        unsafe { self.table.table.remove(self.elem).0 }\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::OccupiedEntry::<'a, K, V, S, A>::replace_entry_with": [
            "/// Provides shared access to the key and owned access to the value of\n/// the entry and allows to replace or remove it based on the\n/// value of the returned option.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n/// use hashbrown::hash_map::Entry;\n///\n/// let mut map: HashMap<&str, u32> = HashMap::new();\n/// map.insert(\"poneyland\", 42);\n///\n/// let entry = match map.entry(\"poneyland\") {\n///     Entry::Occupied(e) => {\n///         e.replace_entry_with(|k, v| {\n///             assert_eq!(k, &\"poneyland\");\n///             assert_eq!(v, 42);\n///             Some(v + 1)\n///         })\n///     }\n///     Entry::Vacant(_) => panic!(),\n/// };\n///\n/// match entry {\n///     Entry::Occupied(e) => {\n///         assert_eq!(e.key(), &\"poneyland\");\n///         assert_eq!(e.get(), &43);\n///     }\n///     Entry::Vacant(_) => panic!(),\n/// }\n///\n/// assert_eq!(map[\"poneyland\"], 43);\n///\n/// let entry = match map.entry(\"poneyland\") {\n///     Entry::Occupied(e) => e.replace_entry_with(|_k, _v| None),\n///     Entry::Vacant(_) => panic!(),\n/// };\n///\n/// match entry {\n///     Entry::Vacant(e) => {\n///         assert_eq!(e.key(), &\"poneyland\");\n///     }\n///     Entry::Occupied(_) => panic!(),\n/// }\n///\n/// assert!(!map.contains_key(\"poneyland\"));\n/// ```\ninline\npub fn replace_entry_with<F>(self, f: F) -> Entry<'a, K, V, S, A>\n    where\n        F: FnOnce(&K, V) -> Option<V>,{\n        unsafe {\n            let mut spare_key = None;\n\n            self.table\n                .table\n                .replace_bucket_with(self.elem.clone(), |(key, value)| {\n                    if let Some(new_value) = f(&key, value) {\n                        Some((key, new_value))\n                    } else {\n                        spare_key = Some(key);\n                        None\n                    }\n                });\n\n            if let Some(key) = spare_key {\n                Entry::Vacant(VacantEntry {\n                    hash: self.hash,\n                    key,\n                    table: self.table,\n                })\n            } else {\n                Entry::Occupied(self)\n            }\n        }\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::OccupiedError": [
            "/// The error returned by [`try_insert`](HashMap::try_insert) when the key already exists.\n///\n/// Contains the occupied entry, and the value that was not inserted.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::hash_map::{HashMap, OccupiedError};\n///\n/// let mut map: HashMap<_, _> = [(\"a\", 10), (\"b\", 20)].into();\n///\n/// // try_insert method returns mutable reference to the value if keys are vacant,\n/// // but if the map did have key present, nothing is updated, and the provided\n/// // value is returned inside `Err(_)` variant\n/// match map.try_insert(\"a\", 100) {\n///     Err(OccupiedError { mut entry, value }) => {\n///         assert_eq!(entry.key(), &\"a\");\n///         assert_eq!(value, 100);\n///         assert_eq!(entry.insert(100), 10)\n///     }\n///     _ => unreachable!(),\n/// }\n/// assert_eq!(map[&\"a\"], 100);\n/// ```\npub struct OccupiedError<'a, K, V, S, A: Allocator = Global> {\n    /// The entry in the map that was already occupied.\n    pub entry: OccupiedEntry<'a, K, V, S, A>,\n    /// The value which was not inserted, because the entry was already occupied.\n    pub value: V,\n}",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::VacantEntry": [
            "/// A view into a vacant entry in a `HashMap`.\n/// It is part of the [`Entry`] enum.\n///\n/// [`Entry`]: enum.Entry.html\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::hash_map::{Entry, HashMap, VacantEntry};\n///\n/// let mut map = HashMap::<&str, i32>::new();\n///\n/// let entry_v: VacantEntry<_, _, _> = match map.entry(\"a\") {\n///     Entry::Vacant(view) => view,\n///     Entry::Occupied(_) => unreachable!(),\n/// };\n/// entry_v.insert(10);\n/// assert!(map[&\"a\"] == 10 && map.len() == 1);\n///\n/// // Nonexistent key (insert and update)\n/// match map.entry(\"b\") {\n///     Entry::Occupied(_) => unreachable!(),\n///     Entry::Vacant(view) => {\n///         let value = view.insert(2);\n///         assert_eq!(*value, 2);\n///         *value = 20;\n///     }\n/// }\n/// assert!(map[&\"b\"] == 20 && map.len() == 2);\n/// ```\npub struct VacantEntry<'a, K, V, S = DefaultHashBuilder, A: Allocator = Global> {\n    hash: u64,\n    key: K,\n    table: &'a mut HashMap<K, V, S, A>,\n}",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::VacantEntry::<'a, K, V, S, A>::insert": [
            "/// Sets the value of the entry with the [`VacantEntry`]'s key,\n/// and returns a mutable reference to it.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n/// use hashbrown::hash_map::Entry;\n///\n/// let mut map: HashMap<&str, u32> = HashMap::new();\n///\n/// if let Entry::Vacant(o) = map.entry(\"poneyland\") {\n///     o.insert(37);\n/// }\n/// assert_eq!(map[\"poneyland\"], 37);\n/// ```\ninline\npub fn insert(self, value: V) -> &'a mut V\n    where\n        K: Hash,\n        S: BuildHasher,{\n        let table = &mut self.table.table;\n        let entry = table.insert_entry(\n            self.hash,\n            (self.key, value),\n            make_hasher::<_, V, S>(&self.table.hash_builder),\n        );\n        &mut entry.1\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::VacantEntry::<'a, K, V, S, A>::insert_entry": [
            "/// Sets the value of the entry with the [`VacantEntry`]'s key,\n/// and returns an [`OccupiedEntry`].\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n/// use hashbrown::hash_map::Entry;\n///\n/// let mut map: HashMap<&str, u32> = HashMap::new();\n///\n/// if let Entry::Vacant(v) = map.entry(\"poneyland\") {\n///     let o = v.insert_entry(37);\n///     assert_eq!(o.get(), &37);\n/// }\n/// ```\ninline\npub fn insert_entry(self, value: V) -> OccupiedEntry<'a, K, V, S, A>\n    where\n        K: Hash,\n        S: BuildHasher,{\n        let elem = self.table.table.insert(\n            self.hash,\n            (self.key, value),\n            make_hasher::<_, V, S>(&self.table.hash_builder),\n        );\n        OccupiedEntry {\n            hash: self.hash,\n            elem,\n            table: self.table,\n        }\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::VacantEntry::<'a, K, V, S, A>::into_key": [
            "/// Take ownership of the key.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::hash_map::{Entry, HashMap};\n///\n/// let mut map: HashMap<&str, u32> = HashMap::new();\n///\n/// match map.entry(\"poneyland\") {\n///     Entry::Occupied(_) => panic!(),\n///     Entry::Vacant(v) => assert_eq!(v.into_key(), \"poneyland\"),\n/// }\n/// ```\ninline\npub fn into_key(self) -> K{\n        self.key\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::VacantEntry::<'a, K, V, S, A>::key": [
            "/// Gets a reference to the key that would be used when inserting a value\n/// through the `VacantEntry`.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut map: HashMap<&str, u32> = HashMap::new();\n/// assert_eq!(map.entry(\"poneyland\").key(), &\"poneyland\");\n/// ```\ninline\npub fn key(&self) -> &K{\n        &self.key\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::VacantEntryRef": [
            "/// A view into a vacant entry in a `HashMap`.\n/// It is part of the [`EntryRef`] enum.\n///\n/// [`EntryRef`]: enum.EntryRef.html\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::hash_map::{EntryRef, HashMap, VacantEntryRef};\n///\n/// let mut map = HashMap::<String, i32>::new();\n///\n/// let entry_v: VacantEntryRef<_, _, _, _> = match map.entry_ref(\"a\") {\n///     EntryRef::Vacant(view) => view,\n///     EntryRef::Occupied(_) => unreachable!(),\n/// };\n/// entry_v.insert(10);\n/// assert!(map[\"a\"] == 10 && map.len() == 1);\n///\n/// // Nonexistent key (insert and update)\n/// match map.entry_ref(\"b\") {\n///     EntryRef::Occupied(_) => unreachable!(),\n///     EntryRef::Vacant(view) => {\n///         let value = view.insert(2);\n///         assert_eq!(*value, 2);\n///         *value = 20;\n///     }\n/// }\n/// assert!(map[\"b\"] == 20 && map.len() == 2);\n/// ```\npub struct VacantEntryRef<'a, 'b, K, Q: ?Sized, V, S, A: Allocator = Global> {\n    hash: u64,\n    key: &'b Q,\n    table: &'a mut HashMap<K, V, S, A>,\n}",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::VacantEntryRef::<'a, 'b, K, Q, V, S, A>::insert": [
            "/// Sets the value of the entry with the `VacantEntryRef`'s key,\n/// and returns a mutable reference to it.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n/// use hashbrown::hash_map::EntryRef;\n///\n/// let mut map: HashMap<String, u32> = HashMap::new();\n/// let key: &str = \"poneyland\";\n///\n/// if let EntryRef::Vacant(o) = map.entry_ref(key) {\n///     o.insert(37);\n/// }\n/// assert_eq!(map[\"poneyland\"], 37);\n/// ```\ninline\npub fn insert(self, value: V) -> &'a mut V\n    where\n        K: Hash,\n        &'b Q: Into<K>,\n        S: BuildHasher,{\n        let table = &mut self.table.table;\n        let entry = table.insert_entry(\n            self.hash,\n            (self.key.into(), value),\n            make_hasher::<_, V, S>(&self.table.hash_builder),\n        );\n        &mut entry.1\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::VacantEntryRef::<'a, 'b, K, Q, V, S, A>::insert_entry": [
            "/// Sets the value of the entry with the [`VacantEntryRef`]'s key,\n/// and returns an [`OccupiedEntry`].\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n/// use hashbrown::hash_map::EntryRef;\n///\n/// let mut map: HashMap<&str, u32> = HashMap::new();\n///\n/// if let EntryRef::Vacant(v) = map.entry_ref(\"poneyland\") {\n///     let o = v.insert_entry(37);\n///     assert_eq!(o.get(), &37);\n/// }\n/// ```\ninline\npub fn insert_entry(self, value: V) -> OccupiedEntry<'a, K, V, S, A>\n    where\n        K: Hash,\n        &'b Q: Into<K>,\n        S: BuildHasher,{\n        let elem = self.table.table.insert(\n            self.hash,\n            (self.key.into(), value),\n            make_hasher::<_, V, S>(&self.table.hash_builder),\n        );\n        OccupiedEntry {\n            hash: self.hash,\n            elem,\n            table: self.table,\n        }\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::VacantEntryRef::<'a, 'b, K, Q, V, S, A>::key": [
            "/// Gets a reference to the key that would be used when inserting a value\n/// through the `VacantEntryRef`.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut map: HashMap<String, u32> = HashMap::new();\n/// let key: &str = \"poneyland\";\n/// assert_eq!(map.entry_ref(key).key(), \"poneyland\");\n/// ```\ninline\npub fn key(&self) -> &'b Q{\n        self.key\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::Values": [
            "/// An iterator over the values of a `HashMap` in arbitrary order.\n/// The iterator element type is `&'a V`.\n///\n/// This `struct` is created by the [`values`] method on [`HashMap`]. See its\n/// documentation for more.\n///\n/// [`values`]: struct.HashMap.html#method.values\n/// [`HashMap`]: struct.HashMap.html\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let map: HashMap<_, _> = [(1, \"a\"), (2, \"b\"), (3, \"c\")].into();\n///\n/// let mut values = map.values();\n/// let mut vec = vec![values.next(), values.next(), values.next()];\n///\n/// // The `Values` iterator produces values in arbitrary order, so the\n/// // values must be sorted to test them against a sorted array.\n/// vec.sort_unstable();\n/// assert_eq!(vec, [Some(&\"a\"), Some(&\"b\"), Some(&\"c\")]);\n///\n/// // It is fused iterator\n/// assert_eq!(values.next(), None);\n/// assert_eq!(values.next(), None);\n/// ```\npub struct Values<'a, K, V> {\n    inner: Iter<'a, K, V>,\n}",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::ValuesMut": [
            "/// A mutable iterator over the values of a `HashMap` in arbitrary order.\n/// The iterator element type is `&'a mut V`.\n///\n/// This `struct` is created by the [`values_mut`] method on [`HashMap`]. See its\n/// documentation for more.\n///\n/// [`values_mut`]: struct.HashMap.html#method.values_mut\n/// [`HashMap`]: struct.HashMap.html\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut map: HashMap<_, _> = [(1, \"One\".to_owned()), (2, \"Two\".into())].into();\n///\n/// let mut values = map.values_mut();\n/// values.next().map(|v| v.push_str(\" Mississippi\"));\n/// values.next().map(|v| v.push_str(\" Mississippi\"));\n///\n/// // It is fused iterator\n/// assert_eq!(values.next(), None);\n/// assert_eq!(values.next(), None);\n///\n/// assert_eq!(map.get(&1).unwrap(), &\"One Mississippi\".to_owned());\n/// assert_eq!(map.get(&2).unwrap(), &\"Two Mississippi\".to_owned());\n/// ```\npub struct ValuesMut<'a, K, V> {\n    inner: IterMut<'a, K, V>,\n}",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::assert_covariance": [
            "#[allow(dead_code)]\nfn assert_covariance(){\n    fn map_key<'new>(v: HashMap<&'static str, u8>) -> HashMap<&'new str, u8> {\n        v\n    }\n    fn map_val<'new>(v: HashMap<u8, &'static str>) -> HashMap<u8, &'new str> {\n        v\n    }\n    fn iter_key<'a, 'new>(v: Iter<'a, &'static str, u8>) -> Iter<'a, &'new str, u8> {\n        v\n    }\n    fn iter_val<'a, 'new>(v: Iter<'a, u8, &'static str>) -> Iter<'a, u8, &'new str> {\n        v\n    }\n    fn into_iter_key<'new, A: Allocator>(\n        v: IntoIter<&'static str, u8, A>,\n    ) -> IntoIter<&'new str, u8, A> {\n        v\n    }\n    fn into_iter_val<'new, A: Allocator>(\n        v: IntoIter<u8, &'static str, A>,\n    ) -> IntoIter<u8, &'new str, A> {\n        v\n    }\n    fn keys_key<'a, 'new>(v: Keys<'a, &'static str, u8>) -> Keys<'a, &'new str, u8> {\n        v\n    }\n    fn keys_val<'a, 'new>(v: Keys<'a, u8, &'static str>) -> Keys<'a, u8, &'new str> {\n        v\n    }\n    fn values_key<'a, 'new>(v: Values<'a, &'static str, u8>) -> Values<'a, &'new str, u8> {\n        v\n    }\n    fn values_val<'a, 'new>(v: Values<'a, u8, &'static str>) -> Values<'a, u8, &'new str> {\n        v\n    }\n    fn drain<'new>(\n        d: Drain<'static, &'static str, &'static str>,\n    ) -> Drain<'new, &'new str, &'new str> {\n        d\n    }\n}",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::assert_covariance::drain": [
            "fn drain<'new>(\n        d: Drain<'static, &'static str, &'static str>,\n    ) -> Drain<'new, &'new str, &'new str>{\n        d\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::assert_covariance::into_iter_key": [
            "fn into_iter_key<'new, A: Allocator>(\n        v: IntoIter<&'static str, u8, A>,\n    ) -> IntoIter<&'new str, u8, A>{\n        v\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::assert_covariance::into_iter_val": [
            "fn into_iter_val<'new, A: Allocator>(\n        v: IntoIter<u8, &'static str, A>,\n    ) -> IntoIter<u8, &'new str, A>{\n        v\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::assert_covariance::iter_key": [
            "fn iter_key<'a, 'new>(v: Iter<'a, &'static str, u8>) -> Iter<'a, &'new str, u8>{\n        v\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::assert_covariance::iter_val": [
            "fn iter_val<'a, 'new>(v: Iter<'a, u8, &'static str>) -> Iter<'a, u8, &'new str>{\n        v\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::assert_covariance::keys_key": [
            "fn keys_key<'a, 'new>(v: Keys<'a, &'static str, u8>) -> Keys<'a, &'new str, u8>{\n        v\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::assert_covariance::keys_val": [
            "fn keys_val<'a, 'new>(v: Keys<'a, u8, &'static str>) -> Keys<'a, u8, &'new str>{\n        v\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::assert_covariance::map_key": [
            "fn map_key<'new>(v: HashMap<&'static str, u8>) -> HashMap<&'new str, u8>{\n        v\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::assert_covariance::map_val": [
            "fn map_val<'new>(v: HashMap<u8, &'static str>) -> HashMap<u8, &'new str>{\n        v\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::assert_covariance::values_key": [
            "fn values_key<'a, 'new>(v: Values<'a, &'static str, u8>) -> Values<'a, &'new str, u8>{\n        v\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::assert_covariance::values_val": [
            "fn values_val<'a, 'new>(v: Values<'a, u8, &'static str>) -> Values<'a, u8, &'new str>{\n        v\n    }",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::equivalent": [
            "/// Ensures that a single closure type across uses of this which, in turn prevents multiple\n/// instances of any functions like `RawTable::reserve` from being generated\ninline\n#[allow(dead_code)]\npub(crate) fn equivalent<Q, K>(k: &Q) -> impl Fn(&K) -> bool + '_\nwhere\n    Q: Equivalent<K> + ?Sized,{\n    move |x| k.equivalent(x)\n}",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::equivalent_key": [
            "/// Ensures that a single closure type across uses of this which, in turn prevents multiple\n/// instances of any functions like `RawTable::reserve` from being generated\ninline\npub(crate) fn equivalent_key<Q, K, V>(k: &Q) -> impl Fn(&(K, V)) -> bool + '_\nwhere\n    Q: Equivalent<K> + ?Sized,{\n    move |x| k.equivalent(&x.0)\n}",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::make_hash": [
            "#[cfg(not(feature = \"nightly\"))]\ninline\npub(crate) fn make_hash<Q, S>(hash_builder: &S, val: &Q) -> u64\nwhere\n    Q: Hash + ?Sized,\n    S: BuildHasher,{\n    use core::hash::Hasher;\n    let mut state = hash_builder.build_hasher();\n    val.hash(&mut state);\n    state.finish()\n}",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "map::make_hasher": [
            "/// Ensures that a single closure type across uses of this which, in turn prevents multiple\n/// instances of any functions like `RawTable::reserve` from being generated\ninline\npub(crate) fn make_hasher<Q, V, S>(hash_builder: &S) -> impl Fn(&(Q, V)) -> u64 + '_\nwhere\n    Q: Hash,\n    S: BuildHasher,{\n    move |val| make_hash::<Q, S>(hash_builder, &val.0)\n}",
            "Real(LocalPath(\"src/map.rs\"))"
        ],
        "raw::Bucket": [
            "/// A reference to a hash table bucket containing a `T`.\n///\n/// This is usually just a pointer to the element itself. However if the element\n/// is a ZST, then we instead track the index of the element in the table so\n/// that `erase` works properly.\npub struct Bucket<T> {\n    // Actually it is pointer to next element than element itself\n    // this is needed to maintain pointer arithmetic invariants\n    // keeping direct pointer to element introduces difficulty.\n    // Using `NonNull` for variance and niche layout\n    ptr: NonNull<T>,\n}",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::Bucket::<T>::as_mut": [
            "/// Returns a unique mutable reference to the `value`.\n///\n/// # Safety\n///\n/// See [`NonNull::as_mut`] for safety concerns.\n///\n/// # Note\n///\n/// [`Hash`] and [`Eq`] on the new `T` value and its borrowed form *must* match\n/// those for the old `T` value, as the map will not re-evaluate where the new\n/// value should go, meaning the value may become \"lost\" if their location\n/// does not reflect their state.\n///\n/// [`NonNull::as_mut`]: https://doc.rust-lang.org/core/ptr/struct.NonNull.html#method.as_mut\n/// [`Hash`]: https://doc.rust-lang.org/core/hash/trait.Hash.html\n/// [`Eq`]: https://doc.rust-lang.org/core/cmp/trait.Eq.html\n#[inline]\npub unsafe fn as_mut<'a>(&self) -> &'a mut T{\n        &mut *self.as_ptr()\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::Bucket::<T>::as_non_null": [
            "/// Acquires the underlying non-null pointer `*mut T` to `data`.\n#[inline]\nfn as_non_null(&self) -> NonNull<T>{\n        // SAFETY: `self.ptr` is already a `NonNull`\n        unsafe { NonNull::new_unchecked(self.as_ptr()) }\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::Bucket::<T>::as_ptr": [
            "/// Acquires the underlying raw pointer `*mut T` to `data`.\n///\n/// # Note\n///\n/// If `T` is not [`Copy`], do not use `*mut T` methods that can cause calling the\n/// destructor of `T` (for example the [`<*mut T>::drop_in_place`] method), because\n/// for properly dropping the data we also need to clear `data` control bytes. If we\n/// drop data, but do not clear `data control byte` it leads to double drop when\n/// [`RawTable`] goes out of scope.\n///\n/// If you modify an already initialized `value`, so [`Hash`] and [`Eq`] on the new\n/// `T` value and its borrowed form *must* match those for the old `T` value, as the map\n/// will not re-evaluate where the new value should go, meaning the value may become\n/// \"lost\" if their location does not reflect their state.\n///\n/// [`RawTable`]: crate::raw::RawTable\n/// [`<*mut T>::drop_in_place`]: https://doc.rust-lang.org/core/primitive.pointer.html#method.drop_in_place\n/// [`Hash`]: https://doc.rust-lang.org/core/hash/trait.Hash.html\n/// [`Eq`]: https://doc.rust-lang.org/core/cmp/trait.Eq.html\n#[inline]\npub fn as_ptr(&self) -> *mut T{\n        if T::IS_ZERO_SIZED {\n            // Just return an arbitrary ZST pointer which is properly aligned\n            // invalid pointer is good enough for ZST\n            invalid_mut(mem::align_of::<T>())\n        } else {\n            unsafe { self.ptr.as_ptr().sub(1) }\n        }\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::Bucket::<T>::as_ref": [
            "/// Returns a shared immutable reference to the `value`.\n///\n/// # Safety\n///\n/// See [`NonNull::as_ref`] for safety concerns.\n///\n/// [`NonNull::as_ref`]: https://doc.rust-lang.org/core/ptr/struct.NonNull.html#method.as_ref\n#[inline]\npub unsafe fn as_ref<'a>(&self) -> &'a T{\n        &*self.as_ptr()\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::Bucket::<T>::drop": [
            "/// Executes the destructor (if any) of the pointed-to `data`.\n///\n/// # Safety\n///\n/// See [`ptr::drop_in_place`] for safety concerns.\n///\n/// You should use [`RawTable::erase`] instead of this function,\n/// or be careful with calling this function directly, because for\n/// properly dropping the data we need also clear `data` control bytes.\n/// If we drop data, but do not erase `data control byte` it leads to\n/// double drop when [`RawTable`] goes out of scope.\n///\n/// [`ptr::drop_in_place`]: https://doc.rust-lang.org/core/ptr/fn.drop_in_place.html\n/// [`RawTable`]: crate::raw::RawTable\n/// [`RawTable::erase`]: crate::raw::RawTable::erase\ninline\npub(crate) unsafe fn drop(&self){\n        self.as_ptr().drop_in_place();\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::Bucket::<T>::from_base_index": [
            "/// Creates a [`Bucket`] that contain pointer to the data.\n/// The pointer calculation is performed by calculating the\n/// offset from given `base` pointer (convenience for\n/// `base.as_ptr().sub(index)`).\n///\n/// `index` is in units of `T`; e.g., an `index` of 3 represents a pointer\n/// offset of `3 * size_of::<T>()` bytes.\n///\n/// If the `T` is a ZST, then we instead track the index of the element\n/// in the table so that `erase` works properly (return\n/// `NonNull::new_unchecked((index + 1) as *mut T)`)\n///\n/// # Safety\n///\n/// If `mem::size_of::<T>() != 0`, then the safety rules are directly derived\n/// from the safety rules for [`<*mut T>::sub`] method of `*mut T` and the safety\n/// rules of [`NonNull::new_unchecked`] function.\n///\n/// Thus, in order to uphold the safety contracts for the [`<*mut T>::sub`] method\n/// and [`NonNull::new_unchecked`] function, as well as for the correct\n/// logic of the work of this crate, the following rules are necessary and\n/// sufficient:\n///\n/// * the `base` pointer must not be `dangling` and must points to the\n///   end of the first `value element` from the `data part` of the table, i.e.\n///   must be the pointer that returned by [`RawTable::data_end`] or by\n///   [`RawTableInner::data_end<T>`];\n///\n/// * `index` must not be greater than `RawTableInner.bucket_mask`, i.e.\n///   `index <= RawTableInner.bucket_mask` or, in other words, `(index + 1)`\n///   must be no greater than the number returned by the function\n///   [`RawTable::buckets`] or [`RawTableInner::buckets`].\n///\n/// If `mem::size_of::<T>() == 0`, then the only requirement is that the\n/// `index` must not be greater than `RawTableInner.bucket_mask`, i.e.\n/// `index <= RawTableInner.bucket_mask` or, in other words, `(index + 1)`\n/// must be no greater than the number returned by the function\n/// [`RawTable::buckets`] or [`RawTableInner::buckets`].\n///\n/// [`Bucket`]: crate::raw::Bucket\n/// [`<*mut T>::sub`]: https://doc.rust-lang.org/core/primitive.pointer.html#method.sub-1\n/// [`NonNull::new_unchecked`]: https://doc.rust-lang.org/stable/std/ptr/struct.NonNull.html#method.new_unchecked\n/// [`RawTable::data_end`]: crate::raw::RawTable::data_end\n/// [`RawTableInner::data_end<T>`]: RawTableInner::data_end<T>\n/// [`RawTable::buckets`]: crate::raw::RawTable::buckets\n/// [`RawTableInner::buckets`]: RawTableInner::buckets\n#[inline]\nunsafe fn from_base_index(base: NonNull<T>, index: usize) -> Self{\n        // If mem::size_of::<T>() != 0 then return a pointer to an `element` in\n        // the data part of the table (we start counting from \"0\", so that\n        // in the expression T[last], the \"last\" index actually one less than the\n        // \"buckets\" number in the table, i.e. \"last = RawTableInner.bucket_mask\"):\n        //\n        //                   `from_base_index(base, 1).as_ptr()` returns a pointer that\n        //                   points here in the data part of the table\n        //                   (to the start of T1)\n        //                        |\n        //                        |        `base: NonNull<T>` must point here\n        //                        |         (to the end of T0 or to the start of C0)\n        //                        v         v\n        // [Padding], Tlast, ..., |T1|, T0, |C0, C1, ..., Clast\n        //                           ^\n        //                           `from_base_index(base, 1)` returns a pointer\n        //                           that points here in the data part of the table\n        //                           (to the end of T1)\n        //\n        // where: T0...Tlast - our stored data; C0...Clast - control bytes\n        // or metadata for data.\n        let ptr = if T::IS_ZERO_SIZED {\n            // won't overflow because index must be less than length (bucket_mask)\n            // and bucket_mask is guaranteed to be less than `isize::MAX`\n            // (see TableLayout::calculate_layout_for method)\n            invalid_mut(index + 1)\n        } else {\n            base.as_ptr().sub(index)\n        };\n        Self {\n            ptr: NonNull::new_unchecked(ptr),\n        }\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::Bucket::<T>::next_n": [
            "/// Create a new [`Bucket`] that is offset from the `self` by the given\n/// `offset`. The pointer calculation is performed by calculating the\n/// offset from `self` pointer (convenience for `self.ptr.as_ptr().sub(offset)`).\n/// This function is used for iterators.\n///\n/// `offset` is in units of `T`; e.g., a `offset` of 3 represents a pointer\n/// offset of `3 * size_of::<T>()` bytes.\n///\n/// # Safety\n///\n/// If `mem::size_of::<T>() != 0`, then the safety rules are directly derived\n/// from the safety rules for [`<*mut T>::sub`] method of `*mut T` and safety\n/// rules of [`NonNull::new_unchecked`] function.\n///\n/// Thus, in order to uphold the safety contracts for [`<*mut T>::sub`] method\n/// and [`NonNull::new_unchecked`] function, as well as for the correct\n/// logic of the work of this crate, the following rules are necessary and\n/// sufficient:\n///\n/// * `self` contained pointer must not be `dangling`;\n///\n/// * `self.to_base_index() + offset` must not be greater than `RawTableInner.bucket_mask`,\n///   i.e. `(self.to_base_index() + offset) <= RawTableInner.bucket_mask` or, in other\n///   words, `self.to_base_index() + offset + 1` must be no greater than the number returned\n///   by the function [`RawTable::buckets`] or [`RawTableInner::buckets`].\n///\n/// If `mem::size_of::<T>() == 0`, then the only requirement is that the\n/// `self.to_base_index() + offset` must not be greater than `RawTableInner.bucket_mask`,\n/// i.e. `(self.to_base_index() + offset) <= RawTableInner.bucket_mask` or, in other words,\n/// `self.to_base_index() + offset + 1` must be no greater than the number returned by the\n/// function [`RawTable::buckets`] or [`RawTableInner::buckets`].\n///\n/// [`Bucket`]: crate::raw::Bucket\n/// [`<*mut T>::sub`]: https://doc.rust-lang.org/core/primitive.pointer.html#method.sub-1\n/// [`NonNull::new_unchecked`]: https://doc.rust-lang.org/stable/std/ptr/struct.NonNull.html#method.new_unchecked\n/// [`RawTable::buckets`]: crate::raw::RawTable::buckets\n/// [`RawTableInner::buckets`]: RawTableInner::buckets\n#[inline]\nunsafe fn next_n(&self, offset: usize) -> Self{\n        let ptr = if T::IS_ZERO_SIZED {\n            // invalid pointer is good enough for ZST\n            invalid_mut(self.ptr.as_ptr() as usize + offset)\n        } else {\n            self.ptr.as_ptr().sub(offset)\n        };\n        Self {\n            ptr: NonNull::new_unchecked(ptr),\n        }\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::Bucket::<T>::read": [
            "/// Reads the `value` from `self` without moving it. This leaves the\n/// memory in `self` unchanged.\n///\n/// # Safety\n///\n/// See [`ptr::read`] for safety concerns.\n///\n/// You should use [`RawTable::remove`] instead of this function,\n/// or be careful with calling this function directly, because compiler\n/// calls its destructor when the read `value` goes out of scope. It\n/// can cause double dropping when [`RawTable`] goes out of scope,\n/// because of not erased `data control byte`.\n///\n/// [`ptr::read`]: https://doc.rust-lang.org/core/ptr/fn.read.html\n/// [`RawTable`]: crate::raw::RawTable\n/// [`RawTable::remove`]: crate::raw::RawTable::remove\n#[inline]\npub(crate) unsafe fn read(&self) -> T{\n        self.as_ptr().read()\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::Bucket::<T>::to_base_index": [
            "/// Calculates the index of a [`Bucket`] as distance between two pointers\n/// (convenience for `base.as_ptr().offset_from(self.ptr.as_ptr()) as usize`).\n/// The returned value is in units of T: the distance in bytes divided by\n/// [`core::mem::size_of::<T>()`].\n///\n/// If the `T` is a ZST, then we return the index of the element in\n/// the table so that `erase` works properly (return `self.ptr.as_ptr() as usize - 1`).\n///\n/// This function is the inverse of [`from_base_index`].\n///\n/// # Safety\n///\n/// If `mem::size_of::<T>() != 0`, then the safety rules are directly derived\n/// from the safety rules for [`<*const T>::offset_from`] method of `*const T`.\n///\n/// Thus, in order to uphold the safety contracts for [`<*const T>::offset_from`]\n/// method, as well as for the correct logic of the work of this crate, the\n/// following rules are necessary and sufficient:\n///\n/// * `base` contained pointer must not be `dangling` and must point to the\n///   end of the first `element` from the `data part` of the table, i.e.\n///   must be a pointer that returns by [`RawTable::data_end`] or by\n///   [`RawTableInner::data_end<T>`];\n///\n/// * `self` also must not contain dangling pointer;\n///\n/// * both `self` and `base` must be created from the same [`RawTable`]\n///   (or [`RawTableInner`]).\n///\n/// If `mem::size_of::<T>() == 0`, this function is always safe.\n///\n/// [`Bucket`]: crate::raw::Bucket\n/// [`from_base_index`]: crate::raw::Bucket::from_base_index\n/// [`RawTable::data_end`]: crate::raw::RawTable::data_end\n/// [`RawTableInner::data_end<T>`]: RawTableInner::data_end<T>\n/// [`RawTable`]: crate::raw::RawTable\n/// [`RawTableInner`]: RawTableInner\n/// [`<*const T>::offset_from`]: https://doc.rust-lang.org/nightly/core/primitive.pointer.html#method.offset_from\n#[inline]\nunsafe fn to_base_index(&self, base: NonNull<T>) -> usize{\n        // If mem::size_of::<T>() != 0 then return an index under which we used to store the\n        // `element` in the data part of the table (we start counting from \"0\", so\n        // that in the expression T[last], the \"last\" index actually is one less than the\n        // \"buckets\" number in the table, i.e. \"last = RawTableInner.bucket_mask\").\n        // For example for 5th element in table calculation is performed like this:\n        //\n        //                        mem::size_of::<T>()\n        //                          |\n        //                          |         `self = from_base_index(base, 5)` that returns pointer\n        //                          |         that points here in the data part of the table\n        //                          |         (to the end of T5)\n        //                          |           |                    `base: NonNull<T>` must point here\n        //                          v           |                    (to the end of T0 or to the start of C0)\n        //                        /???\\         v                      v\n        // [Padding], Tlast, ..., |T10|, ..., T5|, T4, T3, T2, T1, T0, |C0, C1, C2, C3, C4, C5, ..., C10, ..., Clast\n        //                                      \\__________  __________/\n        //                                                 \\/\n        //                                     `bucket.to_base_index(base)` = 5\n        //                                     (base.as_ptr() as usize - self.ptr.as_ptr() as usize) / mem::size_of::<T>()\n        //\n        // where: T0...Tlast - our stored data; C0...Clast - control bytes or metadata for data.\n        if T::IS_ZERO_SIZED {\n            // this can not be UB\n            self.ptr.as_ptr() as usize - 1\n        } else {\n            offset_from(base.as_ptr(), self.ptr.as_ptr())\n        }\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::Bucket::<T>::write": [
            "/// Overwrites a memory location with the given `value` without reading\n/// or dropping the old value (like [`ptr::write`] function).\n///\n/// # Safety\n///\n/// See [`ptr::write`] for safety concerns.\n///\n/// # Note\n///\n/// [`Hash`] and [`Eq`] on the new `T` value and its borrowed form *must* match\n/// those for the old `T` value, as the map will not re-evaluate where the new\n/// value should go, meaning the value may become \"lost\" if their location\n/// does not reflect their state.\n///\n/// [`ptr::write`]: https://doc.rust-lang.org/core/ptr/fn.write.html\n/// [`Hash`]: https://doc.rust-lang.org/core/hash/trait.Hash.html\n/// [`Eq`]: https://doc.rust-lang.org/core/cmp/trait.Eq.html\n#[inline]\npub(crate) unsafe fn write(&self, val: T){\n        self.as_ptr().write(val);\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::Fallibility": [
            "/// Whether memory allocation errors should return an error or abort.\nenum Fallibility {\n    Fallible,\n    Infallible,\n}",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::Fallibility::alloc_err": [
            "/// Error to return on allocation error.\ninline\nfn alloc_err(self, layout: Layout) -> TryReserveError{\n        match self {\n            Fallibility::Fallible => TryReserveError::AllocError { layout },\n            Fallibility::Infallible => handle_alloc_error(layout),\n        }\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::Fallibility::capacity_overflow": [
            "/// Error to return on capacity overflow.\ninline\nfn capacity_overflow(self) -> TryReserveError{\n        match self {\n            Fallibility::Fallible => TryReserveError::CapacityOverflow,\n            Fallibility::Infallible => panic!(\"Hash table capacity overflow\"),\n        }\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::FullBucketsIndices": [
            "/// Iterator which returns an index of every full bucket in the table.\n///\n/// For maximum flexibility this iterator is not bound by a lifetime, but you\n/// must observe several rules when using it:\n/// - You must not free the hash table while iterating (including via growing/shrinking).\n/// - It is fine to erase a bucket that has been yielded by the iterator.\n/// - Erasing a bucket that has not yet been yielded by the iterator may still\n///   result in the iterator yielding index of that bucket.\n/// - It is unspecified whether an element inserted after the iterator was\n///   created will be yielded by that iterator.\n/// - The order in which the iterator yields indices of the buckets is unspecified\n///   and may change in the future.\npub(crate) struct FullBucketsIndices {\n    // Mask of full buckets in the current group. Bits are cleared from this\n    // mask as each element is processed.\n    current_group: BitMaskIter,\n\n    // Initial value of the bytes' indices of the current group (relative\n    // to the start of the control bytes).\n    group_first_index: usize,\n\n    // Pointer to the current group of control bytes,\n    // Must be aligned to the group size (Group::WIDTH).\n    ctrl: NonNull<u8>,\n\n    // Number of elements in the table.\n    items: usize,\n}",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::FullBucketsIndices::next_impl": [
            "/// Advances the iterator and returns the next value.\n///\n/// # Safety\n///\n/// If any of the following conditions are violated, the result is\n/// [`Undefined Behavior`]:\n///\n/// * The [`RawTableInner`] / [`RawTable`] must be alive and not moved,\n///   i.e. table outlives the `FullBucketsIndices`;\n///\n/// * It never tries to iterate after getting all elements.\n///\n/// [`Undefined Behavior`]: https://doc.rust-lang.org/reference/behavior-considered-undefined.html\n#[inline(always)]\nunsafe fn next_impl(&mut self) -> Option<usize>{\n        loop {\n            if let Some(index) = self.current_group.next() {\n                // The returned `self.group_first_index + index` will always\n                // be in the range `0..self.buckets()`. See explanation below.\n                return Some(self.group_first_index + index);\n            }\n\n            // SAFETY: The caller of this function ensures that:\n            //\n            // 1. It never tries to iterate after getting all the elements;\n            // 2. The table is alive and did not moved;\n            // 3. The first `self.ctrl` pointed to the start of the array of control bytes.\n            //\n            // Taking the above into account, we always stay within the bounds, because:\n            //\n            // 1. For tables smaller than the group width (self.buckets() <= Group::WIDTH),\n            //    we will never end up in the given branch, since we should have already\n            //    yielded all the elements of the table.\n            //\n            // 2. For tables larger than the group width. The number of buckets is a\n            //    power of two (2 ^ n), Group::WIDTH is also power of two (2 ^ k). Since\n            //    `(2 ^ n) > (2 ^ k)`, than `(2 ^ n) % (2 ^ k) = 0`. As we start from the\n            //    the start of the array of control bytes, and never try to iterate after\n            //    getting all the elements, the last `self.ctrl` will be equal to\n            //    the `self.buckets() - Group::WIDTH`, so `self.current_group.next()`\n            //    will always contains indices within the range `0..Group::WIDTH`,\n            //    and subsequent `self.group_first_index + index` will always return a\n            //    number less than `self.buckets()`.\n            self.ctrl = NonNull::new_unchecked(self.ctrl.as_ptr().add(Group::WIDTH));\n\n            // SAFETY: See explanation above.\n            self.current_group = Group::load_aligned(self.ctrl.as_ptr().cast())\n                .match_full()\n                .into_iter();\n            self.group_first_index += Group::WIDTH;\n        }\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::InsertSlot": [
            "/// A reference to an empty bucket into which an can be inserted.\npub struct InsertSlot {\n    index: usize,\n}",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::ProbeSeq": [
            "/// Probe sequence based on triangular numbers, which is guaranteed (since our\n/// table size is a power of two) to visit every group of elements exactly once.\n///\n/// A triangular probe has us jump by 1 more group every time. So first we\n/// jump by 1 group (meaning we just continue our linear scan), then 2 groups\n/// (skipping over 1 group), then 3 groups (skipping over 2 groups), and so on.\n///\n/// Proof that the probe will visit every group in the table:\n/// <https://fgiesen.wordpress.com/2015/02/22/triangular-numbers-mod-2n/>\nstruct ProbeSeq {\n    pos: usize,\n    stride: usize,\n}",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::ProbeSeq::move_next": [
            "#[inline]\nfn move_next(&mut self, bucket_mask: usize){\n        // We should have found an empty bucket by now and ended the probe.\n        debug_assert!(\n            self.stride <= bucket_mask,\n            \"Went past end of probe sequence\"\n        );\n\n        self.stride += Group::WIDTH;\n        self.pos += self.stride;\n        self.pos &= bucket_mask;\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawDrain": [
            "/// Iterator which consumes elements without freeing the table storage.\npub struct RawDrain<'a, T, A: Allocator = Global> {\n    iter: RawIter<T>,\n\n    // The table is moved into the iterator for the duration of the drain. This\n    // ensures that an empty table is left if the drain iterator is leaked\n    // without dropping.\n    table: RawTableInner,\n    orig_table: NonNull<RawTableInner>,\n\n    // We don't use a &'a mut RawTable<T> because we want RawDrain to be\n    // covariant over T.\n    marker: PhantomData<&'a RawTable<T, A>>,\n}",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawDrain::<'_, T, A>::iter": [
            "inline\npub fn iter(&self) -> RawIter<T>{\n        self.iter.clone()\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawExtractIf": [
            "pub(crate) struct RawExtractIf<'a, T, A: Allocator> {\n    pub iter: RawIter<T>,\n    pub table: &'a mut RawTable<T, A>,\n}",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawExtractIf::<'_, T, A>::next": [
            "inline\npub(crate) fn next<F>(&mut self, mut f: F) -> Option<T>\n    where\n        F: FnMut(&mut T) -> bool,{\n        unsafe {\n            for item in &mut self.iter {\n                if f(item.as_mut()) {\n                    return Some(self.table.remove(item).0);\n                }\n            }\n        }\n        None\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawIntoIter": [
            "/// Iterator which consumes a table and returns elements.\npub struct RawIntoIter<T, A: Allocator = Global> {\n    iter: RawIter<T>,\n    allocation: Option<(NonNull<u8>, Layout, A)>,\n    marker: PhantomData<T>,\n}",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawIntoIter::<T, A>::iter": [
            "inline\npub fn iter(&self) -> RawIter<T>{\n        self.iter.clone()\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawIter": [
            "/// Iterator which returns a raw pointer to every full bucket in the table.\n///\n/// For maximum flexibility this iterator is not bound by a lifetime, but you\n/// must observe several rules when using it:\n/// - You must not free the hash table while iterating (including via growing/shrinking).\n/// - It is fine to erase a bucket that has been yielded by the iterator.\n/// - Erasing a bucket that has not yet been yielded by the iterator may still\n///   result in the iterator yielding that bucket (unless `reflect_remove` is called).\n/// - It is unspecified whether an element inserted after the iterator was\n///   created will be yielded by that iterator (unless `reflect_insert` is called).\n/// - The order in which the iterator yields bucket is unspecified and may\n///   change in the future.\npub struct RawIter<T> {\n    pub(crate) iter: RawIterRange<T>,\n    items: usize,\n}",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawIter::<T>::drop_elements": [
            "unsafe fn drop_elements(&mut self){\n        if T::NEEDS_DROP && self.items != 0 {\n            for item in self {\n                item.drop();\n            }\n        }\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawIterHash": [
            "/// Iterator over occupied buckets that could match a given hash.\n///\n/// `RawTable` only stores 7 bits of the hash value, so this iterator may return\n/// items that have a hash value different than the one provided. You should\n/// always validate the returned values before using them.\n///\n/// For maximum flexibility this iterator is not bound by a lifetime, but you\n/// must observe several rules when using it:\n/// - You must not free the hash table while iterating (including via growing/shrinking).\n/// - It is fine to erase a bucket that has been yielded by the iterator.\n/// - Erasing a bucket that has not yet been yielded by the iterator may still\n///   result in the iterator yielding that bucket.\n/// - It is unspecified whether an element inserted after the iterator was\n///   created will be yielded by that iterator.\n/// - The order in which the iterator yields buckets is unspecified and may\n///   change in the future.\npub struct RawIterHash<T> {\n    inner: RawIterHashInner,\n    _marker: PhantomData<T>,\n}",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawIterHash::<T>::new": [
            "inline\nunsafe fn new<A: Allocator>(table: &RawTable<T, A>, hash: u64) -> Self{\n        RawIterHash {\n            inner: RawIterHashInner::new(&table.table, hash),\n            _marker: PhantomData,\n        }\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawIterHashInner": [
            "struct RawIterHashInner {\n    // See `RawTableInner`'s corresponding fields for details.\n    // We can't store a `*const RawTableInner` as it would get\n    // invalidated by the user calling `&mut` methods on `RawTable`.\n    bucket_mask: usize,\n    ctrl: NonNull<u8>,\n\n    // The top 7 bits of the hash.\n    tag_hash: Tag,\n\n    // The sequence of groups to probe in the search.\n    probe_seq: ProbeSeq,\n\n    group: Group,\n\n    // The elements within the group with a matching tag-hash.\n    bitmask: BitMaskIter,\n}",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawIterHashInner::new": [
            "inline\nunsafe fn new(table: &RawTableInner, hash: u64) -> Self{\n        let tag_hash = Tag::full(hash);\n        let probe_seq = table.probe_seq(hash);\n        let group = Group::load(table.ctrl(probe_seq.pos));\n        let bitmask = group.match_tag(tag_hash).into_iter();\n\n        RawIterHashInner {\n            bucket_mask: table.bucket_mask,\n            ctrl: table.ctrl,\n            tag_hash,\n            probe_seq,\n            group,\n            bitmask,\n        }\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawIterRange": [
            "/// Iterator over a sub-range of a table. Unlike `RawIter` this iterator does\n/// not track an item count.\npub(crate) struct RawIterRange<T> {\n    // Mask of full buckets in the current group. Bits are cleared from this\n    // mask as each element is processed.\n    current_group: BitMaskIter,\n\n    // Pointer to the buckets for the current group.\n    data: Bucket<T>,\n\n    // Pointer to the next group of control bytes,\n    // Must be aligned to the group size.\n    next_ctrl: *const u8,\n\n    // Pointer one past the last control byte of this range.\n    end: *const u8,\n}",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawIterRange::<T>::fold_impl": [
            "/// Folds every element into an accumulator by applying an operation,\n/// returning the final result.\n///\n/// `fold_impl()` takes three arguments: the number of items remaining in\n/// the iterator, an initial value, and a closure with two arguments: an\n/// 'accumulator', and an element. The closure returns the value that the\n/// accumulator should have for the next iteration.\n///\n/// The initial value is the value the accumulator will have on the first call.\n///\n/// After applying this closure to every element of the iterator, `fold_impl()`\n/// returns the accumulator.\n///\n/// # Safety\n///\n/// If any of the following conditions are violated, the result is\n/// [`Undefined Behavior`]:\n///\n/// * The [`RawTableInner`] / [`RawTable`] must be alive and not moved,\n///   i.e. table outlives the `RawIterRange`;\n///\n/// * The provided `n` value must match the actual number of items\n///   in the table.\n///\n/// [`Undefined Behavior`]: https://doc.rust-lang.org/reference/behavior-considered-undefined.html\n#[allow(clippy::while_let_on_iterator)]\ninline\nunsafe fn fold_impl<F, B>(mut self, mut n: usize, mut acc: B, mut f: F) -> B\n    where\n        F: FnMut(B, Bucket<T>) -> B,{\n        loop {\n            while let Some(index) = self.current_group.next() {\n                // The returned `index` will always be in the range `0..Group::WIDTH`,\n                // so that calling `self.data.next_n(index)` is safe (see detailed explanation below).\n                debug_assert!(n != 0);\n                let bucket = self.data.next_n(index);\n                acc = f(acc, bucket);\n                n -= 1;\n            }\n\n            if n == 0 {\n                return acc;\n            }\n\n            // SAFETY: The caller of this function ensures that:\n            //\n            // 1. The provided `n` value matches the actual number of items in the table;\n            // 2. The table is alive and did not moved.\n            //\n            // Taking the above into account, we always stay within the bounds, because:\n            //\n            // 1. For tables smaller than the group width (self.buckets() <= Group::WIDTH),\n            //    we will never end up in the given branch, since we should have already\n            //    yielded all the elements of the table.\n            //\n            // 2. For tables larger than the group width. The number of buckets is a\n            //    power of two (2 ^ n), Group::WIDTH is also power of two (2 ^ k). Since\n            //    `(2 ^ n) > (2 ^ k)`, than `(2 ^ n) % (2 ^ k) = 0`. As we start from the\n            //    start of the array of control bytes, and never try to iterate after\n            //    getting all the elements, the last `self.current_group` will read bytes\n            //    from the `self.buckets() - Group::WIDTH` index.  We know also that\n            //    `self.current_group.next()` will always return indices within the range\n            //    `0..Group::WIDTH`.\n            //\n            //    Knowing all of the above and taking into account that we are synchronizing\n            //    the `self.data` index with the index we used to read the `self.current_group`,\n            //    the subsequent `self.data.next_n(index)` will always return a bucket with\n            //    an index number less than `self.buckets()`.\n            //\n            //    The last `self.next_ctrl`, whose index would be `self.buckets()`, will never\n            //    actually be read, since we should have already yielded all the elements of\n            //    the table.\n            self.current_group = Group::load_aligned(self.next_ctrl.cast())\n                .match_full()\n                .into_iter();\n            self.data = self.data.next_n(Group::WIDTH);\n            self.next_ctrl = self.next_ctrl.add(Group::WIDTH);\n        }\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawIterRange::<T>::new": [
            "/// Returns a `RawIterRange` covering a subset of a table.\n///\n/// # Safety\n///\n/// If any of the following conditions are violated, the result is\n/// [`undefined behavior`]:\n///\n/// * `ctrl` must be [valid] for reads, i.e. table outlives the `RawIterRange`;\n///\n/// * `ctrl` must be properly aligned to the group size (`Group::WIDTH`);\n///\n/// * `ctrl` must point to the array of properly initialized control bytes;\n///\n/// * `data` must be the [`Bucket`] at the `ctrl` index in the table;\n///\n/// * the value of `len` must be less than or equal to the number of table buckets,\n///   and the returned value of `ctrl.as_ptr().add(len).offset_from(ctrl.as_ptr())`\n///   must be positive.\n///\n/// * The `ctrl.add(len)` pointer must be either in bounds or one\n///   byte past the end of the same [allocated table].\n///\n/// * The `len` must be a power of two.\n///\n/// [valid]: https://doc.rust-lang.org/std/ptr/index.html#safety\n/// [`undefined behavior`]: https://doc.rust-lang.org/reference/behavior-considered-undefined.html\ninline\nunsafe fn new(ctrl: *const u8, data: Bucket<T>, len: usize) -> Self{\n        debug_assert_ne!(len, 0);\n        debug_assert_eq!(ctrl as usize % Group::WIDTH, 0);\n        // SAFETY: The caller must uphold the safety rules for the [`RawIterRange::new`]\n        let end = ctrl.add(len);\n\n        // Load the first group and advance ctrl to point to the next group\n        // SAFETY: The caller must uphold the safety rules for the [`RawIterRange::new`]\n        let current_group = Group::load_aligned(ctrl.cast()).match_full();\n        let next_ctrl = ctrl.add(Group::WIDTH);\n\n        Self {\n            current_group: current_group.into_iter(),\n            data,\n            next_ctrl,\n            end,\n        }\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawIterRange::<T>::next_impl": [
            "/// # Safety\n/// If `DO_CHECK_PTR_RANGE` is false, caller must ensure that we never try to iterate\n/// after yielding all elements.\ninline\nunsafe fn next_impl<const DO_CHECK_PTR_RANGE: bool>(&mut self) -> Option<Bucket<T>>{\n        loop {\n            if let Some(index) = self.current_group.next() {\n                return Some(self.data.next_n(index));\n            }\n\n            if DO_CHECK_PTR_RANGE && self.next_ctrl >= self.end {\n                return None;\n            }\n\n            // We might read past self.end up to the next group boundary,\n            // but this is fine because it only occurs on tables smaller\n            // than the group size where the trailing control bytes are all\n            // EMPTY. On larger tables self.end is guaranteed to be aligned\n            // to the group size (since tables are power-of-two sized).\n            self.current_group = Group::load_aligned(self.next_ctrl.cast())\n                .match_full()\n                .into_iter();\n            self.data = self.data.next_n(Group::WIDTH);\n            self.next_ctrl = self.next_ctrl.add(Group::WIDTH);\n        }\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTable": [
            "/// A raw hash table with an unsafe API.\npub struct RawTable<T, A: Allocator = Global> {\n    table: RawTableInner,\n    alloc: A,\n    // Tell dropck that we own instances of T.\n    marker: PhantomData<T>,\n}",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTable::<T, A>::allocation_size": [
            "/// Returns the total amount of memory allocated internally by the hash\n/// table, in bytes.\n///\n/// The returned number is informational only. It is intended to be\n/// primarily used for memory profiling.\n#[inline]\npub fn allocation_size(&self) -> usize{\n        // SAFETY: We use the same `table_layout` that was used to allocate\n        // this table.\n        unsafe { self.table.allocation_size_or_zero(Self::TABLE_LAYOUT) }\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTable::<T, A>::allocator": [
            "/// Returns a reference to the underlying allocator.\n#[inline]\npub fn allocator(&self) -> &A{\n        &self.alloc\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTable::<T, A>::bucket": [
            "/// Returns a pointer to an element in the table.\n///\n/// The caller must ensure that the `RawTable` outlives the returned [`Bucket<T>`],\n/// otherwise using it may result in [`undefined behavior`].\n///\n/// # Safety\n///\n/// If `mem::size_of::<T>() != 0`, then the caller of this function must observe the\n/// following safety rules:\n///\n/// * The table must already be allocated;\n///\n/// * The `index` must not be greater than the number returned by the [`RawTable::buckets`]\n///   function, i.e. `(index + 1) <= self.buckets()`.\n///\n/// It is safe to call this function with index of zero (`index == 0`) on a table that has\n/// not been allocated, but using the returned [`Bucket`] results in [`undefined behavior`].\n///\n/// If `mem::size_of::<T>() == 0`, then the only requirement is that the `index` must\n/// not be greater than the number returned by the [`RawTable::buckets`] function, i.e.\n/// `(index + 1) <= self.buckets()`.\n///\n/// [`RawTable::buckets`]: RawTable::buckets\n/// [`undefined behavior`]: https://doc.rust-lang.org/reference/behavior-considered-undefined.html\n#[inline]\npub unsafe fn bucket(&self, index: usize) -> Bucket<T>{\n        // If mem::size_of::<T>() != 0 then return a pointer to the `element` in the `data part` of the table\n        // (we start counting from \"0\", so that in the expression T[n], the \"n\" index actually one less than\n        // the \"buckets\" number of our `RawTable`, i.e. \"n = RawTable::buckets() - 1\"):\n        //\n        //           `table.bucket(3).as_ptr()` returns a pointer that points here in the `data`\n        //           part of the `RawTable`, i.e. to the start of T3 (see `Bucket::as_ptr`)\n        //                  |\n        //                  |               `base = self.data_end()` points here\n        //                  |               (to the start of CT0 or to the end of T0)\n        //                  v                 v\n        // [Pad], T_n, ..., |T3|, T2, T1, T0, |CT0, CT1, CT2, CT3, ..., CT_n, CTa_0, CTa_1, ..., CTa_m\n        //                     ^                                              \\__________  __________/\n        //        `table.bucket(3)` returns a pointer that points                        \\/\n        //         here in the `data` part of the `RawTable` (to              additional control bytes\n        //         the end of T3)                                              `m = Group::WIDTH - 1`\n        //\n        // where: T0...T_n  - our stored data;\n        //        CT0...CT_n - control bytes or metadata for `data`;\n        //        CTa_0...CTa_m - additional control bytes (so that the search with loading `Group` bytes from\n        //                        the heap works properly, even if the result of `h1(hash) & self.table.bucket_mask`\n        //                        is equal to `self.table.bucket_mask`). See also `RawTableInner::set_ctrl` function.\n        //\n        // P.S. `h1(hash) & self.table.bucket_mask` is the same as `hash as usize % self.buckets()` because the number\n        // of buckets is a power of two, and `self.table.bucket_mask = self.buckets() - 1`.\n        debug_assert_ne!(self.table.bucket_mask, 0);\n        debug_assert!(index < self.buckets());\n        Bucket::from_base_index(self.data_end(), index)\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTable::<T, A>::bucket_index": [
            "/// Returns the index of a bucket from a `Bucket`.\n#[inline]\npub unsafe fn bucket_index(&self, bucket: &Bucket<T>) -> usize{\n        bucket.to_base_index(self.data_end())\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTable::<T, A>::buckets": [
            "/// Returns the number of buckets in the table.\n#[inline]\npub fn buckets(&self) -> usize{\n        self.table.bucket_mask + 1\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTable::<T, A>::capacity": [
            "/// Returns the number of elements the map can hold without reallocating.\n///\n/// This number is a lower bound; the table might be able to hold\n/// more, but is guaranteed to be able to hold at least this many.\n#[inline]\npub fn capacity(&self) -> usize{\n        self.table.items + self.table.growth_left\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTable::<T, A>::clear": [
            "/// Removes all elements from the table without freeing the backing memory.\ninline\npub fn clear(&mut self){\n        if self.is_empty() {\n            // Special case empty table to avoid surprising O(capacity) time.\n            return;\n        }\n        // Ensure that the table is reset even if one of the drops panic\n        let mut self_ = guard(self, |self_| self_.clear_no_drop());\n        unsafe {\n            // SAFETY: ScopeGuard sets to zero the `items` field of the table\n            // even in case of panic during the dropping of the elements so\n            // that there will be no double drop of the elements.\n            self_.table.drop_elements::<T>();\n        }\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTable::<T, A>::clear_no_drop": [
            "/// Marks all table buckets as empty without dropping their contents.\ninline\npub fn clear_no_drop(&mut self){\n        self.table.clear_no_drop();\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTable::<T, A>::clone_from_impl": [
            "/// Common code for `clone` and `clone_from`. Assumes:\n/// - `self.buckets() == source.buckets()`.\n/// - Any existing elements have been dropped.\n/// - The control bytes are not initialized yet.\ninline\nunsafe fn clone_from_impl(&mut self, source: &Self){\n        // Copy the control bytes unchanged. We do this in a single pass\n        source\n            .table\n            .ctrl(0)\n            .copy_to_nonoverlapping(self.table.ctrl(0), self.table.num_ctrl_bytes());\n\n        // The cloning of elements may panic, in which case we need\n        // to make sure we drop only the elements that have been\n        // cloned so far.\n        let mut guard = guard((0, &mut *self), |(index, self_)| {\n            if T::NEEDS_DROP {\n                for i in 0..*index {\n                    if self_.is_bucket_full(i) {\n                        self_.bucket(i).drop();\n                    }\n                }\n            }\n        });\n\n        for from in source.iter() {\n            let index = source.bucket_index(&from);\n            let to = guard.1.bucket(index);\n            to.write(from.as_ref().clone());\n\n            // Update the index in case we need to unwind.\n            guard.0 = index + 1;\n        }\n\n        // Successfully cloned all items, no need to clean up.\n        mem::forget(guard);\n\n        self.table.items = source.table.items;\n        self.table.growth_left = source.table.growth_left;\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTable::<T, A>::data_end": [
            "/// Returns pointer to one past last `data` element in the table as viewed from\n/// the start point of the allocation.\n///\n/// The caller must ensure that the `RawTable` outlives the returned [`NonNull<T>`],\n/// otherwise using it may result in [`undefined behavior`].\n///\n/// [`undefined behavior`]: https://doc.rust-lang.org/reference/behavior-considered-undefined.html\n#[inline]\npub fn data_end(&self) -> NonNull<T>{\n        //                        `self.table.ctrl.cast()` returns pointer that\n        //                        points here (to the end of `T0`)\n        //                          \n        // [Pad], T_n, ..., T1, T0, |CT0, CT1, ..., CT_n|, CTa_0, CTa_1, ..., CTa_m\n        //                           \\________  ________/\n        //                                    \\/\n        //       `n = buckets - 1`, i.e. `RawTable::buckets() - 1`\n        //\n        // where: T0...T_n  - our stored data;\n        //        CT0...CT_n - control bytes or metadata for `data`.\n        //        CTa_0...CTa_m - additional control bytes, where `m = Group::WIDTH - 1` (so that the search\n        //                        with loading `Group` bytes from the heap works properly, even if the result\n        //                        of `h1(hash) & self.bucket_mask` is equal to `self.bucket_mask`). See also\n        //                        `RawTableInner::set_ctrl` function.\n        //\n        // P.S. `h1(hash) & self.bucket_mask` is the same as `hash as usize % self.buckets()` because the number\n        // of buckets is a power of two, and `self.bucket_mask = self.buckets() - 1`.\n        self.table.ctrl.cast()\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTable::<T, A>::drain": [
            "/// Returns an iterator which removes all elements from the table without\n/// freeing the memory.\ninline\npub fn drain(&mut self) -> RawDrain<'_, T, A>{\n        unsafe {\n            let iter = self.iter();\n            self.drain_iter_from(iter)\n        }\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTable::<T, A>::drain_iter_from": [
            "/// Returns an iterator which removes all elements from the table without\n/// freeing the memory.\n///\n/// Iteration starts at the provided iterator's current location.\n///\n/// It is up to the caller to ensure that the iterator is valid for this\n/// `RawTable` and covers all items that remain in the table.\ninline\npub unsafe fn drain_iter_from(&mut self, iter: RawIter<T>) -> RawDrain<'_, T, A>{\n        debug_assert_eq!(iter.len(), self.len());\n        RawDrain {\n            iter,\n            table: mem::replace(&mut self.table, RawTableInner::NEW),\n            orig_table: NonNull::from(&mut self.table),\n            marker: PhantomData,\n        }\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTable::<T, A>::erase": [
            "/// Erases an element from the table, dropping it in place.\ninline\n#[allow(clippy::needless_pass_by_value)]\npub unsafe fn erase(&mut self, item: Bucket<T>){\n        // Erase the element from the table first since drop might panic.\n        self.erase_no_drop(&item);\n        item.drop();\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTable::<T, A>::erase_no_drop": [
            "/// Erases an element from the table without dropping it.\ninline\nunsafe fn erase_no_drop(&mut self, item: &Bucket<T>){\n        let index = self.bucket_index(item);\n        self.table.erase(index);\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTable::<T, A>::find": [
            "/// Searches for an element in the table.\n#[inline]\npub fn find(&self, hash: u64, mut eq: impl FnMut(&T) -> bool) -> Option<Bucket<T>>{\n        unsafe {\n            // SAFETY:\n            // 1. The [`RawTableInner`] must already have properly initialized control bytes since we\n            //    will never expose `RawTable::new_uninitialized` in a public API.\n            // 1. The `find_inner` function returns the `index` of only the full bucket, which is in\n            //    the range `0..self.buckets()`, so calling `self.bucket(index)` and `Bucket::as_ref`\n            //    is safe.\n            let result = self\n                .table\n                .find_inner(hash, &mut |index| eq(self.bucket(index).as_ref()));\n\n            // Avoid `Option::map` because it bloats LLVM IR.\n            match result {\n                // SAFETY: See explanation above.\n                Some(index) => Some(self.bucket(index)),\n                None => None,\n            }\n        }\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTable::<T, A>::find_or_find_insert_slot": [
            "/// Searches for an element in the table. If the element is not found,\n/// returns `Err` with the position of a slot where an element with the\n/// same hash could be inserted.\n///\n/// This function may resize the table if additional space is required for\n/// inserting an element.\n#[inline]\npub fn find_or_find_insert_slot(\n        &mut self,\n        hash: u64,\n        mut eq: impl FnMut(&T) -> bool,\n        hasher: impl Fn(&T) -> u64,\n    ) -> Result<Bucket<T>, InsertSlot>{\n        self.reserve(1, hasher);\n\n        unsafe {\n            // SAFETY:\n            // 1. We know for sure that there is at least one empty `bucket` in the table.\n            // 2. The [`RawTableInner`] must already have properly initialized control bytes since we will\n            //    never expose `RawTable::new_uninitialized` in a public API.\n            // 3. The `find_or_find_insert_slot_inner` function returns the `index` of only the full bucket,\n            //    which is in the range `0..self.buckets()` (since there is at least one empty `bucket` in\n            //    the table), so calling `self.bucket(index)` and `Bucket::as_ref` is safe.\n            match self\n                .table\n                .find_or_find_insert_slot_inner(hash, &mut |index| eq(self.bucket(index).as_ref()))\n            {\n                // SAFETY: See explanation above.\n                Ok(index) => Ok(self.bucket(index)),\n                Err(slot) => Err(slot),\n            }\n        }\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTable::<T, A>::get": [
            "/// Gets a reference to an element in the table.\n#[inline]\npub fn get(&self, hash: u64, eq: impl FnMut(&T) -> bool) -> Option<&T>{\n        // Avoid `Option::map` because it bloats LLVM IR.\n        match self.find(hash, eq) {\n            Some(bucket) => Some(unsafe { bucket.as_ref() }),\n            None => None,\n        }\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTable::<T, A>::get_many_mut": [
            "/// Attempts to get mutable references to `N` entries in the table at once.\n///\n/// Returns an array of length `N` with the results of each query.\n///\n/// At most one mutable reference will be returned to any entry. `None` will be returned if any\n/// of the hashes are duplicates. `None` will be returned if the hash is not found.\n///\n/// The `eq` argument should be a closure such that `eq(i, k)` returns true if `k` is equal to\n/// the `i`th key to be looked up.\npub fn get_many_mut<const N: usize>(\n        &mut self,\n        hashes: [u64; N],\n        eq: impl FnMut(usize, &T) -> bool,\n    ) -> [Option<&'_ mut T>; N]{\n        unsafe {\n            let ptrs = self.get_many_mut_pointers(hashes, eq);\n\n            for (i, cur) in ptrs.iter().enumerate() {\n                if cur.is_some() && ptrs[..i].contains(cur) {\n                    panic!(\"duplicate keys found\");\n                }\n            }\n            // All bucket are distinct from all previous buckets so we're clear to return the result\n            // of the lookup.\n\n            ptrs.map(|ptr| ptr.map(|mut ptr| ptr.as_mut()))\n        }\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTable::<T, A>::get_many_mut_pointers": [
            "unsafe fn get_many_mut_pointers<const N: usize>(\n        &mut self,\n        hashes: [u64; N],\n        mut eq: impl FnMut(usize, &T) -> bool,\n    ) -> [Option<NonNull<T>>; N]{\n        array::from_fn(|i| {\n            self.find(hashes[i], |k| eq(i, k))\n                .map(|cur| cur.as_non_null())\n        })\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTable::<T, A>::get_many_unchecked_mut": [
            "pub unsafe fn get_many_unchecked_mut<const N: usize>(\n        &mut self,\n        hashes: [u64; N],\n        eq: impl FnMut(usize, &T) -> bool,\n    ) -> [Option<&'_ mut T>; N]{\n        let ptrs = self.get_many_mut_pointers(hashes, eq);\n        ptrs.map(|ptr| ptr.map(|mut ptr| ptr.as_mut()))\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTable::<T, A>::get_mut": [
            "/// Gets a mutable reference to an element in the table.\n#[inline]\npub fn get_mut(&mut self, hash: u64, eq: impl FnMut(&T) -> bool) -> Option<&mut T>{\n        // Avoid `Option::map` because it bloats LLVM IR.\n        match self.find(hash, eq) {\n            Some(bucket) => Some(unsafe { bucket.as_mut() }),\n            None => None,\n        }\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTable::<T, A>::insert": [
            "/// Inserts a new element into the table, and returns its raw bucket.\n///\n/// This does not check if the given element already exists in the table.\ninline\npub fn insert(&mut self, hash: u64, value: T, hasher: impl Fn(&T) -> u64) -> Bucket<T>{\n        unsafe {\n            // SAFETY:\n            // 1. The [`RawTableInner`] must already have properly initialized control bytes since\n            //    we will never expose `RawTable::new_uninitialized` in a public API.\n            //\n            // 2. We reserve additional space (if necessary) right after calling this function.\n            let mut slot = self.table.find_insert_slot(hash);\n\n            // We can avoid growing the table once we have reached our load factor if we are replacing\n            // a tombstone. This works since the number of EMPTY slots does not change in this case.\n            //\n            // SAFETY: The function is guaranteed to return [`InsertSlot`] that contains an index\n            // in the range `0..=self.buckets()`.\n            let old_ctrl = *self.table.ctrl(slot.index);\n            if unlikely(self.table.growth_left == 0 && old_ctrl.special_is_empty()) {\n                self.reserve(1, hasher);\n                // SAFETY: We know for sure that `RawTableInner` has control bytes\n                // initialized and that there is extra space in the table.\n                slot = self.table.find_insert_slot(hash);\n            }\n\n            self.insert_in_slot(hash, slot, value)\n        }\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTable::<T, A>::insert_entry": [
            "/// Inserts a new element into the table, and returns a mutable reference to it.\n///\n/// This does not check if the given element already exists in the table.\ninline\npub fn insert_entry(&mut self, hash: u64, value: T, hasher: impl Fn(&T) -> u64) -> &mut T{\n        unsafe { self.insert(hash, value, hasher).as_mut() }\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTable::<T, A>::insert_in_slot": [
            "/// Inserts a new element into the table in the given slot, and returns its\n/// raw bucket.\n///\n/// # Safety\n///\n/// `slot` must point to a slot previously returned by\n/// `find_or_find_insert_slot`, and no mutation of the table must have\n/// occurred since that call.\n#[inline]\npub unsafe fn insert_in_slot(&mut self, hash: u64, slot: InsertSlot, value: T) -> Bucket<T>{\n        let old_ctrl = *self.table.ctrl(slot.index);\n        self.table.record_item_insert_at(slot.index, old_ctrl, hash);\n\n        let bucket = self.bucket(slot.index);\n        bucket.write(value);\n        bucket\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTable::<T, A>::into_allocation": [
            "/// Converts the table into a raw allocation. The contents of the table\n/// should be dropped using a `RawIter` before freeing the allocation.\ninline\npub(crate) fn into_allocation(self) -> Option<(NonNull<u8>, Layout, A)>{\n        let alloc = if self.table.is_empty_singleton() {\n            None\n        } else {\n            // Avoid `Option::unwrap_or_else` because it bloats LLVM IR.\n            let (layout, ctrl_offset) =\n                match Self::TABLE_LAYOUT.calculate_layout_for(self.table.buckets()) {\n                    Some(lco) => lco,\n                    None => unsafe { hint::unreachable_unchecked() },\n                };\n            Some((\n                unsafe { NonNull::new_unchecked(self.table.ctrl.as_ptr().sub(ctrl_offset).cast()) },\n                layout,\n                unsafe { ptr::read(&self.alloc) },\n            ))\n        };\n        mem::forget(self);\n        alloc\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTable::<T, A>::into_iter_from": [
            "/// Returns an iterator which consumes all elements from the table.\n///\n/// Iteration starts at the provided iterator's current location.\n///\n/// It is up to the caller to ensure that the iterator is valid for this\n/// `RawTable` and covers all items that remain in the table.\npub unsafe fn into_iter_from(self, iter: RawIter<T>) -> RawIntoIter<T, A>{\n        debug_assert_eq!(iter.len(), self.len());\n\n        let allocation = self.into_allocation();\n        RawIntoIter {\n            iter,\n            allocation,\n            marker: PhantomData,\n        }\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTable::<T, A>::is_bucket_full": [
            "/// Checks whether the bucket at `index` is full.\n///\n/// # Safety\n///\n/// The caller must ensure `index` is less than the number of buckets.\n#[inline]\npub unsafe fn is_bucket_full(&self, index: usize) -> bool{\n        self.table.is_bucket_full(index)\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTable::<T, A>::is_empty": [
            "/// Returns `true` if the table contains no elements.\n#[inline]\npub fn is_empty(&self) -> bool{\n        self.len() == 0\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTable::<T, A>::iter": [
            "/// Returns an iterator over every element in the table. It is up to\n/// the caller to ensure that the `RawTable` outlives the `RawIter`.\n/// Because we cannot make the `next` method unsafe on the `RawIter`\n/// struct, we have to make the `iter` method unsafe.\n#[inline]\npub unsafe fn iter(&self) -> RawIter<T>{\n        // SAFETY:\n        // 1. The caller must uphold the safety contract for `iter` method.\n        // 2. The [`RawTableInner`] must already have properly initialized control bytes since\n        //    we will never expose RawTable::new_uninitialized in a public API.\n        self.table.iter()\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTable::<T, A>::iter_hash": [
            "/// Returns an iterator over occupied buckets that could match a given hash.\n///\n/// `RawTable` only stores 7 bits of the hash value, so this iterator may\n/// return items that have a hash value different than the one provided. You\n/// should always validate the returned values before using them.\n///\n/// It is up to the caller to ensure that the `RawTable` outlives the\n/// `RawIterHash`. Because we cannot make the `next` method unsafe on the\n/// `RawIterHash` struct, we have to make the `iter_hash` method unsafe.\ninline\npub unsafe fn iter_hash(&self, hash: u64) -> RawIterHash<T>{\n        RawIterHash::new(self, hash)\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTable::<T, A>::len": [
            "/// Returns the number of elements in the table.\n#[inline]\npub fn len(&self) -> usize{\n        self.table.items\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTable::<T, A>::new_in": [
            "/// Creates a new empty hash table without allocating any memory, using the\n/// given allocator.\n///\n/// In effect this returns a table with exactly 1 bucket. However we can\n/// leave the data pointer dangling since that bucket is never written to\n/// due to our load factor forcing us to always have at least 1 free bucket.\n#[inline]\npub const fn new_in(alloc: A) -> Self{\n        Self {\n            table: RawTableInner::NEW,\n            alloc,\n            marker: PhantomData,\n        }\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTable::<T, A>::new_uninitialized": [
            "/// Allocates a new hash table with the given number of buckets.\n///\n/// The control bytes are left uninitialized.\ninline\nunsafe fn new_uninitialized(\n        alloc: A,\n        buckets: usize,\n        fallibility: Fallibility,\n    ) -> Result<Self, TryReserveError>{\n        debug_assert!(buckets.is_power_of_two());\n\n        Ok(Self {\n            table: RawTableInner::new_uninitialized(\n                &alloc,\n                Self::TABLE_LAYOUT,\n                buckets,\n                fallibility,\n            )?,\n            alloc,\n            marker: PhantomData,\n        })\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTable::<T, A>::remove": [
            "/// Removes an element from the table, returning it.\n///\n/// This also returns an `InsertSlot` pointing to the newly free bucket.\ninline\n#[allow(clippy::needless_pass_by_value)]\npub unsafe fn remove(&mut self, item: Bucket<T>) -> (T, InsertSlot){\n        self.erase_no_drop(&item);\n        (\n            item.read(),\n            InsertSlot {\n                index: self.bucket_index(&item),\n            },\n        )\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTable::<T, A>::remove_entry": [
            "/// Finds and removes an element from the table, returning it.\ninline\npub fn remove_entry(&mut self, hash: u64, eq: impl FnMut(&T) -> bool) -> Option<T>{\n        // Avoid `Option::map` because it bloats LLVM IR.\n        match self.find(hash, eq) {\n            Some(bucket) => Some(unsafe { self.remove(bucket).0 }),\n            None => None,\n        }\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTable::<T, A>::replace_bucket_with": [
            "/// Temporary removes a bucket, applying the given function to the removed\n/// element and optionally put back the returned value in the same bucket.\n///\n/// Returns `true` if the bucket still contains an element\n///\n/// This does not check if the given bucket is actually occupied.\ninline\npub unsafe fn replace_bucket_with<F>(&mut self, bucket: Bucket<T>, f: F) -> bool\n    where\n        F: FnOnce(T) -> Option<T>,{\n        let index = self.bucket_index(&bucket);\n        let old_ctrl = *self.table.ctrl(index);\n        debug_assert!(self.is_bucket_full(index));\n        let old_growth_left = self.table.growth_left;\n        let item = self.remove(bucket).0;\n        if let Some(new_item) = f(item) {\n            self.table.growth_left = old_growth_left;\n            self.table.set_ctrl(index, old_ctrl);\n            self.table.items += 1;\n            self.bucket(index).write(new_item);\n            true\n        } else {\n            false\n        }\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTable::<T, A>::reserve": [
            "/// Ensures that at least `additional` items can be inserted into the table\n/// without reallocation.\ninline\npub fn reserve(&mut self, additional: usize, hasher: impl Fn(&T) -> u64){\n        if unlikely(additional > self.table.growth_left) {\n            // Avoid `Result::unwrap_or_else` because it bloats LLVM IR.\n            unsafe {\n                // SAFETY: The [`RawTableInner`] must already have properly initialized control\n                // bytes since we will never expose RawTable::new_uninitialized in a public API.\n                if self\n                    .reserve_rehash(additional, hasher, Fallibility::Infallible)\n                    .is_err()\n                {\n                    // SAFETY: All allocation errors will be caught inside `RawTableInner::reserve_rehash`.\n                    hint::unreachable_unchecked()\n                }\n            }\n        }\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTable::<T, A>::reserve_rehash": [
            "/// Out-of-line slow path for `reserve` and `try_reserve`.\n///\n/// # Safety\n///\n/// The [`RawTableInner`] must have properly initialized control bytes,\n/// otherwise calling this function results in [`undefined behavior`]\n///\n/// [`undefined behavior`]: https://doc.rust-lang.org/reference/behavior-considered-undefined.html\n#[cold]\n#[inline(never)]\nunsafe fn reserve_rehash(\n        &mut self,\n        additional: usize,\n        hasher: impl Fn(&T) -> u64,\n        fallibility: Fallibility,\n    ) -> Result<(), TryReserveError>{\n        unsafe {\n            // SAFETY:\n            // 1. We know for sure that `alloc` and `layout` matches the [`Allocator`] and\n            //    [`TableLayout`] that were used to allocate this table.\n            // 2. The `drop` function is the actual drop function of the elements stored in\n            //    the table.\n            // 3. The caller ensures that the control bytes of the `RawTableInner`\n            //    are already initialized.\n            self.table.reserve_rehash_inner(\n                &self.alloc,\n                additional,\n                &|table, index| hasher(table.bucket::<T>(index).as_ref()),\n                fallibility,\n                Self::TABLE_LAYOUT,\n                if T::NEEDS_DROP {\n                    Some(|ptr| ptr::drop_in_place(ptr as *mut T))\n                } else {\n                    None\n                },\n            )\n        }\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTable::<T, A>::resize": [
            "/// Allocates a new table of a different size and moves the contents of the\n/// current table into it.\n///\n/// # Safety\n///\n/// The [`RawTableInner`] must have properly initialized control bytes,\n/// otherwise calling this function results in [`undefined behavior`]\n///\n/// The caller of this function must ensure that `capacity >= self.table.items`\n/// otherwise:\n///\n/// * If `self.table.items != 0`, calling of this function with `capacity`\n///   equal to 0 (`capacity == 0`) results in [`undefined behavior`].\n///\n/// * If `self.table.items > capacity_to_buckets(capacity, Self::TABLE_LAYOUT)`\n///   calling this function are never return (will loop infinitely).\n///\n/// See [`RawTableInner::find_insert_slot`] for more information.\n///\n/// [`RawTableInner::find_insert_slot`]: RawTableInner::find_insert_slot\n/// [`undefined behavior`]: https://doc.rust-lang.org/reference/behavior-considered-undefined.html\nunsafe fn resize(\n        &mut self,\n        capacity: usize,\n        hasher: impl Fn(&T) -> u64,\n        fallibility: Fallibility,\n    ) -> Result<(), TryReserveError>{\n        // SAFETY:\n        // 1. The caller of this function guarantees that `capacity >= self.table.items`.\n        // 2. We know for sure that `alloc` and `layout` matches the [`Allocator`] and\n        //    [`TableLayout`] that were used to allocate this table.\n        // 3. The caller ensures that the control bytes of the `RawTableInner`\n        //    are already initialized.\n        self.table.resize_inner(\n            &self.alloc,\n            capacity,\n            &|table, index| hasher(table.bucket::<T>(index).as_ref()),\n            fallibility,\n            Self::TABLE_LAYOUT,\n        )\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTable::<T, A>::shrink_to": [
            "/// Shrinks the table to fit `max(self.len(), min_size)` elements.\ninline\npub fn shrink_to(&mut self, min_size: usize, hasher: impl Fn(&T) -> u64){\n        // Calculate the minimal number of elements that we need to reserve\n        // space for.\n        let min_size = usize::max(self.table.items, min_size);\n        if min_size == 0 {\n            let mut old_inner = mem::replace(&mut self.table, RawTableInner::NEW);\n            unsafe {\n                // SAFETY:\n                // 1. We call the function only once;\n                // 2. We know for sure that `alloc` and `table_layout` matches the [`Allocator`]\n                //    and [`TableLayout`] that were used to allocate this table.\n                // 3. If any elements' drop function panics, then there will only be a memory leak,\n                //    because we have replaced the inner table with a new one.\n                old_inner.drop_inner_table::<T, _>(&self.alloc, Self::TABLE_LAYOUT);\n            }\n            return;\n        }\n\n        // Calculate the number of buckets that we need for this number of\n        // elements. If the calculation overflows then the requested bucket\n        // count must be larger than what we have right and nothing needs to be\n        // done.\n        let min_buckets = match capacity_to_buckets(min_size, Self::TABLE_LAYOUT) {\n            Some(buckets) => buckets,\n            None => return,\n        };\n\n        // If we have more buckets than we need, shrink the table.\n        if min_buckets < self.buckets() {\n            // Fast path if the table is empty\n            if self.table.items == 0 {\n                let new_inner =\n                    RawTableInner::with_capacity(&self.alloc, Self::TABLE_LAYOUT, min_size);\n                let mut old_inner = mem::replace(&mut self.table, new_inner);\n                unsafe {\n                    // SAFETY:\n                    // 1. We call the function only once;\n                    // 2. We know for sure that `alloc` and `table_layout` matches the [`Allocator`]\n                    //    and [`TableLayout`] that were used to allocate this table.\n                    // 3. If any elements' drop function panics, then there will only be a memory leak,\n                    //    because we have replaced the inner table with a new one.\n                    old_inner.drop_inner_table::<T, _>(&self.alloc, Self::TABLE_LAYOUT);\n                }\n            } else {\n                // Avoid `Result::unwrap_or_else` because it bloats LLVM IR.\n                unsafe {\n                    // SAFETY:\n                    // 1. We know for sure that `min_size >= self.table.items`.\n                    // 2. The [`RawTableInner`] must already have properly initialized control bytes since\n                    //    we will never expose RawTable::new_uninitialized in a public API.\n                    if self\n                        .resize(min_size, hasher, Fallibility::Infallible)\n                        .is_err()\n                    {\n                        // SAFETY: The result of calling the `resize` function cannot be an error\n                        // because `fallibility == Fallibility::Infallible.\n                        hint::unreachable_unchecked()\n                    }\n                }\n            }\n        }\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTable::<T, A>::try_reserve": [
            "/// Tries to ensure that at least `additional` items can be inserted into\n/// the table without reallocation.\ninline\npub fn try_reserve(\n        &mut self,\n        additional: usize,\n        hasher: impl Fn(&T) -> u64,\n    ) -> Result<(), TryReserveError>{\n        if additional > self.table.growth_left {\n            // SAFETY: The [`RawTableInner`] must already have properly initialized control\n            // bytes since we will never expose RawTable::new_uninitialized in a public API.\n            unsafe { self.reserve_rehash(additional, hasher, Fallibility::Fallible) }\n        } else {\n            Ok(())\n        }\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTable::<T, A>::with_capacity_in": [
            "/// Allocates a new hash table using the given allocator, with at least enough capacity for\n/// inserting the given number of elements without reallocating.\npub fn with_capacity_in(capacity: usize, alloc: A) -> Self{\n        Self {\n            table: RawTableInner::with_capacity(&alloc, Self::TABLE_LAYOUT, capacity),\n            alloc,\n            marker: PhantomData,\n        }\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTable::<T>::new": [
            "/// Creates a new empty hash table without allocating any memory.\n///\n/// In effect this returns a table with exactly 1 bucket. However we can\n/// leave the data pointer dangling since that bucket is never written to\n/// due to our load factor forcing us to always have at least 1 free bucket.\n#[inline]\npub const fn new() -> Self{\n        Self {\n            table: RawTableInner::NEW,\n            alloc: Global,\n            marker: PhantomData,\n        }\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTable::<T>::with_capacity": [
            "/// Allocates a new hash table with at least enough capacity for inserting\n/// the given number of elements without reallocating.\npub fn with_capacity(capacity: usize) -> Self{\n        Self::with_capacity_in(capacity, Global)\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTableClone": [
            "/// Specialization of `clone_from` for `Copy` types\ntrait RawTableClone {\n    unsafe fn clone_from_spec(&mut self, source: &Self);\n}",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTableInner": [
            "/// Non-generic part of `RawTable` which allows functions to be instantiated only once regardless\n/// of how many different key-value types are used.\nstruct RawTableInner {\n    // Mask to get an index from a hash value. The value is one less than the\n    // number of buckets in the table.\n    bucket_mask: usize,\n\n    // [Padding], T_n, ..., T1, T0, C0, C1, ...\n    //                              ^ points here\n    ctrl: NonNull<u8>,\n\n    // Number of elements that can be inserted before we need to grow the table\n    growth_left: usize,\n\n    // Number of elements in the table, only really used by len()\n    items: usize,\n}",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTableInner::allocation_info": [
            "/// Returns a pointer to the allocated memory and the layout that was used to\n/// allocate the table.\n///\n/// # Safety\n///\n/// Caller of this function must observe the following safety rules:\n///\n/// * The [`RawTableInner`] has already been allocated, otherwise\n///   calling this function results in [`undefined behavior`]\n///\n/// * The `table_layout` must be the same [`TableLayout`] as the `TableLayout`\n///   that was used to allocate this table. Failure to comply with this condition\n///   may result in [`undefined behavior`].\n///\n/// See also [`GlobalAlloc::dealloc`] or [`Allocator::deallocate`] for more  information.\n///\n/// [`undefined behavior`]: https://doc.rust-lang.org/reference/behavior-considered-undefined.html\n/// [`GlobalAlloc::dealloc`]: https://doc.rust-lang.org/alloc/alloc/trait.GlobalAlloc.html#tymethod.dealloc\n/// [`Allocator::deallocate`]: https://doc.rust-lang.org/alloc/alloc/trait.Allocator.html#tymethod.deallocate\n#[inline]\nunsafe fn allocation_info(&self, table_layout: TableLayout) -> (NonNull<u8>, Layout){\n        debug_assert!(\n            !self.is_empty_singleton(),\n            \"this function can only be called on non-empty tables\"\n        );\n\n        // Avoid `Option::unwrap_or_else` because it bloats LLVM IR.\n        let (layout, ctrl_offset) = match table_layout.calculate_layout_for(self.buckets()) {\n            Some(lco) => lco,\n            None => unsafe { hint::unreachable_unchecked() },\n        };\n        (\n            // SAFETY: The caller must uphold the safety contract for `allocation_info` method.\n            unsafe { NonNull::new_unchecked(self.ctrl.as_ptr().sub(ctrl_offset)) },\n            layout,\n        )\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTableInner::allocation_size_or_zero": [
            "/// Returns the total amount of memory allocated internally by the hash\n/// table, in bytes.\n///\n/// The returned number is informational only. It is intended to be\n/// primarily used for memory profiling.\n///\n/// # Safety\n///\n/// The `table_layout` must be the same [`TableLayout`] as the `TableLayout`\n/// that was used to allocate this table. Failure to comply with this condition\n/// may result in [`undefined behavior`].\n///\n///\n/// [`undefined behavior`]: https://doc.rust-lang.org/reference/behavior-considered-undefined.html\n#[inline]\nunsafe fn allocation_size_or_zero(&self, table_layout: TableLayout) -> usize{\n        if self.is_empty_singleton() {\n            0\n        } else {\n            // SAFETY:\n            // 1. We have checked that our table is allocated.\n            // 2. The caller ensures that `table_layout` matches the [`TableLayout`]\n            // that was used to allocate this table.\n            unsafe { self.allocation_info(table_layout).1.size() }\n        }\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTableInner::bucket": [
            "/// Returns a pointer to an element in the table (convenience for\n/// `Bucket::from_base_index(self.data_end::<T>(), index)`).\n///\n/// The caller must ensure that the `RawTableInner` outlives the returned [`Bucket<T>`],\n/// otherwise using it may result in [`undefined behavior`].\n///\n/// # Safety\n///\n/// If `mem::size_of::<T>() != 0`, then the safety rules are directly derived from the\n/// safety rules of the [`Bucket::from_base_index`] function. Therefore, when calling\n/// this function, the following safety rules must be observed:\n///\n/// * The table must already be allocated;\n///\n/// * The `index` must not be greater than the number returned by the [`RawTableInner::buckets`]\n///   function, i.e. `(index + 1) <= self.buckets()`.\n///\n/// * The type `T` must be the actual type of the elements stored in the table, otherwise\n///   using the returned [`Bucket`] may result in [`undefined behavior`].\n///\n/// It is safe to call this function with index of zero (`index == 0`) on a table that has\n/// not been allocated, but using the returned [`Bucket`] results in [`undefined behavior`].\n///\n/// If `mem::size_of::<T>() == 0`, then the only requirement is that the `index` must\n/// not be greater than the number returned by the [`RawTable::buckets`] function, i.e.\n/// `(index + 1) <= self.buckets()`.\n///\n/// ```none\n/// If mem::size_of::<T>() != 0 then return a pointer to the `element` in the `data part` of the table\n/// (we start counting from \"0\", so that in the expression T[n], the \"n\" index actually one less than\n/// the \"buckets\" number of our `RawTableInner`, i.e. \"n = RawTableInner::buckets() - 1\"):\n///\n///           `table.bucket(3).as_ptr()` returns a pointer that points here in the `data`\n///           part of the `RawTableInner`, i.e. to the start of T3 (see [`Bucket::as_ptr`])\n///                  |\n///                  |               `base = table.data_end::<T>()` points here\n///                  |               (to the start of CT0 or to the end of T0)\n///                  v                 v\n/// [Pad], T_n, ..., |T3|, T2, T1, T0, |CT0, CT1, CT2, CT3, ..., CT_n, CTa_0, CTa_1, ..., CTa_m\n///                     ^                                              \\__________  __________/\n///        `table.bucket(3)` returns a pointer that points                        \\/\n///         here in the `data` part of the `RawTableInner`             additional control bytes\n///         (to the end of T3)                                          `m = Group::WIDTH - 1`\n///\n/// where: T0...T_n  - our stored data;\n///        CT0...CT_n - control bytes or metadata for `data`;\n///        CTa_0...CTa_m - additional control bytes (so that the search with loading `Group` bytes from\n///                        the heap works properly, even if the result of `h1(hash) & self.bucket_mask`\n///                        is equal to `self.bucket_mask`). See also `RawTableInner::set_ctrl` function.\n///\n/// P.S. `h1(hash) & self.bucket_mask` is the same as `hash as usize % self.buckets()` because the number\n/// of buckets is a power of two, and `self.bucket_mask = self.buckets() - 1`.\n/// ```\n///\n/// [`Bucket::from_base_index`]: Bucket::from_base_index\n/// [`RawTableInner::buckets`]: RawTableInner::buckets\n/// [`undefined behavior`]: https://doc.rust-lang.org/reference/behavior-considered-undefined.html\n#[inline]\nunsafe fn bucket<T>(&self, index: usize) -> Bucket<T>{\n        debug_assert_ne!(self.bucket_mask, 0);\n        debug_assert!(index < self.buckets());\n        Bucket::from_base_index(self.data_end(), index)\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTableInner::bucket_ptr": [
            "/// Returns a raw `*mut u8` pointer to the start of the `data` element in the table\n/// (convenience for `self.data_end::<u8>().as_ptr().sub((index + 1) * size_of)`).\n///\n/// The caller must ensure that the `RawTableInner` outlives the returned `*mut u8`,\n/// otherwise using it may result in [`undefined behavior`].\n///\n/// # Safety\n///\n/// If any of the following conditions are violated, the result is [`undefined behavior`]:\n///\n/// * The table must already be allocated;\n///\n/// * The `index` must not be greater than the number returned by the [`RawTableInner::buckets`]\n///   function, i.e. `(index + 1) <= self.buckets()`;\n///\n/// * The `size_of` must be equal to the size of the elements stored in the table;\n///\n/// ```none\n/// If mem::size_of::<T>() != 0 then return a pointer to the `element` in the `data part` of the table\n/// (we start counting from \"0\", so that in the expression T[n], the \"n\" index actually one less than\n/// the \"buckets\" number of our `RawTableInner`, i.e. \"n = RawTableInner::buckets() - 1\"):\n///\n///           `table.bucket_ptr(3, mem::size_of::<T>())` returns a pointer that points here in the\n///           `data` part of the `RawTableInner`, i.e. to the start of T3\n///                  |\n///                  |               `base = table.data_end::<u8>()` points here\n///                  |               (to the start of CT0 or to the end of T0)\n///                  v                 v\n/// [Pad], T_n, ..., |T3|, T2, T1, T0, |CT0, CT1, CT2, CT3, ..., CT_n, CTa_0, CTa_1, ..., CTa_m\n///                                                                    \\__________  __________/\n///                                                                               \\/\n///                                                                    additional control bytes\n///                                                                     `m = Group::WIDTH - 1`\n///\n/// where: T0...T_n  - our stored data;\n///        CT0...CT_n - control bytes or metadata for `data`;\n///        CTa_0...CTa_m - additional control bytes (so that the search with loading `Group` bytes from\n///                        the heap works properly, even if the result of `h1(hash) & self.bucket_mask`\n///                        is equal to `self.bucket_mask`). See also `RawTableInner::set_ctrl` function.\n///\n/// P.S. `h1(hash) & self.bucket_mask` is the same as `hash as usize % self.buckets()` because the number\n/// of buckets is a power of two, and `self.bucket_mask = self.buckets() - 1`.\n/// ```\n///\n/// [`RawTableInner::buckets`]: RawTableInner::buckets\n/// [`undefined behavior`]: https://doc.rust-lang.org/reference/behavior-considered-undefined.html\n#[inline]\nunsafe fn bucket_ptr(&self, index: usize, size_of: usize) -> *mut u8{\n        debug_assert_ne!(self.bucket_mask, 0);\n        debug_assert!(index < self.buckets());\n        let base: *mut u8 = self.data_end().as_ptr();\n        base.sub((index + 1) * size_of)\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTableInner::buckets": [
            "#[inline]\nfn buckets(&self) -> usize{\n        self.bucket_mask + 1\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTableInner::clear_no_drop": [
            "/// Marks all table buckets as empty without dropping their contents.\n#[inline]\nfn clear_no_drop(&mut self){\n        if !self.is_empty_singleton() {\n            self.ctrl_slice().fill_empty();\n        }\n        self.items = 0;\n        self.growth_left = bucket_mask_to_capacity(self.bucket_mask);\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTableInner::ctrl": [
            "/// Returns a pointer to a control byte.\n///\n/// # Safety\n///\n/// For the allocated [`RawTableInner`], the result is [`Undefined Behavior`],\n/// if the `index` is greater than the `self.bucket_mask + 1 + Group::WIDTH`.\n/// In that case, calling this function with `index == self.bucket_mask + 1 + Group::WIDTH`\n/// will return a pointer to the end of the allocated table and it is useless on its own.\n///\n/// Calling this function with `index >= self.bucket_mask + 1 + Group::WIDTH` on a\n/// table that has not been allocated results in [`Undefined Behavior`].\n///\n/// So to satisfy both requirements you should always follow the rule that\n/// `index < self.bucket_mask + 1 + Group::WIDTH`\n///\n/// Calling this function on [`RawTableInner`] that are not already allocated is safe\n/// for read-only purpose.\n///\n/// See also [`Bucket::as_ptr()`] method, for more information about of properly removing\n/// or saving `data element` from / into the [`RawTable`] / [`RawTableInner`].\n///\n/// [`Bucket::as_ptr()`]: Bucket::as_ptr()\n/// [`Undefined Behavior`]: https://doc.rust-lang.org/reference/behavior-considered-undefined.html\n#[inline]\nunsafe fn ctrl(&self, index: usize) -> *mut Tag{\n        debug_assert!(index < self.num_ctrl_bytes());\n        // SAFETY: The caller must uphold the safety rules for the [`RawTableInner::ctrl`]\n        self.ctrl.as_ptr().add(index).cast()\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTableInner::ctrl_slice": [
            "/// Gets the slice of all control bytes.\nfn ctrl_slice(&mut self) -> &mut [Tag]{\n        // SAFETY: We've intiailized all control bytes, and have the correct number.\n        unsafe { slice::from_raw_parts_mut(self.ctrl.as_ptr().cast(), self.num_ctrl_bytes()) }\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTableInner::data_end": [
            "/// Returns pointer to one past last `data` element in the table as viewed from\n/// the start point of the allocation (convenience for `self.ctrl.cast()`).\n///\n/// This function actually returns a pointer to the end of the `data element` at\n/// index \"0\" (zero).\n///\n/// The caller must ensure that the `RawTableInner` outlives the returned [`NonNull<T>`],\n/// otherwise using it may result in [`undefined behavior`].\n///\n/// # Note\n///\n/// The type `T` must be the actual type of the elements stored in the table, otherwise\n/// using the returned [`NonNull<T>`] may result in [`undefined behavior`].\n///\n/// ```none\n///                        `table.data_end::<T>()` returns pointer that points here\n///                        (to the end of `T0`)\n///                          \n/// [Pad], T_n, ..., T1, T0, |CT0, CT1, ..., CT_n|, CTa_0, CTa_1, ..., CTa_m\n///                           \\________  ________/\n///                                    \\/\n///       `n = buckets - 1`, i.e. `RawTableInner::buckets() - 1`\n///\n/// where: T0...T_n  - our stored data;\n///        CT0...CT_n - control bytes or metadata for `data`.\n///        CTa_0...CTa_m - additional control bytes, where `m = Group::WIDTH - 1` (so that the search\n///                        with loading `Group` bytes from the heap works properly, even if the result\n///                        of `h1(hash) & self.bucket_mask` is equal to `self.bucket_mask`). See also\n///                        `RawTableInner::set_ctrl` function.\n///\n/// P.S. `h1(hash) & self.bucket_mask` is the same as `hash as usize % self.buckets()` because the number\n/// of buckets is a power of two, and `self.bucket_mask = self.buckets() - 1`.\n/// ```\n///\n/// [`undefined behavior`]: https://doc.rust-lang.org/reference/behavior-considered-undefined.html\n#[inline]\nfn data_end<T>(&self) -> NonNull<T>{\n        self.ctrl.cast()\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTableInner::drop_elements": [
            "/// Executes the destructors (if any) of the values stored in the table.\n///\n/// # Note\n///\n/// This function does not erase the control bytes of the table and does\n/// not make any changes to the `items` or `growth_left` fields of the\n/// table. If necessary, the caller of this function must manually set\n/// up these table fields, for example using the [`clear_no_drop`] function.\n///\n/// Be careful during calling this function, because drop function of\n/// the elements can panic, and this can leave table in an inconsistent\n/// state.\n///\n/// # Safety\n///\n/// The type `T` must be the actual type of the elements stored in the table,\n/// otherwise calling this function may result in [`undefined behavior`].\n///\n/// If `T` is a type that should be dropped and **the table is not empty**,\n/// calling this function more than once results in [`undefined behavior`].\n///\n/// If `T` is not [`Copy`], attempting to use values stored in the table after\n/// calling this function may result in [`undefined behavior`].\n///\n/// It is safe to call this function on a table that has not been allocated,\n/// on a table with uninitialized control bytes, and on a table with no actual\n/// data but with `Full` control bytes if `self.items == 0`.\n///\n/// See also [`Bucket::drop`] / [`Bucket::as_ptr`] methods, for more information\n/// about of properly removing or saving `element` from / into the [`RawTable`] /\n/// [`RawTableInner`].\n///\n/// [`Bucket::drop`]: Bucket::drop\n/// [`Bucket::as_ptr`]: Bucket::as_ptr\n/// [`clear_no_drop`]: RawTableInner::clear_no_drop\n/// [`undefined behavior`]: https://doc.rust-lang.org/reference/behavior-considered-undefined.html\nunsafe fn drop_elements<T>(&mut self){\n        // Check that `self.items != 0`. Protects against the possibility\n        // of creating an iterator on an table with uninitialized control bytes.\n        if T::NEEDS_DROP && self.items != 0 {\n            // SAFETY: We know for sure that RawTableInner will outlive the\n            // returned `RawIter` iterator, and the caller of this function\n            // must uphold the safety contract for `drop_elements` method.\n            for item in self.iter::<T>() {\n                // SAFETY: The caller must uphold the safety contract for\n                // `drop_elements` method.\n                item.drop();\n            }\n        }\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTableInner::drop_inner_table": [
            "/// Executes the destructors (if any) of the values stored in the table and than\n/// deallocates the table.\n///\n/// # Note\n///\n/// Calling this function automatically makes invalid (dangling) all instances of\n/// buckets ([`Bucket`]) and makes invalid (dangling) the `ctrl` field of the table.\n///\n/// This function does not make any changes to the `bucket_mask`, `items` or `growth_left`\n/// fields of the table. If necessary, the caller of this function must manually set\n/// up these table fields.\n///\n/// # Safety\n///\n/// If any of the following conditions are violated, the result is [`undefined behavior`]:\n///\n/// * Calling this function more than once;\n///\n/// * The type `T` must be the actual type of the elements stored in the table.\n///\n/// * The `alloc` must be the same [`Allocator`] as the `Allocator` that was used\n///   to allocate this table.\n///\n/// * The `table_layout` must be the same [`TableLayout`] as the `TableLayout` that\n///   was used to allocate this table.\n///\n/// The caller of this function should pay attention to the possibility of the\n/// elements' drop function panicking, because this:\n///\n///    * May leave the table in an inconsistent state;\n///\n///    * Memory is never deallocated, so a memory leak may occur.\n///\n/// Attempt to use the `ctrl` field of the table (dereference) after calling this\n/// function results in [`undefined behavior`].\n///\n/// It is safe to call this function on a table that has not been allocated,\n/// on a table with uninitialized control bytes, and on a table with no actual\n/// data but with `Full` control bytes if `self.items == 0`.\n///\n/// See also [`RawTableInner::drop_elements`] or [`RawTableInner::free_buckets`]\n/// for more  information.\n///\n/// [`RawTableInner::drop_elements`]: RawTableInner::drop_elements\n/// [`RawTableInner::free_buckets`]: RawTableInner::free_buckets\n/// [`undefined behavior`]: https://doc.rust-lang.org/reference/behavior-considered-undefined.html\nunsafe fn drop_inner_table<T, A: Allocator>(&mut self, alloc: &A, table_layout: TableLayout){\n        if !self.is_empty_singleton() {\n            unsafe {\n                // SAFETY: The caller must uphold the safety contract for `drop_inner_table` method.\n                self.drop_elements::<T>();\n                // SAFETY:\n                // 1. We have checked that our table is allocated.\n                // 2. The caller must uphold the safety contract for `drop_inner_table` method.\n                self.free_buckets(alloc, table_layout);\n            }\n        }\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTableInner::erase": [
            "/// Erases the [`Bucket`]'s control byte at the given index so that it does not\n/// triggered as full, decreases the `items` of the table and, if it can be done,\n/// increases `self.growth_left`.\n///\n/// This function does not actually erase / drop the [`Bucket`] itself, i.e. it\n/// does not make any changes to the `data` parts of the table. The caller of this\n/// function must take care to properly drop the `data`, otherwise calling this\n/// function may result in a memory leak.\n///\n/// # Safety\n///\n/// You must observe the following safety rules when calling this function:\n///\n/// * The [`RawTableInner`] has already been allocated;\n///\n/// * It must be the full control byte at the given position;\n///\n/// * The `index` must not be greater than the `RawTableInner.bucket_mask`, i.e.\n///   `index <= RawTableInner.bucket_mask` or, in other words, `(index + 1)` must\n///   be no greater than the number returned by the function [`RawTableInner::buckets`].\n///\n/// Calling this function on a table that has not been allocated results in [`undefined behavior`].\n///\n/// Calling this function on a table with no elements is unspecified, but calling subsequent\n/// functions is likely to result in [`undefined behavior`] due to overflow subtraction\n/// (`self.items -= 1 cause overflow when self.items == 0`).\n///\n/// See also [`Bucket::as_ptr`] method, for more information about of properly removing\n/// or saving `data element` from / into the [`RawTable`] / [`RawTableInner`].\n///\n/// [`RawTableInner::buckets`]: RawTableInner::buckets\n/// [`Bucket::as_ptr`]: Bucket::as_ptr\n/// [`undefined behavior`]: https://doc.rust-lang.org/reference/behavior-considered-undefined.html\n#[inline]\nunsafe fn erase(&mut self, index: usize){\n        debug_assert!(self.is_bucket_full(index));\n\n        // This is the same as `index.wrapping_sub(Group::WIDTH) % self.buckets()` because\n        // the number of buckets is a power of two, and `self.bucket_mask = self.buckets() - 1`.\n        let index_before = index.wrapping_sub(Group::WIDTH) & self.bucket_mask;\n        // SAFETY:\n        // - The caller must uphold the safety contract for `erase` method;\n        // - `index_before` is guaranteed to be in range due to masking with `self.bucket_mask`\n        let empty_before = Group::load(self.ctrl(index_before)).match_empty();\n        let empty_after = Group::load(self.ctrl(index)).match_empty();\n\n        // Inserting and searching in the map is performed by two key functions:\n        //\n        // - The `find_insert_slot` function that looks up the index of any `Tag::EMPTY` or `Tag::DELETED`\n        //   slot in a group to be able to insert. If it doesn't find an `Tag::EMPTY` or `Tag::DELETED`\n        //   slot immediately in the first group, it jumps to the next `Group` looking for it,\n        //   and so on until it has gone through all the groups in the control bytes.\n        //\n        // - The `find_inner` function that looks for the index of the desired element by looking\n        //   at all the `FULL` bytes in the group. If it did not find the element right away, and\n        //   there is no `Tag::EMPTY` byte in the group, then this means that the `find_insert_slot`\n        //   function may have found a suitable slot in the next group. Therefore, `find_inner`\n        //   jumps further, and if it does not find the desired element and again there is no `Tag::EMPTY`\n        //   byte, then it jumps further, and so on. The search stops only if `find_inner` function\n        //   finds the desired element or hits an `Tag::EMPTY` slot/byte.\n        //\n        // Accordingly, this leads to two consequences:\n        //\n        // - The map must have `Tag::EMPTY` slots (bytes);\n        //\n        // - You can't just mark the byte to be erased as `Tag::EMPTY`, because otherwise the `find_inner`\n        //   function may stumble upon an `Tag::EMPTY` byte before finding the desired element and stop\n        //   searching.\n        //\n        // Thus it is necessary to check all bytes after and before the erased element. If we are in\n        // a contiguous `Group` of `FULL` or `Tag::DELETED` bytes (the number of `FULL` or `Tag::DELETED` bytes\n        // before and after is greater than or equal to `Group::WIDTH`), then we must mark our byte as\n        // `Tag::DELETED` in order for the `find_inner` function to go further. On the other hand, if there\n        // is at least one `Tag::EMPTY` slot in the `Group`, then the `find_inner` function will still stumble\n        // upon an `Tag::EMPTY` byte, so we can safely mark our erased byte as `Tag::EMPTY` as well.\n        //\n        // Finally, since `index_before == (index.wrapping_sub(Group::WIDTH) & self.bucket_mask) == index`\n        // and given all of the above, tables smaller than the group width (self.buckets() < Group::WIDTH)\n        // cannot have `Tag::DELETED` bytes.\n        //\n        // Note that in this context `leading_zeros` refers to the bytes at the end of a group, while\n        // `trailing_zeros` refers to the bytes at the beginning of a group.\n        let ctrl = if empty_before.leading_zeros() + empty_after.trailing_zeros() >= Group::WIDTH {\n            Tag::DELETED\n        } else {\n            self.growth_left += 1;\n            Tag::EMPTY\n        };\n        // SAFETY: the caller must uphold the safety contract for `erase` method.\n        self.set_ctrl(index, ctrl);\n        self.items -= 1;\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTableInner::fallible_with_capacity": [
            "/// Attempts to allocate a new [`RawTableInner`] with at least enough\n/// capacity for inserting the given number of elements without reallocating.\n///\n/// All the control bytes are initialized with the [`Tag::EMPTY`] bytes.\n#[inline]\nfn fallible_with_capacity<A>(\n        alloc: &A,\n        table_layout: TableLayout,\n        capacity: usize,\n        fallibility: Fallibility,\n    ) -> Result<Self, TryReserveError>\n    where\n        A: Allocator,{\n        if capacity == 0 {\n            Ok(Self::NEW)\n        } else {\n            // SAFETY: We checked that we could successfully allocate the new table, and then\n            // initialized all control bytes with the constant `Tag::EMPTY` byte.\n            unsafe {\n                let buckets = capacity_to_buckets(capacity, table_layout)\n                    .ok_or_else(|| fallibility.capacity_overflow())?;\n\n                let mut result =\n                    Self::new_uninitialized(alloc, table_layout, buckets, fallibility)?;\n                // SAFETY: We checked that the table is allocated and therefore the table already has\n                // `self.bucket_mask + 1 + Group::WIDTH` number of control bytes (see TableLayout::calculate_layout_for)\n                // so writing `self.num_ctrl_bytes() == bucket_mask + 1 + Group::WIDTH` bytes is safe.\n                result.ctrl_slice().fill_empty();\n\n                Ok(result)\n            }\n        }\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTableInner::find_inner": [
            "/// Searches for an element in a table, returning the `index` of the found element.\n/// This uses dynamic dispatch to reduce the amount of code generated, but it is\n/// eliminated by LLVM optimizations.\n///\n/// This function does not make any changes to the `data` part of the table, or any\n/// changes to the `items` or `growth_left` field of the table.\n///\n/// The table must have at least 1 empty `bucket`, otherwise, if the\n/// `eq: &mut dyn FnMut(usize) -> bool` function does not return `true`,\n/// this function will also never return (will go into an infinite loop).\n///\n/// This function is guaranteed to provide the `eq: &mut dyn FnMut(usize) -> bool`\n/// function with only `FULL` buckets' indices and return the `index` of the found\n/// element as `Some(index)`, so the index will always be in the range\n/// `0..self.buckets()`.\n///\n/// # Safety\n///\n/// The [`RawTableInner`] must have properly initialized control bytes otherwise calling\n/// this function results in [`undefined behavior`].\n///\n/// [`undefined behavior`]: https://doc.rust-lang.org/reference/behavior-considered-undefined.html\n#[inline(always)]\nunsafe fn find_inner(&self, hash: u64, eq: &mut dyn FnMut(usize) -> bool) -> Option<usize>{\n        let tag_hash = Tag::full(hash);\n        let mut probe_seq = self.probe_seq(hash);\n\n        loop {\n            // SAFETY:\n            // * Caller of this function ensures that the control bytes are properly initialized.\n            //\n            // * `ProbeSeq.pos` cannot be greater than `self.bucket_mask = self.buckets() - 1`\n            //   of the table due to masking with `self.bucket_mask`.\n            //\n            // * Even if `ProbeSeq.pos` returns `position == self.bucket_mask`, it is safe to\n            //   call `Group::load` due to the extended control bytes range, which is\n            //  `self.bucket_mask + 1 + Group::WIDTH` (in fact, this means that the last control\n            //   byte will never be read for the allocated table);\n            //\n            // * Also, even if `RawTableInner` is not already allocated, `ProbeSeq.pos` will\n            //   always return \"0\" (zero), so Group::load will read unaligned `Group::static_empty()`\n            //   bytes, which is safe (see RawTableInner::new_in).\n            let group = unsafe { Group::load(self.ctrl(probe_seq.pos)) };\n\n            for bit in group.match_tag(tag_hash) {\n                // This is the same as `(probe_seq.pos + bit) % self.buckets()` because the number\n                // of buckets is a power of two, and `self.bucket_mask = self.buckets() - 1`.\n                let index = (probe_seq.pos + bit) & self.bucket_mask;\n\n                if likely(eq(index)) {\n                    return Some(index);\n                }\n            }\n\n            if likely(group.match_empty().any_bit_set()) {\n                return None;\n            }\n\n            probe_seq.move_next(self.bucket_mask);\n        }\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTableInner::find_insert_slot": [
            "/// Searches for an empty or deleted bucket which is suitable for inserting\n/// a new element, returning the `index` for the new [`Bucket`].\n///\n/// This function does not make any changes to the `data` part of the table, or any\n/// changes to the `items` or `growth_left` field of the table.\n///\n/// The table must have at least 1 empty or deleted `bucket`, otherwise this function\n/// will never return (will go into an infinite loop) for tables larger than the group\n/// width, or return an index outside of the table indices range if the table is less\n/// than the group width.\n///\n/// If there is at least 1 empty or deleted `bucket` in the table, the function is\n/// guaranteed to return [`InsertSlot`] with an index in the range `0..self.buckets()`,\n/// but in any case, if this function returns [`InsertSlot`], it will contain an index\n/// in the range `0..=self.buckets()`.\n///\n/// # Safety\n///\n/// The [`RawTableInner`] must have properly initialized control bytes otherwise calling\n/// this function results in [`undefined behavior`].\n///\n/// Attempt to write data at the [`InsertSlot`] returned by this function when the table is\n/// less than the group width and if there was not at least one empty or deleted bucket in\n/// the table will cause immediate [`undefined behavior`]. This is because in this case the\n/// function will return `self.bucket_mask + 1` as an index due to the trailing [`Tag::EMPTY`]\n/// control bytes outside the table range.\n///\n/// [`undefined behavior`]: https://doc.rust-lang.org/reference/behavior-considered-undefined.html\n#[inline]\nunsafe fn find_insert_slot(&self, hash: u64) -> InsertSlot{\n        let mut probe_seq = self.probe_seq(hash);\n        loop {\n            // SAFETY:\n            // * Caller of this function ensures that the control bytes are properly initialized.\n            //\n            // * `ProbeSeq.pos` cannot be greater than `self.bucket_mask = self.buckets() - 1`\n            //   of the table due to masking with `self.bucket_mask` and also because the number\n            //   of buckets is a power of two (see `self.probe_seq` function).\n            //\n            // * Even if `ProbeSeq.pos` returns `position == self.bucket_mask`, it is safe to\n            //   call `Group::load` due to the extended control bytes range, which is\n            //  `self.bucket_mask + 1 + Group::WIDTH` (in fact, this means that the last control\n            //   byte will never be read for the allocated table);\n            //\n            // * Also, even if `RawTableInner` is not already allocated, `ProbeSeq.pos` will\n            //   always return \"0\" (zero), so Group::load will read unaligned `Group::static_empty()`\n            //   bytes, which is safe (see RawTableInner::new).\n            let group = unsafe { Group::load(self.ctrl(probe_seq.pos)) };\n\n            let index = self.find_insert_slot_in_group(&group, &probe_seq);\n            if likely(index.is_some()) {\n                // SAFETY:\n                // * Caller of this function ensures that the control bytes are properly initialized.\n                //\n                // * We use this function with the slot / index found by `self.find_insert_slot_in_group`\n                unsafe {\n                    return self.fix_insert_slot(index.unwrap_unchecked());\n                }\n            }\n            probe_seq.move_next(self.bucket_mask);\n        }\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTableInner::find_insert_slot_in_group": [
            "/// Finds the position to insert something in a group.\n///\n/// **This may have false positives and must be fixed up with `fix_insert_slot`\n/// before it's used.**\n///\n/// The function is guaranteed to return the index of an empty or deleted [`Bucket`]\n/// in the range `0..self.buckets()` (`0..=self.bucket_mask`).\n#[inline]\nfn find_insert_slot_in_group(&self, group: &Group, probe_seq: &ProbeSeq) -> Option<usize>{\n        let bit = group.match_empty_or_deleted().lowest_set_bit();\n\n        if likely(bit.is_some()) {\n            // This is the same as `(probe_seq.pos + bit) % self.buckets()` because the number\n            // of buckets is a power of two, and `self.bucket_mask = self.buckets() - 1`.\n            Some((probe_seq.pos + bit.unwrap()) & self.bucket_mask)\n        } else {\n            None\n        }\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTableInner::find_or_find_insert_slot_inner": [
            "/// Searches for an element in the table, or a potential slot where that element could\n/// be inserted (an empty or deleted [`Bucket`] index).\n///\n/// This uses dynamic dispatch to reduce the amount of code generated, but that is\n/// eliminated by LLVM optimizations.\n///\n/// This function does not make any changes to the `data` part of the table, or any\n/// changes to the `items` or `growth_left` field of the table.\n///\n/// The table must have at least 1 empty or deleted `bucket`, otherwise, if the\n/// `eq: &mut dyn FnMut(usize) -> bool` function does not return `true`, this function\n/// will never return (will go into an infinite loop) for tables larger than the group\n/// width, or return an index outside of the table indices range if the table is less\n/// than the group width.\n///\n/// This function is guaranteed to provide the `eq: &mut dyn FnMut(usize) -> bool`\n/// function with only `FULL` buckets' indices and return the `index` of the found\n/// element (as `Ok(index)`). If the element is not found and there is at least 1\n/// empty or deleted [`Bucket`] in the table, the function is guaranteed to return\n/// [`InsertSlot`] with an index in the range `0..self.buckets()`, but in any case,\n/// if this function returns [`InsertSlot`], it will contain an index in the range\n/// `0..=self.buckets()`.\n///\n/// # Safety\n///\n/// The [`RawTableInner`] must have properly initialized control bytes otherwise calling\n/// this function results in [`undefined behavior`].\n///\n/// Attempt to write data at the [`InsertSlot`] returned by this function when the table is\n/// less than the group width and if there was not at least one empty or deleted bucket in\n/// the table will cause immediate [`undefined behavior`]. This is because in this case the\n/// function will return `self.bucket_mask + 1` as an index due to the trailing [`Tag::EMPTY`]\n/// control bytes outside the table range.\n///\n/// [`undefined behavior`]: https://doc.rust-lang.org/reference/behavior-considered-undefined.html\n#[inline]\nunsafe fn find_or_find_insert_slot_inner(\n        &self,\n        hash: u64,\n        eq: &mut dyn FnMut(usize) -> bool,\n    ) -> Result<usize, InsertSlot>{\n        let mut insert_slot = None;\n\n        let tag_hash = Tag::full(hash);\n        let mut probe_seq = self.probe_seq(hash);\n\n        loop {\n            // SAFETY:\n            // * Caller of this function ensures that the control bytes are properly initialized.\n            //\n            // * `ProbeSeq.pos` cannot be greater than `self.bucket_mask = self.buckets() - 1`\n            //   of the table due to masking with `self.bucket_mask` and also because the number\n            //   of buckets is a power of two (see `self.probe_seq` function).\n            //\n            // * Even if `ProbeSeq.pos` returns `position == self.bucket_mask`, it is safe to\n            //   call `Group::load` due to the extended control bytes range, which is\n            //  `self.bucket_mask + 1 + Group::WIDTH` (in fact, this means that the last control\n            //   byte will never be read for the allocated table);\n            //\n            // * Also, even if `RawTableInner` is not already allocated, `ProbeSeq.pos` will\n            //   always return \"0\" (zero), so Group::load will read unaligned `Group::static_empty()`\n            //   bytes, which is safe (see RawTableInner::new).\n            let group = unsafe { Group::load(self.ctrl(probe_seq.pos)) };\n\n            for bit in group.match_tag(tag_hash) {\n                let index = (probe_seq.pos + bit) & self.bucket_mask;\n\n                if likely(eq(index)) {\n                    return Ok(index);\n                }\n            }\n\n            // We didn't find the element we were looking for in the group, try to get an\n            // insertion slot from the group if we don't have one yet.\n            if likely(insert_slot.is_none()) {\n                insert_slot = self.find_insert_slot_in_group(&group, &probe_seq);\n            }\n\n            if let Some(insert_slot) = insert_slot {\n                // Only stop the search if the group contains at least one empty element.\n                // Otherwise, the element that we are looking for might be in a following group.\n                if likely(group.match_empty().any_bit_set()) {\n                    // We must have found a insert slot by now, since the current group contains at\n                    // least one. For tables smaller than the group width, there will still be an\n                    // empty element in the current (and only) group due to the load factor.\n                    unsafe {\n                        // SAFETY:\n                        // * Caller of this function ensures that the control bytes are properly initialized.\n                        //\n                        // * We use this function with the slot / index found by `self.find_insert_slot_in_group`\n                        return Err(self.fix_insert_slot(insert_slot));\n                    }\n                }\n            }\n\n            probe_seq.move_next(self.bucket_mask);\n        }\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTableInner::fix_insert_slot": [
            "/// Fixes up an insertion slot returned by the [`RawTableInner::find_insert_slot_in_group`] method.\n///\n/// In tables smaller than the group width (`self.buckets() < Group::WIDTH`), trailing control\n/// bytes outside the range of the table are filled with [`Tag::EMPTY`] entries. These will unfortunately\n/// trigger a match of [`RawTableInner::find_insert_slot_in_group`] function. This is because\n/// the `Some(bit)` returned by `group.match_empty_or_deleted().lowest_set_bit()` after masking\n/// (`(probe_seq.pos + bit) & self.bucket_mask`) may point to a full bucket that is already occupied.\n/// We detect this situation here and perform a second scan starting at the beginning of the table.\n/// This second scan is guaranteed to find an empty slot (due to the load factor) before hitting the\n/// trailing control bytes (containing [`Tag::EMPTY`] bytes).\n///\n/// If this function is called correctly, it is guaranteed to return [`InsertSlot`] with an\n/// index of an empty or deleted bucket in the range `0..self.buckets()` (see `Warning` and\n/// `Safety`).\n///\n/// # Warning\n///\n/// The table must have at least 1 empty or deleted `bucket`, otherwise if the table is less than\n/// the group width (`self.buckets() < Group::WIDTH`) this function returns an index outside of the\n/// table indices range `0..self.buckets()` (`0..=self.bucket_mask`). Attempt to write data at that\n/// index will cause immediate [`undefined behavior`].\n///\n/// # Safety\n///\n/// The safety rules are directly derived from the safety rules for [`RawTableInner::ctrl`] method.\n/// Thus, in order to uphold those safety contracts, as well as for the correct logic of the work\n/// of this crate, the following rules are necessary and sufficient:\n///\n/// * The [`RawTableInner`] must have properly initialized control bytes otherwise calling this\n///   function results in [`undefined behavior`].\n///\n/// * This function must only be used on insertion slots found by [`RawTableInner::find_insert_slot_in_group`]\n///   (after the `find_insert_slot_in_group` function, but before insertion into the table).\n///\n/// * The `index` must not be greater than the `self.bucket_mask`, i.e. `(index + 1) <= self.buckets()`\n///   (this one is provided by the [`RawTableInner::find_insert_slot_in_group`] function).\n///\n/// Calling this function with an index not provided by [`RawTableInner::find_insert_slot_in_group`]\n/// may result in [`undefined behavior`] even if the index satisfies the safety rules of the\n/// [`RawTableInner::ctrl`] function (`index < self.bucket_mask + 1 + Group::WIDTH`).\n///\n/// [`RawTableInner::ctrl`]: RawTableInner::ctrl\n/// [`RawTableInner::find_insert_slot_in_group`]: RawTableInner::find_insert_slot_in_group\n/// [`undefined behavior`]: https://doc.rust-lang.org/reference/behavior-considered-undefined.html\n#[inline]\nunsafe fn fix_insert_slot(&self, mut index: usize) -> InsertSlot{\n        // SAFETY: The caller of this function ensures that `index` is in the range `0..=self.bucket_mask`.\n        if unlikely(self.is_bucket_full(index)) {\n            debug_assert!(self.bucket_mask < Group::WIDTH);\n            // SAFETY:\n            //\n            // * Since the caller of this function ensures that the control bytes are properly\n            //   initialized and `ptr = self.ctrl(0)` points to the start of the array of control\n            //   bytes, therefore: `ctrl` is valid for reads, properly aligned to `Group::WIDTH`\n            //   and points to the properly initialized control bytes (see also\n            //   `TableLayout::calculate_layout_for` and `ptr::read`);\n            //\n            // * Because the caller of this function ensures that the index was provided by the\n            //   `self.find_insert_slot_in_group()` function, so for for tables larger than the\n            //   group width (self.buckets() >= Group::WIDTH), we will never end up in the given\n            //   branch, since `(probe_seq.pos + bit) & self.bucket_mask` in `find_insert_slot_in_group`\n            //   cannot return a full bucket index. For tables smaller than the group width, calling\n            //   the `unwrap_unchecked` function is also safe, as the trailing control bytes outside\n            //   the range of the table are filled with EMPTY bytes (and we know for sure that there\n            //   is at least one FULL bucket), so this second scan either finds an empty slot (due to\n            //   the load factor) or hits the trailing control bytes (containing EMPTY).\n            index = Group::load_aligned(self.ctrl(0))\n                .match_empty_or_deleted()\n                .lowest_set_bit()\n                .unwrap_unchecked();\n        }\n        InsertSlot { index }\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTableInner::free_buckets": [
            "/// Deallocates the table without dropping any entries.\n///\n/// # Note\n///\n/// This function must be called only after [`drop_elements`](RawTableInner::drop_elements),\n/// else it can lead to leaking of memory. Also calling this function automatically\n/// makes invalid (dangling) all instances of buckets ([`Bucket`]) and makes invalid\n/// (dangling) the `ctrl` field of the table.\n///\n/// # Safety\n///\n/// If any of the following conditions are violated, the result is [`Undefined Behavior`]:\n///\n/// * The [`RawTableInner`] has already been allocated;\n///\n/// * The `alloc` must be the same [`Allocator`] as the `Allocator` that was used\n///   to allocate this table.\n///\n/// * The `table_layout` must be the same [`TableLayout`] as the `TableLayout` that was used\n///   to allocate this table.\n///\n/// See also [`GlobalAlloc::dealloc`] or [`Allocator::deallocate`] for more  information.\n///\n/// [`Undefined Behavior`]: https://doc.rust-lang.org/reference/behavior-considered-undefined.html\n/// [`GlobalAlloc::dealloc`]: https://doc.rust-lang.org/alloc/alloc/trait.GlobalAlloc.html#tymethod.dealloc\n/// [`Allocator::deallocate`]: https://doc.rust-lang.org/alloc/alloc/trait.Allocator.html#tymethod.deallocate\n#[inline]\nunsafe fn free_buckets<A>(&mut self, alloc: &A, table_layout: TableLayout)\n    where\n        A: Allocator,{\n        // SAFETY: The caller must uphold the safety contract for `free_buckets`\n        // method.\n        let (ptr, layout) = self.allocation_info(table_layout);\n        alloc.deallocate(ptr, layout);\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTableInner::full_buckets_indices": [
            "/// Returns an iterator over full buckets indices in the table.\n///\n/// # Safety\n///\n/// Behavior is undefined if any of the following conditions are violated:\n///\n/// * The caller has to ensure that the `RawTableInner` outlives the\n///   `FullBucketsIndices`. Because we cannot make the `next` method\n///   unsafe on the `FullBucketsIndices` struct, we have to make the\n///   `full_buckets_indices` method unsafe.\n///\n/// * The [`RawTableInner`] must have properly initialized control bytes.\n#[inline(always)]\nunsafe fn full_buckets_indices(&self) -> FullBucketsIndices{\n        // SAFETY:\n        // 1. Since the caller of this function ensures that the control bytes\n        //    are properly initialized and `self.ctrl(0)` points to the start\n        //    of the array of control bytes, therefore: `ctrl` is valid for reads,\n        //    properly aligned to `Group::WIDTH` and points to the properly initialized\n        //    control bytes.\n        // 2. The value of `items` is equal to the amount of data (values) added\n        //    to the table.\n        //\n        //                         `ctrl` points here (to the start\n        //                         of the first control byte `CT0`)\n        //                          \n        // [Pad], T_n, ..., T1, T0, |CT0, CT1, ..., CT_n|, Group::WIDTH\n        //                           \\________  ________/\n        //                                    \\/\n        //       `n = buckets - 1`, i.e. `RawTableInner::buckets() - 1`\n        //\n        // where: T0...T_n  - our stored data;\n        //        CT0...CT_n - control bytes or metadata for `data`.\n        let ctrl = NonNull::new_unchecked(self.ctrl(0).cast::<u8>());\n\n        FullBucketsIndices {\n            // Load the first group\n            // SAFETY: See explanation above.\n            current_group: Group::load_aligned(ctrl.as_ptr().cast())\n                .match_full()\n                .into_iter(),\n            group_first_index: 0,\n            ctrl,\n            items: self.items,\n        }\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTableInner::is_bucket_full": [
            "/// Checks whether the bucket at `index` is full.\n///\n/// # Safety\n///\n/// The caller must ensure `index` is less than the number of buckets.\n#[inline]\nunsafe fn is_bucket_full(&self, index: usize) -> bool{\n        debug_assert!(index < self.buckets());\n        (*self.ctrl(index)).is_full()\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTableInner::is_empty_singleton": [
            "#[inline]\nfn is_empty_singleton(&self) -> bool{\n        self.bucket_mask == 0\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTableInner::is_in_same_group": [
            "#[inline]\nfn is_in_same_group(&self, i: usize, new_i: usize, hash: u64) -> bool{\n        let probe_seq_pos = self.probe_seq(hash).pos;\n        let probe_index =\n            |pos: usize| (pos.wrapping_sub(probe_seq_pos) & self.bucket_mask) / Group::WIDTH;\n        probe_index(i) == probe_index(new_i)\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTableInner::iter": [
            "/// Returns an iterator over every element in the table.\n///\n/// # Safety\n///\n/// If any of the following conditions are violated, the result\n/// is [`undefined behavior`]:\n///\n/// * The caller has to ensure that the `RawTableInner` outlives the\n///   `RawIter`. Because we cannot make the `next` method unsafe on\n///   the `RawIter` struct, we have to make the `iter` method unsafe.\n///\n/// * The [`RawTableInner`] must have properly initialized control bytes.\n///\n/// The type `T` must be the actual type of the elements stored in the table,\n/// otherwise using the returned [`RawIter`] results in [`undefined behavior`].\n///\n/// [`undefined behavior`]: https://doc.rust-lang.org/reference/behavior-considered-undefined.html\n#[inline]\nunsafe fn iter<T>(&self) -> RawIter<T>{\n        // SAFETY:\n        // 1. Since the caller of this function ensures that the control bytes\n        //    are properly initialized and `self.data_end()` points to the start\n        //    of the array of control bytes, therefore: `ctrl` is valid for reads,\n        //    properly aligned to `Group::WIDTH` and points to the properly initialized\n        //    control bytes.\n        // 2. `data` bucket index in the table is equal to the `ctrl` index (i.e.\n        //    equal to zero).\n        // 3. We pass the exact value of buckets of the table to the function.\n        //\n        //                         `ctrl` points here (to the start\n        //                         of the first control byte `CT0`)\n        //                          \n        // [Pad], T_n, ..., T1, T0, |CT0, CT1, ..., CT_n|, CTa_0, CTa_1, ..., CTa_m\n        //                           \\________  ________/\n        //                                    \\/\n        //       `n = buckets - 1`, i.e. `RawTableInner::buckets() - 1`\n        //\n        // where: T0...T_n  - our stored data;\n        //        CT0...CT_n - control bytes or metadata for `data`.\n        //        CTa_0...CTa_m - additional control bytes, where `m = Group::WIDTH - 1` (so that the search\n        //                        with loading `Group` bytes from the heap works properly, even if the result\n        //                        of `h1(hash) & self.bucket_mask` is equal to `self.bucket_mask`). See also\n        //                        `RawTableInner::set_ctrl` function.\n        //\n        // P.S. `h1(hash) & self.bucket_mask` is the same as `hash as usize % self.buckets()` because the number\n        // of buckets is a power of two, and `self.bucket_mask = self.buckets() - 1`.\n        let data = Bucket::from_base_index(self.data_end(), 0);\n        RawIter {\n            // SAFETY: See explanation above\n            iter: RawIterRange::new(self.ctrl.as_ptr(), data, self.buckets()),\n            items: self.items,\n        }\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTableInner::new": [
            "/// Creates a new empty hash table without allocating any memory.\n///\n/// In effect this returns a table with exactly 1 bucket. However we can\n/// leave the data pointer dangling since that bucket is never accessed\n/// due to our load factor forcing us to always have at least 1 free bucket.\n#[inline]\nconst fn new() -> Self{\n        Self {\n            // Be careful to cast the entire slice to a raw pointer.\n            ctrl: unsafe {\n                NonNull::new_unchecked(Group::static_empty().as_ptr().cast_mut().cast())\n            },\n            bucket_mask: 0,\n            items: 0,\n            growth_left: 0,\n        }\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTableInner::new_uninitialized": [
            "/// Allocates a new [`RawTableInner`] with the given number of buckets.\n/// The control bytes and buckets are left uninitialized.\n///\n/// # Safety\n///\n/// The caller of this function must ensure that the `buckets` is power of two\n/// and also initialize all control bytes of the length `self.bucket_mask + 1 +\n/// Group::WIDTH` with the [`Tag::EMPTY`] bytes.\n///\n/// See also [`Allocator`] API for other safety concerns.\n///\n/// [`Allocator`]: https://doc.rust-lang.org/alloc/alloc/trait.Allocator.html\ninline\nunsafe fn new_uninitialized<A>(\n        alloc: &A,\n        table_layout: TableLayout,\n        buckets: usize,\n        fallibility: Fallibility,\n    ) -> Result<Self, TryReserveError>\n    where\n        A: Allocator,{\n        debug_assert!(buckets.is_power_of_two());\n\n        // Avoid `Option::ok_or_else` because it bloats LLVM IR.\n        let (layout, ctrl_offset) = match table_layout.calculate_layout_for(buckets) {\n            Some(lco) => lco,\n            None => return Err(fallibility.capacity_overflow()),\n        };\n\n        let ptr: NonNull<u8> = match do_alloc(alloc, layout) {\n            Ok(block) => block.cast(),\n            Err(_) => return Err(fallibility.alloc_err(layout)),\n        };\n\n        // SAFETY: null pointer will be caught in above check\n        let ctrl = NonNull::new_unchecked(ptr.as_ptr().add(ctrl_offset));\n        Ok(Self {\n            ctrl,\n            bucket_mask: buckets - 1,\n            items: 0,\n            growth_left: bucket_mask_to_capacity(buckets - 1),\n        })\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTableInner::num_ctrl_bytes": [
            "#[inline]\nfn num_ctrl_bytes(&self) -> usize{\n        self.bucket_mask + 1 + Group::WIDTH\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTableInner::prepare_insert_slot": [
            "/// Searches for an empty or deleted bucket which is suitable for inserting a new\n/// element and sets the hash for that slot. Returns an index of that slot and the\n/// old control byte stored in the found index.\n///\n/// This function does not check if the given element exists in the table. Also,\n/// this function does not check if there is enough space in the table to insert\n/// a new element. The caller of the function must make sure that the table has at\n/// least 1 empty or deleted `bucket`, otherwise this function will never return\n/// (will go into an infinite loop) for tables larger than the group width, or\n/// return an index outside of the table indices range if the table is less than\n/// the group width.\n///\n/// If there is at least 1 empty or deleted `bucket` in the table, the function is\n/// guaranteed to return an `index` in the range `0..self.buckets()`, but in any case,\n/// if this function returns an `index` it will be in the range `0..=self.buckets()`.\n///\n/// This function does not make any changes to the `data` parts of the table,\n/// or any changes to the `items` or `growth_left` field of the table.\n///\n/// # Safety\n///\n/// The safety rules are directly derived from the safety rules for the\n/// [`RawTableInner::set_ctrl_hash`] and [`RawTableInner::find_insert_slot`] methods.\n/// Thus, in order to uphold the safety contracts for that methods, as well as for\n/// the correct logic of the work of this crate, you must observe the following rules\n/// when calling this function:\n///\n/// * The [`RawTableInner`] has already been allocated and has properly initialized\n///   control bytes otherwise calling this function results in [`undefined behavior`].\n///\n/// * The caller of this function must ensure that the \"data\" parts of the table\n///   will have an entry in the returned index (matching the given hash) right\n///   after calling this function.\n///\n/// Attempt to write data at the `index` returned by this function when the table is\n/// less than the group width and if there was not at least one empty or deleted bucket in\n/// the table will cause immediate [`undefined behavior`]. This is because in this case the\n/// function will return `self.bucket_mask + 1` as an index due to the trailing [`Tag::EMPTY`]\n/// control bytes outside the table range.\n///\n/// The caller must independently increase the `items` field of the table, and also,\n/// if the old control byte was [`Tag::EMPTY`], then decrease the table's `growth_left`\n/// field, and do not change it if the old control byte was [`Tag::DELETED`].\n///\n/// See also [`Bucket::as_ptr`] method, for more information about of properly removing\n/// or saving `element` from / into the [`RawTable`] / [`RawTableInner`].\n///\n/// [`Bucket::as_ptr`]: Bucket::as_ptr\n/// [`undefined behavior`]: https://doc.rust-lang.org/reference/behavior-considered-undefined.html\n/// [`RawTableInner::ctrl`]: RawTableInner::ctrl\n/// [`RawTableInner::set_ctrl_hash`]: RawTableInner::set_ctrl_hash\n/// [`RawTableInner::find_insert_slot`]: RawTableInner::find_insert_slot\n#[inline]\nunsafe fn prepare_insert_slot(&mut self, hash: u64) -> (usize, Tag){\n        // SAFETY: Caller of this function ensures that the control bytes are properly initialized.\n        let index: usize = self.find_insert_slot(hash).index;\n        // SAFETY:\n        // 1. The `find_insert_slot` function either returns an `index` less than or\n        //    equal to `self.buckets() = self.bucket_mask + 1` of the table, or never\n        //    returns if it cannot find an empty or deleted slot.\n        // 2. The caller of this function guarantees that the table has already been\n        //    allocated\n        let old_ctrl = *self.ctrl(index);\n        self.set_ctrl_hash(index, hash);\n        (index, old_ctrl)\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTableInner::prepare_rehash_in_place": [
            "/// Prepares for rehashing data in place (that is, without allocating new memory).\n/// Converts all full index `control bytes` to `Tag::DELETED` and all `Tag::DELETED` control\n/// bytes to `Tag::EMPTY`, i.e. performs the following conversion:\n///\n/// - `Tag::EMPTY` control bytes   -> `Tag::EMPTY`;\n/// - `Tag::DELETED` control bytes -> `Tag::EMPTY`;\n/// - `FULL` control bytes    -> `Tag::DELETED`.\n///\n/// This function does not make any changes to the `data` parts of the table,\n/// or any changes to the `items` or `growth_left` field of the table.\n///\n/// # Safety\n///\n/// You must observe the following safety rules when calling this function:\n///\n/// * The [`RawTableInner`] has already been allocated;\n///\n/// * The caller of this function must convert the `Tag::DELETED` bytes back to `FULL`\n///   bytes when re-inserting them into their ideal position (which was impossible\n///   to do during the first insert due to tombstones). If the caller does not do\n///   this, then calling this function may result in a memory leak.\n///\n/// * The [`RawTableInner`] must have properly initialized control bytes otherwise\n///   calling this function results in [`undefined behavior`].\n///\n/// Calling this function on a table that has not been allocated results in\n/// [`undefined behavior`].\n///\n/// See also [`Bucket::as_ptr`] method, for more information about of properly removing\n/// or saving `data element` from / into the [`RawTable`] / [`RawTableInner`].\n///\n/// [`Bucket::as_ptr`]: Bucket::as_ptr\n/// [`undefined behavior`]: https://doc.rust-lang.org/reference/behavior-considered-undefined.html\n#[allow(clippy::mut_mut)]\n#[inline]\nunsafe fn prepare_rehash_in_place(&mut self){\n        // Bulk convert all full control bytes to DELETED, and all DELETED control bytes to EMPTY.\n        // This effectively frees up all buckets containing a DELETED entry.\n        //\n        // SAFETY:\n        // 1. `i` is guaranteed to be within bounds since we are iterating from zero to `buckets - 1`;\n        // 2. Even if `i` will be `i == self.bucket_mask`, it is safe to call `Group::load_aligned`\n        //    due to the extended control bytes range, which is `self.bucket_mask + 1 + Group::WIDTH`;\n        // 3. The caller of this function guarantees that [`RawTableInner`] has already been allocated;\n        // 4. We can use `Group::load_aligned` and `Group::store_aligned` here since we start from 0\n        //    and go to the end with a step equal to `Group::WIDTH` (see TableLayout::calculate_layout_for).\n        for i in (0..self.buckets()).step_by(Group::WIDTH) {\n            let group = Group::load_aligned(self.ctrl(i));\n            let group = group.convert_special_to_empty_and_full_to_deleted();\n            group.store_aligned(self.ctrl(i));\n        }\n\n        // Fix up the trailing control bytes. See the comments in set_ctrl\n        // for the handling of tables smaller than the group width.\n        //\n        // SAFETY: The caller of this function guarantees that [`RawTableInner`]\n        // has already been allocated\n        if unlikely(self.buckets() < Group::WIDTH) {\n            // SAFETY: We have `self.bucket_mask + 1 + Group::WIDTH` number of control bytes,\n            // so copying `self.buckets() == self.bucket_mask + 1` bytes with offset equal to\n            // `Group::WIDTH` is safe\n            self.ctrl(0)\n                .copy_to(self.ctrl(Group::WIDTH), self.buckets());\n        } else {\n            // SAFETY: We have `self.bucket_mask + 1 + Group::WIDTH` number of\n            // control bytes,so copying `Group::WIDTH` bytes with offset equal\n            // to `self.buckets() == self.bucket_mask + 1` is safe\n            self.ctrl(0)\n                .copy_to(self.ctrl(self.buckets()), Group::WIDTH);\n        }\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTableInner::prepare_resize": [
            "/// Attempts to allocate a new hash table with at least enough capacity\n/// for inserting the given number of elements without reallocating,\n/// and return it inside `ScopeGuard` to protect against panic in the hash\n/// function.\n///\n/// # Note\n///\n/// It is recommended (but not required):\n///\n/// * That the new table's `capacity` be greater than or equal to `self.items`.\n///\n/// * The `alloc` is the same [`Allocator`] as the `Allocator` used\n///   to allocate this table.\n///\n/// * The `table_layout` is the same [`TableLayout`] as the `TableLayout` used\n///   to allocate this table.\n///\n/// If `table_layout` does not match the `TableLayout` that was used to allocate\n/// this table, then using `mem::swap` with the `self` and the new table returned\n/// by this function results in [`undefined behavior`].\n///\n/// [`undefined behavior`]: https://doc.rust-lang.org/reference/behavior-considered-undefined.html\n#[allow(clippy::mut_mut)]\n#[inline]\nfn prepare_resize<'a, A>(\n        &self,\n        alloc: &'a A,\n        table_layout: TableLayout,\n        capacity: usize,\n        fallibility: Fallibility,\n    ) -> Result<crate::scopeguard::ScopeGuard<Self, impl FnMut(&mut Self) + 'a>, TryReserveError>\n    where\n        A: Allocator,{\n        debug_assert!(self.items <= capacity);\n\n        // Allocate and initialize the new table.\n        let new_table =\n            RawTableInner::fallible_with_capacity(alloc, table_layout, capacity, fallibility)?;\n\n        // The hash function may panic, in which case we simply free the new\n        // table without dropping any elements that may have been copied into\n        // it.\n        //\n        // This guard is also used to free the old table on success, see\n        // the comment at the bottom of this function.\n        Ok(guard(new_table, move |self_| {\n            if !self_.is_empty_singleton() {\n                // SAFETY:\n                // 1. We have checked that our table is allocated.\n                // 2. We know for sure that the `alloc` and `table_layout` matches the\n                //    [`Allocator`] and [`TableLayout`] used to allocate this table.\n                unsafe { self_.free_buckets(alloc, table_layout) };\n            }\n        }))\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTableInner::probe_seq": [
            "/// Returns an iterator-like object for a probe sequence on the table.\n///\n/// This iterator never terminates, but is guaranteed to visit each bucket\n/// group exactly once. The loop using `probe_seq` must terminate upon\n/// reaching a group containing an empty bucket.\n#[inline]\nfn probe_seq(&self, hash: u64) -> ProbeSeq{\n        ProbeSeq {\n            // This is the same as `hash as usize % self.buckets()` because the number\n            // of buckets is a power of two, and `self.bucket_mask = self.buckets() - 1`.\n            pos: h1(hash) & self.bucket_mask,\n            stride: 0,\n        }\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTableInner::record_item_insert_at": [
            "#[inline]\nunsafe fn record_item_insert_at(&mut self, index: usize, old_ctrl: Tag, hash: u64){\n        self.growth_left -= usize::from(old_ctrl.special_is_empty());\n        self.set_ctrl_hash(index, hash);\n        self.items += 1;\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTableInner::rehash_in_place": [
            "/// Rehashes the contents of the table in place (i.e. without changing the\n/// allocation).\n///\n/// If `hasher` panics then some the table's contents may be lost.\n///\n/// This uses dynamic dispatch to reduce the amount of\n/// code generated, but it is eliminated by LLVM optimizations when inlined.\n///\n/// # Safety\n///\n/// If any of the following conditions are violated, the result is [`undefined behavior`]:\n///\n/// * The `size_of` must be equal to the size of the elements stored in the table;\n///\n/// * The `drop` function (`fn(*mut u8)`) must be the actual drop function of\n///   the elements stored in the table.\n///\n/// * The [`RawTableInner`] has already been allocated;\n///\n/// * The [`RawTableInner`] must have properly initialized control bytes.\n///\n/// [`undefined behavior`]: https://doc.rust-lang.org/reference/behavior-considered-undefined.html\n#[allow(clippy::inline_always)]\ninline(always)\nunsafe fn rehash_in_place(\n        &mut self,\n        hasher: &dyn Fn(&mut Self, usize) -> u64,\n        size_of: usize,\n        drop: Option<unsafe fn(*mut u8)>,\n    ){\n        // If the hash function panics then properly clean up any elements\n        // that we haven't rehashed yet. We unfortunately can't preserve the\n        // element since we lost their hash and have no way of recovering it\n        // without risking another panic.\n        self.prepare_rehash_in_place();\n\n        let mut guard = guard(self, move |self_| {\n            if let Some(drop) = drop {\n                for i in 0..self_.buckets() {\n                    if *self_.ctrl(i) == Tag::DELETED {\n                        self_.set_ctrl(i, Tag::EMPTY);\n                        drop(self_.bucket_ptr(i, size_of));\n                        self_.items -= 1;\n                    }\n                }\n            }\n            self_.growth_left = bucket_mask_to_capacity(self_.bucket_mask) - self_.items;\n        });\n\n        // At this point, DELETED elements are elements that we haven't\n        // rehashed yet. Find them and re-insert them at their ideal\n        // position.\n        'outer: for i in 0..guard.buckets() {\n            if *guard.ctrl(i) != Tag::DELETED {\n                continue;\n            }\n\n            let i_p = guard.bucket_ptr(i, size_of);\n\n            'inner: loop {\n                // Hash the current item\n                let hash = hasher(*guard, i);\n\n                // Search for a suitable place to put it\n                //\n                // SAFETY: Caller of this function ensures that the control bytes\n                // are properly initialized.\n                let new_i = guard.find_insert_slot(hash).index;\n\n                // Probing works by scanning through all of the control\n                // bytes in groups, which may not be aligned to the group\n                // size. If both the new and old position fall within the\n                // same unaligned group, then there is no benefit in moving\n                // it and we can just continue to the next item.\n                if likely(guard.is_in_same_group(i, new_i, hash)) {\n                    guard.set_ctrl_hash(i, hash);\n                    continue 'outer;\n                }\n\n                let new_i_p = guard.bucket_ptr(new_i, size_of);\n\n                // We are moving the current item to a new position. Write\n                // our H2 to the control byte of the new position.\n                let prev_ctrl = guard.replace_ctrl_hash(new_i, hash);\n                if prev_ctrl == Tag::EMPTY {\n                    guard.set_ctrl(i, Tag::EMPTY);\n                    // If the target slot is empty, simply move the current\n                    // element into the new slot and clear the old control\n                    // byte.\n                    ptr::copy_nonoverlapping(i_p, new_i_p, size_of);\n                    continue 'outer;\n                } else {\n                    // If the target slot is occupied, swap the two elements\n                    // and then continue processing the element that we just\n                    // swapped into the old slot.\n                    debug_assert_eq!(prev_ctrl, Tag::DELETED);\n                    ptr::swap_nonoverlapping(i_p, new_i_p, size_of);\n                    continue 'inner;\n                }\n            }\n        }\n\n        guard.growth_left = bucket_mask_to_capacity(guard.bucket_mask) - guard.items;\n\n        mem::forget(guard);\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTableInner::replace_ctrl_hash": [
            "/// Replaces the hash in the control byte at the given index with the provided one,\n/// and possibly also replicates the new control byte at the end of the array of control\n/// bytes, returning the old control byte.\n///\n/// This function does not make any changes to the `data` parts of the table,\n/// or any changes to the `items` or `growth_left` field of the table.\n///\n/// # Safety\n///\n/// The safety rules are directly derived from the safety rules for [`RawTableInner::set_ctrl_hash`]\n/// and [`RawTableInner::ctrl`] methods. Thus, in order to uphold the safety contracts for both\n/// methods, you must observe the following rules when calling this function:\n///\n/// * The [`RawTableInner`] has already been allocated;\n///\n/// * The `index` must not be greater than the `RawTableInner.bucket_mask`, i.e.\n///   `index <= RawTableInner.bucket_mask` or, in other words, `(index + 1)` must\n///   be no greater than the number returned by the function [`RawTableInner::buckets`].\n///\n/// Calling this function on a table that has not been allocated results in [`undefined behavior`].\n///\n/// See also [`Bucket::as_ptr`] method, for more information about of properly removing\n/// or saving `data element` from / into the [`RawTable`] / [`RawTableInner`].\n///\n/// [`RawTableInner::set_ctrl_hash`]: RawTableInner::set_ctrl_hash\n/// [`RawTableInner::buckets`]: RawTableInner::buckets\n/// [`Bucket::as_ptr`]: Bucket::as_ptr\n/// [`undefined behavior`]: https://doc.rust-lang.org/reference/behavior-considered-undefined.html\n#[inline]\nunsafe fn replace_ctrl_hash(&mut self, index: usize, hash: u64) -> Tag{\n        // SAFETY: The caller must uphold the safety rules for the [`RawTableInner::replace_ctrl_hash`]\n        let prev_ctrl = *self.ctrl(index);\n        self.set_ctrl_hash(index, hash);\n        prev_ctrl\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTableInner::reserve_rehash_inner": [
            "/// Reserves or rehashes to make room for `additional` more elements.\n///\n/// This uses dynamic dispatch to reduce the amount of\n/// code generated, but it is eliminated by LLVM optimizations when inlined.\n///\n/// # Safety\n///\n/// If any of the following conditions are violated, the result is\n/// [`undefined behavior`]:\n///\n/// * The `alloc` must be the same [`Allocator`] as the `Allocator` used\n///   to allocate this table.\n///\n/// * The `layout` must be the same [`TableLayout`] as the `TableLayout`\n///   used to allocate this table.\n///\n/// * The `drop` function (`fn(*mut u8)`) must be the actual drop function of\n///   the elements stored in the table.\n///\n/// * The [`RawTableInner`] must have properly initialized control bytes.\n///\n/// [`undefined behavior`]: https://doc.rust-lang.org/reference/behavior-considered-undefined.html\n#[allow(clippy::inline_always)]\n#[inline(always)]\nunsafe fn reserve_rehash_inner<A>(\n        &mut self,\n        alloc: &A,\n        additional: usize,\n        hasher: &dyn Fn(&mut Self, usize) -> u64,\n        fallibility: Fallibility,\n        layout: TableLayout,\n        drop: Option<unsafe fn(*mut u8)>,\n    ) -> Result<(), TryReserveError>\n    where\n        A: Allocator,{\n        // Avoid `Option::ok_or_else` because it bloats LLVM IR.\n        let new_items = match self.items.checked_add(additional) {\n            Some(new_items) => new_items,\n            None => return Err(fallibility.capacity_overflow()),\n        };\n        let full_capacity = bucket_mask_to_capacity(self.bucket_mask);\n        if new_items <= full_capacity / 2 {\n            // Rehash in-place without re-allocating if we have plenty of spare\n            // capacity that is locked up due to DELETED entries.\n\n            // SAFETY:\n            // 1. We know for sure that `[`RawTableInner`]` has already been allocated\n            //    (since new_items <= full_capacity / 2);\n            // 2. The caller ensures that `drop` function is the actual drop function of\n            //    the elements stored in the table.\n            // 3. The caller ensures that `layout` matches the [`TableLayout`] that was\n            //    used to allocate this table.\n            // 4. The caller ensures that the control bytes of the `RawTableInner`\n            //    are already initialized.\n            self.rehash_in_place(hasher, layout.size, drop);\n            Ok(())\n        } else {\n            // Otherwise, conservatively resize to at least the next size up\n            // to avoid churning deletes into frequent rehashes.\n            //\n            // SAFETY:\n            // 1. We know for sure that `capacity >= self.items`.\n            // 2. The caller ensures that `alloc` and `layout` matches the [`Allocator`] and\n            //    [`TableLayout`] that were used to allocate this table.\n            // 3. The caller ensures that the control bytes of the `RawTableInner`\n            //    are already initialized.\n            self.resize_inner(\n                alloc,\n                usize::max(new_items, full_capacity + 1),\n                hasher,\n                fallibility,\n                layout,\n            )\n        }\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTableInner::resize_inner": [
            "/// Allocates a new table of a different size and moves the contents of the\n/// current table into it.\n///\n/// This uses dynamic dispatch to reduce the amount of\n/// code generated, but it is eliminated by LLVM optimizations when inlined.\n///\n/// # Safety\n///\n/// If any of the following conditions are violated, the result is\n/// [`undefined behavior`]:\n///\n/// * The `alloc` must be the same [`Allocator`] as the `Allocator` used\n///   to allocate this table;\n///\n/// * The `layout` must be the same [`TableLayout`] as the `TableLayout`\n///   used to allocate this table;\n///\n/// * The [`RawTableInner`] must have properly initialized control bytes.\n///\n/// The caller of this function must ensure that `capacity >= self.items`\n/// otherwise:\n///\n/// * If `self.items != 0`, calling of this function with `capacity == 0`\n///   results in [`undefined behavior`].\n///\n/// * If `capacity_to_buckets(capacity) < Group::WIDTH` and\n///   `self.items > capacity_to_buckets(capacity)` calling this function\n///   results in [`undefined behavior`].\n///\n/// * If `capacity_to_buckets(capacity) >= Group::WIDTH` and\n///   `self.items > capacity_to_buckets(capacity)` calling this function\n///   are never return (will go into an infinite loop).\n///\n/// Note: It is recommended (but not required) that the new table's `capacity`\n/// be greater than or equal to `self.items`. In case if `capacity <= self.items`\n/// this function can never return. See [`RawTableInner::find_insert_slot`] for\n/// more information.\n///\n/// [`RawTableInner::find_insert_slot`]: RawTableInner::find_insert_slot\n/// [`undefined behavior`]: https://doc.rust-lang.org/reference/behavior-considered-undefined.html\n#[allow(clippy::inline_always)]\n#[inline(always)]\nunsafe fn resize_inner<A>(\n        &mut self,\n        alloc: &A,\n        capacity: usize,\n        hasher: &dyn Fn(&mut Self, usize) -> u64,\n        fallibility: Fallibility,\n        layout: TableLayout,\n    ) -> Result<(), TryReserveError>\n    where\n        A: Allocator,{\n        // SAFETY: We know for sure that `alloc` and `layout` matches the [`Allocator`] and [`TableLayout`]\n        // that were used to allocate this table.\n        let mut new_table = self.prepare_resize(alloc, layout, capacity, fallibility)?;\n\n        // SAFETY: We know for sure that RawTableInner will outlive the\n        // returned `FullBucketsIndices` iterator, and the caller of this\n        // function ensures that the control bytes are properly initialized.\n        for full_byte_index in self.full_buckets_indices() {\n            // This may panic.\n            let hash = hasher(self, full_byte_index);\n\n            // SAFETY:\n            // We can use a simpler version of insert() here since:\n            // 1. There are no DELETED entries.\n            // 2. We know there is enough space in the table.\n            // 3. All elements are unique.\n            // 4. The caller of this function guarantees that `capacity > 0`\n            //    so `new_table` must already have some allocated memory.\n            // 5. We set `growth_left` and `items` fields of the new table\n            //    after the loop.\n            // 6. We insert into the table, at the returned index, the data\n            //    matching the given hash immediately after calling this function.\n            let (new_index, _) = new_table.prepare_insert_slot(hash);\n\n            // SAFETY:\n            //\n            // * `src` is valid for reads of `layout.size` bytes, since the\n            //   table is alive and the `full_byte_index` is guaranteed to be\n            //   within bounds (see `FullBucketsIndices::next_impl`);\n            //\n            // * `dst` is valid for writes of `layout.size` bytes, since the\n            //   caller ensures that `table_layout` matches the [`TableLayout`]\n            //   that was used to allocate old table and we have the `new_index`\n            //   returned by `prepare_insert_slot`.\n            //\n            // * Both `src` and `dst` are properly aligned.\n            //\n            // * Both `src` and `dst` point to different region of memory.\n            ptr::copy_nonoverlapping(\n                self.bucket_ptr(full_byte_index, layout.size),\n                new_table.bucket_ptr(new_index, layout.size),\n                layout.size,\n            );\n        }\n\n        // The hash function didn't panic, so we can safely set the\n        // `growth_left` and `items` fields of the new table.\n        new_table.growth_left -= self.items;\n        new_table.items = self.items;\n\n        // We successfully copied all elements without panicking. Now replace\n        // self with the new table. The old table will have its memory freed but\n        // the items will not be dropped (since they have been moved into the\n        // new table).\n        // SAFETY: The caller ensures that `table_layout` matches the [`TableLayout`]\n        // that was used to allocate this table.\n        mem::swap(self, &mut new_table);\n\n        Ok(())\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTableInner::set_ctrl": [
            "/// Sets a control byte, and possibly also the replicated control byte at\n/// the end of the array.\n///\n/// This function does not make any changes to the `data` parts of the table,\n/// or any changes to the `items` or `growth_left` field of the table.\n///\n/// # Safety\n///\n/// You must observe the following safety rules when calling this function:\n///\n/// * The [`RawTableInner`] has already been allocated;\n///\n/// * The `index` must not be greater than the `RawTableInner.bucket_mask`, i.e.\n///   `index <= RawTableInner.bucket_mask` or, in other words, `(index + 1)` must\n///   be no greater than the number returned by the function [`RawTableInner::buckets`].\n///\n/// Calling this function on a table that has not been allocated results in [`undefined behavior`].\n///\n/// See also [`Bucket::as_ptr`] method, for more information about of properly removing\n/// or saving `data element` from / into the [`RawTable`] / [`RawTableInner`].\n///\n/// [`RawTableInner::buckets`]: RawTableInner::buckets\n/// [`Bucket::as_ptr`]: Bucket::as_ptr\n/// [`undefined behavior`]: https://doc.rust-lang.org/reference/behavior-considered-undefined.html\n#[inline]\nunsafe fn set_ctrl(&mut self, index: usize, ctrl: Tag){\n        // Replicate the first Group::WIDTH control bytes at the end of\n        // the array without using a branch. If the tables smaller than\n        // the group width (self.buckets() < Group::WIDTH),\n        // `index2 = Group::WIDTH + index`, otherwise `index2` is:\n        //\n        // - If index >= Group::WIDTH then index == index2.\n        // - Otherwise index2 == self.bucket_mask + 1 + index.\n        //\n        // The very last replicated control byte is never actually read because\n        // we mask the initial index for unaligned loads, but we write it\n        // anyways because it makes the set_ctrl implementation simpler.\n        //\n        // If there are fewer buckets than Group::WIDTH then this code will\n        // replicate the buckets at the end of the trailing group. For example\n        // with 2 buckets and a group size of 4, the control bytes will look\n        // like this:\n        //\n        //     Real    |             Replicated\n        // ---------------------------------------------\n        // | [A] | [B] | [Tag::EMPTY] | [EMPTY] | [A] | [B] |\n        // ---------------------------------------------\n\n        // This is the same as `(index.wrapping_sub(Group::WIDTH)) % self.buckets() + Group::WIDTH`\n        // because the number of buckets is a power of two, and `self.bucket_mask = self.buckets() - 1`.\n        let index2 = ((index.wrapping_sub(Group::WIDTH)) & self.bucket_mask) + Group::WIDTH;\n\n        // SAFETY: The caller must uphold the safety rules for the [`RawTableInner::set_ctrl`]\n        *self.ctrl(index) = ctrl;\n        *self.ctrl(index2) = ctrl;\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTableInner::set_ctrl_hash": [
            "/// Sets a control byte to the hash, and possibly also the replicated control byte at\n/// the end of the array.\n///\n/// This function does not make any changes to the `data` parts of the table,\n/// or any changes to the `items` or `growth_left` field of the table.\n///\n/// # Safety\n///\n/// The safety rules are directly derived from the safety rules for [`RawTableInner::set_ctrl`]\n/// method. Thus, in order to uphold the safety contracts for the method, you must observe the\n/// following rules when calling this function:\n///\n/// * The [`RawTableInner`] has already been allocated;\n///\n/// * The `index` must not be greater than the `RawTableInner.bucket_mask`, i.e.\n///   `index <= RawTableInner.bucket_mask` or, in other words, `(index + 1)` must\n///   be no greater than the number returned by the function [`RawTableInner::buckets`].\n///\n/// Calling this function on a table that has not been allocated results in [`undefined behavior`].\n///\n/// See also [`Bucket::as_ptr`] method, for more information about of properly removing\n/// or saving `data element` from / into the [`RawTable`] / [`RawTableInner`].\n///\n/// [`RawTableInner::set_ctrl`]: RawTableInner::set_ctrl\n/// [`RawTableInner::buckets`]: RawTableInner::buckets\n/// [`Bucket::as_ptr`]: Bucket::as_ptr\n/// [`undefined behavior`]: https://doc.rust-lang.org/reference/behavior-considered-undefined.html\n#[inline]\nunsafe fn set_ctrl_hash(&mut self, index: usize, hash: u64){\n        // SAFETY: The caller must uphold the safety rules for the [`RawTableInner::set_ctrl_hash`]\n        self.set_ctrl(index, Tag::full(hash));\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::RawTableInner::with_capacity": [
            "/// Allocates a new [`RawTableInner`] with at least enough capacity for inserting\n/// the given number of elements without reallocating.\n///\n/// Panics if the new capacity exceeds [`isize::MAX`] bytes and [`abort`] the program\n/// in case of allocation error. Use [`fallible_with_capacity`] instead if you want to\n/// handle memory allocation failure.\n///\n/// All the control bytes are initialized with the [`Tag::EMPTY`] bytes.\n///\n/// [`fallible_with_capacity`]: RawTableInner::fallible_with_capacity\n/// [`abort`]: https://doc.rust-lang.org/alloc/alloc/fn.handle_alloc_error.html\nfn with_capacity<A>(alloc: &A, table_layout: TableLayout, capacity: usize) -> Self\n    where\n        A: Allocator,{\n        // Avoid `Result::unwrap_or_else` because it bloats LLVM IR.\n        match Self::fallible_with_capacity(alloc, table_layout, capacity, Fallibility::Infallible) {\n            Ok(table_inner) => table_inner,\n            // SAFETY: All allocation errors will be caught inside `RawTableInner::new_uninitialized`.\n            Err(_) => unsafe { hint::unreachable_unchecked() },\n        }\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::SizedTypeProperties": [
            "trait SizedTypeProperties: Sized {\n    const IS_ZERO_SIZED: bool = mem::size_of::<Self>() == 0;\n    const NEEDS_DROP: bool = mem::needs_drop::<Self>();\n}",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::TableLayout": [
            "/// Helper which allows the max calculation for `ctrl_align` to be statically computed for each `T`\n/// while keeping the rest of `calculate_layout_for` independent of `T`\nstruct TableLayout {\n    size: usize,\n    ctrl_align: usize,\n}",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::TableLayout::calculate_layout_for": [
            "#[inline]\nfn calculate_layout_for(self, buckets: usize) -> Option<(Layout, usize)>{\n        debug_assert!(buckets.is_power_of_two());\n\n        let TableLayout { size, ctrl_align } = self;\n        // Manual layout calculation since Layout methods are not yet stable.\n        let ctrl_offset =\n            size.checked_mul(buckets)?.checked_add(ctrl_align - 1)? & !(ctrl_align - 1);\n        let len = ctrl_offset.checked_add(buckets + Group::WIDTH)?;\n\n        // We need an additional check to ensure that the allocation doesn't\n        // exceed `isize::MAX` (https://github.com/rust-lang/rust/pull/95295).\n        if len > isize::MAX as usize - (ctrl_align - 1) {\n            return None;\n        }\n\n        Some((\n            unsafe { Layout::from_size_align_unchecked(len, ctrl_align) },\n            ctrl_offset,\n        ))\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::TableLayout::new": [
            "#[inline]\nconst fn new<T>() -> Self{\n        let layout = Layout::new::<T>();\n        Self {\n            size: layout.size(),\n            ctrl_align: if layout.align() > Group::WIDTH {\n                layout.align()\n            } else {\n                Group::WIDTH\n            },\n        }\n    }",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::alloc::inner::do_alloc": [
            "#[allow(clippy::map_err_ignore)]\npub(crate) fn do_alloc<A: Allocator>(alloc: &A, layout: Layout) -> Result<NonNull<u8>, ()>{\n        match alloc.allocate(layout) {\n            Ok(ptr) => Ok(ptr.cast()),\n            Err(_) => Err(()),\n        }\n    }",
            "Real(LocalPath(\"src/raw/alloc.rs\"))"
        ],
        "raw::bucket_mask_to_capacity": [
            "/// Returns the maximum effective capacity for the given bucket mask, taking\n/// the maximum load factor into account.\n#[inline]\nfn bucket_mask_to_capacity(bucket_mask: usize) -> usize{\n    if bucket_mask < 8 {\n        // For tables with 1/2/4/8 buckets, we always reserve one empty slot.\n        // Keep in mind that the bucket mask is one less than the bucket count.\n        bucket_mask\n    } else {\n        // For larger tables we reserve 12.5% of the slots as empty.\n        ((bucket_mask + 1) / 8) * 7\n    }\n}",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::capacity_to_buckets": [
            "/// Returns the number of buckets needed to hold the given number of items,\n/// taking the maximum load factor into account.\n///\n/// Returns `None` if an overflow occurs.\ninline\nfn capacity_to_buckets(cap: usize, table_layout: TableLayout) -> Option<usize>{\n    debug_assert_ne!(cap, 0);\n\n    // For small tables we require at least 1 empty bucket so that lookups are\n    // guaranteed to terminate if an element doesn't exist in the table.\n    if cap < 15 {\n        // Consider a small TableLayout like { size: 1, ctrl_align: 16 } on a\n        // platform with Group::WIDTH of 16 (like x86_64 with SSE2). For small\n        // bucket sizes, this ends up wasting quite a few bytes just to pad to\n        // the relatively larger ctrl_align:\n        //\n        // | capacity | buckets | bytes allocated | bytes per item |\n        // | -------- | ------- | --------------- | -------------- |\n        // |        3 |       4 |              36 | (Yikes!)  12.0 |\n        // |        7 |       8 |              40 | (Poor)     5.7 |\n        // |       14 |      16 |              48 |            3.4 |\n        // |       28 |      32 |              80 |            3.3 |\n        //\n        // In general, buckets * table_layout.size >= table_layout.ctrl_align\n        // must be true to avoid these edges. This is implemented by adjusting\n        // the minimum capacity upwards for small items. This code only needs\n        // to handle ctrl_align which are less than or equal to Group::WIDTH,\n        // because valid layout sizes are always a multiple of the alignment,\n        // so anything with alignment over the Group::WIDTH won't hit this edge\n        // case.\n\n        // This is brittle, e.g. if we ever add 32 byte groups, it will select\n        // 3 regardless of the table_layout.size.\n        let min_cap = match (Group::WIDTH, table_layout.size) {\n            (16, 0..=1) => 14,\n            (16, 2..=3) => 7,\n            (8, 0..=1) => 7,\n            _ => 3,\n        };\n        let cap = min_cap.max(cap);\n        // We don't bother with a table size of 2 buckets since that can only\n        // hold a single element. Instead, we skip directly to a 4 bucket table\n        // which can hold 3 elements.\n        return Some(if cap < 4 {\n            4\n        } else if cap < 8 {\n            8\n        } else {\n            16\n        });\n    }\n\n    // Otherwise require 1/8 buckets to be empty (87.5% load)\n    //\n    // Be careful when modifying this, calculate_layout relies on the\n    // overflow check here.\n    let adjusted_cap = cap.checked_mul(8)? / 7;\n\n    // Any overflows will have been caught by the checked_mul. Also, any\n    // rounding errors from the division above will be cleaned up by\n    // next_power_of_two (which can't overflow because of the previous division).\n    Some(adjusted_cap.next_power_of_two())\n}",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::h1": [
            "/// Primary hash function, used to select the initial bucket to probe from.\n#[inline]\n#[allow(clippy::cast_possible_truncation)]\nfn h1(hash: u64) -> usize{\n    // On 32-bit platforms we simply ignore the higher hash bits.\n    hash as usize\n}",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw::offset_from": [
            "#[inline]\nunsafe fn offset_from<T>(to: *const T, from: *const T) -> usize{\n    to.offset_from(from) as usize\n}",
            "Real(LocalPath(\"src/raw/mod.rs\"))"
        ],
        "raw_entry::<impl map::HashMap<K, V, S, A>>::raw_entry": [
            "/// Creates a raw immutable entry builder for the `HashMap`.\n///\n/// Raw entries provide the lowest level of control for searching and\n/// manipulating a map. They must be manually initialized with a hash and\n/// then manually searched.\n///\n/// This is useful for\n/// * Hash memoization\n/// * Using a search key that doesn't work with the Borrow trait\n/// * Using custom comparison logic without newtype wrappers\n///\n/// Unless you are in such a situation, higher-level and more foolproof APIs like\n/// `get` should be preferred.\n///\n/// Immutable raw entries have very limited use; you might instead want `raw_entry_mut`.\n///\n/// # Examples\n///\n/// ```\n/// use core::hash::{BuildHasher, Hash};\n/// use hashbrown::HashMap;\n///\n/// let mut map = HashMap::new();\n/// map.extend([(\"a\", 100), (\"b\", 200), (\"c\", 300)]);\n///\n/// fn compute_hash<K: Hash + ?Sized, S: BuildHasher>(hash_builder: &S, key: &K) -> u64 {\n///     use core::hash::Hasher;\n///     let mut state = hash_builder.build_hasher();\n///     key.hash(&mut state);\n///     state.finish()\n/// }\n///\n/// for k in [\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"] {\n///     let hash = compute_hash(map.hasher(), k);\n///     let v = map.get(&k).cloned();\n///     let kv = v.as_ref().map(|v| (&k, v));\n///\n///     println!(\"Key: {} and value: {:?}\", k, v);\n///\n///     assert_eq!(map.raw_entry().from_key(&k), kv);\n///     assert_eq!(map.raw_entry().from_hash(hash, |q| *q == k), kv);\n///     assert_eq!(map.raw_entry().from_key_hashed_nocheck(hash, &k), kv);\n/// }\n/// ```\ninline\npub fn raw_entry(&self) -> RawEntryBuilder<'_, K, V, S, A>{\n        RawEntryBuilder { map: self }\n    }",
            "Real(LocalPath(\"src/raw_entry.rs\"))"
        ],
        "raw_entry::<impl map::HashMap<K, V, S, A>>::raw_entry_mut": [
            "/// Creates a raw entry builder for the `HashMap`.\n///\n/// Raw entries provide the lowest level of control for searching and\n/// manipulating a map. They must be manually initialized with a hash and\n/// then manually searched. After this, insertions into a vacant entry\n/// still require an owned key to be provided.\n///\n/// Raw entries are useful for such exotic situations as:\n///\n/// * Hash memoization\n/// * Deferring the creation of an owned key until it is known to be required\n/// * Using a search key that doesn't work with the Borrow trait\n/// * Using custom comparison logic without newtype wrappers\n///\n/// Because raw entries provide much more low-level control, it's much easier\n/// to put the `HashMap` into an inconsistent state which, while memory-safe,\n/// will cause the map to produce seemingly random results. Higher-level and\n/// more foolproof APIs like `entry` should be preferred when possible.\n///\n/// In particular, the hash used to initialized the raw entry must still be\n/// consistent with the hash of the key that is ultimately stored in the entry.\n/// This is because implementations of `HashMap` may need to recompute hashes\n/// when resizing, at which point only the keys are available.\n///\n/// Raw entries give mutable access to the keys. This must not be used\n/// to modify how the key would compare or hash, as the map will not re-evaluate\n/// where the key should go, meaning the keys may become \"lost\" if their\n/// location does not reflect their state. For instance, if you change a key\n/// so that the map now contains keys which compare equal, search may start\n/// acting erratically, with two keys randomly masking each other. Implementations\n/// are free to assume this doesn't happen (within the limits of memory-safety).\n///\n/// # Examples\n///\n/// ```\n/// use core::hash::{BuildHasher, Hash};\n/// use hashbrown::hash_map::{HashMap, RawEntryMut};\n///\n/// let mut map = HashMap::new();\n/// map.extend([(\"a\", 100), (\"b\", 200), (\"c\", 300)]);\n///\n/// fn compute_hash<K: Hash + ?Sized, S: BuildHasher>(hash_builder: &S, key: &K) -> u64 {\n///     use core::hash::Hasher;\n///     let mut state = hash_builder.build_hasher();\n///     key.hash(&mut state);\n///     state.finish()\n/// }\n///\n/// // Existing key (insert and update)\n/// match map.raw_entry_mut().from_key(&\"a\") {\n///     RawEntryMut::Vacant(_) => unreachable!(),\n///     RawEntryMut::Occupied(mut view) => {\n///         assert_eq!(view.get(), &100);\n///         let v = view.get_mut();\n///         let new_v = (*v) * 10;\n///         *v = new_v;\n///         assert_eq!(view.insert(1111), 1000);\n///     }\n/// }\n///\n/// assert_eq!(map[&\"a\"], 1111);\n/// assert_eq!(map.len(), 3);\n///\n/// // Existing key (take)\n/// let hash = compute_hash(map.hasher(), &\"c\");\n/// match map.raw_entry_mut().from_key_hashed_nocheck(hash, &\"c\") {\n///     RawEntryMut::Vacant(_) => unreachable!(),\n///     RawEntryMut::Occupied(view) => {\n///         assert_eq!(view.remove_entry(), (\"c\", 300));\n///     }\n/// }\n/// assert_eq!(map.raw_entry().from_key(&\"c\"), None);\n/// assert_eq!(map.len(), 2);\n///\n/// // Nonexistent key (insert and update)\n/// let key = \"d\";\n/// let hash = compute_hash(map.hasher(), &key);\n/// match map.raw_entry_mut().from_hash(hash, |q| *q == key) {\n///     RawEntryMut::Occupied(_) => unreachable!(),\n///     RawEntryMut::Vacant(view) => {\n///         let (k, value) = view.insert(\"d\", 4000);\n///         assert_eq!((*k, *value), (\"d\", 4000));\n///         *value = 40000;\n///     }\n/// }\n/// assert_eq!(map[&\"d\"], 40000);\n/// assert_eq!(map.len(), 3);\n///\n/// match map.raw_entry_mut().from_hash(hash, |q| *q == key) {\n///     RawEntryMut::Vacant(_) => unreachable!(),\n///     RawEntryMut::Occupied(view) => {\n///         assert_eq!(view.remove_entry(), (\"d\", 40000));\n///     }\n/// }\n/// assert_eq!(map.get(&\"d\"), None);\n/// assert_eq!(map.len(), 2);\n/// ```\ninline\npub fn raw_entry_mut(&mut self) -> RawEntryBuilderMut<'_, K, V, S, A>{\n        RawEntryBuilderMut { map: self }\n    }",
            "Real(LocalPath(\"src/raw_entry.rs\"))"
        ],
        "raw_entry::RawEntryBuilder": [
            "/// A builder for computing where in a [`HashMap`] a key-value pair would be stored.\n///\n/// See the [`HashMap::raw_entry`] docs for usage examples.\n///\n/// [`HashMap::raw_entry`]: struct.HashMap.html#method.raw_entry\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::hash_map::{HashMap, RawEntryBuilder};\n/// use core::hash::{BuildHasher, Hash};\n///\n/// let mut map = HashMap::new();\n/// map.extend([(1, 10), (2, 20), (3, 30)]);\n///\n/// fn compute_hash<K: Hash + ?Sized, S: BuildHasher>(hash_builder: &S, key: &K) -> u64 {\n///     use core::hash::Hasher;\n///     let mut state = hash_builder.build_hasher();\n///     key.hash(&mut state);\n///     state.finish()\n/// }\n///\n/// for k in 0..6 {\n///     let hash = compute_hash(map.hasher(), &k);\n///     let v = map.get(&k).cloned();\n///     let kv = v.as_ref().map(|v| (&k, v));\n///\n///     println!(\"Key: {} and value: {:?}\", k, v);\n///     let builder: RawEntryBuilder<_, _, _> = map.raw_entry();\n///     assert_eq!(builder.from_key(&k), kv);\n///     assert_eq!(map.raw_entry().from_hash(hash, |q| *q == k), kv);\n///     assert_eq!(map.raw_entry().from_key_hashed_nocheck(hash, &k), kv);\n/// }\n/// ```\npub struct RawEntryBuilder<'a, K, V, S, A: Allocator = Global> {\n    map: &'a HashMap<K, V, S, A>,\n}",
            "Real(LocalPath(\"src/raw_entry.rs\"))"
        ],
        "raw_entry::RawEntryBuilder::<'a, K, V, S, A>::from_hash": [
            "/// Access an immutable entry by hash and matching function.\n///\n/// # Examples\n///\n/// ```\n/// use core::hash::{BuildHasher, Hash};\n/// use hashbrown::HashMap;\n///\n/// fn compute_hash<K: Hash + ?Sized, S: BuildHasher>(hash_builder: &S, key: &K) -> u64 {\n///     use core::hash::Hasher;\n///     let mut state = hash_builder.build_hasher();\n///     key.hash(&mut state);\n///     state.finish()\n/// }\n///\n/// let map: HashMap<&str, u32> = [(\"a\", 100), (\"b\", 200)].into();\n/// let key = \"a\";\n/// let hash = compute_hash(map.hasher(), &key);\n/// assert_eq!(map.raw_entry().from_hash(hash, |k| k == &key), Some((&\"a\", &100)));\n/// ```\ninline\n#[allow(clippy::wrong_self_convention)]\npub fn from_hash<F>(self, hash: u64, is_match: F) -> Option<(&'a K, &'a V)>\n    where\n        F: FnMut(&K) -> bool,{\n        self.search(hash, is_match)\n    }",
            "Real(LocalPath(\"src/raw_entry.rs\"))"
        ],
        "raw_entry::RawEntryBuilder::<'a, K, V, S, A>::from_key": [
            "/// Access an immutable entry by key.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let map: HashMap<&str, u32> = [(\"a\", 100), (\"b\", 200)].into();\n/// let key = \"a\";\n/// assert_eq!(map.raw_entry().from_key(&key), Some((&\"a\", &100)));\n/// ```\ninline\n#[allow(clippy::wrong_self_convention)]\npub fn from_key<Q>(self, k: &Q) -> Option<(&'a K, &'a V)>\n    where\n        S: BuildHasher,\n        Q: Hash + Equivalent<K> + ?Sized,{\n        let hash = make_hash::<Q, S>(&self.map.hash_builder, k);\n        self.from_key_hashed_nocheck(hash, k)\n    }",
            "Real(LocalPath(\"src/raw_entry.rs\"))"
        ],
        "raw_entry::RawEntryBuilder::<'a, K, V, S, A>::from_key_hashed_nocheck": [
            "/// Access an immutable entry by a key and its hash.\n///\n/// # Examples\n///\n/// ```\n/// use core::hash::{BuildHasher, Hash};\n/// use hashbrown::HashMap;\n///\n/// fn compute_hash<K: Hash + ?Sized, S: BuildHasher>(hash_builder: &S, key: &K) -> u64 {\n///     use core::hash::Hasher;\n///     let mut state = hash_builder.build_hasher();\n///     key.hash(&mut state);\n///     state.finish()\n/// }\n///\n/// let map: HashMap<&str, u32> = [(\"a\", 100), (\"b\", 200)].into();\n/// let key = \"a\";\n/// let hash = compute_hash(map.hasher(), &key);\n/// assert_eq!(map.raw_entry().from_key_hashed_nocheck(hash, &key), Some((&\"a\", &100)));\n/// ```\ninline\n#[allow(clippy::wrong_self_convention)]\npub fn from_key_hashed_nocheck<Q>(self, hash: u64, k: &Q) -> Option<(&'a K, &'a V)>\n    where\n        Q: Equivalent<K> + ?Sized,{\n        self.from_hash(hash, equivalent(k))\n    }",
            "Real(LocalPath(\"src/raw_entry.rs\"))"
        ],
        "raw_entry::RawEntryBuilder::<'a, K, V, S, A>::search": [
            "inline\nfn search<F>(self, hash: u64, mut is_match: F) -> Option<(&'a K, &'a V)>\n    where\n        F: FnMut(&K) -> bool,{\n        match self.map.table.get(hash, |(k, _)| is_match(k)) {\n            Some((key, value)) => Some((key, value)),\n            None => None,\n        }\n    }",
            "Real(LocalPath(\"src/raw_entry.rs\"))"
        ],
        "raw_entry::RawEntryBuilderMut": [
            "/// A builder for computing where in a [`HashMap`] a key-value pair would be stored.\n///\n/// See the [`HashMap::raw_entry_mut`] docs for usage examples.\n///\n/// [`HashMap::raw_entry_mut`]: struct.HashMap.html#method.raw_entry_mut\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::hash_map::{RawEntryBuilderMut, RawEntryMut::Vacant, RawEntryMut::Occupied};\n/// use hashbrown::HashMap;\n/// use core::hash::{BuildHasher, Hash};\n///\n/// let mut map = HashMap::new();\n/// map.extend([(1, 11), (2, 12), (3, 13), (4, 14), (5, 15), (6, 16)]);\n/// assert_eq!(map.len(), 6);\n///\n/// fn compute_hash<K: Hash + ?Sized, S: BuildHasher>(hash_builder: &S, key: &K) -> u64 {\n///     use core::hash::Hasher;\n///     let mut state = hash_builder.build_hasher();\n///     key.hash(&mut state);\n///     state.finish()\n/// }\n///\n/// let builder: RawEntryBuilderMut<_, _, _> = map.raw_entry_mut();\n///\n/// // Existing key\n/// match builder.from_key(&6) {\n///     Vacant(_) => unreachable!(),\n///     Occupied(view) => assert_eq!(view.get(), &16),\n/// }\n///\n/// for key in 0..12 {\n///     let hash = compute_hash(map.hasher(), &key);\n///     let value = map.get(&key).cloned();\n///     let key_value = value.as_ref().map(|v| (&key, v));\n///\n///     println!(\"Key: {} and value: {:?}\", key, value);\n///\n///     match map.raw_entry_mut().from_key(&key) {\n///         Occupied(mut o) => assert_eq!(Some(o.get_key_value()), key_value),\n///         Vacant(_) => assert_eq!(value, None),\n///     }\n///     match map.raw_entry_mut().from_key_hashed_nocheck(hash, &key) {\n///         Occupied(mut o) => assert_eq!(Some(o.get_key_value()), key_value),\n///         Vacant(_) => assert_eq!(value, None),\n///     }\n///     match map.raw_entry_mut().from_hash(hash, |q| *q == key) {\n///         Occupied(mut o) => assert_eq!(Some(o.get_key_value()), key_value),\n///         Vacant(_) => assert_eq!(value, None),\n///     }\n/// }\n///\n/// assert_eq!(map.len(), 6);\n/// ```\npub struct RawEntryBuilderMut<'a, K, V, S, A: Allocator = Global> {\n    map: &'a mut HashMap<K, V, S, A>,\n}",
            "Real(LocalPath(\"src/raw_entry.rs\"))"
        ],
        "raw_entry::RawEntryBuilderMut::<'a, K, V, S, A>::from_hash": [
            "/// Creates a `RawEntryMut` from the given hash and matching function.\n///\n/// # Examples\n///\n/// ```\n/// use core::hash::{BuildHasher, Hash};\n/// use hashbrown::hash_map::{HashMap, RawEntryMut};\n///\n/// fn compute_hash<K: Hash + ?Sized, S: BuildHasher>(hash_builder: &S, key: &K) -> u64 {\n///     use core::hash::Hasher;\n///     let mut state = hash_builder.build_hasher();\n///     key.hash(&mut state);\n///     state.finish()\n/// }\n///\n/// let mut map: HashMap<&str, u32> = HashMap::new();\n/// let key = \"a\";\n/// let hash = compute_hash(map.hasher(), &key);\n/// let entry: RawEntryMut<&str, u32, _> = map.raw_entry_mut().from_hash(hash, |k| k == &key);\n/// entry.insert(key, 100);\n/// assert_eq!(map[&\"a\"], 100);\n/// ```\ninline\n#[allow(clippy::wrong_self_convention)]\npub fn from_hash<F>(self, hash: u64, is_match: F) -> RawEntryMut<'a, K, V, S, A>\n    where\n        for<'b> F: FnMut(&'b K) -> bool,{\n        self.search(hash, is_match)\n    }",
            "Real(LocalPath(\"src/raw_entry.rs\"))"
        ],
        "raw_entry::RawEntryBuilderMut::<'a, K, V, S, A>::from_key": [
            "/// Creates a `RawEntryMut` from the given key.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::hash_map::{HashMap, RawEntryMut};\n///\n/// let mut map: HashMap<&str, u32> = HashMap::new();\n/// let key = \"a\";\n/// let entry: RawEntryMut<&str, u32, _> = map.raw_entry_mut().from_key(&key);\n/// entry.insert(key, 100);\n/// assert_eq!(map[&\"a\"], 100);\n/// ```\ninline\n#[allow(clippy::wrong_self_convention)]\npub fn from_key<Q>(self, k: &Q) -> RawEntryMut<'a, K, V, S, A>\n    where\n        S: BuildHasher,\n        Q: Hash + Equivalent<K> + ?Sized,{\n        let hash = make_hash::<Q, S>(&self.map.hash_builder, k);\n        self.from_key_hashed_nocheck(hash, k)\n    }",
            "Real(LocalPath(\"src/raw_entry.rs\"))"
        ],
        "raw_entry::RawEntryBuilderMut::<'a, K, V, S, A>::from_key_hashed_nocheck": [
            "/// Creates a `RawEntryMut` from the given key and its hash.\n///\n/// # Examples\n///\n/// ```\n/// use core::hash::{BuildHasher, Hash};\n/// use hashbrown::hash_map::{HashMap, RawEntryMut};\n///\n/// fn compute_hash<K: Hash + ?Sized, S: BuildHasher>(hash_builder: &S, key: &K) -> u64 {\n///     use core::hash::Hasher;\n///     let mut state = hash_builder.build_hasher();\n///     key.hash(&mut state);\n///     state.finish()\n/// }\n///\n/// let mut map: HashMap<&str, u32> = HashMap::new();\n/// let key = \"a\";\n/// let hash = compute_hash(map.hasher(), &key);\n/// let entry: RawEntryMut<&str, u32, _> = map.raw_entry_mut().from_key_hashed_nocheck(hash, &key);\n/// entry.insert(key, 100);\n/// assert_eq!(map[&\"a\"], 100);\n/// ```\n#[inline]\n#[allow(clippy::wrong_self_convention)]\npub fn from_key_hashed_nocheck<Q>(self, hash: u64, k: &Q) -> RawEntryMut<'a, K, V, S, A>\n    where\n        Q: Equivalent<K> + ?Sized,{\n        self.from_hash(hash, equivalent(k))\n    }",
            "Real(LocalPath(\"src/raw_entry.rs\"))"
        ],
        "raw_entry::RawEntryBuilderMut::<'a, K, V, S, A>::search": [
            "inline\nfn search<F>(self, hash: u64, mut is_match: F) -> RawEntryMut<'a, K, V, S, A>\n    where\n        for<'b> F: FnMut(&'b K) -> bool,{\n        match self.map.table.find(hash, |(k, _)| is_match(k)) {\n            Some(elem) => RawEntryMut::Occupied(RawOccupiedEntryMut {\n                elem,\n                table: &mut self.map.table,\n                hash_builder: &self.map.hash_builder,\n            }),\n            None => RawEntryMut::Vacant(RawVacantEntryMut {\n                table: &mut self.map.table,\n                hash_builder: &self.map.hash_builder,\n            }),\n        }\n    }",
            "Real(LocalPath(\"src/raw_entry.rs\"))"
        ],
        "raw_entry::RawEntryMut": [
            "/// A view into a single entry in a map, which may either be vacant or occupied.\n///\n/// This is a lower-level version of [`Entry`].\n///\n/// This `enum` is constructed through the [`raw_entry_mut`] method on [`HashMap`],\n/// then calling one of the methods of that [`RawEntryBuilderMut`].\n///\n/// [`HashMap`]: struct.HashMap.html\n/// [`Entry`]: enum.Entry.html\n/// [`raw_entry_mut`]: struct.HashMap.html#method.raw_entry_mut\n/// [`RawEntryBuilderMut`]: struct.RawEntryBuilderMut.html\n///\n/// # Examples\n///\n/// ```\n/// use core::hash::{BuildHasher, Hash};\n/// use hashbrown::hash_map::{HashMap, RawEntryMut, RawOccupiedEntryMut};\n///\n/// let mut map = HashMap::new();\n/// map.extend([('a', 1), ('b', 2), ('c', 3)]);\n/// assert_eq!(map.len(), 3);\n///\n/// fn compute_hash<K: Hash + ?Sized, S: BuildHasher>(hash_builder: &S, key: &K) -> u64 {\n///     use core::hash::Hasher;\n///     let mut state = hash_builder.build_hasher();\n///     key.hash(&mut state);\n///     state.finish()\n/// }\n///\n/// // Existing key (insert)\n/// let raw: RawEntryMut<_, _, _> = map.raw_entry_mut().from_key(&'a');\n/// let _raw_o: RawOccupiedEntryMut<_, _, _> = raw.insert('a', 10);\n/// assert_eq!(map.len(), 3);\n///\n/// // Nonexistent key (insert)\n/// map.raw_entry_mut().from_key(&'d').insert('d', 40);\n/// assert_eq!(map.len(), 4);\n///\n/// // Existing key (or_insert)\n/// let hash = compute_hash(map.hasher(), &'b');\n/// let kv = map\n///     .raw_entry_mut()\n///     .from_key_hashed_nocheck(hash, &'b')\n///     .or_insert('b', 20);\n/// assert_eq!(kv, (&mut 'b', &mut 2));\n/// *kv.1 = 20;\n/// assert_eq!(map.len(), 4);\n///\n/// // Nonexistent key (or_insert)\n/// let hash = compute_hash(map.hasher(), &'e');\n/// let kv = map\n///     .raw_entry_mut()\n///     .from_key_hashed_nocheck(hash, &'e')\n///     .or_insert('e', 50);\n/// assert_eq!(kv, (&mut 'e', &mut 50));\n/// assert_eq!(map.len(), 5);\n///\n/// // Existing key (or_insert_with)\n/// let hash = compute_hash(map.hasher(), &'c');\n/// let kv = map\n///     .raw_entry_mut()\n///     .from_hash(hash, |q| q == &'c')\n///     .or_insert_with(|| ('c', 30));\n/// assert_eq!(kv, (&mut 'c', &mut 3));\n/// *kv.1 = 30;\n/// assert_eq!(map.len(), 5);\n///\n/// // Nonexistent key (or_insert_with)\n/// let hash = compute_hash(map.hasher(), &'f');\n/// let kv = map\n///     .raw_entry_mut()\n///     .from_hash(hash, |q| q == &'f')\n///     .or_insert_with(|| ('f', 60));\n/// assert_eq!(kv, (&mut 'f', &mut 60));\n/// assert_eq!(map.len(), 6);\n///\n/// println!(\"Our HashMap: {:?}\", map);\n///\n/// let mut vec: Vec<_> = map.iter().map(|(&k, &v)| (k, v)).collect();\n/// // The `Iter` iterator produces items in arbitrary order, so the\n/// // items must be sorted to test them against a sorted array.\n/// vec.sort_unstable();\n/// assert_eq!(vec, [('a', 10), ('b', 20), ('c', 30), ('d', 40), ('e', 50), ('f', 60)]);\n/// ```\npub enum RawEntryMut<'a, K, V, S, A: Allocator = Global> {\n    /// An occupied entry.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::{hash_map::RawEntryMut, HashMap};\n    /// let mut map: HashMap<_, _> = [(\"a\", 100), (\"b\", 200)].into();\n    ///\n    /// match map.raw_entry_mut().from_key(&\"a\") {\n    ///     RawEntryMut::Vacant(_) => unreachable!(),\n    ///     RawEntryMut::Occupied(_) => { }\n    /// }\n    /// ```\n    Occupied(RawOccupiedEntryMut<'a, K, V, S, A>),\n    /// A vacant entry.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::{hash_map::RawEntryMut, HashMap};\n    /// let mut map: HashMap<&str, i32> = HashMap::new();\n    ///\n    /// match map.raw_entry_mut().from_key(\"a\") {\n    ///     RawEntryMut::Occupied(_) => unreachable!(),\n    ///     RawEntryMut::Vacant(_) => { }\n    /// }\n    /// ```\n    Vacant(RawVacantEntryMut<'a, K, V, S, A>),\n}",
            "Real(LocalPath(\"src/raw_entry.rs\"))"
        ],
        "raw_entry::RawEntryMut::<'a, K, V, S, A>::and_modify": [
            "/// Provides in-place mutable access to an occupied entry before any\n/// potential inserts into the map.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut map: HashMap<&str, u32> = HashMap::new();\n///\n/// map.raw_entry_mut()\n///    .from_key(\"poneyland\")\n///    .and_modify(|_k, v| { *v += 1 })\n///    .or_insert(\"poneyland\", 42);\n/// assert_eq!(map[\"poneyland\"], 42);\n///\n/// map.raw_entry_mut()\n///    .from_key(\"poneyland\")\n///    .and_modify(|_k, v| { *v += 1 })\n///    .or_insert(\"poneyland\", 0);\n/// assert_eq!(map[\"poneyland\"], 43);\n/// ```\ninline\npub fn and_modify<F>(self, f: F) -> Self\n    where\n        F: FnOnce(&mut K, &mut V),{\n        match self {\n            RawEntryMut::Occupied(mut entry) => {\n                {\n                    let (k, v) = entry.get_key_value_mut();\n                    f(k, v);\n                }\n                RawEntryMut::Occupied(entry)\n            }\n            RawEntryMut::Vacant(entry) => RawEntryMut::Vacant(entry),\n        }\n    }",
            "Real(LocalPath(\"src/raw_entry.rs\"))"
        ],
        "raw_entry::RawEntryMut::<'a, K, V, S, A>::and_replace_entry_with": [
            "/// Provides shared access to the key and owned access to the value of\n/// an occupied entry and allows to replace or remove it based on the\n/// value of the returned option.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n/// use hashbrown::hash_map::RawEntryMut;\n///\n/// let mut map: HashMap<&str, u32> = HashMap::new();\n///\n/// let entry = map\n///     .raw_entry_mut()\n///     .from_key(\"poneyland\")\n///     .and_replace_entry_with(|_k, _v| panic!());\n///\n/// match entry {\n///     RawEntryMut::Vacant(_) => {},\n///     RawEntryMut::Occupied(_) => panic!(),\n/// }\n///\n/// map.insert(\"poneyland\", 42);\n///\n/// let entry = map\n///     .raw_entry_mut()\n///     .from_key(\"poneyland\")\n///     .and_replace_entry_with(|k, v| {\n///         assert_eq!(k, &\"poneyland\");\n///         assert_eq!(v, 42);\n///         Some(v + 1)\n///     });\n///\n/// match entry {\n///     RawEntryMut::Occupied(e) => {\n///         assert_eq!(e.key(), &\"poneyland\");\n///         assert_eq!(e.get(), &43);\n///     },\n///     RawEntryMut::Vacant(_) => panic!(),\n/// }\n///\n/// assert_eq!(map[\"poneyland\"], 43);\n///\n/// let entry = map\n///     .raw_entry_mut()\n///     .from_key(\"poneyland\")\n///     .and_replace_entry_with(|_k, _v| None);\n///\n/// match entry {\n///     RawEntryMut::Vacant(_) => {},\n///     RawEntryMut::Occupied(_) => panic!(),\n/// }\n///\n/// assert!(!map.contains_key(\"poneyland\"));\n/// ```\ninline\npub fn and_replace_entry_with<F>(self, f: F) -> Self\n    where\n        F: FnOnce(&K, V) -> Option<V>,{\n        match self {\n            RawEntryMut::Occupied(entry) => entry.replace_entry_with(f),\n            RawEntryMut::Vacant(_) => self,\n        }\n    }",
            "Real(LocalPath(\"src/raw_entry.rs\"))"
        ],
        "raw_entry::RawEntryMut::<'a, K, V, S, A>::insert": [
            "/// Sets the value of the entry, and returns a `RawOccupiedEntryMut`.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut map: HashMap<&str, u32> = HashMap::new();\n/// let entry = map.raw_entry_mut().from_key(\"horseyland\").insert(\"horseyland\", 37);\n///\n/// assert_eq!(entry.remove_entry(), (\"horseyland\", 37));\n/// ```\ninline\npub fn insert(self, key: K, value: V) -> RawOccupiedEntryMut<'a, K, V, S, A>\n    where\n        K: Hash,\n        S: BuildHasher,{\n        match self {\n            RawEntryMut::Occupied(mut entry) => {\n                entry.insert(value);\n                entry\n            }\n            RawEntryMut::Vacant(entry) => entry.insert_entry(key, value),\n        }\n    }",
            "Real(LocalPath(\"src/raw_entry.rs\"))"
        ],
        "raw_entry::RawEntryMut::<'a, K, V, S, A>::or_insert": [
            "/// Ensures a value is in the entry by inserting the default if empty, and returns\n/// mutable references to the key and value in the entry.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut map: HashMap<&str, u32> = HashMap::new();\n///\n/// map.raw_entry_mut().from_key(\"poneyland\").or_insert(\"poneyland\", 3);\n/// assert_eq!(map[\"poneyland\"], 3);\n///\n/// *map.raw_entry_mut().from_key(\"poneyland\").or_insert(\"poneyland\", 10).1 *= 2;\n/// assert_eq!(map[\"poneyland\"], 6);\n/// ```\ninline\npub fn or_insert(self, default_key: K, default_val: V) -> (&'a mut K, &'a mut V)\n    where\n        K: Hash,\n        S: BuildHasher,{\n        match self {\n            RawEntryMut::Occupied(entry) => entry.into_key_value(),\n            RawEntryMut::Vacant(entry) => entry.insert(default_key, default_val),\n        }\n    }",
            "Real(LocalPath(\"src/raw_entry.rs\"))"
        ],
        "raw_entry::RawEntryMut::<'a, K, V, S, A>::or_insert_with": [
            "/// Ensures a value is in the entry by inserting the result of the default function if empty,\n/// and returns mutable references to the key and value in the entry.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashMap;\n///\n/// let mut map: HashMap<&str, String> = HashMap::new();\n///\n/// map.raw_entry_mut().from_key(\"poneyland\").or_insert_with(|| {\n///     (\"poneyland\", \"hoho\".to_string())\n/// });\n///\n/// assert_eq!(map[\"poneyland\"], \"hoho\".to_string());\n/// ```\ninline\npub fn or_insert_with<F>(self, default: F) -> (&'a mut K, &'a mut V)\n    where\n        F: FnOnce() -> (K, V),\n        K: Hash,\n        S: BuildHasher,{\n        match self {\n            RawEntryMut::Occupied(entry) => entry.into_key_value(),\n            RawEntryMut::Vacant(entry) => {\n                let (k, v) = default();\n                entry.insert(k, v)\n            }\n        }\n    }",
            "Real(LocalPath(\"src/raw_entry.rs\"))"
        ],
        "raw_entry::RawOccupiedEntryMut": [
            "/// A view into an occupied entry in a `HashMap`.\n/// It is part of the [`RawEntryMut`] enum.\n///\n/// [`RawEntryMut`]: enum.RawEntryMut.html\n///\n/// # Examples\n///\n/// ```\n/// use core::hash::{BuildHasher, Hash};\n/// use hashbrown::hash_map::{HashMap, RawEntryMut, RawOccupiedEntryMut};\n///\n/// let mut map = HashMap::new();\n/// map.extend([(\"a\", 10), (\"b\", 20), (\"c\", 30)]);\n///\n/// fn compute_hash<K: Hash + ?Sized, S: BuildHasher>(hash_builder: &S, key: &K) -> u64 {\n///     use core::hash::Hasher;\n///     let mut state = hash_builder.build_hasher();\n///     key.hash(&mut state);\n///     state.finish()\n/// }\n///\n/// let _raw_o: RawOccupiedEntryMut<_, _, _> = map.raw_entry_mut().from_key(&\"a\").insert(\"a\", 100);\n/// assert_eq!(map.len(), 3);\n///\n/// // Existing key (insert and update)\n/// match map.raw_entry_mut().from_key(&\"a\") {\n///     RawEntryMut::Vacant(_) => unreachable!(),\n///     RawEntryMut::Occupied(mut view) => {\n///         assert_eq!(view.get(), &100);\n///         let v = view.get_mut();\n///         let new_v = (*v) * 10;\n///         *v = new_v;\n///         assert_eq!(view.insert(1111), 1000);\n///     }\n/// }\n///\n/// assert_eq!(map[&\"a\"], 1111);\n/// assert_eq!(map.len(), 3);\n///\n/// // Existing key (take)\n/// let hash = compute_hash(map.hasher(), &\"c\");\n/// match map.raw_entry_mut().from_key_hashed_nocheck(hash, &\"c\") {\n///     RawEntryMut::Vacant(_) => unreachable!(),\n///     RawEntryMut::Occupied(view) => {\n///         assert_eq!(view.remove_entry(), (\"c\", 30));\n///     }\n/// }\n/// assert_eq!(map.raw_entry().from_key(&\"c\"), None);\n/// assert_eq!(map.len(), 2);\n///\n/// let hash = compute_hash(map.hasher(), &\"b\");\n/// match map.raw_entry_mut().from_hash(hash, |q| *q == \"b\") {\n///     RawEntryMut::Vacant(_) => unreachable!(),\n///     RawEntryMut::Occupied(view) => {\n///         assert_eq!(view.remove_entry(), (\"b\", 20));\n///     }\n/// }\n/// assert_eq!(map.get(&\"b\"), None);\n/// assert_eq!(map.len(), 1);\n/// ```\npub struct RawOccupiedEntryMut<'a, K, V, S, A: Allocator = Global> {\n    elem: Bucket<(K, V)>,\n    table: &'a mut RawTable<(K, V), A>,\n    hash_builder: &'a S,\n}",
            "Real(LocalPath(\"src/raw_entry.rs\"))"
        ],
        "raw_entry::RawOccupiedEntryMut::<'a, K, V, S, A>::get": [
            "/// Gets a reference to the value in the entry.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::hash_map::{HashMap, RawEntryMut};\n///\n/// let mut map: HashMap<&str, u32> = [(\"a\", 100), (\"b\", 200)].into();\n///\n/// match map.raw_entry_mut().from_key(&\"a\") {\n///     RawEntryMut::Vacant(_) => panic!(),\n///     RawEntryMut::Occupied(o) => assert_eq!(o.get(), &100),\n/// }\n/// ```\ninline\npub fn get(&self) -> &V{\n        unsafe { &self.elem.as_ref().1 }\n    }",
            "Real(LocalPath(\"src/raw_entry.rs\"))"
        ],
        "raw_entry::RawOccupiedEntryMut::<'a, K, V, S, A>::get_key_value": [
            "/// Gets a reference to the key and value in the entry.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::hash_map::{HashMap, RawEntryMut};\n///\n/// let mut map: HashMap<&str, u32> = [(\"a\", 100), (\"b\", 200)].into();\n///\n/// match map.raw_entry_mut().from_key(&\"a\") {\n///     RawEntryMut::Vacant(_) => panic!(),\n///     RawEntryMut::Occupied(o) => assert_eq!(o.get_key_value(), (&\"a\", &100)),\n/// }\n/// ```\ninline\npub fn get_key_value(&self) -> (&K, &V){\n        unsafe {\n            let (key, value) = self.elem.as_ref();\n            (key, value)\n        }\n    }",
            "Real(LocalPath(\"src/raw_entry.rs\"))"
        ],
        "raw_entry::RawOccupiedEntryMut::<'a, K, V, S, A>::get_key_value_mut": [
            "/// Gets a mutable reference to the key and value in the entry.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::hash_map::{HashMap, RawEntryMut};\n/// use std::rc::Rc;\n///\n/// let key_one = Rc::new(\"a\");\n/// let key_two = Rc::new(\"a\");\n///\n/// let mut map: HashMap<Rc<&str>, u32> = HashMap::new();\n/// map.insert(key_one.clone(), 10);\n///\n/// assert_eq!(map[&key_one], 10);\n/// assert!(Rc::strong_count(&key_one) == 2 && Rc::strong_count(&key_two) == 1);\n///\n/// match map.raw_entry_mut().from_key(&key_one) {\n///     RawEntryMut::Vacant(_) => panic!(),\n///     RawEntryMut::Occupied(mut o) => {\n///         let (inside_key, inside_value) = o.get_key_value_mut();\n///         *inside_key = key_two.clone();\n///         *inside_value = 100;\n///     }\n/// }\n/// assert_eq!(map[&key_two], 100);\n/// assert!(Rc::strong_count(&key_one) == 1 && Rc::strong_count(&key_two) == 2);\n/// ```\ninline\npub fn get_key_value_mut(&mut self) -> (&mut K, &mut V){\n        unsafe {\n            let &mut (ref mut key, ref mut value) = self.elem.as_mut();\n            (key, value)\n        }\n    }",
            "Real(LocalPath(\"src/raw_entry.rs\"))"
        ],
        "raw_entry::RawOccupiedEntryMut::<'a, K, V, S, A>::get_mut": [
            "/// Gets a mutable reference to the value in the entry.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::hash_map::{HashMap, RawEntryMut};\n///\n/// let mut map: HashMap<&str, u32> = [(\"a\", 100), (\"b\", 200)].into();\n///\n/// match map.raw_entry_mut().from_key(&\"a\") {\n///     RawEntryMut::Vacant(_) => panic!(),\n///     RawEntryMut::Occupied(mut o) => *o.get_mut() += 900,\n/// }\n///\n/// assert_eq!(map[&\"a\"], 1000);\n/// ```\ninline\npub fn get_mut(&mut self) -> &mut V{\n        unsafe { &mut self.elem.as_mut().1 }\n    }",
            "Real(LocalPath(\"src/raw_entry.rs\"))"
        ],
        "raw_entry::RawOccupiedEntryMut::<'a, K, V, S, A>::insert": [
            "/// Sets the value of the entry, and returns the entry's old value.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::hash_map::{HashMap, RawEntryMut};\n///\n/// let mut map: HashMap<&str, u32> = [(\"a\", 100), (\"b\", 200)].into();\n///\n/// match map.raw_entry_mut().from_key(&\"a\") {\n///     RawEntryMut::Vacant(_) => panic!(),\n///     RawEntryMut::Occupied(mut o) => assert_eq!(o.insert(1000), 100),\n/// }\n///\n/// assert_eq!(map[&\"a\"], 1000);\n/// ```\ninline\npub fn insert(&mut self, value: V) -> V{\n        mem::replace(self.get_mut(), value)\n    }",
            "Real(LocalPath(\"src/raw_entry.rs\"))"
        ],
        "raw_entry::RawOccupiedEntryMut::<'a, K, V, S, A>::insert_key": [
            "/// Sets the value of the entry, and returns the entry's old value.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::hash_map::{HashMap, RawEntryMut};\n/// use std::rc::Rc;\n///\n/// let key_one = Rc::new(\"a\");\n/// let key_two = Rc::new(\"a\");\n///\n/// let mut map: HashMap<Rc<&str>, u32> = HashMap::new();\n/// map.insert(key_one.clone(), 10);\n///\n/// assert_eq!(map[&key_one], 10);\n/// assert!(Rc::strong_count(&key_one) == 2 && Rc::strong_count(&key_two) == 1);\n///\n/// match map.raw_entry_mut().from_key(&key_one) {\n///     RawEntryMut::Vacant(_) => panic!(),\n///     RawEntryMut::Occupied(mut o) => {\n///         let old_key = o.insert_key(key_two.clone());\n///         assert!(Rc::ptr_eq(&old_key, &key_one));\n///     }\n/// }\n/// assert_eq!(map[&key_two], 10);\n/// assert!(Rc::strong_count(&key_one) == 1 && Rc::strong_count(&key_two) == 2);\n/// ```\ninline\npub fn insert_key(&mut self, key: K) -> K{\n        mem::replace(self.key_mut(), key)\n    }",
            "Real(LocalPath(\"src/raw_entry.rs\"))"
        ],
        "raw_entry::RawOccupiedEntryMut::<'a, K, V, S, A>::into_key": [
            "/// Converts the entry into a mutable reference to the key in the entry\n/// with a lifetime bound to the map itself.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::hash_map::{HashMap, RawEntryMut};\n/// use std::rc::Rc;\n///\n/// let key_one = Rc::new(\"a\");\n/// let key_two = Rc::new(\"a\");\n///\n/// let mut map: HashMap<Rc<&str>, u32> = HashMap::new();\n/// map.insert(key_one.clone(), 10);\n///\n/// assert_eq!(map[&key_one], 10);\n/// assert!(Rc::strong_count(&key_one) == 2 && Rc::strong_count(&key_two) == 1);\n///\n/// let inside_key: &mut Rc<&str>;\n///\n/// match map.raw_entry_mut().from_key(&key_one) {\n///     RawEntryMut::Vacant(_) => panic!(),\n///     RawEntryMut::Occupied(o) => inside_key = o.into_key(),\n/// }\n/// *inside_key = key_two.clone();\n///\n/// assert_eq!(map[&key_two], 10);\n/// assert!(Rc::strong_count(&key_one) == 1 && Rc::strong_count(&key_two) == 2);\n/// ```\ninline\npub fn into_key(self) -> &'a mut K{\n        unsafe { &mut self.elem.as_mut().0 }\n    }",
            "Real(LocalPath(\"src/raw_entry.rs\"))"
        ],
        "raw_entry::RawOccupiedEntryMut::<'a, K, V, S, A>::into_key_value": [
            "/// Converts the `OccupiedEntry` into a mutable reference to the key and value in the entry\n/// with a lifetime bound to the map itself.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::hash_map::{HashMap, RawEntryMut};\n/// use std::rc::Rc;\n///\n/// let key_one = Rc::new(\"a\");\n/// let key_two = Rc::new(\"a\");\n///\n/// let mut map: HashMap<Rc<&str>, u32> = HashMap::new();\n/// map.insert(key_one.clone(), 10);\n///\n/// assert_eq!(map[&key_one], 10);\n/// assert!(Rc::strong_count(&key_one) == 2 && Rc::strong_count(&key_two) == 1);\n///\n/// let inside_key: &mut Rc<&str>;\n/// let inside_value: &mut u32;\n/// match map.raw_entry_mut().from_key(&key_one) {\n///     RawEntryMut::Vacant(_) => panic!(),\n///     RawEntryMut::Occupied(o) => {\n///         let tuple = o.into_key_value();\n///         inside_key = tuple.0;\n///         inside_value = tuple.1;\n///     }\n/// }\n/// *inside_key = key_two.clone();\n/// *inside_value = 100;\n/// assert_eq!(map[&key_two], 100);\n/// assert!(Rc::strong_count(&key_one) == 1 && Rc::strong_count(&key_two) == 2);\n/// ```\ninline\npub fn into_key_value(self) -> (&'a mut K, &'a mut V){\n        unsafe {\n            let &mut (ref mut key, ref mut value) = self.elem.as_mut();\n            (key, value)\n        }\n    }",
            "Real(LocalPath(\"src/raw_entry.rs\"))"
        ],
        "raw_entry::RawOccupiedEntryMut::<'a, K, V, S, A>::into_mut": [
            "/// Converts the `OccupiedEntry` into a mutable reference to the value in the entry\n/// with a lifetime bound to the map itself.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::hash_map::{HashMap, RawEntryMut};\n///\n/// let mut map: HashMap<&str, u32> = [(\"a\", 100), (\"b\", 200)].into();\n///\n/// let value: &mut u32;\n///\n/// match map.raw_entry_mut().from_key(&\"a\") {\n///     RawEntryMut::Vacant(_) => panic!(),\n///     RawEntryMut::Occupied(o) => value = o.into_mut(),\n/// }\n/// *value += 900;\n///\n/// assert_eq!(map[&\"a\"], 1000);\n/// ```\ninline\npub fn into_mut(self) -> &'a mut V{\n        unsafe { &mut self.elem.as_mut().1 }\n    }",
            "Real(LocalPath(\"src/raw_entry.rs\"))"
        ],
        "raw_entry::RawOccupiedEntryMut::<'a, K, V, S, A>::key": [
            "/// Gets a reference to the key in the entry.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::hash_map::{HashMap, RawEntryMut};\n///\n/// let mut map: HashMap<&str, u32> = [(\"a\", 100), (\"b\", 200)].into();\n///\n/// match map.raw_entry_mut().from_key(&\"a\") {\n///     RawEntryMut::Vacant(_) => panic!(),\n///     RawEntryMut::Occupied(o) => assert_eq!(o.key(), &\"a\")\n/// }\n/// ```\ninline\npub fn key(&self) -> &K{\n        unsafe { &self.elem.as_ref().0 }\n    }",
            "Real(LocalPath(\"src/raw_entry.rs\"))"
        ],
        "raw_entry::RawOccupiedEntryMut::<'a, K, V, S, A>::key_mut": [
            "/// Gets a mutable reference to the key in the entry.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::hash_map::{HashMap, RawEntryMut};\n/// use std::rc::Rc;\n///\n/// let key_one = Rc::new(\"a\");\n/// let key_two = Rc::new(\"a\");\n///\n/// let mut map: HashMap<Rc<&str>, u32> = HashMap::new();\n/// map.insert(key_one.clone(), 10);\n///\n/// assert_eq!(map[&key_one], 10);\n/// assert!(Rc::strong_count(&key_one) == 2 && Rc::strong_count(&key_two) == 1);\n///\n/// match map.raw_entry_mut().from_key(&key_one) {\n///     RawEntryMut::Vacant(_) => panic!(),\n///     RawEntryMut::Occupied(mut o) => {\n///         *o.key_mut() = key_two.clone();\n///     }\n/// }\n/// assert_eq!(map[&key_two], 10);\n/// assert!(Rc::strong_count(&key_one) == 1 && Rc::strong_count(&key_two) == 2);\n/// ```\ninline\npub fn key_mut(&mut self) -> &mut K{\n        unsafe { &mut self.elem.as_mut().0 }\n    }",
            "Real(LocalPath(\"src/raw_entry.rs\"))"
        ],
        "raw_entry::RawOccupiedEntryMut::<'a, K, V, S, A>::remove": [
            "/// Takes the value out of the entry, and returns it.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::hash_map::{HashMap, RawEntryMut};\n///\n/// let mut map: HashMap<&str, u32> = [(\"a\", 100), (\"b\", 200)].into();\n///\n/// match map.raw_entry_mut().from_key(&\"a\") {\n///     RawEntryMut::Vacant(_) => panic!(),\n///     RawEntryMut::Occupied(o) => assert_eq!(o.remove(), 100),\n/// }\n/// assert_eq!(map.get(&\"a\"), None);\n/// ```\ninline\npub fn remove(self) -> V{\n        self.remove_entry().1\n    }",
            "Real(LocalPath(\"src/raw_entry.rs\"))"
        ],
        "raw_entry::RawOccupiedEntryMut::<'a, K, V, S, A>::remove_entry": [
            "/// Take the ownership of the key and value from the map.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::hash_map::{HashMap, RawEntryMut};\n///\n/// let mut map: HashMap<&str, u32> = [(\"a\", 100), (\"b\", 200)].into();\n///\n/// match map.raw_entry_mut().from_key(&\"a\") {\n///     RawEntryMut::Vacant(_) => panic!(),\n///     RawEntryMut::Occupied(o) => assert_eq!(o.remove_entry(), (\"a\", 100)),\n/// }\n/// assert_eq!(map.get(&\"a\"), None);\n/// ```\ninline\npub fn remove_entry(self) -> (K, V){\n        unsafe { self.table.remove(self.elem).0 }\n    }",
            "Real(LocalPath(\"src/raw_entry.rs\"))"
        ],
        "raw_entry::RawOccupiedEntryMut::<'a, K, V, S, A>::replace_entry_with": [
            "/// Provides shared access to the key and owned access to the value of\n/// the entry and allows to replace or remove it based on the\n/// value of the returned option.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::hash_map::{HashMap, RawEntryMut};\n///\n/// let mut map: HashMap<&str, u32> = [(\"a\", 100), (\"b\", 200)].into();\n///\n/// let raw_entry = match map.raw_entry_mut().from_key(&\"a\") {\n///     RawEntryMut::Vacant(_) => panic!(),\n///     RawEntryMut::Occupied(o) => o.replace_entry_with(|k, v| {\n///         assert_eq!(k, &\"a\");\n///         assert_eq!(v, 100);\n///         Some(v + 900)\n///     }),\n/// };\n/// let raw_entry = match raw_entry {\n///     RawEntryMut::Vacant(_) => panic!(),\n///     RawEntryMut::Occupied(o) => o.replace_entry_with(|k, v| {\n///         assert_eq!(k, &\"a\");\n///         assert_eq!(v, 1000);\n///         None\n///     }),\n/// };\n/// match raw_entry {\n///     RawEntryMut::Vacant(_) => { },\n///     RawEntryMut::Occupied(_) => panic!(),\n/// };\n/// assert_eq!(map.get(&\"a\"), None);\n/// ```\ninline\npub fn replace_entry_with<F>(self, f: F) -> RawEntryMut<'a, K, V, S, A>\n    where\n        F: FnOnce(&K, V) -> Option<V>,{\n        unsafe {\n            let still_occupied = self\n                .table\n                .replace_bucket_with(self.elem.clone(), |(key, value)| {\n                    f(&key, value).map(|new_value| (key, new_value))\n                });\n\n            if still_occupied {\n                RawEntryMut::Occupied(self)\n            } else {\n                RawEntryMut::Vacant(RawVacantEntryMut {\n                    table: self.table,\n                    hash_builder: self.hash_builder,\n                })\n            }\n        }\n    }",
            "Real(LocalPath(\"src/raw_entry.rs\"))"
        ],
        "raw_entry::RawVacantEntryMut": [
            "/// A view into a vacant entry in a `HashMap`.\n/// It is part of the [`RawEntryMut`] enum.\n///\n/// [`RawEntryMut`]: enum.RawEntryMut.html\n///\n/// # Examples\n///\n/// ```\n/// use core::hash::{BuildHasher, Hash};\n/// use hashbrown::hash_map::{HashMap, RawEntryMut, RawVacantEntryMut};\n///\n/// let mut map = HashMap::<&str, i32>::new();\n///\n/// fn compute_hash<K: Hash + ?Sized, S: BuildHasher>(hash_builder: &S, key: &K) -> u64 {\n///     use core::hash::Hasher;\n///     let mut state = hash_builder.build_hasher();\n///     key.hash(&mut state);\n///     state.finish()\n/// }\n///\n/// let raw_v: RawVacantEntryMut<_, _, _> = match map.raw_entry_mut().from_key(&\"a\") {\n///     RawEntryMut::Vacant(view) => view,\n///     RawEntryMut::Occupied(_) => unreachable!(),\n/// };\n/// raw_v.insert(\"a\", 10);\n/// assert!(map[&\"a\"] == 10 && map.len() == 1);\n///\n/// // Nonexistent key (insert and update)\n/// let hash = compute_hash(map.hasher(), &\"b\");\n/// match map.raw_entry_mut().from_key_hashed_nocheck(hash, &\"b\") {\n///     RawEntryMut::Occupied(_) => unreachable!(),\n///     RawEntryMut::Vacant(view) => {\n///         let (k, value) = view.insert(\"b\", 2);\n///         assert_eq!((*k, *value), (\"b\", 2));\n///         *value = 20;\n///     }\n/// }\n/// assert!(map[&\"b\"] == 20 && map.len() == 2);\n///\n/// let hash = compute_hash(map.hasher(), &\"c\");\n/// match map.raw_entry_mut().from_hash(hash, |q| *q == \"c\") {\n///     RawEntryMut::Occupied(_) => unreachable!(),\n///     RawEntryMut::Vacant(view) => {\n///         assert_eq!(view.insert(\"c\", 30), (&mut \"c\", &mut 30));\n///     }\n/// }\n/// assert!(map[&\"c\"] == 30 && map.len() == 3);\n/// ```\npub struct RawVacantEntryMut<'a, K, V, S, A: Allocator = Global> {\n    table: &'a mut RawTable<(K, V), A>,\n    hash_builder: &'a S,\n}",
            "Real(LocalPath(\"src/raw_entry.rs\"))"
        ],
        "raw_entry::RawVacantEntryMut::<'a, K, V, S, A>::insert": [
            "/// Sets the value of the entry with the `VacantEntry`'s key,\n/// and returns a mutable reference to it.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::hash_map::{HashMap, RawEntryMut};\n///\n/// let mut map: HashMap<&str, u32> = [(\"a\", 100), (\"b\", 200)].into();\n///\n/// match map.raw_entry_mut().from_key(&\"c\") {\n///     RawEntryMut::Occupied(_) => panic!(),\n///     RawEntryMut::Vacant(v) => assert_eq!(v.insert(\"c\", 300), (&mut \"c\", &mut 300)),\n/// }\n///\n/// assert_eq!(map[&\"c\"], 300);\n/// ```\ninline\npub fn insert(self, key: K, value: V) -> (&'a mut K, &'a mut V)\n    where\n        K: Hash,\n        S: BuildHasher,{\n        let hash = make_hash::<K, S>(self.hash_builder, &key);\n        self.insert_hashed_nocheck(hash, key, value)\n    }",
            "Real(LocalPath(\"src/raw_entry.rs\"))"
        ],
        "raw_entry::RawVacantEntryMut::<'a, K, V, S, A>::insert_entry": [
            "inline\nfn insert_entry(self, key: K, value: V) -> RawOccupiedEntryMut<'a, K, V, S, A>\n    where\n        K: Hash,\n        S: BuildHasher,{\n        let hash = make_hash::<K, S>(self.hash_builder, &key);\n        let elem = self.table.insert(\n            hash,\n            (key, value),\n            make_hasher::<_, V, S>(self.hash_builder),\n        );\n        RawOccupiedEntryMut {\n            elem,\n            table: self.table,\n            hash_builder: self.hash_builder,\n        }\n    }",
            "Real(LocalPath(\"src/raw_entry.rs\"))"
        ],
        "raw_entry::RawVacantEntryMut::<'a, K, V, S, A>::insert_hashed_nocheck": [
            "/// Sets the value of the entry with the `VacantEntry`'s key,\n/// and returns a mutable reference to it.\n///\n/// # Examples\n///\n/// ```\n/// use core::hash::{BuildHasher, Hash};\n/// use hashbrown::hash_map::{HashMap, RawEntryMut};\n///\n/// fn compute_hash<K: Hash + ?Sized, S: BuildHasher>(hash_builder: &S, key: &K) -> u64 {\n///     use core::hash::Hasher;\n///     let mut state = hash_builder.build_hasher();\n///     key.hash(&mut state);\n///     state.finish()\n/// }\n///\n/// let mut map: HashMap<&str, u32> = [(\"a\", 100), (\"b\", 200)].into();\n/// let key = \"c\";\n/// let hash = compute_hash(map.hasher(), &key);\n///\n/// match map.raw_entry_mut().from_key_hashed_nocheck(hash, &key) {\n///     RawEntryMut::Occupied(_) => panic!(),\n///     RawEntryMut::Vacant(v) => assert_eq!(\n///         v.insert_hashed_nocheck(hash, key, 300),\n///         (&mut \"c\", &mut 300)\n///     ),\n/// }\n///\n/// assert_eq!(map[&\"c\"], 300);\n/// ```\ninline\n#[allow(clippy::shadow_unrelated)]\npub fn insert_hashed_nocheck(self, hash: u64, key: K, value: V) -> (&'a mut K, &'a mut V)\n    where\n        K: Hash,\n        S: BuildHasher,{\n        let &mut (ref mut k, ref mut v) = self.table.insert_entry(\n            hash,\n            (key, value),\n            make_hasher::<_, V, S>(self.hash_builder),\n        );\n        (k, v)\n    }",
            "Real(LocalPath(\"src/raw_entry.rs\"))"
        ],
        "raw_entry::RawVacantEntryMut::<'a, K, V, S, A>::insert_with_hasher": [
            "/// Set the value of an entry with a custom hasher function.\n///\n/// # Examples\n///\n/// ```\n/// use core::hash::{BuildHasher, Hash};\n/// use hashbrown::hash_map::{HashMap, RawEntryMut};\n///\n/// fn make_hasher<K, S>(hash_builder: &S) -> impl Fn(&K) -> u64 + '_\n/// where\n///     K: Hash + ?Sized,\n///     S: BuildHasher,\n/// {\n///     move |key: &K| {\n///         use core::hash::Hasher;\n///         let mut state = hash_builder.build_hasher();\n///         key.hash(&mut state);\n///         state.finish()\n///     }\n/// }\n///\n/// let mut map: HashMap<&str, u32> = HashMap::new();\n/// let key = \"a\";\n/// let hash_builder = map.hasher().clone();\n/// let hash = make_hasher(&hash_builder)(&key);\n///\n/// match map.raw_entry_mut().from_hash(hash, |q| q == &key) {\n///     RawEntryMut::Occupied(_) => panic!(),\n///     RawEntryMut::Vacant(v) => assert_eq!(\n///         v.insert_with_hasher(hash, key, 100, make_hasher(&hash_builder)),\n///         (&mut \"a\", &mut 100)\n///     ),\n/// }\n/// map.extend([(\"b\", 200), (\"c\", 300), (\"d\", 400), (\"e\", 500), (\"f\", 600)]);\n/// assert_eq!(map[&\"a\"], 100);\n/// ```\ninline\npub fn insert_with_hasher<H>(\n        self,\n        hash: u64,\n        key: K,\n        value: V,\n        hasher: H,\n    ) -> (&'a mut K, &'a mut V)\n    where\n        H: Fn(&K) -> u64,{\n        let &mut (ref mut k, ref mut v) = self\n            .table\n            .insert_entry(hash, (key, value), |x| hasher(&x.0));\n        (k, v)\n    }",
            "Real(LocalPath(\"src/raw_entry.rs\"))"
        ],
        "scopeguard::ScopeGuard": [
            "pub struct ScopeGuard<T, F>\nwhere\n    F: FnMut(&mut T),\n{\n    dropfn: F,\n    value: T,\n}",
            "Real(LocalPath(\"src/scopeguard.rs\"))"
        ],
        "scopeguard::ScopeGuard::<T, F>::into_inner": [
            "#[inline]\npub fn into_inner(guard: Self) -> T{\n        // Cannot move out of Drop-implementing types, so\n        // ptr::read the value out of a ManuallyDrop<Self>\n        // Don't use mem::forget as that might invalidate value\n        let guard = ManuallyDrop::new(guard);\n        unsafe {\n            let value = ptr::read(&guard.value);\n            // read the closure so that it is dropped\n            let _ = ptr::read(&guard.dropfn);\n            value\n        }\n    }",
            "Real(LocalPath(\"src/scopeguard.rs\"))"
        ],
        "scopeguard::guard": [
            "#[inline]\npub fn guard<T, F>(value: T, dropfn: F) -> ScopeGuard<T, F>\nwhere\n    F: FnMut(&mut T),{\n    ScopeGuard { dropfn, value }\n}",
            "Real(LocalPath(\"src/scopeguard.rs\"))"
        ],
        "set::Difference": [
            "/// A lazy iterator producing elements in the difference of `HashSet`s.\n///\n/// This `struct` is created by the [`difference`] method on [`HashSet`].\n/// See its documentation for more.\n///\n/// [`HashSet`]: struct.HashSet.html\n/// [`difference`]: struct.HashSet.html#method.difference\npub struct Difference<'a, T, S, A: Allocator = Global> {\n    // iterator of the first set\n    iter: Iter<'a, T>,\n    // the second set\n    other: &'a HashSet<T, S, A>,\n}",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "set::Drain": [
            "/// A draining iterator over the items of a `HashSet`.\n///\n/// This `struct` is created by the [`drain`] method on [`HashSet`].\n/// See its documentation for more.\n///\n/// [`HashSet`]: struct.HashSet.html\n/// [`drain`]: struct.HashSet.html#method.drain\npub struct Drain<'a, K, A: Allocator = Global> {\n    iter: map::Drain<'a, K, (), A>,\n}",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "set::Entry": [
            "/// A view into a single entry in a set, which may either be vacant or occupied.\n///\n/// This `enum` is constructed from the [`entry`] method on [`HashSet`].\n///\n/// [`HashSet`]: struct.HashSet.html\n/// [`entry`]: struct.HashSet.html#method.entry\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::hash_set::{Entry, HashSet, OccupiedEntry};\n///\n/// let mut set = HashSet::new();\n/// set.extend([\"a\", \"b\", \"c\"]);\n/// assert_eq!(set.len(), 3);\n///\n/// // Existing value (insert)\n/// let entry: Entry<_, _> = set.entry(\"a\");\n/// let _raw_o: OccupiedEntry<_, _> = entry.insert();\n/// assert_eq!(set.len(), 3);\n/// // Nonexistent value (insert)\n/// set.entry(\"d\").insert();\n///\n/// // Existing value (or_insert)\n/// set.entry(\"b\").or_insert();\n/// // Nonexistent value (or_insert)\n/// set.entry(\"e\").or_insert();\n///\n/// println!(\"Our HashSet: {:?}\", set);\n///\n/// let mut vec: Vec<_> = set.iter().copied().collect();\n/// // The `Iter` iterator produces items in arbitrary order, so the\n/// // items must be sorted to test them against a sorted array.\n/// vec.sort_unstable();\n/// assert_eq!(vec, [\"a\", \"b\", \"c\", \"d\", \"e\"]);\n/// ```\npub enum Entry<'a, T, S, A = Global>\nwhere\n    A: Allocator,\n{\n    /// An occupied entry.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::hash_set::{Entry, HashSet};\n    /// let mut set: HashSet<_> = [\"a\", \"b\"].into();\n    ///\n    /// match set.entry(\"a\") {\n    ///     Entry::Vacant(_) => unreachable!(),\n    ///     Entry::Occupied(_) => { }\n    /// }\n    /// ```\n    Occupied(OccupiedEntry<'a, T, S, A>),\n\n    /// A vacant entry.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// use hashbrown::hash_set::{Entry, HashSet};\n    /// let mut set: HashSet<&str> = HashSet::new();\n    ///\n    /// match set.entry(\"a\") {\n    ///     Entry::Occupied(_) => unreachable!(),\n    ///     Entry::Vacant(_) => { }\n    /// }\n    /// ```\n    Vacant(VacantEntry<'a, T, S, A>),\n}",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "set::Entry::<'a, T, S, A>::get": [
            "/// Returns a reference to this entry's value.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n///\n/// let mut set: HashSet<&str> = HashSet::new();\n/// set.entry(\"poneyland\").or_insert();\n/// // existing key\n/// assert_eq!(set.entry(\"poneyland\").get(), &\"poneyland\");\n/// // nonexistent key\n/// assert_eq!(set.entry(\"horseland\").get(), &\"horseland\");\n/// ```\ninline\npub fn get(&self) -> &T{\n        match *self {\n            Entry::Occupied(ref entry) => entry.get(),\n            Entry::Vacant(ref entry) => entry.get(),\n        }\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "set::Entry::<'a, T, S, A>::insert": [
            "/// Sets the value of the entry, and returns an `OccupiedEntry`.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n///\n/// let mut set: HashSet<&str> = HashSet::new();\n/// let entry = set.entry(\"horseyland\").insert();\n///\n/// assert_eq!(entry.get(), &\"horseyland\");\n/// ```\ninline\npub fn insert(self) -> OccupiedEntry<'a, T, S, A>\n    where\n        T: Hash,\n        S: BuildHasher,{\n        match self {\n            Entry::Occupied(entry) => entry,\n            Entry::Vacant(entry) => entry.insert(),\n        }\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "set::Entry::<'a, T, S, A>::or_insert": [
            "/// Ensures a value is in the entry by inserting if it was vacant.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n///\n/// let mut set: HashSet<&str> = HashSet::new();\n///\n/// // nonexistent key\n/// set.entry(\"poneyland\").or_insert();\n/// assert!(set.contains(\"poneyland\"));\n///\n/// // existing key\n/// set.entry(\"poneyland\").or_insert();\n/// assert!(set.contains(\"poneyland\"));\n/// assert_eq!(set.len(), 1);\n/// ```\ninline\npub fn or_insert(self)\n    where\n        T: Hash,\n        S: BuildHasher,{\n        if let Entry::Vacant(entry) = self {\n            entry.insert();\n        }\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "set::ExtractIf": [
            "/// A draining iterator over entries of a `HashSet` which don't satisfy the predicate `f`.\n///\n/// This `struct` is created by the [`extract_if`] method on [`HashSet`]. See its\n/// documentation for more.\n///\n/// [`extract_if`]: struct.HashSet.html#method.extract_if\n/// [`HashSet`]: struct.HashSet.html\n#[must_use = \"Iterators are lazy unless consumed\"]\npub struct ExtractIf<'a, K, F, A: Allocator = Global> {\n    f: F,\n    inner: RawExtractIf<'a, (K, ()), A>,\n}",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "set::HashSet": [
            "/// A hash set implemented as a `HashMap` where the value is `()`.\n///\n/// As with the [`HashMap`] type, a `HashSet` requires that the elements\n/// implement the [`Eq`] and [`Hash`] traits. This can frequently be achieved by\n/// using `#[derive(PartialEq, Eq, Hash)]`. If you implement these yourself,\n/// it is important that the following property holds:\n///\n/// ```text\n/// k1 == k2 -> hash(k1) == hash(k2)\n/// ```\n///\n/// In other words, if two keys are equal, their hashes must be equal.\n///\n///\n/// It is a logic error for an item to be modified in such a way that the\n/// item's hash, as determined by the [`Hash`] trait, or its equality, as\n/// determined by the [`Eq`] trait, changes while it is in the set. This is\n/// normally only possible through [`Cell`], [`RefCell`], global state, I/O, or\n/// unsafe code.\n///\n/// It is also a logic error for the [`Hash`] implementation of a key to panic.\n/// This is generally only possible if the trait is implemented manually. If a\n/// panic does occur then the contents of the `HashSet` may become corrupted and\n/// some items may be dropped from the table.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n/// // Type inference lets us omit an explicit type signature (which\n/// // would be `HashSet<String>` in this example).\n/// let mut books = HashSet::new();\n///\n/// // Add some books.\n/// books.insert(\"A Dance With Dragons\".to_string());\n/// books.insert(\"To Kill a Mockingbird\".to_string());\n/// books.insert(\"The Odyssey\".to_string());\n/// books.insert(\"The Great Gatsby\".to_string());\n///\n/// // Check for a specific one.\n/// if !books.contains(\"The Winds of Winter\") {\n///     println!(\"We have {} books, but The Winds of Winter ain't one.\",\n///              books.len());\n/// }\n///\n/// // Remove a book.\n/// books.remove(\"The Odyssey\");\n///\n/// // Iterate over everything.\n/// for book in &books {\n///     println!(\"{}\", book);\n/// }\n/// ```\n///\n/// The easiest way to use `HashSet` with a custom type is to derive\n/// [`Eq`] and [`Hash`]. We must also derive [`PartialEq`]. This will in the\n/// future be implied by [`Eq`].\n///\n/// ```\n/// use hashbrown::HashSet;\n/// #[derive(Hash, Eq, PartialEq, Debug)]\n/// struct Viking {\n///     name: String,\n///     power: usize,\n/// }\n///\n/// let mut vikings = HashSet::new();\n///\n/// vikings.insert(Viking { name: \"Einar\".to_string(), power: 9 });\n/// vikings.insert(Viking { name: \"Einar\".to_string(), power: 9 });\n/// vikings.insert(Viking { name: \"Olaf\".to_string(), power: 4 });\n/// vikings.insert(Viking { name: \"Harald\".to_string(), power: 8 });\n///\n/// // Use derived implementation to print the vikings.\n/// for x in &vikings {\n///     println!(\"{:?}\", x);\n/// }\n/// ```\n///\n/// A `HashSet` with fixed list of elements can be initialized from an array:\n///\n/// ```\n/// use hashbrown::HashSet;\n///\n/// let viking_names: HashSet<&'static str> =\n///     [ \"Einar\", \"Olaf\", \"Harald\" ].into_iter().collect();\n/// // use the values stored in the set\n/// ```\n///\n/// [`Cell`]: https://doc.rust-lang.org/std/cell/struct.Cell.html\n/// [`Eq`]: https://doc.rust-lang.org/std/cmp/trait.Eq.html\n/// [`Hash`]: https://doc.rust-lang.org/std/hash/trait.Hash.html\n/// [`HashMap`]: struct.HashMap.html\n/// [`PartialEq`]: https://doc.rust-lang.org/std/cmp/trait.PartialEq.html\n/// [`RefCell`]: https://doc.rust-lang.org/std/cell/struct.RefCell.html\npub struct HashSet<T, S = DefaultHashBuilder, A: Allocator = Global> {\n    pub(crate) map: HashMap<T, (), S, A>,\n}",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "set::HashSet::<T, S, A>::allocation_size": [
            "/// Returns the total amount of memory allocated internally by the hash\n/// set, in bytes.\n///\n/// The returned number is informational only. It is intended to be\n/// primarily used for memory profiling.\n#[inline]\npub fn allocation_size(&self) -> usize{\n        self.map.allocation_size()\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "set::HashSet::<T, S, A>::allocator": [
            "/// Returns a reference to the underlying allocator.\n#[inline]\npub fn allocator(&self) -> &A{\n        self.map.allocator()\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "set::HashSet::<T, S, A>::capacity": [
            "/// Returns the number of elements the set can hold without reallocating.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n/// let set: HashSet<i32> = HashSet::with_capacity(100);\n/// assert!(set.capacity() >= 100);\n/// ```\ninline\npub fn capacity(&self) -> usize{\n        self.map.capacity()\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "set::HashSet::<T, S, A>::clear": [
            "/// Clears the set, removing all values.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n///\n/// let mut v = HashSet::new();\n/// v.insert(1);\n/// v.clear();\n/// assert!(v.is_empty());\n/// ```\ninline\npub fn clear(&mut self){\n        self.map.clear();\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "set::HashSet::<T, S, A>::contains": [
            "/// Returns `true` if the set contains a value.\n///\n/// The value may be any borrowed form of the set's value type, but\n/// [`Hash`] and [`Eq`] on the borrowed form *must* match those for\n/// the value type.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n///\n/// let set: HashSet<_> = [1, 2, 3].into_iter().collect();\n/// assert_eq!(set.contains(&1), true);\n/// assert_eq!(set.contains(&4), false);\n/// ```\n///\n/// [`Eq`]: https://doc.rust-lang.org/std/cmp/trait.Eq.html\n/// [`Hash`]: https://doc.rust-lang.org/std/hash/trait.Hash.html\ninline\npub fn contains<Q>(&self, value: &Q) -> bool\n    where\n        Q: Hash + Equivalent<T> + ?Sized,{\n        self.map.contains_key(value)\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "set::HashSet::<T, S, A>::difference": [
            "/// Visits the values representing the difference,\n/// i.e., the values that are in `self` but not in `other`.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n/// let a: HashSet<_> = [1, 2, 3].into_iter().collect();\n/// let b: HashSet<_> = [4, 2, 3, 4].into_iter().collect();\n///\n/// // Can be seen as `a - b`.\n/// for x in a.difference(&b) {\n///     println!(\"{}\", x); // Print 1\n/// }\n///\n/// let diff: HashSet<_> = a.difference(&b).collect();\n/// assert_eq!(diff, [1].iter().collect());\n///\n/// // Note that difference is not symmetric,\n/// // and `b - a` means something else:\n/// let diff: HashSet<_> = b.difference(&a).collect();\n/// assert_eq!(diff, [4].iter().collect());\n/// ```\ninline\npub fn difference<'a>(&'a self, other: &'a Self) -> Difference<'a, T, S, A>{\n        Difference {\n            iter: self.iter(),\n            other,\n        }\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "set::HashSet::<T, S, A>::drain": [
            "/// Clears the set, returning all elements in an iterator.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n///\n/// let mut set: HashSet<_> = [1, 2, 3].into_iter().collect();\n/// assert!(!set.is_empty());\n///\n/// // print 1, 2, 3 in an arbitrary order\n/// for i in set.drain() {\n///     println!(\"{}\", i);\n/// }\n///\n/// assert!(set.is_empty());\n/// ```\ninline\npub fn drain(&mut self) -> Drain<'_, T, A>{\n        Drain {\n            iter: self.map.drain(),\n        }\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "set::HashSet::<T, S, A>::entry": [
            "/// Gets the given value's corresponding entry in the set for in-place manipulation.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n/// use hashbrown::hash_set::Entry::*;\n///\n/// let mut singles = HashSet::new();\n/// let mut dupes = HashSet::new();\n///\n/// for ch in \"a short treatise on fungi\".chars() {\n///     if let Vacant(dupe_entry) = dupes.entry(ch) {\n///         // We haven't already seen a duplicate, so\n///         // check if we've at least seen it once.\n///         match singles.entry(ch) {\n///             Vacant(single_entry) => {\n///                 // We found a new character for the first time.\n///                 single_entry.insert();\n///             }\n///             Occupied(single_entry) => {\n///                 // We've already seen this once, \"move\" it to dupes.\n///                 single_entry.remove();\n///                 dupe_entry.insert();\n///             }\n///         }\n///     }\n/// }\n///\n/// assert!(!singles.contains(&'t') && dupes.contains(&'t'));\n/// assert!(singles.contains(&'u') && !dupes.contains(&'u'));\n/// assert!(!singles.contains(&'v') && !dupes.contains(&'v'));\n/// ```\ninline\npub fn entry(&mut self, value: T) -> Entry<'_, T, S, A>{\n        match self.map.entry(value) {\n            map::Entry::Occupied(entry) => Entry::Occupied(OccupiedEntry { inner: entry }),\n            map::Entry::Vacant(entry) => Entry::Vacant(VacantEntry { inner: entry }),\n        }\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "set::HashSet::<T, S, A>::extract_if": [
            "/// Drains elements which are true under the given predicate,\n/// and returns an iterator over the removed items.\n///\n/// In other words, move all elements `e` such that `f(&e)` returns `true` out\n/// into another iterator.\n///\n/// If the returned `ExtractIf` is not exhausted, e.g. because it is dropped without iterating\n/// or the iteration short-circuits, then the remaining elements will be retained.\n/// Use [`retain()`] with a negated predicate if you do not need the returned iterator.\n///\n/// [`retain()`]: HashSet::retain\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n///\n/// let mut set: HashSet<i32> = (0..8).collect();\n/// let drained: HashSet<i32> = set.extract_if(|v| v % 2 == 0).collect();\n///\n/// let mut evens = drained.into_iter().collect::<Vec<_>>();\n/// let mut odds = set.into_iter().collect::<Vec<_>>();\n/// evens.sort();\n/// odds.sort();\n///\n/// assert_eq!(evens, vec![0, 2, 4, 6]);\n/// assert_eq!(odds, vec![1, 3, 5, 7]);\n/// ```\ninline\npub fn extract_if<F>(&mut self, f: F) -> ExtractIf<'_, T, F, A>\n    where\n        F: FnMut(&T) -> bool,{\n        ExtractIf {\n            f,\n            inner: RawExtractIf {\n                iter: unsafe { self.map.table.iter() },\n                table: &mut self.map.table,\n            },\n        }\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "set::HashSet::<T, S, A>::get": [
            "/// Returns a reference to the value in the set, if any, that is equal to the given value.\n///\n/// The value may be any borrowed form of the set's value type, but\n/// [`Hash`] and [`Eq`] on the borrowed form *must* match those for\n/// the value type.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n///\n/// let set: HashSet<_> = [1, 2, 3].into_iter().collect();\n/// assert_eq!(set.get(&2), Some(&2));\n/// assert_eq!(set.get(&4), None);\n/// ```\n///\n/// [`Eq`]: https://doc.rust-lang.org/std/cmp/trait.Eq.html\n/// [`Hash`]: https://doc.rust-lang.org/std/hash/trait.Hash.html\ninline\npub fn get<Q>(&self, value: &Q) -> Option<&T>\n    where\n        Q: Hash + Equivalent<T> + ?Sized,{\n        // Avoid `Option::map` because it bloats LLVM IR.\n        match self.map.get_key_value(value) {\n            Some((k, _)) => Some(k),\n            None => None,\n        }\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "set::HashSet::<T, S, A>::get_or_insert": [
            "/// Inserts the given `value` into the set if it is not present, then\n/// returns a reference to the value in the set.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n///\n/// let mut set: HashSet<_> = [1, 2, 3].into_iter().collect();\n/// assert_eq!(set.len(), 3);\n/// assert_eq!(set.get_or_insert(2), &2);\n/// assert_eq!(set.get_or_insert(100), &100);\n/// assert_eq!(set.len(), 4); // 100 was inserted\n/// ```\ninline\npub fn get_or_insert(&mut self, value: T) -> &T{\n        let hash = make_hash(&self.map.hash_builder, &value);\n        let bucket = match self.map.find_or_find_insert_slot(hash, &value) {\n            Ok(bucket) => bucket,\n            Err(slot) => unsafe { self.map.table.insert_in_slot(hash, slot, (value, ())) },\n        };\n        unsafe { &bucket.as_ref().0 }\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "set::HashSet::<T, S, A>::get_or_insert_with": [
            "/// Inserts a value computed from `f` into the set if the given `value` is\n/// not present, then returns a reference to the value in the set.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n///\n/// let mut set: HashSet<String> = [\"cat\", \"dog\", \"horse\"]\n///     .iter().map(|&pet| pet.to_owned()).collect();\n///\n/// assert_eq!(set.len(), 3);\n/// for &pet in &[\"cat\", \"dog\", \"fish\"] {\n///     let value = set.get_or_insert_with(pet, str::to_owned);\n///     assert_eq!(value, pet);\n/// }\n/// assert_eq!(set.len(), 4); // a new \"fish\" was inserted\n/// ```\n///\n/// The following example will panic because the new value doesn't match.\n///\n/// ```should_panic\n/// let mut set = hashbrown::HashSet::new();\n/// set.get_or_insert_with(\"rust\", |_| String::new());\n/// ```\ninline\npub fn get_or_insert_with<Q, F>(&mut self, value: &Q, f: F) -> &T\n    where\n        Q: Hash + Equivalent<T> + ?Sized,\n        F: FnOnce(&Q) -> T,{\n        let hash = make_hash(&self.map.hash_builder, value);\n        let bucket = match self.map.find_or_find_insert_slot(hash, value) {\n            Ok(bucket) => bucket,\n            Err(slot) => {\n                let new = f(value);\n                assert!(value.equivalent(&new), \"new value is not equivalent\");\n                unsafe { self.map.table.insert_in_slot(hash, slot, (new, ())) }\n            }\n        };\n        unsafe { &bucket.as_ref().0 }\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "set::HashSet::<T, S, A>::hasher": [
            "/// Returns a reference to the set's [`BuildHasher`].\n///\n/// [`BuildHasher`]: https://doc.rust-lang.org/std/hash/trait.BuildHasher.html\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n/// use hashbrown::DefaultHashBuilder;\n///\n/// let hasher = DefaultHashBuilder::default();\n/// let set: HashSet<i32> = HashSet::with_hasher(hasher);\n/// let hasher: &DefaultHashBuilder = set.hasher();\n/// ```\ninline\npub fn hasher(&self) -> &S{\n        self.map.hasher()\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "set::HashSet::<T, S, A>::insert": [
            "/// Adds a value to the set.\n///\n/// If the set did not have this value present, `true` is returned.\n///\n/// If the set did have this value present, `false` is returned.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n///\n/// let mut set = HashSet::new();\n///\n/// assert_eq!(set.insert(2), true);\n/// assert_eq!(set.insert(2), false);\n/// assert_eq!(set.len(), 1);\n/// ```\ninline\npub fn insert(&mut self, value: T) -> bool{\n        self.map.insert(value, ()).is_none()\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "set::HashSet::<T, S, A>::insert_unique_unchecked": [
            "/// Insert a value the set without checking if the value already exists in the set.\n///\n/// This operation is faster than regular insert, because it does not perform\n/// lookup before insertion.\n///\n/// This operation is useful during initial population of the set.\n/// For example, when constructing a set from another set, we know\n/// that values are unique.\n///\n/// # Safety\n///\n/// This operation is safe if a value does not exist in the set.\n///\n/// However, if a value exists in the set already, the behavior is unspecified:\n/// this operation may panic, loop forever, or any following operation with the set\n/// may panic, loop forever or return arbitrary result.\n///\n/// That said, this operation (and following operations) are guaranteed to\n/// not violate memory safety.\n///\n/// However this operation is still unsafe because the resulting `HashSet`\n/// may be passed to unsafe code which does expect the set to behave\n/// correctly, and would cause unsoundness as a result.\ninline\npub unsafe fn insert_unique_unchecked(&mut self, value: T) -> &T{\n        self.map.insert_unique_unchecked(value, ()).0\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "set::HashSet::<T, S, A>::intersection": [
            "/// Visits the values representing the intersection,\n/// i.e., the values that are both in `self` and `other`.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n/// let a: HashSet<_> = [1, 2, 3].into_iter().collect();\n/// let b: HashSet<_> = [4, 2, 3, 4].into_iter().collect();\n///\n/// // Print 2, 3 in arbitrary order.\n/// for x in a.intersection(&b) {\n///     println!(\"{}\", x);\n/// }\n///\n/// let intersection: HashSet<_> = a.intersection(&b).collect();\n/// assert_eq!(intersection, [2, 3].iter().collect());\n/// ```\ninline\npub fn intersection<'a>(&'a self, other: &'a Self) -> Intersection<'a, T, S, A>{\n        let (smaller, larger) = if self.len() <= other.len() {\n            (self, other)\n        } else {\n            (other, self)\n        };\n        Intersection {\n            iter: smaller.iter(),\n            other: larger,\n        }\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "set::HashSet::<T, S, A>::is_disjoint": [
            "/// Returns `true` if `self` has no elements in common with `other`.\n/// This is equivalent to checking for an empty intersection.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n///\n/// let a: HashSet<_> = [1, 2, 3].into_iter().collect();\n/// let mut b = HashSet::new();\n///\n/// assert_eq!(a.is_disjoint(&b), true);\n/// b.insert(4);\n/// assert_eq!(a.is_disjoint(&b), true);\n/// b.insert(1);\n/// assert_eq!(a.is_disjoint(&b), false);\n/// ```\npub fn is_disjoint(&self, other: &Self) -> bool{\n        self.intersection(other).next().is_none()\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "set::HashSet::<T, S, A>::is_empty": [
            "/// Returns `true` if the set contains no elements.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n///\n/// let mut v = HashSet::new();\n/// assert!(v.is_empty());\n/// v.insert(1);\n/// assert!(!v.is_empty());\n/// ```\ninline\npub fn is_empty(&self) -> bool{\n        self.map.is_empty()\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "set::HashSet::<T, S, A>::is_subset": [
            "/// Returns `true` if the set is a subset of another,\n/// i.e., `other` contains at least all the values in `self`.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n///\n/// let sup: HashSet<_> = [1, 2, 3].into_iter().collect();\n/// let mut set = HashSet::new();\n///\n/// assert_eq!(set.is_subset(&sup), true);\n/// set.insert(2);\n/// assert_eq!(set.is_subset(&sup), true);\n/// set.insert(4);\n/// assert_eq!(set.is_subset(&sup), false);\n/// ```\npub fn is_subset(&self, other: &Self) -> bool{\n        self.len() <= other.len() && self.iter().all(|v| other.contains(v))\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "set::HashSet::<T, S, A>::is_superset": [
            "/// Returns `true` if the set is a superset of another,\n/// i.e., `self` contains at least all the values in `other`.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n///\n/// let sub: HashSet<_> = [1, 2].into_iter().collect();\n/// let mut set = HashSet::new();\n///\n/// assert_eq!(set.is_superset(&sub), false);\n///\n/// set.insert(0);\n/// set.insert(1);\n/// assert_eq!(set.is_superset(&sub), false);\n///\n/// set.insert(2);\n/// assert_eq!(set.is_superset(&sub), true);\n/// ```\ninline\npub fn is_superset(&self, other: &Self) -> bool{\n        other.is_subset(self)\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "set::HashSet::<T, S, A>::iter": [
            "/// An iterator visiting all elements in arbitrary order.\n/// The iterator element type is `&'a T`.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n/// let mut set = HashSet::new();\n/// set.insert(\"a\");\n/// set.insert(\"b\");\n///\n/// // Will print in an arbitrary order.\n/// for x in set.iter() {\n///     println!(\"{}\", x);\n/// }\n/// ```\ninline\npub fn iter(&self) -> Iter<'_, T>{\n        Iter {\n            iter: self.map.keys(),\n        }\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "set::HashSet::<T, S, A>::len": [
            "/// Returns the number of elements in the set.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n///\n/// let mut v = HashSet::new();\n/// assert_eq!(v.len(), 0);\n/// v.insert(1);\n/// assert_eq!(v.len(), 1);\n/// ```\ninline\npub fn len(&self) -> usize{\n        self.map.len()\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "set::HashSet::<T, S, A>::remove": [
            "/// Removes a value from the set. Returns whether the value was\n/// present in the set.\n///\n/// The value may be any borrowed form of the set's value type, but\n/// [`Hash`] and [`Eq`] on the borrowed form *must* match those for\n/// the value type.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n///\n/// let mut set = HashSet::new();\n///\n/// set.insert(2);\n/// assert_eq!(set.remove(&2), true);\n/// assert_eq!(set.remove(&2), false);\n/// ```\n///\n/// [`Eq`]: https://doc.rust-lang.org/std/cmp/trait.Eq.html\n/// [`Hash`]: https://doc.rust-lang.org/std/hash/trait.Hash.html\ninline\npub fn remove<Q>(&mut self, value: &Q) -> bool\n    where\n        Q: Hash + Equivalent<T> + ?Sized,{\n        self.map.remove(value).is_some()\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "set::HashSet::<T, S, A>::replace": [
            "/// Adds a value to the set, replacing the existing value, if any, that is equal to the given\n/// one. Returns the replaced value.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n///\n/// let mut set = HashSet::new();\n/// set.insert(Vec::<i32>::new());\n///\n/// assert_eq!(set.get(&[][..]).unwrap().capacity(), 0);\n/// set.replace(Vec::with_capacity(10));\n/// assert_eq!(set.get(&[][..]).unwrap().capacity(), 10);\n/// ```\ninline\npub fn replace(&mut self, value: T) -> Option<T>{\n        let hash = make_hash(&self.map.hash_builder, &value);\n        match self.map.find_or_find_insert_slot(hash, &value) {\n            Ok(bucket) => Some(mem::replace(unsafe { &mut bucket.as_mut().0 }, value)),\n            Err(slot) => {\n                unsafe {\n                    self.map.table.insert_in_slot(hash, slot, (value, ()));\n                }\n                None\n            }\n        }\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "set::HashSet::<T, S, A>::reserve": [
            "/// Reserves capacity for at least `additional` more elements to be inserted\n/// in the `HashSet`. The collection may reserve more space to avoid\n/// frequent reallocations.\n///\n/// # Panics\n///\n/// Panics if the new capacity exceeds [`isize::MAX`] bytes and [`abort`] the program\n/// in case of allocation error. Use [`try_reserve`](HashSet::try_reserve) instead\n/// if you want to handle memory allocation failure.\n///\n/// [`isize::MAX`]: https://doc.rust-lang.org/std/primitive.isize.html\n/// [`abort`]: https://doc.rust-lang.org/alloc/alloc/fn.handle_alloc_error.html\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n/// let mut set: HashSet<i32> = HashSet::new();\n/// set.reserve(10);\n/// assert!(set.capacity() >= 10);\n/// ```\ninline\npub fn reserve(&mut self, additional: usize){\n        self.map.reserve(additional);\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "set::HashSet::<T, S, A>::retain": [
            "/// Retains only the elements specified by the predicate.\n///\n/// In other words, remove all elements `e` such that `f(&e)` returns `false`.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n///\n/// let xs = [1,2,3,4,5,6];\n/// let mut set: HashSet<i32> = xs.into_iter().collect();\n/// set.retain(|&k| k % 2 == 0);\n/// assert_eq!(set.len(), 3);\n/// ```\npub fn retain<F>(&mut self, mut f: F)\n    where\n        F: FnMut(&T) -> bool,{\n        self.map.retain(|k, _| f(k));\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "set::HashSet::<T, S, A>::shrink_to": [
            "/// Shrinks the capacity of the set with a lower limit. It will drop\n/// down no lower than the supplied limit while maintaining the internal rules\n/// and possibly leaving some space in accordance with the resize policy.\n///\n/// Panics if the current capacity is smaller than the supplied\n/// minimum capacity.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n///\n/// let mut set = HashSet::with_capacity(100);\n/// set.insert(1);\n/// set.insert(2);\n/// assert!(set.capacity() >= 100);\n/// set.shrink_to(10);\n/// assert!(set.capacity() >= 10);\n/// set.shrink_to(0);\n/// assert!(set.capacity() >= 2);\n/// ```\ninline\npub fn shrink_to(&mut self, min_capacity: usize){\n        self.map.shrink_to(min_capacity);\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "set::HashSet::<T, S, A>::shrink_to_fit": [
            "/// Shrinks the capacity of the set as much as possible. It will drop\n/// down as much as possible while maintaining the internal rules\n/// and possibly leaving some space in accordance with the resize policy.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n///\n/// let mut set = HashSet::with_capacity(100);\n/// set.insert(1);\n/// set.insert(2);\n/// assert!(set.capacity() >= 100);\n/// set.shrink_to_fit();\n/// assert!(set.capacity() >= 2);\n/// ```\ninline\npub fn shrink_to_fit(&mut self){\n        self.map.shrink_to_fit();\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "set::HashSet::<T, S, A>::symmetric_difference": [
            "/// Visits the values representing the symmetric difference,\n/// i.e., the values that are in `self` or in `other` but not in both.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n/// let a: HashSet<_> = [1, 2, 3].into_iter().collect();\n/// let b: HashSet<_> = [4, 2, 3, 4].into_iter().collect();\n///\n/// // Print 1, 4 in arbitrary order.\n/// for x in a.symmetric_difference(&b) {\n///     println!(\"{}\", x);\n/// }\n///\n/// let diff1: HashSet<_> = a.symmetric_difference(&b).collect();\n/// let diff2: HashSet<_> = b.symmetric_difference(&a).collect();\n///\n/// assert_eq!(diff1, diff2);\n/// assert_eq!(diff1, [1, 4].iter().collect());\n/// ```\ninline\npub fn symmetric_difference<'a>(&'a self, other: &'a Self) -> SymmetricDifference<'a, T, S, A>{\n        SymmetricDifference {\n            iter: self.difference(other).chain(other.difference(self)),\n        }\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "set::HashSet::<T, S, A>::take": [
            "/// Removes and returns the value in the set, if any, that is equal to the given one.\n///\n/// The value may be any borrowed form of the set's value type, but\n/// [`Hash`] and [`Eq`] on the borrowed form *must* match those for\n/// the value type.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n///\n/// let mut set: HashSet<_> = [1, 2, 3].into_iter().collect();\n/// assert_eq!(set.take(&2), Some(2));\n/// assert_eq!(set.take(&2), None);\n/// ```\n///\n/// [`Eq`]: https://doc.rust-lang.org/std/cmp/trait.Eq.html\n/// [`Hash`]: https://doc.rust-lang.org/std/hash/trait.Hash.html\ninline\npub fn take<Q>(&mut self, value: &Q) -> Option<T>\n    where\n        Q: Hash + Equivalent<T> + ?Sized,{\n        // Avoid `Option::map` because it bloats LLVM IR.\n        match self.map.remove_entry(value) {\n            Some((k, _)) => Some(k),\n            None => None,\n        }\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "set::HashSet::<T, S, A>::try_reserve": [
            "/// Tries to reserve capacity for at least `additional` more elements to be inserted\n/// in the given `HashSet<K,V>`. The collection may reserve more space to avoid\n/// frequent reallocations.\n///\n/// # Errors\n///\n/// If the capacity overflows, or the allocator reports a failure, then an error\n/// is returned.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n/// let mut set: HashSet<i32> = HashSet::new();\n/// set.try_reserve(10).expect(\"why is the test harness OOMing on 10 bytes?\");\n/// ```\ninline\npub fn try_reserve(&mut self, additional: usize) -> Result<(), TryReserveError>{\n        self.map.try_reserve(additional)\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "set::HashSet::<T, S, A>::union": [
            "/// Visits the values representing the union,\n/// i.e., all the values in `self` or `other`, without duplicates.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n/// let a: HashSet<_> = [1, 2, 3].into_iter().collect();\n/// let b: HashSet<_> = [4, 2, 3, 4].into_iter().collect();\n///\n/// // Print 1, 2, 3, 4 in arbitrary order.\n/// for x in a.union(&b) {\n///     println!(\"{}\", x);\n/// }\n///\n/// let union: HashSet<_> = a.union(&b).collect();\n/// assert_eq!(union, [1, 2, 3, 4].iter().collect());\n/// ```\ninline\npub fn union<'a>(&'a self, other: &'a Self) -> Union<'a, T, S, A>{\n        // We'll iterate one set in full, and only the remaining difference from the other.\n        // Use the smaller set for the difference in order to reduce hash lookups.\n        let (smaller, larger) = if self.len() <= other.len() {\n            (self, other)\n        } else {\n            (other, self)\n        };\n        Union {\n            iter: larger.iter().chain(smaller.difference(larger)),\n        }\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "set::HashSet::<T, S, A>::with_capacity_and_hasher_in": [
            "/// Creates an empty `HashSet` with the specified capacity, using\n/// `hasher` to hash the keys.\n///\n/// The hash set will be able to hold at least `capacity` elements without\n/// reallocating. If `capacity` is 0, the hash set will not allocate.\n///\n/// # HashDoS resistance\n///\n/// The `hash_builder` normally use a fixed key by default and that does\n/// not allow the `HashSet` to be protected against attacks such as [`HashDoS`].\n/// Users who require HashDoS resistance should explicitly use\n/// [`std::collections::hash_map::RandomState`]\n/// as the hasher when creating a [`HashSet`].\n///\n/// The `hash_builder` passed should implement the [`BuildHasher`] trait for\n/// the `HashSet` to be useful, see its documentation for details.\n///\n/// [`HashDoS`]: https://en.wikipedia.org/wiki/Collision_attack\n/// [`std::collections::hash_map::RandomState`]: https://doc.rust-lang.org/std/collections/hash_map/struct.RandomState.html\n/// [`BuildHasher`]: https://doc.rust-lang.org/std/hash/trait.BuildHasher.html\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n/// use hashbrown::DefaultHashBuilder;\n///\n/// let s = DefaultHashBuilder::default();\n/// let mut set = HashSet::with_capacity_and_hasher(10, s);\n/// set.insert(1);\n/// ```\ninline\npub fn with_capacity_and_hasher_in(capacity: usize, hasher: S, alloc: A) -> Self{\n        Self {\n            map: HashMap::with_capacity_and_hasher_in(capacity, hasher, alloc),\n        }\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "set::HashSet::<T, S, A>::with_hasher_in": [
            "/// Creates a new empty hash set which will use the given hasher to hash\n/// keys.\n///\n/// The hash set is initially created with a capacity of 0, so it will not\n/// allocate until it is first inserted into.\n///\n/// # HashDoS resistance\n///\n/// The `hash_builder` normally use a fixed key by default and that does\n/// not allow the `HashSet` to be protected against attacks such as [`HashDoS`].\n/// Users who require HashDoS resistance should explicitly use\n/// [`std::collections::hash_map::RandomState`]\n/// as the hasher when creating a [`HashSet`].\n///\n/// The `hash_builder` passed should implement the [`BuildHasher`] trait for\n/// the `HashSet` to be useful, see its documentation for details.\n///\n/// [`HashDoS`]: https://en.wikipedia.org/wiki/Collision_attack\n/// [`std::collections::hash_map::RandomState`]: https://doc.rust-lang.org/std/collections/hash_map/struct.RandomState.html\n/// [`BuildHasher`]: https://doc.rust-lang.org/std/hash/trait.BuildHasher.html\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n/// use hashbrown::DefaultHashBuilder;\n///\n/// let s = DefaultHashBuilder::default();\n/// let mut set = HashSet::with_hasher(s);\n/// set.insert(2);\n/// ```\ninline\npub const fn with_hasher_in(hasher: S, alloc: A) -> Self{\n        Self {\n            map: HashMap::with_hasher_in(hasher, alloc),\n        }\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "set::HashSet::<T, S>::with_capacity_and_hasher": [
            "/// Creates an empty `HashSet` with the specified capacity, using\n/// `hasher` to hash the keys.\n///\n/// The hash set will be able to hold at least `capacity` elements without\n/// reallocating. If `capacity` is 0, the hash set will not allocate.\n///\n/// # HashDoS resistance\n///\n/// The `hash_builder` normally use a fixed key by default and that does\n/// not allow the `HashSet` to be protected against attacks such as [`HashDoS`].\n/// Users who require HashDoS resistance should explicitly use\n/// [`std::collections::hash_map::RandomState`]\n/// as the hasher when creating a [`HashSet`].\n///\n/// The `hash_builder` passed should implement the [`BuildHasher`] trait for\n/// the `HashSet` to be useful, see its documentation for details.\n///\n/// [`HashDoS`]: https://en.wikipedia.org/wiki/Collision_attack\n/// [`std::collections::hash_map::RandomState`]: https://doc.rust-lang.org/std/collections/hash_map/struct.RandomState.html\n/// [`BuildHasher`]: https://doc.rust-lang.org/std/hash/trait.BuildHasher.html\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n/// use hashbrown::DefaultHashBuilder;\n///\n/// let s = DefaultHashBuilder::default();\n/// let mut set = HashSet::with_capacity_and_hasher(10, s);\n/// set.insert(1);\n/// ```\ninline\npub fn with_capacity_and_hasher(capacity: usize, hasher: S) -> Self{\n        Self {\n            map: HashMap::with_capacity_and_hasher(capacity, hasher),\n        }\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "set::HashSet::<T, S>::with_hasher": [
            "/// Creates a new empty hash set which will use the given hasher to hash\n/// keys.\n///\n/// The hash set is initially created with a capacity of 0, so it will not\n/// allocate until it is first inserted into.\n///\n/// # HashDoS resistance\n///\n/// The `hash_builder` normally use a fixed key by default and that does\n/// not allow the `HashSet` to be protected against attacks such as [`HashDoS`].\n/// Users who require HashDoS resistance should explicitly use\n/// [`std::collections::hash_map::RandomState`]\n/// as the hasher when creating a [`HashSet`].\n///\n/// The `hash_builder` passed should implement the [`BuildHasher`] trait for\n/// the `HashSet` to be useful, see its documentation for details.\n///\n/// [`HashDoS`]: https://en.wikipedia.org/wiki/Collision_attack\n/// [`std::collections::hash_map::RandomState`]: https://doc.rust-lang.org/std/collections/hash_map/struct.RandomState.html\n/// [`BuildHasher`]: https://doc.rust-lang.org/std/hash/trait.BuildHasher.html\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n/// use hashbrown::DefaultHashBuilder;\n///\n/// let s = DefaultHashBuilder::default();\n/// let mut set = HashSet::with_hasher(s);\n/// set.insert(2);\n/// ```\ninline\npub const fn with_hasher(hasher: S) -> Self{\n        Self {\n            map: HashMap::with_hasher(hasher),\n        }\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "set::HashSet::<T, foldhash::fast::RandomState, A>::new_in": [
            "/// Creates an empty `HashSet`.\n///\n/// The hash set is initially created with a capacity of 0, so it will not allocate until it\n/// is first inserted into.\n///\n/// # HashDoS resistance\n///\n/// The `hash_builder` normally use a fixed key by default and that does\n/// not allow the `HashSet` to be protected against attacks such as [`HashDoS`].\n/// Users who require HashDoS resistance should explicitly use\n/// [`std::collections::hash_map::RandomState`]\n/// as the hasher when creating a [`HashSet`], for example with\n/// [`with_hasher_in`](HashSet::with_hasher_in) method.\n///\n/// [`HashDoS`]: https://en.wikipedia.org/wiki/Collision_attack\n/// [`std::collections::hash_map::RandomState`]: https://doc.rust-lang.org/std/collections/hash_map/struct.RandomState.html\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n/// let set: HashSet<i32> = HashSet::new();\n/// ```\ninline\npub fn new_in(alloc: A) -> Self{\n        Self {\n            map: HashMap::new_in(alloc),\n        }\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "set::HashSet::<T, foldhash::fast::RandomState, A>::with_capacity_in": [
            "/// Creates an empty `HashSet` with the specified capacity.\n///\n/// The hash set will be able to hold at least `capacity` elements without\n/// reallocating. If `capacity` is 0, the hash set will not allocate.\n///\n/// # HashDoS resistance\n///\n/// The `hash_builder` normally use a fixed key by default and that does\n/// not allow the `HashSet` to be protected against attacks such as [`HashDoS`].\n/// Users who require HashDoS resistance should explicitly use\n/// [`std::collections::hash_map::RandomState`]\n/// as the hasher when creating a [`HashSet`], for example with\n/// [`with_capacity_and_hasher_in`](HashSet::with_capacity_and_hasher_in) method.\n///\n/// [`HashDoS`]: https://en.wikipedia.org/wiki/Collision_attack\n/// [`std::collections::hash_map::RandomState`]: https://doc.rust-lang.org/std/collections/hash_map/struct.RandomState.html\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n/// let set: HashSet<i32> = HashSet::with_capacity(10);\n/// assert!(set.capacity() >= 10);\n/// ```\ninline\npub fn with_capacity_in(capacity: usize, alloc: A) -> Self{\n        Self {\n            map: HashMap::with_capacity_in(capacity, alloc),\n        }\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "set::HashSet::<T>::new": [
            "/// Creates an empty `HashSet`.\n///\n/// The hash set is initially created with a capacity of 0, so it will not allocate until it\n/// is first inserted into.\n///\n/// # HashDoS resistance\n///\n/// The `hash_builder` normally use a fixed key by default and that does\n/// not allow the `HashSet` to be protected against attacks such as [`HashDoS`].\n/// Users who require HashDoS resistance should explicitly use\n/// [`std::collections::hash_map::RandomState`]\n/// as the hasher when creating a [`HashSet`], for example with\n/// [`with_hasher`](HashSet::with_hasher) method.\n///\n/// [`HashDoS`]: https://en.wikipedia.org/wiki/Collision_attack\n/// [`std::collections::hash_map::RandomState`]: https://doc.rust-lang.org/std/collections/hash_map/struct.RandomState.html\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n/// let set: HashSet<i32> = HashSet::new();\n/// ```\ninline\npub fn new() -> Self{\n        Self {\n            map: HashMap::new(),\n        }\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "set::HashSet::<T>::with_capacity": [
            "/// Creates an empty `HashSet` with the specified capacity.\n///\n/// The hash set will be able to hold at least `capacity` elements without\n/// reallocating. If `capacity` is 0, the hash set will not allocate.\n///\n/// # HashDoS resistance\n///\n/// The `hash_builder` normally use a fixed key by default and that does\n/// not allow the `HashSet` to be protected against attacks such as [`HashDoS`].\n/// Users who require HashDoS resistance should explicitly use\n/// [`std::collections::hash_map::RandomState`]\n/// as the hasher when creating a [`HashSet`], for example with\n/// [`with_capacity_and_hasher`](HashSet::with_capacity_and_hasher) method.\n///\n/// [`HashDoS`]: https://en.wikipedia.org/wiki/Collision_attack\n/// [`std::collections::hash_map::RandomState`]: https://doc.rust-lang.org/std/collections/hash_map/struct.RandomState.html\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n/// let set: HashSet<i32> = HashSet::with_capacity(10);\n/// assert!(set.capacity() >= 10);\n/// ```\ninline\npub fn with_capacity(capacity: usize) -> Self{\n        Self {\n            map: HashMap::with_capacity(capacity),\n        }\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "set::Intersection": [
            "/// A lazy iterator producing elements in the intersection of `HashSet`s.\n///\n/// This `struct` is created by the [`intersection`] method on [`HashSet`].\n/// See its documentation for more.\n///\n/// [`HashSet`]: struct.HashSet.html\n/// [`intersection`]: struct.HashSet.html#method.intersection\npub struct Intersection<'a, T, S, A: Allocator = Global> {\n    // iterator of the first set\n    iter: Iter<'a, T>,\n    // the second set\n    other: &'a HashSet<T, S, A>,\n}",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "set::IntoIter": [
            "/// An owning iterator over the items of a `HashSet`.\n///\n/// This `struct` is created by the [`into_iter`] method on [`HashSet`]\n/// (provided by the `IntoIterator` trait). See its documentation for more.\n///\n/// [`HashSet`]: struct.HashSet.html\n/// [`into_iter`]: struct.HashSet.html#method.into_iter\npub struct IntoIter<K, A: Allocator = Global> {\n    iter: map::IntoIter<K, (), A>,\n}",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "set::Iter": [
            "/// An iterator over the items of a `HashSet`.\n///\n/// This `struct` is created by the [`iter`] method on [`HashSet`].\n/// See its documentation for more.\n///\n/// [`HashSet`]: struct.HashSet.html\n/// [`iter`]: struct.HashSet.html#method.iter\npub struct Iter<'a, K> {\n    iter: Keys<'a, K, ()>,\n}",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "set::OccupiedEntry": [
            "/// A view into an occupied entry in a `HashSet`.\n/// It is part of the [`Entry`] enum.\n///\n/// [`Entry`]: enum.Entry.html\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::hash_set::{Entry, HashSet, OccupiedEntry};\n///\n/// let mut set = HashSet::new();\n/// set.extend([\"a\", \"b\", \"c\"]);\n///\n/// let _entry_o: OccupiedEntry<_, _> = set.entry(\"a\").insert();\n/// assert_eq!(set.len(), 3);\n///\n/// // Existing key\n/// match set.entry(\"a\") {\n///     Entry::Vacant(_) => unreachable!(),\n///     Entry::Occupied(view) => {\n///         assert_eq!(view.get(), &\"a\");\n///     }\n/// }\n///\n/// assert_eq!(set.len(), 3);\n///\n/// // Existing key (take)\n/// match set.entry(\"c\") {\n///     Entry::Vacant(_) => unreachable!(),\n///     Entry::Occupied(view) => {\n///         assert_eq!(view.remove(), \"c\");\n///     }\n/// }\n/// assert_eq!(set.get(&\"c\"), None);\n/// assert_eq!(set.len(), 2);\n/// ```\npub struct OccupiedEntry<'a, T, S, A: Allocator = Global> {\n    inner: map::OccupiedEntry<'a, T, (), S, A>,\n}",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "set::OccupiedEntry::<'_, T, S, A>::get": [
            "/// Gets a reference to the value in the entry.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::hash_set::{Entry, HashSet};\n///\n/// let mut set: HashSet<&str> = HashSet::new();\n/// set.entry(\"poneyland\").or_insert();\n///\n/// match set.entry(\"poneyland\") {\n///     Entry::Vacant(_) => panic!(),\n///     Entry::Occupied(entry) => assert_eq!(entry.get(), &\"poneyland\"),\n/// }\n/// ```\ninline\npub fn get(&self) -> &T{\n        self.inner.key()\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "set::OccupiedEntry::<'_, T, S, A>::remove": [
            "/// Takes the value out of the entry, and returns it.\n/// Keeps the allocated memory for reuse.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n/// use hashbrown::hash_set::Entry;\n///\n/// let mut set: HashSet<&str> = HashSet::new();\n/// // The set is empty\n/// assert!(set.is_empty() && set.capacity() == 0);\n///\n/// set.entry(\"poneyland\").or_insert();\n/// let capacity_before_remove = set.capacity();\n///\n/// if let Entry::Occupied(o) = set.entry(\"poneyland\") {\n///     assert_eq!(o.remove(), \"poneyland\");\n/// }\n///\n/// assert_eq!(set.contains(\"poneyland\"), false);\n/// // Now set hold none elements but capacity is equal to the old one\n/// assert!(set.len() == 0 && set.capacity() == capacity_before_remove);\n/// ```\ninline\npub fn remove(self) -> T{\n        self.inner.remove_entry().0\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "set::SymmetricDifference": [
            "/// A lazy iterator producing elements in the symmetric difference of `HashSet`s.\n///\n/// This `struct` is created by the [`symmetric_difference`] method on\n/// [`HashSet`]. See its documentation for more.\n///\n/// [`HashSet`]: struct.HashSet.html\n/// [`symmetric_difference`]: struct.HashSet.html#method.symmetric_difference\npub struct SymmetricDifference<'a, T, S, A: Allocator = Global> {\n    iter: Chain<Difference<'a, T, S, A>, Difference<'a, T, S, A>>,\n}",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "set::Union": [
            "/// A lazy iterator producing elements in the union of `HashSet`s.\n///\n/// This `struct` is created by the [`union`] method on [`HashSet`].\n/// See its documentation for more.\n///\n/// [`HashSet`]: struct.HashSet.html\n/// [`union`]: struct.HashSet.html#method.union\npub struct Union<'a, T, S, A: Allocator = Global> {\n    iter: Chain<Iter<'a, T>, Difference<'a, T, S, A>>,\n}",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "set::VacantEntry": [
            "/// A view into a vacant entry in a `HashSet`.\n/// It is part of the [`Entry`] enum.\n///\n/// [`Entry`]: enum.Entry.html\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::hash_set::{Entry, HashSet, VacantEntry};\n///\n/// let mut set = HashSet::<&str>::new();\n///\n/// let entry_v: VacantEntry<_, _> = match set.entry(\"a\") {\n///     Entry::Vacant(view) => view,\n///     Entry::Occupied(_) => unreachable!(),\n/// };\n/// entry_v.insert();\n/// assert!(set.contains(\"a\") && set.len() == 1);\n///\n/// // Nonexistent key (insert)\n/// match set.entry(\"b\") {\n///     Entry::Vacant(view) => { view.insert(); },\n///     Entry::Occupied(_) => unreachable!(),\n/// }\n/// assert!(set.contains(\"b\") && set.len() == 2);\n/// ```\npub struct VacantEntry<'a, T, S, A: Allocator = Global> {\n    inner: map::VacantEntry<'a, T, (), S, A>,\n}",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "set::VacantEntry::<'a, T, S, A>::get": [
            "/// Gets a reference to the value that would be used when inserting\n/// through the `VacantEntry`.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n///\n/// let mut set: HashSet<&str> = HashSet::new();\n/// assert_eq!(set.entry(\"poneyland\").get(), &\"poneyland\");\n/// ```\ninline\npub fn get(&self) -> &T{\n        self.inner.key()\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "set::VacantEntry::<'a, T, S, A>::insert": [
            "/// Sets the value of the entry with the `VacantEntry`'s value.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashSet;\n/// use hashbrown::hash_set::Entry;\n///\n/// let mut set: HashSet<&str> = HashSet::new();\n///\n/// if let Entry::Vacant(o) = set.entry(\"poneyland\") {\n///     o.insert();\n/// }\n/// assert!(set.contains(\"poneyland\"));\n/// ```\ninline\npub fn insert(self) -> OccupiedEntry<'a, T, S, A>\n    where\n        T: Hash,\n        S: BuildHasher,{\n        OccupiedEntry {\n            inner: self.inner.insert_entry(()),\n        }\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "set::VacantEntry::<'a, T, S, A>::into_value": [
            "/// Take ownership of the value.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::hash_set::{Entry, HashSet};\n///\n/// let mut set: HashSet<&str> = HashSet::new();\n///\n/// match set.entry(\"poneyland\") {\n///     Entry::Occupied(_) => panic!(),\n///     Entry::Vacant(v) => assert_eq!(v.into_value(), \"poneyland\"),\n/// }\n/// ```\ninline\npub fn into_value(self) -> T{\n        self.inner.into_key()\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "set::assert_covariance": [
            "#[allow(dead_code)]\nfn assert_covariance(){\n    fn set<'new>(v: HashSet<&'static str>) -> HashSet<&'new str> {\n        v\n    }\n    fn iter<'a, 'new>(v: Iter<'a, &'static str>) -> Iter<'a, &'new str> {\n        v\n    }\n    fn into_iter<'new, A: Allocator>(v: IntoIter<&'static str, A>) -> IntoIter<&'new str, A> {\n        v\n    }\n    fn difference<'a, 'new, A: Allocator>(\n        v: Difference<'a, &'static str, DefaultHashBuilder, A>,\n    ) -> Difference<'a, &'new str, DefaultHashBuilder, A> {\n        v\n    }\n    fn symmetric_difference<'a, 'new, A: Allocator>(\n        v: SymmetricDifference<'a, &'static str, DefaultHashBuilder, A>,\n    ) -> SymmetricDifference<'a, &'new str, DefaultHashBuilder, A> {\n        v\n    }\n    fn intersection<'a, 'new, A: Allocator>(\n        v: Intersection<'a, &'static str, DefaultHashBuilder, A>,\n    ) -> Intersection<'a, &'new str, DefaultHashBuilder, A> {\n        v\n    }\n    fn union<'a, 'new, A: Allocator>(\n        v: Union<'a, &'static str, DefaultHashBuilder, A>,\n    ) -> Union<'a, &'new str, DefaultHashBuilder, A> {\n        v\n    }\n    fn drain<'new, A: Allocator>(d: Drain<'static, &'static str, A>) -> Drain<'new, &'new str, A> {\n        d\n    }\n}",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "set::assert_covariance::difference": [
            "fn difference<'a, 'new, A: Allocator>(\n        v: Difference<'a, &'static str, DefaultHashBuilder, A>,\n    ) -> Difference<'a, &'new str, DefaultHashBuilder, A>{\n        v\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "set::assert_covariance::drain": [
            "fn drain<'new, A: Allocator>(d: Drain<'static, &'static str, A>) -> Drain<'new, &'new str, A>{\n        d\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "set::assert_covariance::intersection": [
            "fn intersection<'a, 'new, A: Allocator>(\n        v: Intersection<'a, &'static str, DefaultHashBuilder, A>,\n    ) -> Intersection<'a, &'new str, DefaultHashBuilder, A>{\n        v\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "set::assert_covariance::into_iter": [
            "fn into_iter<'new, A: Allocator>(v: IntoIter<&'static str, A>) -> IntoIter<&'new str, A>{\n        v\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "set::assert_covariance::iter": [
            "fn iter<'a, 'new>(v: Iter<'a, &'static str>) -> Iter<'a, &'new str>{\n        v\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "set::assert_covariance::set": [
            "fn set<'new>(v: HashSet<&'static str>) -> HashSet<&'new str>{\n        v\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "set::assert_covariance::symmetric_difference": [
            "fn symmetric_difference<'a, 'new, A: Allocator>(\n        v: SymmetricDifference<'a, &'static str, DefaultHashBuilder, A>,\n    ) -> SymmetricDifference<'a, &'new str, DefaultHashBuilder, A>{\n        v\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "set::assert_covariance::union": [
            "fn union<'a, 'new, A: Allocator>(\n        v: Union<'a, &'static str, DefaultHashBuilder, A>,\n    ) -> Union<'a, &'new str, DefaultHashBuilder, A>{\n        v\n    }",
            "Real(LocalPath(\"src/set.rs\"))"
        ],
        "table::AbsentEntry": [
            "/// Type representing the absence of an entry, as returned by [`HashTable::find_entry`].\n///\n/// This type only exists due to [limitations] in Rust's NLL borrow checker. In\n/// the future, `find_entry` will return an `Option<OccupiedEntry>` and this\n/// type will be removed.\n///\n/// [limitations]: https://smallcultfollowing.com/babysteps/blog/2018/06/15/mir-based-borrow-check-nll-status-update/#polonius\n///\n/// # Examples\n///\n/// ```\n/// # #[cfg(feature = \"nightly\")]\n/// # fn test() {\n/// use hashbrown::hash_table::{AbsentEntry, Entry};\n/// use hashbrown::{HashTable, DefaultHashBuilder};\n/// use std::hash::BuildHasher;\n///\n/// let mut table: HashTable<&str> = HashTable::new();\n/// let hasher = DefaultHashBuilder::default();\n/// let hasher = |val: &_| hasher.hash_one(val);\n///\n/// let entry_v: AbsentEntry<_, _> = table.find_entry(hasher(&\"a\"), |&x| x == \"a\").unwrap_err();\n/// entry_v\n///     .into_table()\n///     .insert_unique(hasher(&\"a\"), \"a\", hasher);\n/// assert!(table.find(hasher(&\"a\"), |&x| x == \"a\").is_some() && table.len() == 1);\n///\n/// // Nonexistent key (insert)\n/// match table.entry(hasher(&\"b\"), |&x| x == \"b\", hasher) {\n///     Entry::Vacant(view) => {\n///         view.insert(\"b\");\n///     }\n///     Entry::Occupied(_) => unreachable!(),\n/// }\n/// assert!(table.find(hasher(&\"b\"), |&x| x == \"b\").is_some() && table.len() == 2);\n/// # }\n/// # fn main() {\n/// #     #[cfg(feature = \"nightly\")]\n/// #     test()\n/// # }\n/// ```\npub struct AbsentEntry<'a, T, A = Global>\nwhere\n    A: Allocator,\n{\n    table: &'a mut HashTable<T, A>,\n}",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "table::AbsentEntry::<'a, T, A>::into_table": [
            "/// Converts the `AbsentEntry` into a mutable reference to the underlying\n/// table.\npub fn into_table(self) -> &'a mut HashTable<T, A>{\n        self.table\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "table::Drain": [
            "/// A draining iterator over the items of a `HashTable`.\n///\n/// This `struct` is created by the [`drain`] method on [`HashTable`].\n/// See its documentation for more.\n///\n/// [`HashTable`]: struct.HashTable.html\n/// [`drain`]: struct.HashTable.html#method.drain\npub struct Drain<'a, T, A: Allocator = Global> {\n    inner: RawDrain<'a, T, A>,\n}",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "table::Entry": [
            "/// A view into a single entry in a table, which may either be vacant or occupied.\n///\n/// This `enum` is constructed from the [`entry`] method on [`HashTable`].\n///\n/// [`HashTable`]: struct.HashTable.html\n/// [`entry`]: struct.HashTable.html#method.entry\n///\n/// # Examples\n///\n/// ```\n/// # #[cfg(feature = \"nightly\")]\n/// # fn test() {\n/// use hashbrown::hash_table::{Entry, OccupiedEntry};\n/// use hashbrown::{HashTable, DefaultHashBuilder};\n/// use std::hash::BuildHasher;\n///\n/// let mut table = HashTable::new();\n/// let hasher = DefaultHashBuilder::default();\n/// let hasher = |val: &_| hasher.hash_one(val);\n/// for x in [\"a\", \"b\", \"c\"] {\n///     table.insert_unique(hasher(&x), x, hasher);\n/// }\n/// assert_eq!(table.len(), 3);\n///\n/// // Existing value (insert)\n/// let entry: Entry<_> = table.entry(hasher(&\"a\"), |&x| x == \"a\", hasher);\n/// let _raw_o: OccupiedEntry<_, _> = entry.insert(\"a\");\n/// assert_eq!(table.len(), 3);\n/// // Nonexistent value (insert)\n/// table.entry(hasher(&\"d\"), |&x| x == \"d\", hasher).insert(\"d\");\n///\n/// // Existing value (or_insert)\n/// table\n///     .entry(hasher(&\"b\"), |&x| x == \"b\", hasher)\n///     .or_insert(\"b\");\n/// // Nonexistent value (or_insert)\n/// table\n///     .entry(hasher(&\"e\"), |&x| x == \"e\", hasher)\n///     .or_insert(\"e\");\n///\n/// println!(\"Our HashTable: {:?}\", table);\n///\n/// let mut vec: Vec<_> = table.iter().copied().collect();\n/// // The `Iter` iterator produces items in arbitrary order, so the\n/// // items must be sorted to test them against a sorted array.\n/// vec.sort_unstable();\n/// assert_eq!(vec, [\"a\", \"b\", \"c\", \"d\", \"e\"]);\n/// # }\n/// # fn main() {\n/// #     #[cfg(feature = \"nightly\")]\n/// #     test()\n/// # }\n/// ```\npub enum Entry<'a, T, A = Global>\nwhere\n    A: Allocator,\n{\n    /// An occupied entry.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// # #[cfg(feature = \"nightly\")]\n    /// # fn test() {\n    /// use hashbrown::hash_table::{Entry, OccupiedEntry};\n    /// use hashbrown::{HashTable, DefaultHashBuilder};\n    /// use std::hash::BuildHasher;\n    ///\n    /// let mut table = HashTable::new();\n    /// let hasher = DefaultHashBuilder::default();\n    /// let hasher = |val: &_| hasher.hash_one(val);\n    /// for x in [\"a\", \"b\"] {\n    ///     table.insert_unique(hasher(&x), x, hasher);\n    /// }\n    ///\n    /// match table.entry(hasher(&\"a\"), |&x| x == \"a\", hasher) {\n    ///     Entry::Vacant(_) => unreachable!(),\n    ///     Entry::Occupied(_) => {}\n    /// }\n    /// # }\n    /// # fn main() {\n    /// #     #[cfg(feature = \"nightly\")]\n    /// #     test()\n    /// # }\n    /// ```\n    Occupied(OccupiedEntry<'a, T, A>),\n\n    /// A vacant entry.\n    ///\n    /// # Examples\n    ///\n    /// ```\n    /// # #[cfg(feature = \"nightly\")]\n    /// # fn test() {\n    /// use hashbrown::hash_table::{Entry, OccupiedEntry};\n    /// use hashbrown::{HashTable, DefaultHashBuilder};\n    /// use std::hash::BuildHasher;\n    ///\n    /// let mut table = HashTable::<&str>::new();\n    /// let hasher = DefaultHashBuilder::default();\n    /// let hasher = |val: &_| hasher.hash_one(val);\n    ///\n    /// match table.entry(hasher(&\"a\"), |&x| x == \"a\", hasher) {\n    ///     Entry::Vacant(_) => {}\n    ///     Entry::Occupied(_) => unreachable!(),\n    /// }\n    /// # }\n    /// # fn main() {\n    /// #     #[cfg(feature = \"nightly\")]\n    /// #     test()\n    /// # }\n    /// ```\n    Vacant(VacantEntry<'a, T, A>),\n}",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "table::Entry::<'a, T, A>::and_modify": [
            "/// Provides in-place mutable access to an occupied entry before any\n/// potential inserts into the table.\n///\n/// # Examples\n///\n/// ```\n/// # #[cfg(feature = \"nightly\")]\n/// # fn test() {\n/// use hashbrown::{HashTable, DefaultHashBuilder};\n/// use std::hash::BuildHasher;\n///\n/// let mut table: HashTable<(&str, u32)> = HashTable::new();\n/// let hasher = DefaultHashBuilder::default();\n/// let hasher = |val: &_| hasher.hash_one(val);\n///\n/// table\n///     .entry(\n///         hasher(&\"poneyland\"),\n///         |&(x, _)| x == \"poneyland\",\n///         |(k, _)| hasher(&k),\n///     )\n///     .and_modify(|(_, v)| *v += 1)\n///     .or_insert((\"poneyland\", 42));\n/// assert_eq!(\n///     table.find(hasher(&\"poneyland\"), |&(k, _)| k == \"poneyland\"),\n///     Some(&(\"poneyland\", 42))\n/// );\n///\n/// table\n///     .entry(\n///         hasher(&\"poneyland\"),\n///         |&(x, _)| x == \"poneyland\",\n///         |(k, _)| hasher(&k),\n///     )\n///     .and_modify(|(_, v)| *v += 1)\n///     .or_insert((\"poneyland\", 42));\n/// assert_eq!(\n///     table.find(hasher(&\"poneyland\"), |&(k, _)| k == \"poneyland\"),\n///     Some(&(\"poneyland\", 43))\n/// );\n/// # }\n/// # fn main() {\n/// #     #[cfg(feature = \"nightly\")]\n/// #     test()\n/// # }\n/// ```\npub fn and_modify(self, f: impl FnOnce(&mut T)) -> Self{\n        match self {\n            Entry::Occupied(mut entry) => {\n                f(entry.get_mut());\n                Entry::Occupied(entry)\n            }\n            Entry::Vacant(entry) => Entry::Vacant(entry),\n        }\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "table::Entry::<'a, T, A>::insert": [
            "/// Sets the value of the entry, replacing any existing value if there is\n/// one, and returns an [`OccupiedEntry`].\n///\n/// # Examples\n///\n/// ```\n/// # #[cfg(feature = \"nightly\")]\n/// # fn test() {\n/// use hashbrown::{HashTable, DefaultHashBuilder};\n/// use std::hash::BuildHasher;\n///\n/// let mut table: HashTable<&str> = HashTable::new();\n/// let hasher = DefaultHashBuilder::default();\n/// let hasher = |val: &_| hasher.hash_one(val);\n///\n/// let entry = table\n///     .entry(hasher(&\"horseyland\"), |&x| x == \"horseyland\", hasher)\n///     .insert(\"horseyland\");\n///\n/// assert_eq!(entry.get(), &\"horseyland\");\n/// # }\n/// # fn main() {\n/// #     #[cfg(feature = \"nightly\")]\n/// #     test()\n/// # }\n/// ```\npub fn insert(self, value: T) -> OccupiedEntry<'a, T, A>{\n        match self {\n            Entry::Occupied(mut entry) => {\n                *entry.get_mut() = value;\n                entry\n            }\n            Entry::Vacant(entry) => entry.insert(value),\n        }\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "table::Entry::<'a, T, A>::or_insert": [
            "/// Ensures a value is in the entry by inserting if it was vacant.\n///\n/// Returns an [`OccupiedEntry`] pointing to the now-occupied entry.\n///\n/// # Examples\n///\n/// ```\n/// # #[cfg(feature = \"nightly\")]\n/// # fn test() {\n/// use hashbrown::{HashTable, DefaultHashBuilder};\n/// use std::hash::BuildHasher;\n///\n/// let mut table: HashTable<&str> = HashTable::new();\n/// let hasher = DefaultHashBuilder::default();\n/// let hasher = |val: &_| hasher.hash_one(val);\n///\n/// // nonexistent key\n/// table\n///     .entry(hasher(&\"poneyland\"), |&x| x == \"poneyland\", hasher)\n///     .or_insert(\"poneyland\");\n/// assert!(table\n///     .find(hasher(&\"poneyland\"), |&x| x == \"poneyland\")\n///     .is_some());\n///\n/// // existing key\n/// table\n///     .entry(hasher(&\"poneyland\"), |&x| x == \"poneyland\", hasher)\n///     .or_insert(\"poneyland\");\n/// assert!(table\n///     .find(hasher(&\"poneyland\"), |&x| x == \"poneyland\")\n///     .is_some());\n/// assert_eq!(table.len(), 1);\n/// # }\n/// # fn main() {\n/// #     #[cfg(feature = \"nightly\")]\n/// #     test()\n/// # }\n/// ```\npub fn or_insert(self, default: T) -> OccupiedEntry<'a, T, A>{\n        match self {\n            Entry::Occupied(entry) => entry,\n            Entry::Vacant(entry) => entry.insert(default),\n        }\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "table::Entry::<'a, T, A>::or_insert_with": [
            "/// Ensures a value is in the entry by inserting the result of the default function if empty..\n///\n/// Returns an [`OccupiedEntry`] pointing to the now-occupied entry.\n///\n/// # Examples\n///\n/// ```\n/// # #[cfg(feature = \"nightly\")]\n/// # fn test() {\n/// use hashbrown::{HashTable, DefaultHashBuilder};\n/// use std::hash::BuildHasher;\n///\n/// let mut table: HashTable<String> = HashTable::new();\n/// let hasher = DefaultHashBuilder::default();\n/// let hasher = |val: &_| hasher.hash_one(val);\n///\n/// table\n///     .entry(hasher(\"poneyland\"), |x| x == \"poneyland\", |val| hasher(val))\n///     .or_insert_with(|| \"poneyland\".to_string());\n///\n/// assert!(table\n///     .find(hasher(&\"poneyland\"), |x| x == \"poneyland\")\n///     .is_some());\n/// # }\n/// # fn main() {\n/// #     #[cfg(feature = \"nightly\")]\n/// #     test()\n/// # }\n/// ```\npub fn or_insert_with(self, default: impl FnOnce() -> T) -> OccupiedEntry<'a, T, A>{\n        match self {\n            Entry::Occupied(entry) => entry,\n            Entry::Vacant(entry) => entry.insert(default()),\n        }\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "table::ExtractIf": [
            "/// A draining iterator over entries of a `HashTable` which don't satisfy the predicate `f`.\n///\n/// This `struct` is created by [`HashTable::extract_if`]. See its\n/// documentation for more.\n#[must_use = \"Iterators are lazy unless consumed\"]\npub struct ExtractIf<'a, T, F, A: Allocator = Global> {\n    f: F,\n    inner: RawExtractIf<'a, T, A>,\n}",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "table::HashTable": [
            "/// Low-level hash table with explicit hashing.\n///\n/// The primary use case for this type over [`HashMap`] or [`HashSet`] is to\n/// support types that do not implement the [`Hash`] and [`Eq`] traits, but\n/// instead require additional data not contained in the key itself to compute a\n/// hash and compare two elements for equality.\n///\n/// Examples of when this can be useful include:\n/// - An `IndexMap` implementation where indices into a `Vec` are stored as\n///   elements in a `HashTable<usize>`. Hashing and comparing the elements\n///   requires indexing the associated `Vec` to get the actual value referred to\n///   by the index.\n/// - Avoiding re-computing a hash when it is already known.\n/// - Mutating the key of an element in a way that doesn't affect its hash.\n///\n/// To achieve this, `HashTable` methods that search for an element in the table\n/// require a hash value and equality function to be explicitly passed in as\n/// arguments. The method will then iterate over the elements with the given\n/// hash and call the equality function on each of them, until a match is found.\n///\n/// In most cases, a `HashTable` will not be exposed directly in an API. It will\n/// instead be wrapped in a helper type which handles the work of calculating\n/// hash values and comparing elements.\n///\n/// Due to its low-level nature, this type provides fewer guarantees than\n/// [`HashMap`] and [`HashSet`]. Specifically, the API allows you to shoot\n/// yourself in the foot by having multiple elements with identical keys in the\n/// table. The table itself will still function correctly and lookups will\n/// arbitrarily return one of the matching elements. However you should avoid\n/// doing this because it changes the runtime of hash table operations from\n/// `O(1)` to `O(k)` where `k` is the number of duplicate entries.\n///\n/// [`HashMap`]: super::HashMap\n/// [`HashSet`]: super::HashSet\n/// [`Eq`]: https://doc.rust-lang.org/std/cmp/trait.Eq.html\n/// [`Hash`]: https://doc.rust-lang.org/std/hash/trait.Hash.html\npub struct HashTable<T, A = Global>\nwhere\n    A: Allocator,\n{\n    pub(crate) raw: RawTable<T, A>,\n}",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "table::HashTable::<T, A>::allocation_size": [
            "/// Returns the total amount of memory allocated internally by the hash\n/// table, in bytes.\n///\n/// The returned number is informational only. It is intended to be\n/// primarily used for memory profiling.\n#[inline]\npub fn allocation_size(&self) -> usize{\n        self.raw.allocation_size()\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "table::HashTable::<T, A>::allocator": [
            "/// Returns a reference to the underlying allocator.\npub fn allocator(&self) -> &A{\n        self.raw.allocator()\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "table::HashTable::<T, A>::capacity": [
            "/// Returns the number of elements the table can hold without reallocating.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashTable;\n/// let table: HashTable<i32> = HashTable::with_capacity(100);\n/// assert!(table.capacity() >= 100);\n/// ```\npub fn capacity(&self) -> usize{\n        self.raw.capacity()\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "table::HashTable::<T, A>::clear": [
            "/// Clears the table, removing all values.\n///\n/// # Examples\n///\n/// ```\n/// # #[cfg(feature = \"nightly\")]\n/// # fn test() {\n/// use hashbrown::{HashTable, DefaultHashBuilder};\n/// use std::hash::BuildHasher;\n///\n/// let mut v = HashTable::new();\n/// let hasher = DefaultHashBuilder::default();\n/// let hasher = |val: &_| hasher.hash_one(val);\n/// v.insert_unique(hasher(&1), 1, hasher);\n/// v.clear();\n/// assert!(v.is_empty());\n/// # }\n/// # fn main() {\n/// #     #[cfg(feature = \"nightly\")]\n/// #     test()\n/// # }\n/// ```\npub fn clear(&mut self){\n        self.raw.clear();\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "table::HashTable::<T, A>::drain": [
            "/// Clears the set, returning all elements in an iterator.\n///\n/// # Examples\n///\n/// ```\n/// # #[cfg(feature = \"nightly\")]\n/// # fn test() {\n/// use hashbrown::{HashTable, DefaultHashBuilder};\n/// use std::hash::BuildHasher;\n///\n/// let mut table = HashTable::new();\n/// let hasher = DefaultHashBuilder::default();\n/// let hasher = |val: &_| hasher.hash_one(val);\n/// for x in 1..=3 {\n///     table.insert_unique(hasher(&x), x, hasher);\n/// }\n/// assert!(!table.is_empty());\n///\n/// // print 1, 2, 3 in an arbitrary order\n/// for i in table.drain() {\n///     println!(\"{}\", i);\n/// }\n///\n/// assert!(table.is_empty());\n/// # }\n/// # fn main() {\n/// #     #[cfg(feature = \"nightly\")]\n/// #     test()\n/// # }\n/// ```\npub fn drain(&mut self) -> Drain<'_, T, A>{\n        Drain {\n            inner: self.raw.drain(),\n        }\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "table::HashTable::<T, A>::entry": [
            "/// Returns an `Entry` for an entry in the table with the given hash\n/// and which satisfies the equality function passed.\n///\n/// This can be used to remove the entry from the table, or insert a new\n/// entry with the given hash if one doesn't already exist.\n///\n/// This method will call `eq` for all entries with the given hash, but may\n/// also call it for entries with a different hash. `eq` should only return\n/// true for the desired entry, at which point the search is stopped.\n///\n/// This method may grow the table in preparation for an insertion. Call\n/// [`HashTable::find_entry`] if this is undesirable.\n///\n/// `hasher` is called if entries need to be moved or copied to a new table.\n/// This must return the same hash value that each entry was inserted with.\n///\n/// # Examples\n///\n/// ```\n/// # #[cfg(feature = \"nightly\")]\n/// # fn test() {\n/// use hashbrown::hash_table::Entry;\n/// use hashbrown::{HashTable, DefaultHashBuilder};\n/// use std::hash::BuildHasher;\n///\n/// let mut table = HashTable::new();\n/// let hasher = DefaultHashBuilder::default();\n/// let hasher = |val: &_| hasher.hash_one(val);\n/// table.insert_unique(hasher(&1), (1, \"a\"), |val| hasher(&val.0));\n/// if let Entry::Occupied(entry) = table.entry(hasher(&1), |val| val.0 == 1, |val| hasher(&val.0))\n/// {\n///     entry.remove();\n/// }\n/// if let Entry::Vacant(entry) = table.entry(hasher(&2), |val| val.0 == 2, |val| hasher(&val.0)) {\n///     entry.insert((2, \"b\"));\n/// }\n/// assert_eq!(table.find(hasher(&1), |val| val.0 == 1), None);\n/// assert_eq!(table.find(hasher(&2), |val| val.0 == 2), Some(&(2, \"b\")));\n/// # }\n/// # fn main() {\n/// #     #[cfg(feature = \"nightly\")]\n/// #     test()\n/// # }\n/// ```\ninline\npub fn entry(\n        &mut self,\n        hash: u64,\n        eq: impl FnMut(&T) -> bool,\n        hasher: impl Fn(&T) -> u64,\n    ) -> Entry<'_, T, A>{\n        match self.raw.find_or_find_insert_slot(hash, eq, hasher) {\n            Ok(bucket) => Entry::Occupied(OccupiedEntry {\n                hash,\n                bucket,\n                table: self,\n            }),\n            Err(insert_slot) => Entry::Vacant(VacantEntry {\n                hash,\n                insert_slot,\n                table: self,\n            }),\n        }\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "table::HashTable::<T, A>::extract_if": [
            "/// Drains elements which are true under the given predicate,\n/// and returns an iterator over the removed items.\n///\n/// In other words, move all elements `e` such that `f(&e)` returns `true` out\n/// into another iterator.\n///\n/// If the returned `ExtractIf` is not exhausted, e.g. because it is dropped without iterating\n/// or the iteration short-circuits, then the remaining elements will be retained.\n/// Use [`retain()`] with a negated predicate if you do not need the returned iterator.\n///\n/// [`retain()`]: HashTable::retain\n///\n/// # Examples\n///\n/// ```\n/// # #[cfg(feature = \"nightly\")]\n/// # fn test() {\n/// use hashbrown::{HashTable, DefaultHashBuilder};\n/// use std::hash::BuildHasher;\n///\n/// let mut table = HashTable::new();\n/// let hasher = DefaultHashBuilder::default();\n/// let hasher = |val: &_| hasher.hash_one(val);\n/// for x in 0..8 {\n///     table.insert_unique(hasher(&x), x, hasher);\n/// }\n/// let drained: Vec<i32> = table.extract_if(|&mut v| v % 2 == 0).collect();\n///\n/// let mut evens = drained.into_iter().collect::<Vec<_>>();\n/// let mut odds = table.into_iter().collect::<Vec<_>>();\n/// evens.sort();\n/// odds.sort();\n///\n/// assert_eq!(evens, vec![0, 2, 4, 6]);\n/// assert_eq!(odds, vec![1, 3, 5, 7]);\n/// # }\n/// # fn main() {\n/// #     #[cfg(feature = \"nightly\")]\n/// #     test()\n/// # }\n/// ```\npub fn extract_if<F>(&mut self, f: F) -> ExtractIf<'_, T, F, A>\n    where\n        F: FnMut(&mut T) -> bool,{\n        ExtractIf {\n            f,\n            inner: RawExtractIf {\n                iter: unsafe { self.raw.iter() },\n                table: &mut self.raw,\n            },\n        }\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "table::HashTable::<T, A>::find": [
            "/// Returns a reference to an entry in the table with the given hash and\n/// which satisfies the equality function passed.\n///\n/// This method will call `eq` for all entries with the given hash, but may\n/// also call it for entries with a different hash. `eq` should only return\n/// true for the desired entry, at which point the search is stopped.\n///\n/// # Examples\n///\n/// ```\n/// # #[cfg(feature = \"nightly\")]\n/// # fn test() {\n/// use hashbrown::{HashTable, DefaultHashBuilder};\n/// use std::hash::BuildHasher;\n///\n/// let mut table = HashTable::new();\n/// let hasher = DefaultHashBuilder::default();\n/// let hasher = |val: &_| hasher.hash_one(val);\n/// table.insert_unique(hasher(&1), 1, hasher);\n/// table.insert_unique(hasher(&2), 2, hasher);\n/// table.insert_unique(hasher(&3), 3, hasher);\n/// assert_eq!(table.find(hasher(&2), |&val| val == 2), Some(&2));\n/// assert_eq!(table.find(hasher(&4), |&val| val == 4), None);\n/// # }\n/// # fn main() {\n/// #     #[cfg(feature = \"nightly\")]\n/// #     test()\n/// # }\n/// ```\npub fn find(&self, hash: u64, eq: impl FnMut(&T) -> bool) -> Option<&T>{\n        self.raw.get(hash, eq)\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "table::HashTable::<T, A>::find_entry": [
            "/// Returns an `OccupiedEntry` for an entry in the table with the given hash\n/// and which satisfies the equality function passed.\n///\n/// This can be used to remove the entry from the table. Call\n/// [`HashTable::entry`] instead if you wish to insert an entry if the\n/// lookup fails.\n///\n/// This method will call `eq` for all entries with the given hash, but may\n/// also call it for entries with a different hash. `eq` should only return\n/// true for the desired entry, at which point the search is stopped.\n///\n/// # Examples\n///\n/// ```\n/// # #[cfg(feature = \"nightly\")]\n/// # fn test() {\n/// use hashbrown::{HashTable, DefaultHashBuilder};\n/// use std::hash::BuildHasher;\n///\n/// let mut table = HashTable::new();\n/// let hasher = DefaultHashBuilder::default();\n/// let hasher = |val: &_| hasher.hash_one(val);\n/// table.insert_unique(hasher(&1), (1, \"a\"), |val| hasher(&val.0));\n/// if let Ok(entry) = table.find_entry(hasher(&1), |val| val.0 == 1) {\n///     entry.remove();\n/// }\n/// assert_eq!(table.find(hasher(&1), |val| val.0 == 1), None);\n/// # }\n/// # fn main() {\n/// #     #[cfg(feature = \"nightly\")]\n/// #     test()\n/// # }\n/// ```\ninline\npub fn find_entry(\n        &mut self,\n        hash: u64,\n        eq: impl FnMut(&T) -> bool,\n    ) -> Result<OccupiedEntry<'_, T, A>, AbsentEntry<'_, T, A>>{\n        match self.raw.find(hash, eq) {\n            Some(bucket) => Ok(OccupiedEntry {\n                hash,\n                bucket,\n                table: self,\n            }),\n            None => Err(AbsentEntry { table: self }),\n        }\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "table::HashTable::<T, A>::find_mut": [
            "/// Returns a mutable reference to an entry in the table with the given hash\n/// and which satisfies the equality function passed.\n///\n/// This method will call `eq` for all entries with the given hash, but may\n/// also call it for entries with a different hash. `eq` should only return\n/// true for the desired entry, at which point the search is stopped.\n///\n/// When mutating an entry, you should ensure that it still retains the same\n/// hash value as when it was inserted, otherwise lookups of that entry may\n/// fail to find it.\n///\n/// # Examples\n///\n/// ```\n/// # #[cfg(feature = \"nightly\")]\n/// # fn test() {\n/// use hashbrown::{HashTable, DefaultHashBuilder};\n/// use std::hash::BuildHasher;\n///\n/// let mut table = HashTable::new();\n/// let hasher = DefaultHashBuilder::default();\n/// let hasher = |val: &_| hasher.hash_one(val);\n/// table.insert_unique(hasher(&1), (1, \"a\"), |val| hasher(&val.0));\n/// if let Some(val) = table.find_mut(hasher(&1), |val| val.0 == 1) {\n///     val.1 = \"b\";\n/// }\n/// assert_eq!(table.find(hasher(&1), |val| val.0 == 1), Some(&(1, \"b\")));\n/// assert_eq!(table.find(hasher(&2), |val| val.0 == 2), None);\n/// # }\n/// # fn main() {\n/// #     #[cfg(feature = \"nightly\")]\n/// #     test()\n/// # }\n/// ```\npub fn find_mut(&mut self, hash: u64, eq: impl FnMut(&T) -> bool) -> Option<&mut T>{\n        self.raw.get_mut(hash, eq)\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "table::HashTable::<T, A>::get_many_mut": [
            "/// Attempts to get mutable references to `N` values in the map at once.\n///\n/// The `eq` argument should be a closure such that `eq(i, k)` returns true if `k` is equal to\n/// the `i`th key to be looked up.\n///\n/// Returns an array of length `N` with the results of each query. For soundness, at most one\n/// mutable reference will be returned to any value. `None` will be used if the key is missing.\n///\n/// # Panics\n///\n/// Panics if any keys are overlapping.\n///\n/// # Examples\n///\n/// ```\n/// # #[cfg(feature = \"nightly\")]\n/// # fn test() {\n/// use hashbrown::hash_table::Entry;\n/// use hashbrown::{HashTable, DefaultHashBuilder};\n/// use std::hash::BuildHasher;\n///\n/// let mut libraries: HashTable<(&str, u32)> = HashTable::new();\n/// let hasher = DefaultHashBuilder::default();\n/// let hasher = |val: &_| hasher.hash_one(val);\n/// for (k, v) in [\n///     (\"Bodleian Library\", 1602),\n///     (\"Athenum\", 1807),\n///     (\"Herzogin-Anna-Amalia-Bibliothek\", 1691),\n///     (\"Library of Congress\", 1800),\n/// ] {\n///     libraries.insert_unique(hasher(&k), (k, v), |(k, _)| hasher(&k));\n/// }\n///\n/// let keys = [\"Athenum\", \"Library of Congress\"];\n/// let got = libraries.get_many_mut(keys.map(|k| hasher(&k)), |i, val| keys[i] == val.0);\n/// assert_eq!(\n///     got,\n///     [Some(&mut (\"Athenum\", 1807)), Some(&mut (\"Library of Congress\", 1800))],\n/// );\n///\n/// // Missing keys result in None\n/// let keys = [\"Athenum\", \"New York Public Library\"];\n/// let got = libraries.get_many_mut(keys.map(|k| hasher(&k)), |i, val| keys[i] == val.0);\n/// assert_eq!(got, [Some(&mut (\"Athenum\", 1807)), None]);\n/// # }\n/// # fn main() {\n/// #     #[cfg(feature = \"nightly\")]\n/// #     test()\n/// # }\n/// ```\n///\n/// ```should_panic\n/// # #[cfg(feature = \"nightly\")]\n/// # fn test() {\n/// # use hashbrown::{HashTable, DefaultHashBuilder};\n/// # use std::hash::BuildHasher;\n///\n/// let mut libraries: HashTable<(&str, u32)> = HashTable::new();\n/// let hasher = DefaultHashBuilder::default();\n/// let hasher = |val: &_| hasher.hash_one(val);\n/// for (k, v) in [\n///     (\"Athenum\", 1807),\n///     (\"Library of Congress\", 1800),\n/// ] {\n///     libraries.insert_unique(hasher(&k), (k, v), |(k, _)| hasher(&k));\n/// }\n///\n/// // Duplicate keys result in a panic!\n/// let keys = [\"Athenum\", \"Athenum\"];\n/// let got = libraries.get_many_mut(keys.map(|k| hasher(&k)), |i, val| keys[i] == val.0);\n/// # }\n/// # fn main() {\n/// #     #[cfg(feature = \"nightly\")]\n/// #     test();\n/// #     #[cfg(not(feature = \"nightly\"))]\n/// #     panic!();\n/// # }\n/// ```\npub fn get_many_mut<const N: usize>(\n        &mut self,\n        hashes: [u64; N],\n        eq: impl FnMut(usize, &T) -> bool,\n    ) -> [Option<&'_ mut T>; N]{\n        self.raw.get_many_mut(hashes, eq)\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "table::HashTable::<T, A>::get_many_unchecked_mut": [
            "/// Attempts to get mutable references to `N` values in the map at once, without validating that\n/// the values are unique.\n///\n/// The `eq` argument should be a closure such that `eq(i, k)` returns true if `k` is equal to\n/// the `i`th key to be looked up.\n///\n/// Returns an array of length `N` with the results of each query. `None` will be returned if\n/// any of the keys are missing.\n///\n/// For a safe alternative see [`get_many_mut`](`HashTable::get_many_mut`).\n///\n/// # Safety\n///\n/// Calling this method with overlapping keys is *[undefined behavior]* even if the resulting\n/// references are not used.\n///\n/// [undefined behavior]: https://doc.rust-lang.org/reference/behavior-considered-undefined.html\n///\n/// # Examples\n///\n/// ```\n/// # #[cfg(feature = \"nightly\")]\n/// # fn test() {\n/// use hashbrown::hash_table::Entry;\n/// use hashbrown::{HashTable, DefaultHashBuilder};\n/// use std::hash::BuildHasher;\n///\n/// let mut libraries: HashTable<(&str, u32)> = HashTable::new();\n/// let hasher = DefaultHashBuilder::default();\n/// let hasher = |val: &_| hasher.hash_one(val);\n/// for (k, v) in [\n///     (\"Bodleian Library\", 1602),\n///     (\"Athenum\", 1807),\n///     (\"Herzogin-Anna-Amalia-Bibliothek\", 1691),\n///     (\"Library of Congress\", 1800),\n/// ] {\n///     libraries.insert_unique(hasher(&k), (k, v), |(k, _)| hasher(&k));\n/// }\n///\n/// let keys = [\"Athenum\", \"Library of Congress\"];\n/// let got = libraries.get_many_mut(keys.map(|k| hasher(&k)), |i, val| keys[i] == val.0);\n/// assert_eq!(\n///     got,\n///     [Some(&mut (\"Athenum\", 1807)), Some(&mut (\"Library of Congress\", 1800))],\n/// );\n///\n/// // Missing keys result in None\n/// let keys = [\"Athenum\", \"New York Public Library\"];\n/// let got = libraries.get_many_mut(keys.map(|k| hasher(&k)), |i, val| keys[i] == val.0);\n/// assert_eq!(got, [Some(&mut (\"Athenum\", 1807)), None]);\n/// # }\n/// # fn main() {\n/// #     #[cfg(feature = \"nightly\")]\n/// #     test()\n/// # }\n/// ```\npub unsafe fn get_many_unchecked_mut<const N: usize>(\n        &mut self,\n        hashes: [u64; N],\n        eq: impl FnMut(usize, &T) -> bool,\n    ) -> [Option<&'_ mut T>; N]{\n        self.raw.get_many_unchecked_mut(hashes, eq)\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "table::HashTable::<T, A>::insert_unique": [
            "/// Inserts an element into the `HashTable` with the given hash value, but\n/// without checking whether an equivalent element already exists within the\n/// table.\n///\n/// `hasher` is called if entries need to be moved or copied to a new table.\n/// This must return the same hash value that each entry was inserted with.\n///\n/// # Examples\n///\n/// ```\n/// # #[cfg(feature = \"nightly\")]\n/// # fn test() {\n/// use hashbrown::{HashTable, DefaultHashBuilder};\n/// use std::hash::BuildHasher;\n///\n/// let mut v = HashTable::new();\n/// let hasher = DefaultHashBuilder::default();\n/// let hasher = |val: &_| hasher.hash_one(val);\n/// v.insert_unique(hasher(&1), 1, hasher);\n/// # }\n/// # fn main() {\n/// #     #[cfg(feature = \"nightly\")]\n/// #     test()\n/// # }\n/// ```\npub fn insert_unique(\n        &mut self,\n        hash: u64,\n        value: T,\n        hasher: impl Fn(&T) -> u64,\n    ) -> OccupiedEntry<'_, T, A>{\n        let bucket = self.raw.insert(hash, value, hasher);\n        OccupiedEntry {\n            hash,\n            bucket,\n            table: self,\n        }\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "table::HashTable::<T, A>::is_empty": [
            "/// Returns `true` if the set contains no elements.\n///\n/// # Examples\n///\n/// ```\n/// # #[cfg(feature = \"nightly\")]\n/// # fn test() {\n/// use hashbrown::{HashTable, DefaultHashBuilder};\n/// use std::hash::BuildHasher;\n///\n/// let hasher = DefaultHashBuilder::default();\n/// let hasher = |val: &_| hasher.hash_one(val);\n/// let mut v = HashTable::new();\n/// assert!(v.is_empty());\n/// v.insert_unique(hasher(&1), 1, hasher);\n/// assert!(!v.is_empty());\n/// # }\n/// # fn main() {\n/// #     #[cfg(feature = \"nightly\")]\n/// #     test()\n/// # }\n/// ```\npub fn is_empty(&self) -> bool{\n        self.raw.is_empty()\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "table::HashTable::<T, A>::iter": [
            "/// An iterator visiting all elements in arbitrary order.\n/// The iterator element type is `&'a T`.\n///\n/// # Examples\n///\n/// ```\n/// # #[cfg(feature = \"nightly\")]\n/// # fn test() {\n/// use hashbrown::{HashTable, DefaultHashBuilder};\n/// use std::hash::BuildHasher;\n///\n/// let mut table = HashTable::new();\n/// let hasher = DefaultHashBuilder::default();\n/// let hasher = |val: &_| hasher.hash_one(val);\n/// table.insert_unique(hasher(&\"a\"), \"b\", hasher);\n/// table.insert_unique(hasher(&\"b\"), \"b\", hasher);\n///\n/// // Will print in an arbitrary order.\n/// for x in table.iter() {\n///     println!(\"{}\", x);\n/// }\n/// # }\n/// # fn main() {\n/// #     #[cfg(feature = \"nightly\")]\n/// #     test()\n/// # }\n/// ```\npub fn iter(&self) -> Iter<'_, T>{\n        Iter {\n            inner: unsafe { self.raw.iter() },\n            marker: PhantomData,\n        }\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "table::HashTable::<T, A>::iter_hash": [
            "/// An iterator visiting all elements which may match a hash.\n/// The iterator element type is `&'a T`.\n///\n/// This iterator may return elements from the table that have a hash value\n/// different than the one provided. You should always validate the returned\n/// values before using them.\n///\n/// # Examples\n///\n/// ```\n/// # #[cfg(feature = \"nightly\")]\n/// # fn test() {\n/// use hashbrown::{HashTable, DefaultHashBuilder};\n/// use std::hash::BuildHasher;\n///\n/// let mut table = HashTable::new();\n/// let hasher = DefaultHashBuilder::default();\n/// let hasher = |val: &_| hasher.hash_one(val);\n/// table.insert_unique(hasher(&\"a\"), \"a\", hasher);\n/// table.insert_unique(hasher(&\"a\"), \"b\", hasher);\n/// table.insert_unique(hasher(&\"b\"), \"c\", hasher);\n///\n/// // Will print \"a\" and \"b\" (and possibly \"c\") in an arbitrary order.\n/// for x in table.iter_hash(hasher(&\"a\")) {\n///     println!(\"{}\", x);\n/// }\n/// # }\n/// # fn main() {\n/// #     #[cfg(feature = \"nightly\")]\n/// #     test()\n/// # }\n/// ```\npub fn iter_hash(&self, hash: u64) -> IterHash<'_, T>{\n        IterHash {\n            inner: unsafe { self.raw.iter_hash(hash) },\n            marker: PhantomData,\n        }\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "table::HashTable::<T, A>::iter_hash_mut": [
            "/// A mutable iterator visiting all elements which may match a hash.\n/// The iterator element type is `&'a mut T`.\n///\n/// This iterator may return elements from the table that have a hash value\n/// different than the one provided. You should always validate the returned\n/// values before using them.\n///\n/// # Examples\n///\n/// ```\n/// # #[cfg(feature = \"nightly\")]\n/// # fn test() {\n/// use hashbrown::{HashTable, DefaultHashBuilder};\n/// use std::hash::BuildHasher;\n///\n/// let mut table = HashTable::new();\n/// let hasher = DefaultHashBuilder::default();\n/// let hasher = |val: &_| hasher.hash_one(val);\n/// table.insert_unique(hasher(&1), 2, hasher);\n/// table.insert_unique(hasher(&1), 3, hasher);\n/// table.insert_unique(hasher(&2), 5, hasher);\n///\n/// // Update matching values\n/// for val in table.iter_hash_mut(hasher(&1)) {\n///     *val *= 2;\n/// }\n///\n/// assert_eq!(table.len(), 3);\n/// let mut vec: Vec<i32> = Vec::new();\n///\n/// for val in &table {\n///     println!(\"val: {}\", val);\n///     vec.push(*val);\n/// }\n///\n/// // The values will contain 4 and 6 and may contain either 5 or 10.\n/// assert!(vec.contains(&4));\n/// assert!(vec.contains(&6));\n///\n/// assert_eq!(table.len(), 3);\n/// # }\n/// # fn main() {\n/// #     #[cfg(feature = \"nightly\")]\n/// #     test()\n/// # }\n/// ```\npub fn iter_hash_mut(&mut self, hash: u64) -> IterHashMut<'_, T>{\n        IterHashMut {\n            inner: unsafe { self.raw.iter_hash(hash) },\n            marker: PhantomData,\n        }\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "table::HashTable::<T, A>::iter_mut": [
            "/// An iterator visiting all elements in arbitrary order,\n/// with mutable references to the elements.\n/// The iterator element type is `&'a mut T`.\n///\n/// # Examples\n///\n/// ```\n/// # #[cfg(feature = \"nightly\")]\n/// # fn test() {\n/// use hashbrown::{HashTable, DefaultHashBuilder};\n/// use std::hash::BuildHasher;\n///\n/// let mut table = HashTable::new();\n/// let hasher = DefaultHashBuilder::default();\n/// let hasher = |val: &_| hasher.hash_one(val);\n/// table.insert_unique(hasher(&1), 1, hasher);\n/// table.insert_unique(hasher(&2), 2, hasher);\n/// table.insert_unique(hasher(&3), 3, hasher);\n///\n/// // Update all values\n/// for val in table.iter_mut() {\n///     *val *= 2;\n/// }\n///\n/// assert_eq!(table.len(), 3);\n/// let mut vec: Vec<i32> = Vec::new();\n///\n/// for val in &table {\n///     println!(\"val: {}\", val);\n///     vec.push(*val);\n/// }\n///\n/// // The `Iter` iterator produces items in arbitrary order, so the\n/// // items must be sorted to test them against a sorted array.\n/// vec.sort_unstable();\n/// assert_eq!(vec, [2, 4, 6]);\n///\n/// assert_eq!(table.len(), 3);\n/// # }\n/// # fn main() {\n/// #     #[cfg(feature = \"nightly\")]\n/// #     test()\n/// # }\n/// ```\npub fn iter_mut(&mut self) -> IterMut<'_, T>{\n        IterMut {\n            inner: unsafe { self.raw.iter() },\n            marker: PhantomData,\n        }\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "table::HashTable::<T, A>::len": [
            "/// Returns the number of elements in the table.\n///\n/// # Examples\n///\n/// ```\n/// # #[cfg(feature = \"nightly\")]\n/// # fn test() {\n/// use hashbrown::{HashTable, DefaultHashBuilder};\n/// use std::hash::BuildHasher;\n///\n/// let hasher = DefaultHashBuilder::default();\n/// let hasher = |val: &_| hasher.hash_one(val);\n/// let mut v = HashTable::new();\n/// assert_eq!(v.len(), 0);\n/// v.insert_unique(hasher(&1), 1, hasher);\n/// assert_eq!(v.len(), 1);\n/// # }\n/// # fn main() {\n/// #     #[cfg(feature = \"nightly\")]\n/// #     test()\n/// # }\n/// ```\npub fn len(&self) -> usize{\n        self.raw.len()\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "table::HashTable::<T, A>::new_in": [
            "/// Creates an empty `HashTable` using the given allocator.\n///\n/// The hash table is initially created with a capacity of 0, so it will not allocate until it\n/// is first inserted into.\n///\n/// # Examples\n///\n/// ```\n/// # #[cfg(feature = \"nightly\")]\n/// # fn test() {\n/// use bumpalo::Bump;\n/// use hashbrown::{HashTable, DefaultHashBuilder};\n/// use std::hash::BuildHasher;\n///\n/// let bump = Bump::new();\n/// let mut table = HashTable::new_in(&bump);\n/// let hasher = DefaultHashBuilder::default();\n/// let hasher = |val: &_| hasher.hash_one(val);\n///\n/// // The created HashTable holds none elements\n/// assert_eq!(table.len(), 0);\n///\n/// // The created HashTable also doesn't allocate memory\n/// assert_eq!(table.capacity(), 0);\n///\n/// // Now we insert element inside created HashTable\n/// table.insert_unique(hasher(&\"One\"), \"One\", hasher);\n/// // We can see that the HashTable holds 1 element\n/// assert_eq!(table.len(), 1);\n/// // And it also allocates some capacity\n/// assert!(table.capacity() > 1);\n/// # }\n/// # fn main() {\n/// #     #[cfg(feature = \"nightly\")]\n/// #     test()\n/// # }\n/// ```\npub const fn new_in(alloc: A) -> Self{\n        Self {\n            raw: RawTable::new_in(alloc),\n        }\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "table::HashTable::<T, A>::reserve": [
            "/// Reserves capacity for at least `additional` more elements to be inserted\n/// in the `HashTable`. The collection may reserve more space to avoid\n/// frequent reallocations.\n///\n/// `hasher` is called if entries need to be moved or copied to a new table.\n/// This must return the same hash value that each entry was inserted with.\n///\n/// # Panics\n///\n/// Panics if the new capacity exceeds [`isize::MAX`] bytes and [`abort`] the program\n/// in case of allocation error. Use [`try_reserve`](HashTable::try_reserve) instead\n/// if you want to handle memory allocation failure.\n///\n/// [`isize::MAX`]: https://doc.rust-lang.org/std/primitive.isize.html\n/// [`abort`]: https://doc.rust-lang.org/alloc/alloc/fn.handle_alloc_error.html\n///\n/// # Examples\n///\n/// ```\n/// # #[cfg(feature = \"nightly\")]\n/// # fn test() {\n/// use hashbrown::{HashTable, DefaultHashBuilder};\n/// use std::hash::BuildHasher;\n///\n/// let mut table: HashTable<i32> = HashTable::new();\n/// let hasher = DefaultHashBuilder::default();\n/// let hasher = |val: &_| hasher.hash_one(val);\n/// table.reserve(10, hasher);\n/// assert!(table.capacity() >= 10);\n/// # }\n/// # fn main() {\n/// #     #[cfg(feature = \"nightly\")]\n/// #     test()\n/// # }\n/// ```\npub fn reserve(&mut self, additional: usize, hasher: impl Fn(&T) -> u64){\n        self.raw.reserve(additional, hasher)\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "table::HashTable::<T, A>::retain": [
            "/// Retains only the elements specified by the predicate.\n///\n/// In other words, remove all elements `e` such that `f(&e)` returns `false`.\n///\n/// # Examples\n///\n/// ```\n/// # #[cfg(feature = \"nightly\")]\n/// # fn test() {\n/// use hashbrown::{HashTable, DefaultHashBuilder};\n/// use std::hash::BuildHasher;\n///\n/// let mut table = HashTable::new();\n/// let hasher = DefaultHashBuilder::default();\n/// let hasher = |val: &_| hasher.hash_one(val);\n/// for x in 1..=6 {\n///     table.insert_unique(hasher(&x), x, hasher);\n/// }\n/// table.retain(|&mut x| x % 2 == 0);\n/// assert_eq!(table.len(), 3);\n/// # }\n/// # fn main() {\n/// #     #[cfg(feature = \"nightly\")]\n/// #     test()\n/// # }\n/// ```\npub fn retain(&mut self, mut f: impl FnMut(&mut T) -> bool){\n        // Here we only use `iter` as a temporary, preventing use-after-free\n        unsafe {\n            for item in self.raw.iter() {\n                if !f(item.as_mut()) {\n                    self.raw.erase(item);\n                }\n            }\n        }\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "table::HashTable::<T, A>::shrink_to": [
            "/// Shrinks the capacity of the table with a lower limit. It will drop\n/// down no lower than the supplied limit while maintaining the internal rules\n/// and possibly leaving some space in accordance with the resize policy.\n///\n/// `hasher` is called if entries need to be moved or copied to a new table.\n/// This must return the same hash value that each entry was inserted with.\n///\n/// Panics if the current capacity is smaller than the supplied\n/// minimum capacity.\n///\n/// # Examples\n///\n/// ```\n/// # #[cfg(feature = \"nightly\")]\n/// # fn test() {\n/// use hashbrown::{HashTable, DefaultHashBuilder};\n/// use std::hash::BuildHasher;\n///\n/// let mut table = HashTable::with_capacity(100);\n/// let hasher = DefaultHashBuilder::default();\n/// let hasher = |val: &_| hasher.hash_one(val);\n/// table.insert_unique(hasher(&1), 1, hasher);\n/// table.insert_unique(hasher(&2), 2, hasher);\n/// assert!(table.capacity() >= 100);\n/// table.shrink_to(10, hasher);\n/// assert!(table.capacity() >= 10);\n/// table.shrink_to(0, hasher);\n/// assert!(table.capacity() >= 2);\n/// # }\n/// # fn main() {\n/// #     #[cfg(feature = \"nightly\")]\n/// #     test()\n/// # }\n/// ```\npub fn shrink_to(&mut self, min_capacity: usize, hasher: impl Fn(&T) -> u64){\n        self.raw.shrink_to(min_capacity, hasher);\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "table::HashTable::<T, A>::shrink_to_fit": [
            "/// Shrinks the capacity of the table as much as possible. It will drop\n/// down as much as possible while maintaining the internal rules\n/// and possibly leaving some space in accordance with the resize policy.\n///\n/// `hasher` is called if entries need to be moved or copied to a new table.\n/// This must return the same hash value that each entry was inserted with.\n///\n/// # Examples\n///\n/// ```\n/// # #[cfg(feature = \"nightly\")]\n/// # fn test() {\n/// use hashbrown::{HashTable, DefaultHashBuilder};\n/// use std::hash::BuildHasher;\n///\n/// let mut table = HashTable::with_capacity(100);\n/// let hasher = DefaultHashBuilder::default();\n/// let hasher = |val: &_| hasher.hash_one(val);\n/// table.insert_unique(hasher(&1), 1, hasher);\n/// table.insert_unique(hasher(&2), 2, hasher);\n/// assert!(table.capacity() >= 100);\n/// table.shrink_to_fit(hasher);\n/// assert!(table.capacity() >= 2);\n/// # }\n/// # fn main() {\n/// #     #[cfg(feature = \"nightly\")]\n/// #     test()\n/// # }\n/// ```\npub fn shrink_to_fit(&mut self, hasher: impl Fn(&T) -> u64){\n        self.raw.shrink_to(self.len(), hasher)\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "table::HashTable::<T, A>::try_reserve": [
            "/// Tries to reserve capacity for at least `additional` more elements to be inserted\n/// in the given `HashTable`. The collection may reserve more space to avoid\n/// frequent reallocations.\n///\n/// `hasher` is called if entries need to be moved or copied to a new table.\n/// This must return the same hash value that each entry was inserted with.\n///\n/// # Errors\n///\n/// If the capacity overflows, or the allocator reports a failure, then an error\n/// is returned.\n///\n/// # Examples\n///\n/// ```\n/// # #[cfg(feature = \"nightly\")]\n/// # fn test() {\n/// use hashbrown::{HashTable, DefaultHashBuilder};\n/// use std::hash::BuildHasher;\n///\n/// let mut table: HashTable<i32> = HashTable::new();\n/// let hasher = DefaultHashBuilder::default();\n/// let hasher = |val: &_| hasher.hash_one(val);\n/// table\n///     .try_reserve(10, hasher)\n///     .expect(\"why is the test harness OOMing on 10 bytes?\");\n/// # }\n/// # fn main() {\n/// #     #[cfg(feature = \"nightly\")]\n/// #     test()\n/// # }\n/// ```\npub fn try_reserve(\n        &mut self,\n        additional: usize,\n        hasher: impl Fn(&T) -> u64,\n    ) -> Result<(), TryReserveError>{\n        self.raw.try_reserve(additional, hasher)\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "table::HashTable::<T, A>::with_capacity_in": [
            "/// Creates an empty `HashTable` with the specified capacity using the given allocator.\n///\n/// The hash table will be able to hold at least `capacity` elements without\n/// reallocating. If `capacity` is 0, the hash table will not allocate.\n///\n/// # Examples\n///\n/// ```\n/// # #[cfg(feature = \"nightly\")]\n/// # fn test() {\n/// use bumpalo::Bump;\n/// use hashbrown::{HashTable, DefaultHashBuilder};\n/// use std::hash::BuildHasher;\n///\n/// let bump = Bump::new();\n/// let mut table = HashTable::with_capacity_in(5, &bump);\n/// let hasher = DefaultHashBuilder::default();\n/// let hasher = |val: &_| hasher.hash_one(val);\n///\n/// // The created HashTable holds none elements\n/// assert_eq!(table.len(), 0);\n/// // But it can hold at least 5 elements without reallocating\n/// let empty_map_capacity = table.capacity();\n/// assert!(empty_map_capacity >= 5);\n///\n/// // Now we insert some 5 elements inside created HashTable\n/// table.insert_unique(hasher(&\"One\"), \"One\", hasher);\n/// table.insert_unique(hasher(&\"Two\"), \"Two\", hasher);\n/// table.insert_unique(hasher(&\"Three\"), \"Three\", hasher);\n/// table.insert_unique(hasher(&\"Four\"), \"Four\", hasher);\n/// table.insert_unique(hasher(&\"Five\"), \"Five\", hasher);\n///\n/// // We can see that the HashTable holds 5 elements\n/// assert_eq!(table.len(), 5);\n/// // But its capacity isn't changed\n/// assert_eq!(table.capacity(), empty_map_capacity)\n/// # }\n/// # fn main() {\n/// #     #[cfg(feature = \"nightly\")]\n/// #     test()\n/// # }\n/// ```\npub fn with_capacity_in(capacity: usize, alloc: A) -> Self{\n        Self {\n            raw: RawTable::with_capacity_in(capacity, alloc),\n        }\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "table::HashTable::<T>::new": [
            "/// Creates an empty `HashTable`.\n///\n/// The hash table is initially created with a capacity of 0, so it will not allocate until it\n/// is first inserted into.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashTable;\n/// let mut table: HashTable<&str> = HashTable::new();\n/// assert_eq!(table.len(), 0);\n/// assert_eq!(table.capacity(), 0);\n/// ```\npub const fn new() -> Self{\n        Self {\n            raw: RawTable::new(),\n        }\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "table::HashTable::<T>::with_capacity": [
            "/// Creates an empty `HashTable` with the specified capacity.\n///\n/// The hash table will be able to hold at least `capacity` elements without\n/// reallocating. If `capacity` is 0, the hash table will not allocate.\n///\n/// # Examples\n///\n/// ```\n/// use hashbrown::HashTable;\n/// let mut table: HashTable<&str> = HashTable::with_capacity(10);\n/// assert_eq!(table.len(), 0);\n/// assert!(table.capacity() >= 10);\n/// ```\npub fn with_capacity(capacity: usize) -> Self{\n        Self {\n            raw: RawTable::with_capacity(capacity),\n        }\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "table::IntoIter": [
            "/// An owning iterator over the entries of a `HashTable` in arbitrary order.\n/// The iterator element type is `T`.\n///\n/// This `struct` is created by the [`into_iter`] method on [`HashTable`]\n/// (provided by the [`IntoIterator`] trait). See its documentation for more.\n/// The table cannot be used after calling that method.\n///\n/// [`into_iter`]: struct.HashTable.html#method.into_iter\n/// [`HashTable`]: struct.HashTable.html\n/// [`IntoIterator`]: https://doc.rust-lang.org/core/iter/trait.IntoIterator.html\npub struct IntoIter<T, A = Global>\nwhere\n    A: Allocator,\n{\n    inner: RawIntoIter<T, A>,\n}",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "table::Iter": [
            "/// An iterator over the entries of a `HashTable` in arbitrary order.\n/// The iterator element type is `&'a T`.\n///\n/// This `struct` is created by the [`iter`] method on [`HashTable`]. See its\n/// documentation for more.\n///\n/// [`iter`]: struct.HashTable.html#method.iter\n/// [`HashTable`]: struct.HashTable.html\npub struct Iter<'a, T> {\n    inner: RawIter<T>,\n    marker: PhantomData<&'a T>,\n}",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "table::IterHash": [
            "/// An iterator over the entries of a `HashTable` that could match a given hash.\n/// The iterator element type is `&'a T`.\n///\n/// This `struct` is created by the [`iter_hash`] method on [`HashTable`]. See its\n/// documentation for more.\n///\n/// [`iter_hash`]: struct.HashTable.html#method.iter_hash\n/// [`HashTable`]: struct.HashTable.html\npub struct IterHash<'a, T> {\n    inner: RawIterHash<T>,\n    marker: PhantomData<&'a T>,\n}",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "table::IterHashMut": [
            "/// A mutable iterator over the entries of a `HashTable` that could match a given hash.\n/// The iterator element type is `&'a mut T`.\n///\n/// This `struct` is created by the [`iter_hash_mut`] method on [`HashTable`]. See its\n/// documentation for more.\n///\n/// [`iter_hash_mut`]: struct.HashTable.html#method.iter_hash_mut\n/// [`HashTable`]: struct.HashTable.html\npub struct IterHashMut<'a, T> {\n    inner: RawIterHash<T>,\n    marker: PhantomData<&'a mut T>,\n}",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "table::IterMut": [
            "/// A mutable iterator over the entries of a `HashTable` in arbitrary order.\n/// The iterator element type is `&'a mut T`.\n///\n/// This `struct` is created by the [`iter_mut`] method on [`HashTable`]. See its\n/// documentation for more.\n///\n/// [`iter_mut`]: struct.HashTable.html#method.iter_mut\n/// [`HashTable`]: struct.HashTable.html\npub struct IterMut<'a, T> {\n    inner: RawIter<T>,\n    marker: PhantomData<&'a mut T>,\n}",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "table::OccupiedEntry": [
            "/// A view into an occupied entry in a `HashTable`.\n/// It is part of the [`Entry`] enum.\n///\n/// [`Entry`]: enum.Entry.html\n///\n/// # Examples\n///\n/// ```\n/// # #[cfg(feature = \"nightly\")]\n/// # fn test() {\n/// use hashbrown::hash_table::{Entry, OccupiedEntry};\n/// use hashbrown::{HashTable, DefaultHashBuilder};\n/// use std::hash::BuildHasher;\n///\n/// let mut table = HashTable::new();\n/// let hasher = DefaultHashBuilder::default();\n/// let hasher = |val: &_| hasher.hash_one(val);\n/// for x in [\"a\", \"b\", \"c\"] {\n///     table.insert_unique(hasher(&x), x, hasher);\n/// }\n/// assert_eq!(table.len(), 3);\n///\n/// let _entry_o: OccupiedEntry<_, _> = table.find_entry(hasher(&\"a\"), |&x| x == \"a\").unwrap();\n/// assert_eq!(table.len(), 3);\n///\n/// // Existing key\n/// match table.entry(hasher(&\"a\"), |&x| x == \"a\", hasher) {\n///     Entry::Vacant(_) => unreachable!(),\n///     Entry::Occupied(view) => {\n///         assert_eq!(view.get(), &\"a\");\n///     }\n/// }\n///\n/// assert_eq!(table.len(), 3);\n///\n/// // Existing key (take)\n/// match table.entry(hasher(&\"c\"), |&x| x == \"c\", hasher) {\n///     Entry::Vacant(_) => unreachable!(),\n///     Entry::Occupied(view) => {\n///         assert_eq!(view.remove().0, \"c\");\n///     }\n/// }\n/// assert_eq!(table.find(hasher(&\"c\"), |&x| x == \"c\"), None);\n/// assert_eq!(table.len(), 2);\n/// # }\n/// # fn main() {\n/// #     #[cfg(feature = \"nightly\")]\n/// #     test()\n/// # }\n/// ```\npub struct OccupiedEntry<'a, T, A = Global>\nwhere\n    A: Allocator,\n{\n    hash: u64,\n    bucket: Bucket<T>,\n    table: &'a mut HashTable<T, A>,\n}",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "table::OccupiedEntry::<'a, T, A>::get": [
            "/// Gets a reference to the value in the entry.\n///\n/// # Examples\n///\n/// ```\n/// # #[cfg(feature = \"nightly\")]\n/// # fn test() {\n/// use hashbrown::hash_table::Entry;\n/// use hashbrown::{HashTable, DefaultHashBuilder};\n/// use std::hash::BuildHasher;\n///\n/// let mut table: HashTable<&str> = HashTable::new();\n/// let hasher = DefaultHashBuilder::default();\n/// let hasher = |val: &_| hasher.hash_one(val);\n/// table.insert_unique(hasher(&\"poneyland\"), \"poneyland\", hasher);\n///\n/// match table.entry(hasher(&\"poneyland\"), |&x| x == \"poneyland\", hasher) {\n///     Entry::Vacant(_) => panic!(),\n///     Entry::Occupied(entry) => assert_eq!(entry.get(), &\"poneyland\"),\n/// }\n/// # }\n/// # fn main() {\n/// #     #[cfg(feature = \"nightly\")]\n/// #     test()\n/// # }\n/// ```\n#[inline]\npub fn get(&self) -> &T{\n        unsafe { self.bucket.as_ref() }\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "table::OccupiedEntry::<'a, T, A>::get_mut": [
            "/// Gets a mutable reference to the value in the entry.\n///\n/// If you need a reference to the `OccupiedEntry` which may outlive the\n/// destruction of the `Entry` value, see [`into_mut`].\n///\n/// [`into_mut`]: #method.into_mut\n///\n/// # Examples\n///\n/// ```\n/// # #[cfg(feature = \"nightly\")]\n/// # fn test() {\n/// use hashbrown::hash_table::Entry;\n/// use hashbrown::{HashTable, DefaultHashBuilder};\n/// use std::hash::BuildHasher;\n///\n/// let mut table: HashTable<(&str, u32)> = HashTable::new();\n/// let hasher = DefaultHashBuilder::default();\n/// let hasher = |val: &_| hasher.hash_one(val);\n/// table.insert_unique(hasher(&\"poneyland\"), (\"poneyland\", 12), |(k, _)| hasher(&k));\n///\n/// assert_eq!(\n///     table.find(hasher(&\"poneyland\"), |&(x, _)| x == \"poneyland\",),\n///     Some(&(\"poneyland\", 12))\n/// );\n///\n/// if let Entry::Occupied(mut o) = table.entry(\n///     hasher(&\"poneyland\"),\n///     |&(x, _)| x == \"poneyland\",\n///     |(k, _)| hasher(&k),\n/// ) {\n///     o.get_mut().1 += 10;\n///     assert_eq!(o.get().1, 22);\n///\n///     // We can use the same Entry multiple times.\n///     o.get_mut().1 += 2;\n/// }\n///\n/// assert_eq!(\n///     table.find(hasher(&\"poneyland\"), |&(x, _)| x == \"poneyland\",),\n///     Some(&(\"poneyland\", 24))\n/// );\n/// # }\n/// # fn main() {\n/// #     #[cfg(feature = \"nightly\")]\n/// #     test()\n/// # }\n/// ```\n#[inline]\npub fn get_mut(&mut self) -> &mut T{\n        unsafe { self.bucket.as_mut() }\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "table::OccupiedEntry::<'a, T, A>::into_mut": [
            "/// Converts the `OccupiedEntry` into a mutable reference to the value in the entry\n/// with a lifetime bound to the table itself.\n///\n/// If you need multiple references to the `OccupiedEntry`, see [`get_mut`].\n///\n/// [`get_mut`]: #method.get_mut\n///\n/// # Examples\n///\n/// ```\n/// # #[cfg(feature = \"nightly\")]\n/// # fn test() {\n/// use hashbrown::hash_table::Entry;\n/// use hashbrown::{HashTable, DefaultHashBuilder};\n/// use std::hash::BuildHasher;\n///\n/// let mut table: HashTable<(&str, u32)> = HashTable::new();\n/// let hasher = DefaultHashBuilder::default();\n/// let hasher = |val: &_| hasher.hash_one(val);\n/// table.insert_unique(hasher(&\"poneyland\"), (\"poneyland\", 12), |(k, _)| hasher(&k));\n///\n/// assert_eq!(\n///     table.find(hasher(&\"poneyland\"), |&(x, _)| x == \"poneyland\",),\n///     Some(&(\"poneyland\", 12))\n/// );\n///\n/// let value: &mut (&str, u32);\n/// match table.entry(\n///     hasher(&\"poneyland\"),\n///     |&(x, _)| x == \"poneyland\",\n///     |(k, _)| hasher(&k),\n/// ) {\n///     Entry::Occupied(entry) => value = entry.into_mut(),\n///     Entry::Vacant(_) => panic!(),\n/// }\n/// value.1 += 10;\n///\n/// assert_eq!(\n///     table.find(hasher(&\"poneyland\"), |&(x, _)| x == \"poneyland\",),\n///     Some(&(\"poneyland\", 22))\n/// );\n/// # }\n/// # fn main() {\n/// #     #[cfg(feature = \"nightly\")]\n/// #     test()\n/// # }\n/// ```\npub fn into_mut(self) -> &'a mut T{\n        unsafe { self.bucket.as_mut() }\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "table::OccupiedEntry::<'a, T, A>::into_table": [
            "/// Converts the `OccupiedEntry` into a mutable reference to the underlying\n/// table.\npub fn into_table(self) -> &'a mut HashTable<T, A>{\n        self.table\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "table::OccupiedEntry::<'a, T, A>::remove": [
            "/// Takes the value out of the entry, and returns it along with a\n/// `VacantEntry` that can be used to insert another value with the same\n/// hash as the one that was just removed.\n///\n/// # Examples\n///\n/// ```\n/// # #[cfg(feature = \"nightly\")]\n/// # fn test() {\n/// use hashbrown::hash_table::Entry;\n/// use hashbrown::{HashTable, DefaultHashBuilder};\n/// use std::hash::BuildHasher;\n///\n/// let mut table: HashTable<&str> = HashTable::new();\n/// let hasher = DefaultHashBuilder::default();\n/// let hasher = |val: &_| hasher.hash_one(val);\n/// // The table is empty\n/// assert!(table.is_empty() && table.capacity() == 0);\n///\n/// table.insert_unique(hasher(&\"poneyland\"), \"poneyland\", hasher);\n/// let capacity_before_remove = table.capacity();\n///\n/// if let Entry::Occupied(o) = table.entry(hasher(&\"poneyland\"), |&x| x == \"poneyland\", hasher) {\n///     assert_eq!(o.remove().0, \"poneyland\");\n/// }\n///\n/// assert!(table\n///     .find(hasher(&\"poneyland\"), |&x| x == \"poneyland\")\n///     .is_none());\n/// // Now table hold none elements but capacity is equal to the old one\n/// assert!(table.len() == 0 && table.capacity() == capacity_before_remove);\n/// # }\n/// # fn main() {\n/// #     #[cfg(feature = \"nightly\")]\n/// #     test()\n/// # }\n/// ```\ninline\npub fn remove(self) -> (T, VacantEntry<'a, T, A>){\n        let (val, slot) = unsafe { self.table.raw.remove(self.bucket) };\n        (\n            val,\n            VacantEntry {\n                hash: self.hash,\n                insert_slot: slot,\n                table: self.table,\n            },\n        )\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "table::VacantEntry": [
            "/// A view into a vacant entry in a `HashTable`.\n/// It is part of the [`Entry`] enum.\n///\n/// [`Entry`]: enum.Entry.html\n///\n/// # Examples\n///\n/// ```\n/// # #[cfg(feature = \"nightly\")]\n/// # fn test() {\n/// use hashbrown::hash_table::{Entry, VacantEntry};\n/// use hashbrown::{HashTable, DefaultHashBuilder};\n/// use std::hash::BuildHasher;\n///\n/// let mut table: HashTable<&str> = HashTable::new();\n/// let hasher = DefaultHashBuilder::default();\n/// let hasher = |val: &_| hasher.hash_one(val);\n///\n/// let entry_v: VacantEntry<_, _> = match table.entry(hasher(&\"a\"), |&x| x == \"a\", hasher) {\n///     Entry::Vacant(view) => view,\n///     Entry::Occupied(_) => unreachable!(),\n/// };\n/// entry_v.insert(\"a\");\n/// assert!(table.find(hasher(&\"a\"), |&x| x == \"a\").is_some() && table.len() == 1);\n///\n/// // Nonexistent key (insert)\n/// match table.entry(hasher(&\"b\"), |&x| x == \"b\", hasher) {\n///     Entry::Vacant(view) => {\n///         view.insert(\"b\");\n///     }\n///     Entry::Occupied(_) => unreachable!(),\n/// }\n/// assert!(table.find(hasher(&\"b\"), |&x| x == \"b\").is_some() && table.len() == 2);\n/// # }\n/// # fn main() {\n/// #     #[cfg(feature = \"nightly\")]\n/// #     test()\n/// # }\n/// ```\npub struct VacantEntry<'a, T, A = Global>\nwhere\n    A: Allocator,\n{\n    hash: u64,\n    insert_slot: InsertSlot,\n    table: &'a mut HashTable<T, A>,\n}",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "table::VacantEntry::<'a, T, A>::insert": [
            "/// Inserts a new element into the table with the hash that was used to\n/// obtain the `VacantEntry`.\n///\n/// An `OccupiedEntry` is returned for the newly inserted element.\n///\n/// # Examples\n///\n/// ```\n/// # #[cfg(feature = \"nightly\")]\n/// # fn test() {\n/// use hashbrown::hash_table::Entry;\n/// use hashbrown::{HashTable, DefaultHashBuilder};\n/// use std::hash::BuildHasher;\n///\n/// let mut table: HashTable<&str> = HashTable::new();\n/// let hasher = DefaultHashBuilder::default();\n/// let hasher = |val: &_| hasher.hash_one(val);\n///\n/// if let Entry::Vacant(o) = table.entry(hasher(&\"poneyland\"), |&x| x == \"poneyland\", hasher) {\n///     o.insert(\"poneyland\");\n/// }\n/// assert_eq!(\n///     table.find(hasher(&\"poneyland\"), |&x| x == \"poneyland\"),\n///     Some(&\"poneyland\")\n/// );\n/// # }\n/// # fn main() {\n/// #     #[cfg(feature = \"nightly\")]\n/// #     test()\n/// # }\n/// ```\n#[inline]\npub fn insert(self, value: T) -> OccupiedEntry<'a, T, A>{\n        let bucket = unsafe {\n            self.table\n                .raw\n                .insert_in_slot(self.hash, self.insert_slot, value)\n        };\n        OccupiedEntry {\n            hash: self.hash,\n            bucket,\n            table: self.table,\n        }\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "table::VacantEntry::<'a, T, A>::into_table": [
            "/// Converts the `VacantEntry` into a mutable reference to the underlying\n/// table.\npub fn into_table(self) -> &'a mut HashTable<T, A>{\n        self.table\n    }",
            "Real(LocalPath(\"src/table.rs\"))"
        ],
        "util::invalid_mut": [
            "#[inline(always)]\n#[allow(clippy::useless_transmute)]\npub(crate) fn invalid_mut<T>(addr: usize) -> *mut T{\n    unsafe { core::mem::transmute(addr) }\n}",
            "Real(LocalPath(\"src/util.rs\"))"
        ]
    },
    "struct_constructor": {
        "&'^0.Named(DefId(0:2705 ~ hashbrown[38f8]::raw::{impl#12}::ctrl_slice::'_), \"'_\") mut [control::tag::Tag]": [
            "ctrl_slice"
        ],
        "&'static [control::tag::Tag; UnevaluatedConst { def: DefId(0:2511 ~ hashbrown[38f8]::control::group::sse2::{impl#0}::static_empty::{constant#0}), args: [] }]": [
            "static_empty"
        ],
        "(&'^0.Named(DefId(0:2845 ~ hashbrown[38f8]::map::{impl#5}::insert_unique_unchecked::'_), \"'_\") K/#0, &'^0.Named(DefId(0:2845 ~ hashbrown[38f8]::map::{impl#5}::insert_unique_unchecked::'_), \"'_\") mut V/#1)": [
            "insert_unique_unchecked"
        ],
        "(&'^0.Named(DefId(0:3024 ~ hashbrown[38f8]::raw_entry::{impl#7}::get_key_value::'_), \"'_\") K/#1, &'^0.Named(DefId(0:3024 ~ hashbrown[38f8]::raw_entry::{impl#7}::get_key_value::'_), \"'_\") V/#2)": [
            "get_key_value"
        ],
        "(&'^0.Named(DefId(0:3025 ~ hashbrown[38f8]::raw_entry::{impl#7}::get_key_value_mut::'_), \"'_\") mut K/#1, &'^0.Named(DefId(0:3025 ~ hashbrown[38f8]::raw_entry::{impl#7}::get_key_value_mut::'_), \"'_\") mut V/#2)": [
            "get_key_value_mut"
        ],
        "(&'a/#0 mut K/#1, &'a/#0 mut V/#2)": [
            "insert",
            "insert_hashed_nocheck",
            "insert_with_hasher",
            "into_key_value",
            "or_insert",
            "or_insert_with"
        ],
        "(K/#1, V/#2)": [
            "remove_entry"
        ],
        "(T/#0, raw::InsertSlot)": [
            "remove"
        ],
        "(T/#1, table::VacantEntry<'a/#0, T/#1, A/#2>)": [
            "remove"
        ],
        "(core::ptr::NonNull<u8>, core::alloc::Layout)": [
            "allocation_info"
        ],
        "(usize, control::tag::Tag)": [
            "prepare_insert_slot"
        ],
        "(usize, core::option::Option<usize>)": [
            "size_hint"
        ],
        "*mut control::tag::Tag": [
            "ctrl"
        ],
        "*mut u8": [
            "bucket_ptr"
        ],
        "Alias(Opaque, AliasTy { args: [Q/#0, K/#1, '^0.Named(DefId(0:2785 ~ hashbrown[38f8]::map::equivalent::'_), \"'_\")], def_id: DefId(0:2786 ~ hashbrown[38f8]::map::equivalent::{opaque#0}) })": [
            "equivalent"
        ],
        "Alias(Opaque, AliasTy { args: [Q/#0, K/#1, V/#2, '^0.Named(DefId(0:2781 ~ hashbrown[38f8]::map::equivalent_key::'_), \"'_\")], def_id: DefId(0:2782 ~ hashbrown[38f8]::map::equivalent_key::{opaque#0}) })": [
            "equivalent_key"
        ],
        "Alias(Opaque, AliasTy { args: [Q/#0, V/#1, S/#2, '^0.Named(DefId(0:2777 ~ hashbrown[38f8]::map::make_hasher::'_), \"'_\")], def_id: DefId(0:2778 ~ hashbrown[38f8]::map::make_hasher::{opaque#0}) })": [
            "make_hasher"
        ],
        "TryReserveError": [
            "alloc_err",
            "capacity_overflow",
            "clone"
        ],
        "[core::option::Option<&'^0.Named(DefId(0:2659 ~ hashbrown[38f8]::raw::{impl#8}::get_many_mut::'_), \"'_\") mut T/#0>; N/#2]": [
            "get_many_mut"
        ],
        "[core::option::Option<&'^0.Named(DefId(0:2662 ~ hashbrown[38f8]::raw::{impl#8}::get_many_unchecked_mut::'_), \"'_\") mut T/#0>; N/#2]": [
            "get_many_unchecked_mut"
        ],
        "[core::option::Option<&'^0.Named(DefId(0:2828 ~ hashbrown[38f8]::map::{impl#5}::get_many_mut::'_), \"'_\") mut V/#1>; N/#5]": [
            "get_many_mut"
        ],
        "[core::option::Option<&'^0.Named(DefId(0:2830 ~ hashbrown[38f8]::map::{impl#5}::get_many_unchecked_mut::'_), \"'_\") mut V/#1>; N/#5]": [
            "get_many_unchecked_mut"
        ],
        "[core::option::Option<&'^0.Named(DefId(0:2836 ~ hashbrown[38f8]::map::{impl#5}::get_many_mut_inner::'_), \"'_\") mut (K/#0, V/#1)>; N/#5]": [
            "get_many_mut_inner"
        ],
        "[core::option::Option<&'^0.Named(DefId(0:2838 ~ hashbrown[38f8]::map::{impl#5}::get_many_unchecked_mut_inner::'_), \"'_\") mut (K/#0, V/#1)>; N/#5]": [
            "get_many_unchecked_mut_inner"
        ],
        "[core::option::Option<&'^0.Named(DefId(0:3262 ~ hashbrown[38f8]::table::{impl#1}::get_many_mut::'_), \"'_\") mut T/#0>; N/#2]": [
            "get_many_mut"
        ],
        "[core::option::Option<&'^0.Named(DefId(0:3265 ~ hashbrown[38f8]::table::{impl#1}::get_many_unchecked_mut::'_), \"'_\") mut T/#0>; N/#2]": [
            "get_many_unchecked_mut"
        ],
        "[core::option::Option<(&'^0.Named(DefId(0:2832 ~ hashbrown[38f8]::map::{impl#5}::get_many_key_value_mut::'_), \"'_\") K/#0, &'^0.Named(DefId(0:2832 ~ hashbrown[38f8]::map::{impl#5}::get_many_key_value_mut::'_), \"'_\") mut V/#1)>; N/#5]": [
            "get_many_key_value_mut"
        ],
        "[core::option::Option<(&'^0.Named(DefId(0:2834 ~ hashbrown[38f8]::map::{impl#5}::get_many_key_value_unchecked_mut::'_), \"'_\") K/#0, &'^0.Named(DefId(0:2834 ~ hashbrown[38f8]::map::{impl#5}::get_many_key_value_unchecked_mut::'_), \"'_\") mut V/#1)>; N/#5]": [
            "get_many_key_value_unchecked_mut"
        ],
        "[core::option::Option<core::ptr::NonNull<T/#0>>; N/#2]": [
            "get_many_mut_pointers"
        ],
        "[u64; N/#5]": [
            "build_hashes_inner"
        ],
        "bool": [
            "any_bit_set",
            "contains",
            "contains_key",
            "eq",
            "insert",
            "is_bucket_full",
            "is_disjoint",
            "is_empty",
            "is_empty_singleton",
            "is_full",
            "is_in_same_group",
            "is_special",
            "is_subset",
            "is_superset",
            "remove",
            "replace_bucket_with",
            "special_is_empty"
        ],
        "control::bitmask::BitMask": [
            "clone",
            "match_empty",
            "match_empty_or_deleted",
            "match_full",
            "match_tag"
        ],
        "control::bitmask::BitMaskIter": [
            "clone",
            "into_iter"
        ],
        "control::group::sse2::Group": [
            "clone",
            "load",
            "load_aligned"
        ],
        "control::tag::Tag": [
            "clone",
            "full",
            "replace_ctrl_hash"
        ],
        "core::option::Option": [
            "calculate_layout_for",
            "capacity_to_buckets",
            "find",
            "find_inner",
            "find_insert_slot_in_group",
            "find_mut",
            "from_hash",
            "from_key",
            "from_key_hashed_nocheck",
            "get",
            "get_inner",
            "get_inner_mut",
            "get_key_value",
            "get_key_value_mut",
            "get_mut",
            "insert",
            "into_allocation",
            "lowest_set_bit",
            "next",
            "next_impl",
            "remove",
            "remove_entry",
            "replace",
            "search",
            "take"
        ],
        "core::ptr::NonNull": [
            "as_non_null",
            "data_end"
        ],
        "core::result::Result": [
            "do_alloc",
            "fallible_with_capacity",
            "find_entry",
            "find_or_find_insert_slot",
            "find_or_find_insert_slot_inner",
            "fmt",
            "new_uninitialized",
            "prepare_resize",
            "reserve_rehash",
            "reserve_rehash_inner",
            "resize",
            "resize_inner",
            "try_insert",
            "try_reserve"
        ],
        "map::Drain": [
            "drain"
        ],
        "map::Entry": [
            "entry",
            "replace_entry_with"
        ],
        "map::EntryRef": [
            "entry_ref"
        ],
        "map::ExtractIf": [
            "extract_if"
        ],
        "map::HashMap": [
            "clone",
            "default",
            "from",
            "from_iter",
            "new",
            "new_in",
            "with_capacity",
            "with_capacity_and_hasher",
            "with_capacity_and_hasher_in",
            "with_capacity_in",
            "with_hasher",
            "with_hasher_in"
        ],
        "map::IntoIter": [
            "default",
            "into_iter"
        ],
        "map::IntoKeys": [
            "default",
            "into_keys"
        ],
        "map::IntoValues": [
            "default",
            "into_values"
        ],
        "map::Iter": [
            "clone",
            "default",
            "into_iter",
            "iter"
        ],
        "map::IterMut": [
            "default",
            "into_iter",
            "iter_mut"
        ],
        "map::Keys": [
            "clone",
            "default",
            "keys"
        ],
        "map::OccupiedEntry": [
            "insert",
            "insert_entry"
        ],
        "map::Values": [
            "clone",
            "default",
            "values"
        ],
        "map::ValuesMut": [
            "default",
            "values_mut"
        ],
        "raw::Bucket": [
            "bucket",
            "clone",
            "from_base_index",
            "insert",
            "insert_in_slot",
            "next_n"
        ],
        "raw::Fallibility": [
            "clone"
        ],
        "raw::FullBucketsIndices": [
            "full_buckets_indices"
        ],
        "raw::InsertSlot": [
            "find_insert_slot",
            "fix_insert_slot"
        ],
        "raw::ProbeSeq": [
            "clone",
            "probe_seq"
        ],
        "raw::RawDrain": [
            "drain",
            "drain_iter_from"
        ],
        "raw::RawIntoIter": [
            "default",
            "into_iter",
            "into_iter_from"
        ],
        "raw::RawIter": [
            "clone",
            "default",
            "iter"
        ],
        "raw::RawIterHash": [
            "clone",
            "default",
            "iter_hash",
            "new"
        ],
        "raw::RawIterHashInner": [
            "clone",
            "new"
        ],
        "raw::RawIterRange": [
            "clone",
            "new"
        ],
        "raw::RawTable": [
            "clone",
            "default",
            "new",
            "new_in",
            "with_capacity",
            "with_capacity_in"
        ],
        "raw::RawTableInner": [
            "new",
            "with_capacity"
        ],
        "raw::TableLayout": [
            "clone",
            "new"
        ],
        "raw_entry::RawEntryBuilder": [
            "raw_entry"
        ],
        "raw_entry::RawEntryBuilderMut": [
            "raw_entry_mut"
        ],
        "raw_entry::RawEntryMut": [
            "from_hash",
            "from_key",
            "from_key_hashed_nocheck",
            "replace_entry_with",
            "search"
        ],
        "raw_entry::RawOccupiedEntryMut": [
            "insert",
            "insert_entry"
        ],
        "scopeguard::ScopeGuard": [
            "guard"
        ],
        "set::Difference": [
            "clone",
            "difference"
        ],
        "set::Drain": [
            "drain"
        ],
        "set::Entry": [
            "entry"
        ],
        "set::ExtractIf": [
            "extract_if"
        ],
        "set::HashSet": [
            "bitand",
            "bitor",
            "bitxor",
            "clone",
            "default",
            "from",
            "from_iter",
            "new",
            "new_in",
            "sub",
            "with_capacity",
            "with_capacity_and_hasher",
            "with_capacity_and_hasher_in",
            "with_capacity_in",
            "with_hasher",
            "with_hasher_in"
        ],
        "set::Intersection": [
            "clone",
            "intersection"
        ],
        "set::IntoIter": [
            "default",
            "into_iter"
        ],
        "set::Iter": [
            "clone",
            "default",
            "into_iter",
            "iter"
        ],
        "set::OccupiedEntry": [
            "insert"
        ],
        "set::SymmetricDifference": [
            "clone",
            "symmetric_difference"
        ],
        "set::Union": [
            "clone",
            "union"
        ],
        "table::Drain": [
            "drain"
        ],
        "table::Entry": [
            "entry"
        ],
        "table::ExtractIf": [
            "extract_if"
        ],
        "table::HashTable": [
            "clone",
            "default",
            "new",
            "new_in",
            "with_capacity",
            "with_capacity_in"
        ],
        "table::IntoIter": [
            "default",
            "into_iter"
        ],
        "table::Iter": [
            "clone",
            "default",
            "into_iter",
            "iter"
        ],
        "table::IterHash": [
            "clone",
            "default",
            "iter_hash"
        ],
        "table::IterHashMut": [
            "default",
            "iter_hash_mut"
        ],
        "table::IterMut": [
            "default",
            "into_iter",
            "iter_mut"
        ],
        "table::OccupiedEntry": [
            "insert",
            "insert_unique",
            "or_insert",
            "or_insert_with"
        ],
        "u64": [
            "make_hash"
        ],
        "usize": [
            "allocation_size",
            "allocation_size_or_zero",
            "bucket_index",
            "buckets",
            "capacity",
            "h1",
            "leading_zeros",
            "len",
            "nonzero_trailing_zeros",
            "num_ctrl_bytes",
            "offset_from",
            "to_base_index",
            "trailing_zeros"
        ]
    },
    "struct_to_trait": {
        "<T as raw::SizedTypeProperties>::T": [
            "raw::SizedTypeProperties"
        ],
        "TryReserveError": [
            "core::clone::Clone",
            "core::cmp::Eq",
            "core::cmp::PartialEq",
            "core::fmt::Debug",
            "core::marker::StructuralPartialEq"
        ],
        "control::bitmask::BitMask": [
            "core::clone::Clone",
            "core::iter::IntoIterator",
            "core::marker::Copy"
        ],
        "control::bitmask::BitMaskIter": [
            "core::clone::Clone",
            "core::iter::Iterator"
        ],
        "control::group::sse2::Group": [
            "core::clone::Clone",
            "core::marker::Copy"
        ],
        "control::tag::Tag": [
            "core::clone::Clone",
            "core::cmp::Eq",
            "core::cmp::PartialEq",
            "core::fmt::Debug",
            "core::marker::Copy",
            "core::marker::StructuralPartialEq"
        ],
        "map::Drain": [
            "core::fmt::Debug",
            "core::iter::ExactSizeIterator",
            "core::iter::FusedIterator",
            "core::iter::Iterator"
        ],
        "map::Entry": [
            "core::fmt::Debug"
        ],
        "map::EntryRef": [
            "core::fmt::Debug"
        ],
        "map::ExtractIf": [
            "core::iter::FusedIterator",
            "core::iter::Iterator"
        ],
        "map::HashMap": [
            "core::clone::Clone",
            "core::cmp::Eq",
            "core::cmp::PartialEq",
            "core::convert::From",
            "core::default::Default",
            "core::fmt::Debug",
            "core::iter::Extend",
            "core::iter::FromIterator",
            "core::iter::IntoIterator",
            "core::ops::Index"
        ],
        "map::IntoIter": [
            "core::default::Default",
            "core::fmt::Debug",
            "core::iter::ExactSizeIterator",
            "core::iter::FusedIterator",
            "core::iter::Iterator"
        ],
        "map::IntoKeys": [
            "core::default::Default",
            "core::fmt::Debug",
            "core::iter::ExactSizeIterator",
            "core::iter::FusedIterator",
            "core::iter::Iterator"
        ],
        "map::IntoValues": [
            "core::default::Default",
            "core::fmt::Debug",
            "core::iter::ExactSizeIterator",
            "core::iter::FusedIterator",
            "core::iter::Iterator"
        ],
        "map::Iter": [
            "core::clone::Clone",
            "core::default::Default",
            "core::fmt::Debug",
            "core::iter::ExactSizeIterator",
            "core::iter::FusedIterator",
            "core::iter::Iterator"
        ],
        "map::IterMut": [
            "core::default::Default",
            "core::fmt::Debug",
            "core::iter::ExactSizeIterator",
            "core::iter::FusedIterator",
            "core::iter::Iterator",
            "core::marker::Send"
        ],
        "map::Keys": [
            "core::clone::Clone",
            "core::default::Default",
            "core::fmt::Debug",
            "core::iter::ExactSizeIterator",
            "core::iter::FusedIterator",
            "core::iter::Iterator"
        ],
        "map::OccupiedEntry": [
            "core::fmt::Debug",
            "core::marker::Send",
            "core::marker::Sync"
        ],
        "map::OccupiedError": [
            "core::fmt::Debug",
            "core::fmt::Display"
        ],
        "map::VacantEntry": [
            "core::fmt::Debug"
        ],
        "map::VacantEntryRef": [
            "core::fmt::Debug"
        ],
        "map::Values": [
            "core::clone::Clone",
            "core::default::Default",
            "core::fmt::Debug",
            "core::iter::ExactSizeIterator",
            "core::iter::FusedIterator",
            "core::iter::Iterator"
        ],
        "map::ValuesMut": [
            "core::default::Default",
            "core::fmt::Debug",
            "core::iter::ExactSizeIterator",
            "core::iter::FusedIterator",
            "core::iter::Iterator"
        ],
        "raw::Bucket": [
            "core::clone::Clone",
            "core::marker::Send"
        ],
        "raw::Fallibility": [
            "core::clone::Clone",
            "core::marker::Copy"
        ],
        "raw::FullBucketsIndices": [
            "core::iter::ExactSizeIterator",
            "core::iter::FusedIterator",
            "core::iter::Iterator"
        ],
        "raw::ProbeSeq": [
            "core::clone::Clone"
        ],
        "raw::RawDrain": [
            "core::iter::ExactSizeIterator",
            "core::iter::FusedIterator",
            "core::iter::Iterator",
            "core::marker::Send",
            "core::marker::Sync",
            "core::ops::Drop"
        ],
        "raw::RawIntoIter": [
            "core::default::Default",
            "core::iter::ExactSizeIterator",
            "core::iter::FusedIterator",
            "core::iter::Iterator",
            "core::marker::Send",
            "core::marker::Sync",
            "core::ops::Drop"
        ],
        "raw::RawIter": [
            "core::clone::Clone",
            "core::default::Default",
            "core::iter::ExactSizeIterator",
            "core::iter::FusedIterator",
            "core::iter::Iterator"
        ],
        "raw::RawIterHash": [
            "core::clone::Clone",
            "core::default::Default",
            "core::iter::Iterator"
        ],
        "raw::RawIterHashInner": [
            "core::clone::Clone",
            "core::iter::Iterator"
        ],
        "raw::RawIterRange": [
            "core::clone::Clone",
            "core::iter::FusedIterator",
            "core::iter::Iterator",
            "core::marker::Send",
            "core::marker::Sync"
        ],
        "raw::RawTable": [
            "core::clone::Clone",
            "core::default::Default",
            "core::iter::IntoIterator",
            "core::marker::Send",
            "core::marker::Sync",
            "core::ops::Drop",
            "raw::RawTableClone"
        ],
        "raw::TableLayout": [
            "core::clone::Clone",
            "core::marker::Copy"
        ],
        "raw_entry::RawEntryBuilder": [
            "core::fmt::Debug"
        ],
        "raw_entry::RawEntryBuilderMut": [
            "core::fmt::Debug"
        ],
        "raw_entry::RawEntryMut": [
            "core::fmt::Debug"
        ],
        "raw_entry::RawOccupiedEntryMut": [
            "core::fmt::Debug",
            "core::marker::Send",
            "core::marker::Sync"
        ],
        "raw_entry::RawVacantEntryMut": [
            "core::fmt::Debug"
        ],
        "scopeguard::ScopeGuard": [
            "core::ops::Deref",
            "core::ops::DerefMut",
            "core::ops::Drop"
        ],
        "set::Difference": [
            "core::clone::Clone",
            "core::fmt::Debug",
            "core::iter::FusedIterator",
            "core::iter::Iterator"
        ],
        "set::Drain": [
            "core::fmt::Debug",
            "core::iter::ExactSizeIterator",
            "core::iter::FusedIterator",
            "core::iter::Iterator"
        ],
        "set::Entry": [
            "core::fmt::Debug"
        ],
        "set::ExtractIf": [
            "core::iter::FusedIterator",
            "core::iter::Iterator"
        ],
        "set::HashSet": [
            "core::clone::Clone",
            "core::cmp::Eq",
            "core::cmp::PartialEq",
            "core::convert::From",
            "core::default::Default",
            "core::fmt::Debug",
            "core::iter::Extend",
            "core::iter::FromIterator",
            "core::iter::IntoIterator",
            "core::ops::BitAndAssign",
            "core::ops::BitOrAssign",
            "core::ops::BitXorAssign",
            "core::ops::SubAssign"
        ],
        "set::Intersection": [
            "core::clone::Clone",
            "core::fmt::Debug",
            "core::iter::FusedIterator",
            "core::iter::Iterator"
        ],
        "set::IntoIter": [
            "core::default::Default",
            "core::fmt::Debug",
            "core::iter::ExactSizeIterator",
            "core::iter::FusedIterator",
            "core::iter::Iterator"
        ],
        "set::Iter": [
            "core::clone::Clone",
            "core::default::Default",
            "core::fmt::Debug",
            "core::iter::ExactSizeIterator",
            "core::iter::FusedIterator",
            "core::iter::Iterator"
        ],
        "set::OccupiedEntry": [
            "core::fmt::Debug"
        ],
        "set::SymmetricDifference": [
            "core::clone::Clone",
            "core::fmt::Debug",
            "core::iter::FusedIterator",
            "core::iter::Iterator"
        ],
        "set::Union": [
            "core::clone::Clone",
            "core::fmt::Debug",
            "core::iter::FusedIterator",
            "core::iter::Iterator"
        ],
        "set::VacantEntry": [
            "core::fmt::Debug"
        ],
        "table::AbsentEntry": [
            "core::fmt::Debug"
        ],
        "table::Drain": [
            "core::fmt::Debug",
            "core::iter::ExactSizeIterator",
            "core::iter::FusedIterator",
            "core::iter::Iterator"
        ],
        "table::Entry": [
            "core::fmt::Debug"
        ],
        "table::ExtractIf": [
            "core::iter::FusedIterator",
            "core::iter::Iterator"
        ],
        "table::HashTable": [
            "core::clone::Clone",
            "core::default::Default",
            "core::fmt::Debug",
            "core::iter::IntoIterator"
        ],
        "table::IntoIter": [
            "core::default::Default",
            "core::fmt::Debug",
            "core::iter::ExactSizeIterator",
            "core::iter::FusedIterator",
            "core::iter::Iterator"
        ],
        "table::Iter": [
            "core::clone::Clone",
            "core::default::Default",
            "core::fmt::Debug",
            "core::iter::ExactSizeIterator",
            "core::iter::FusedIterator",
            "core::iter::Iterator"
        ],
        "table::IterHash": [
            "core::clone::Clone",
            "core::default::Default",
            "core::fmt::Debug",
            "core::iter::FusedIterator",
            "core::iter::Iterator"
        ],
        "table::IterHashMut": [
            "core::default::Default",
            "core::fmt::Debug",
            "core::iter::FusedIterator",
            "core::iter::Iterator"
        ],
        "table::IterMut": [
            "core::default::Default",
            "core::fmt::Debug",
            "core::iter::ExactSizeIterator",
            "core::iter::FusedIterator",
            "core::iter::Iterator"
        ],
        "table::OccupiedEntry": [
            "core::fmt::Debug",
            "core::marker::Send",
            "core::marker::Sync"
        ],
        "table::VacantEntry": [
            "core::fmt::Debug"
        ]
    },
    "targets": {
        "<&'a map::HashMap<K, V, S, A> as core::iter::IntoIterator>::into_iter": [
            "into_iter",
            "Real(LocalPath(\"src/map.rs\"))",
            "core::iter::IntoIterator"
        ],
        "<&'a mut map::HashMap<K, V, S, A> as core::iter::IntoIterator>::into_iter": [
            "into_iter",
            "Real(LocalPath(\"src/map.rs\"))",
            "core::iter::IntoIterator"
        ],
        "<&'a mut table::HashTable<T, A> as core::iter::IntoIterator>::into_iter": [
            "into_iter",
            "Real(LocalPath(\"src/table.rs\"))",
            "core::iter::IntoIterator"
        ],
        "<&'a set::HashSet<T, S, A> as core::iter::IntoIterator>::into_iter": [
            "into_iter",
            "Real(LocalPath(\"src/set.rs\"))",
            "core::iter::IntoIterator"
        ],
        "<&'a table::HashTable<T, A> as core::iter::IntoIterator>::into_iter": [
            "into_iter",
            "Real(LocalPath(\"src/table.rs\"))",
            "core::iter::IntoIterator"
        ],
        "<&set::HashSet<T, S, A> as core::ops::BitAnd<&set::HashSet<T, S, A>>>::bitand": [
            "bitand",
            "Real(LocalPath(\"src/set.rs\"))",
            "core::ops::BitAnd"
        ],
        "<&set::HashSet<T, S, A> as core::ops::BitOr<&set::HashSet<T, S, A>>>::bitor": [
            "bitor",
            "Real(LocalPath(\"src/set.rs\"))",
            "core::ops::BitOr"
        ],
        "<&set::HashSet<T, S, A> as core::ops::BitXor<&set::HashSet<T, S, A>>>::bitxor": [
            "bitxor",
            "Real(LocalPath(\"src/set.rs\"))",
            "core::ops::BitXor"
        ],
        "<&set::HashSet<T, S, A> as core::ops::Sub<&set::HashSet<T, S, A>>>::sub": [
            "sub",
            "Real(LocalPath(\"src/set.rs\"))",
            "core::ops::Sub"
        ],
        "<[control::tag::Tag] as control::tag::TagSliceExt>::fill_tag": [
            "fill_tag",
            "Real(LocalPath(\"src/control/tag.rs\"))",
            "control::tag::TagSliceExt"
        ],
        "<control::bitmask::BitMask as core::iter::IntoIterator>::into_iter": [
            "into_iter",
            "Real(LocalPath(\"src/control/bitmask.rs\"))",
            "core::iter::IntoIterator"
        ],
        "<control::bitmask::BitMaskIter as core::iter::Iterator>::next": [
            "next",
            "Real(LocalPath(\"src/control/bitmask.rs\"))",
            "core::iter::Iterator"
        ],
        "<control::tag::Tag as core::fmt::Debug>::fmt": [
            "fmt",
            "Real(LocalPath(\"src/control/tag.rs\"))",
            "core::fmt::Debug"
        ],
        "<map::Drain<'_, K, V, A> as core::fmt::Debug>::fmt": [
            "fmt",
            "Real(LocalPath(\"src/map.rs\"))",
            "core::fmt::Debug"
        ],
        "<map::Drain<'_, K, V, A> as core::iter::ExactSizeIterator>::len": [
            "len",
            "Real(LocalPath(\"src/map.rs\"))",
            "core::iter::ExactSizeIterator"
        ],
        "<map::Drain<'_, K, V, A> as core::iter::Iterator>::fold": [
            "fold",
            "Real(LocalPath(\"src/map.rs\"))",
            "core::iter::Iterator"
        ],
        "<map::Drain<'_, K, V, A> as core::iter::Iterator>::next": [
            "next",
            "Real(LocalPath(\"src/map.rs\"))",
            "core::iter::Iterator"
        ],
        "<map::Drain<'_, K, V, A> as core::iter::Iterator>::size_hint": [
            "size_hint",
            "Real(LocalPath(\"src/map.rs\"))",
            "core::iter::Iterator"
        ],
        "<map::Entry<'_, K, V, S, A> as core::fmt::Debug>::fmt": [
            "fmt",
            "Real(LocalPath(\"src/map.rs\"))",
            "core::fmt::Debug"
        ],
        "<map::EntryRef<'_, '_, K, Q, V, S, A> as core::fmt::Debug>::fmt": [
            "fmt",
            "Real(LocalPath(\"src/map.rs\"))",
            "core::fmt::Debug"
        ],
        "<map::ExtractIf<'_, K, V, F, A> as core::iter::Iterator>::next": [
            "next",
            "Real(LocalPath(\"src/map.rs\"))",
            "core::iter::Iterator"
        ],
        "<map::ExtractIf<'_, K, V, F, A> as core::iter::Iterator>::size_hint": [
            "size_hint",
            "Real(LocalPath(\"src/map.rs\"))",
            "core::iter::Iterator"
        ],
        "<map::HashMap<K, V, S, A> as core::clone::Clone>::clone": [
            "clone",
            "Real(LocalPath(\"src/map.rs\"))",
            "core::clone::Clone"
        ],
        "<map::HashMap<K, V, S, A> as core::clone::Clone>::clone_from": [
            "clone_from",
            "Real(LocalPath(\"src/map.rs\"))",
            "core::clone::Clone"
        ],
        "<map::HashMap<K, V, S, A> as core::cmp::PartialEq>::eq": [
            "eq",
            "Real(LocalPath(\"src/map.rs\"))",
            "core::cmp::PartialEq"
        ],
        "<map::HashMap<K, V, S, A> as core::default::Default>::default": [
            "default",
            "Real(LocalPath(\"src/map.rs\"))",
            "core::default::Default"
        ],
        "<map::HashMap<K, V, S, A> as core::fmt::Debug>::fmt": [
            "fmt",
            "Real(LocalPath(\"src/map.rs\"))",
            "core::fmt::Debug"
        ],
        "<map::HashMap<K, V, S, A> as core::iter::Extend<&'a (K, V)>>::extend": [
            "extend",
            "Real(LocalPath(\"src/map.rs\"))",
            "core::iter::Extend"
        ],
        "<map::HashMap<K, V, S, A> as core::iter::Extend<(&'a K, &'a V)>>::extend": [
            "extend",
            "Real(LocalPath(\"src/map.rs\"))",
            "core::iter::Extend"
        ],
        "<map::HashMap<K, V, S, A> as core::iter::Extend<(K, V)>>::extend": [
            "extend",
            "Real(LocalPath(\"src/map.rs\"))",
            "core::iter::Extend"
        ],
        "<map::HashMap<K, V, S, A> as core::iter::FromIterator<(K, V)>>::from_iter": [
            "from_iter",
            "Real(LocalPath(\"src/map.rs\"))",
            "core::iter::FromIterator"
        ],
        "<map::HashMap<K, V, S, A> as core::iter::IntoIterator>::into_iter": [
            "into_iter",
            "Real(LocalPath(\"src/map.rs\"))",
            "core::iter::IntoIterator"
        ],
        "<map::HashMap<K, V, S, A> as core::ops::Index<&Q>>::index": [
            "index",
            "Real(LocalPath(\"src/map.rs\"))",
            "core::ops::Index"
        ],
        "<map::HashMap<K, V, foldhash::fast::RandomState, A> as core::convert::From<[(K, V); N]>>::from": [
            "from",
            "Real(LocalPath(\"src/map.rs\"))",
            "core::convert::From"
        ],
        "<map::IntoIter<K, V, A> as core::default::Default>::default": [
            "default",
            "Real(LocalPath(\"src/map.rs\"))",
            "core::default::Default"
        ],
        "<map::IntoIter<K, V, A> as core::fmt::Debug>::fmt": [
            "fmt",
            "Real(LocalPath(\"src/map.rs\"))",
            "core::fmt::Debug"
        ],
        "<map::IntoIter<K, V, A> as core::iter::ExactSizeIterator>::len": [
            "len",
            "Real(LocalPath(\"src/map.rs\"))",
            "core::iter::ExactSizeIterator"
        ],
        "<map::IntoIter<K, V, A> as core::iter::Iterator>::fold": [
            "fold",
            "Real(LocalPath(\"src/map.rs\"))",
            "core::iter::Iterator"
        ],
        "<map::IntoIter<K, V, A> as core::iter::Iterator>::next": [
            "next",
            "Real(LocalPath(\"src/map.rs\"))",
            "core::iter::Iterator"
        ],
        "<map::IntoIter<K, V, A> as core::iter::Iterator>::size_hint": [
            "size_hint",
            "Real(LocalPath(\"src/map.rs\"))",
            "core::iter::Iterator"
        ],
        "<map::IntoKeys<K, V, A> as core::default::Default>::default": [
            "default",
            "Real(LocalPath(\"src/map.rs\"))",
            "core::default::Default"
        ],
        "<map::IntoKeys<K, V, A> as core::fmt::Debug>::fmt": [
            "fmt",
            "Real(LocalPath(\"src/map.rs\"))",
            "core::fmt::Debug"
        ],
        "<map::IntoKeys<K, V, A> as core::iter::ExactSizeIterator>::len": [
            "len",
            "Real(LocalPath(\"src/map.rs\"))",
            "core::iter::ExactSizeIterator"
        ],
        "<map::IntoKeys<K, V, A> as core::iter::Iterator>::fold": [
            "fold",
            "Real(LocalPath(\"src/map.rs\"))",
            "core::iter::Iterator"
        ],
        "<map::IntoKeys<K, V, A> as core::iter::Iterator>::next": [
            "next",
            "Real(LocalPath(\"src/map.rs\"))",
            "core::iter::Iterator"
        ],
        "<map::IntoKeys<K, V, A> as core::iter::Iterator>::size_hint": [
            "size_hint",
            "Real(LocalPath(\"src/map.rs\"))",
            "core::iter::Iterator"
        ],
        "<map::IntoValues<K, V, A> as core::default::Default>::default": [
            "default",
            "Real(LocalPath(\"src/map.rs\"))",
            "core::default::Default"
        ],
        "<map::IntoValues<K, V, A> as core::fmt::Debug>::fmt": [
            "fmt",
            "Real(LocalPath(\"src/map.rs\"))",
            "core::fmt::Debug"
        ],
        "<map::IntoValues<K, V, A> as core::iter::ExactSizeIterator>::len": [
            "len",
            "Real(LocalPath(\"src/map.rs\"))",
            "core::iter::ExactSizeIterator"
        ],
        "<map::IntoValues<K, V, A> as core::iter::Iterator>::fold": [
            "fold",
            "Real(LocalPath(\"src/map.rs\"))",
            "core::iter::Iterator"
        ],
        "<map::IntoValues<K, V, A> as core::iter::Iterator>::next": [
            "next",
            "Real(LocalPath(\"src/map.rs\"))",
            "core::iter::Iterator"
        ],
        "<map::IntoValues<K, V, A> as core::iter::Iterator>::size_hint": [
            "size_hint",
            "Real(LocalPath(\"src/map.rs\"))",
            "core::iter::Iterator"
        ],
        "<map::Iter<'_, K, V> as core::clone::Clone>::clone": [
            "clone",
            "Real(LocalPath(\"src/map.rs\"))",
            "core::clone::Clone"
        ],
        "<map::Iter<'_, K, V> as core::default::Default>::default": [
            "default",
            "Real(LocalPath(\"src/map.rs\"))",
            "core::default::Default"
        ],
        "<map::Iter<'_, K, V> as core::fmt::Debug>::fmt": [
            "fmt",
            "Real(LocalPath(\"src/map.rs\"))",
            "core::fmt::Debug"
        ],
        "<map::Iter<'_, K, V> as core::iter::ExactSizeIterator>::len": [
            "len",
            "Real(LocalPath(\"src/map.rs\"))",
            "core::iter::ExactSizeIterator"
        ],
        "<map::Iter<'a, K, V> as core::iter::Iterator>::fold": [
            "fold",
            "Real(LocalPath(\"src/map.rs\"))",
            "core::iter::Iterator"
        ],
        "<map::Iter<'a, K, V> as core::iter::Iterator>::next": [
            "next",
            "Real(LocalPath(\"src/map.rs\"))",
            "core::iter::Iterator"
        ],
        "<map::Iter<'a, K, V> as core::iter::Iterator>::size_hint": [
            "size_hint",
            "Real(LocalPath(\"src/map.rs\"))",
            "core::iter::Iterator"
        ],
        "<map::IterMut<'_, K, V> as core::default::Default>::default": [
            "default",
            "Real(LocalPath(\"src/map.rs\"))",
            "core::default::Default"
        ],
        "<map::IterMut<'_, K, V> as core::fmt::Debug>::fmt": [
            "fmt",
            "Real(LocalPath(\"src/map.rs\"))",
            "core::fmt::Debug"
        ],
        "<map::IterMut<'_, K, V> as core::iter::ExactSizeIterator>::len": [
            "len",
            "Real(LocalPath(\"src/map.rs\"))",
            "core::iter::ExactSizeIterator"
        ],
        "<map::IterMut<'a, K, V> as core::iter::Iterator>::fold": [
            "fold",
            "Real(LocalPath(\"src/map.rs\"))",
            "core::iter::Iterator"
        ],
        "<map::IterMut<'a, K, V> as core::iter::Iterator>::next": [
            "next",
            "Real(LocalPath(\"src/map.rs\"))",
            "core::iter::Iterator"
        ],
        "<map::IterMut<'a, K, V> as core::iter::Iterator>::size_hint": [
            "size_hint",
            "Real(LocalPath(\"src/map.rs\"))",
            "core::iter::Iterator"
        ],
        "<map::Keys<'_, K, V> as core::clone::Clone>::clone": [
            "clone",
            "Real(LocalPath(\"src/map.rs\"))",
            "core::clone::Clone"
        ],
        "<map::Keys<'_, K, V> as core::default::Default>::default": [
            "default",
            "Real(LocalPath(\"src/map.rs\"))",
            "core::default::Default"
        ],
        "<map::Keys<'_, K, V> as core::fmt::Debug>::fmt": [
            "fmt",
            "Real(LocalPath(\"src/map.rs\"))",
            "core::fmt::Debug"
        ],
        "<map::Keys<'_, K, V> as core::iter::ExactSizeIterator>::len": [
            "len",
            "Real(LocalPath(\"src/map.rs\"))",
            "core::iter::ExactSizeIterator"
        ],
        "<map::Keys<'a, K, V> as core::iter::Iterator>::fold": [
            "fold",
            "Real(LocalPath(\"src/map.rs\"))",
            "core::iter::Iterator"
        ],
        "<map::Keys<'a, K, V> as core::iter::Iterator>::next": [
            "next",
            "Real(LocalPath(\"src/map.rs\"))",
            "core::iter::Iterator"
        ],
        "<map::Keys<'a, K, V> as core::iter::Iterator>::size_hint": [
            "size_hint",
            "Real(LocalPath(\"src/map.rs\"))",
            "core::iter::Iterator"
        ],
        "<map::OccupiedEntry<'_, K, V, S, A> as core::fmt::Debug>::fmt": [
            "fmt",
            "Real(LocalPath(\"src/map.rs\"))",
            "core::fmt::Debug"
        ],
        "<map::OccupiedError<'_, K, V, S, A> as core::fmt::Debug>::fmt": [
            "fmt",
            "Real(LocalPath(\"src/map.rs\"))",
            "core::fmt::Debug"
        ],
        "<map::OccupiedError<'_, K, V, S, A> as core::fmt::Display>::fmt": [
            "fmt",
            "Real(LocalPath(\"src/map.rs\"))",
            "core::fmt::Display"
        ],
        "<map::VacantEntry<'_, K, V, S, A> as core::fmt::Debug>::fmt": [
            "fmt",
            "Real(LocalPath(\"src/map.rs\"))",
            "core::fmt::Debug"
        ],
        "<map::VacantEntryRef<'_, '_, K, Q, V, S, A> as core::fmt::Debug>::fmt": [
            "fmt",
            "Real(LocalPath(\"src/map.rs\"))",
            "core::fmt::Debug"
        ],
        "<map::Values<'_, K, V> as core::clone::Clone>::clone": [
            "clone",
            "Real(LocalPath(\"src/map.rs\"))",
            "core::clone::Clone"
        ],
        "<map::Values<'_, K, V> as core::default::Default>::default": [
            "default",
            "Real(LocalPath(\"src/map.rs\"))",
            "core::default::Default"
        ],
        "<map::Values<'_, K, V> as core::fmt::Debug>::fmt": [
            "fmt",
            "Real(LocalPath(\"src/map.rs\"))",
            "core::fmt::Debug"
        ],
        "<map::Values<'_, K, V> as core::iter::ExactSizeIterator>::len": [
            "len",
            "Real(LocalPath(\"src/map.rs\"))",
            "core::iter::ExactSizeIterator"
        ],
        "<map::Values<'a, K, V> as core::iter::Iterator>::fold": [
            "fold",
            "Real(LocalPath(\"src/map.rs\"))",
            "core::iter::Iterator"
        ],
        "<map::Values<'a, K, V> as core::iter::Iterator>::next": [
            "next",
            "Real(LocalPath(\"src/map.rs\"))",
            "core::iter::Iterator"
        ],
        "<map::Values<'a, K, V> as core::iter::Iterator>::size_hint": [
            "size_hint",
            "Real(LocalPath(\"src/map.rs\"))",
            "core::iter::Iterator"
        ],
        "<map::ValuesMut<'_, K, V> as core::default::Default>::default": [
            "default",
            "Real(LocalPath(\"src/map.rs\"))",
            "core::default::Default"
        ],
        "<map::ValuesMut<'_, K, V> as core::fmt::Debug>::fmt": [
            "fmt",
            "Real(LocalPath(\"src/map.rs\"))",
            "core::fmt::Debug"
        ],
        "<map::ValuesMut<'_, K, V> as core::iter::ExactSizeIterator>::len": [
            "len",
            "Real(LocalPath(\"src/map.rs\"))",
            "core::iter::ExactSizeIterator"
        ],
        "<map::ValuesMut<'a, K, V> as core::iter::Iterator>::fold": [
            "fold",
            "Real(LocalPath(\"src/map.rs\"))",
            "core::iter::Iterator"
        ],
        "<map::ValuesMut<'a, K, V> as core::iter::Iterator>::next": [
            "next",
            "Real(LocalPath(\"src/map.rs\"))",
            "core::iter::Iterator"
        ],
        "<map::ValuesMut<'a, K, V> as core::iter::Iterator>::size_hint": [
            "size_hint",
            "Real(LocalPath(\"src/map.rs\"))",
            "core::iter::Iterator"
        ],
        "<raw::Bucket<T> as core::clone::Clone>::clone": [
            "clone",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            "core::clone::Clone"
        ],
        "<raw::FullBucketsIndices as core::iter::Iterator>::next": [
            "next",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            "core::iter::Iterator"
        ],
        "<raw::FullBucketsIndices as core::iter::Iterator>::size_hint": [
            "size_hint",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            "core::iter::Iterator"
        ],
        "<raw::RawDrain<'_, T, A> as core::iter::Iterator>::next": [
            "next",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            "core::iter::Iterator"
        ],
        "<raw::RawDrain<'_, T, A> as core::iter::Iterator>::size_hint": [
            "size_hint",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            "core::iter::Iterator"
        ],
        "<raw::RawDrain<'_, T, A> as core::ops::Drop>::drop": [
            "drop",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            "core::ops::Drop"
        ],
        "<raw::RawIntoIter<T, A> as core::default::Default>::default": [
            "default",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            "core::default::Default"
        ],
        "<raw::RawIntoIter<T, A> as core::iter::Iterator>::next": [
            "next",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            "core::iter::Iterator"
        ],
        "<raw::RawIntoIter<T, A> as core::iter::Iterator>::size_hint": [
            "size_hint",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            "core::iter::Iterator"
        ],
        "<raw::RawIntoIter<T, A> as core::ops::Drop>::drop": [
            "drop",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            "core::ops::Drop"
        ],
        "<raw::RawIter<T> as core::clone::Clone>::clone": [
            "clone",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            "core::clone::Clone"
        ],
        "<raw::RawIter<T> as core::default::Default>::default": [
            "default",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            "core::default::Default"
        ],
        "<raw::RawIter<T> as core::iter::Iterator>::fold": [
            "fold",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            "core::iter::Iterator"
        ],
        "<raw::RawIter<T> as core::iter::Iterator>::next": [
            "next",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            "core::iter::Iterator"
        ],
        "<raw::RawIter<T> as core::iter::Iterator>::size_hint": [
            "size_hint",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            "core::iter::Iterator"
        ],
        "<raw::RawIterHash<T> as core::clone::Clone>::clone": [
            "clone",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            "core::clone::Clone"
        ],
        "<raw::RawIterHash<T> as core::default::Default>::default": [
            "default",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            "core::default::Default"
        ],
        "<raw::RawIterHash<T> as core::iter::Iterator>::next": [
            "next",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            "core::iter::Iterator"
        ],
        "<raw::RawIterHashInner as core::iter::Iterator>::next": [
            "next",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            "core::iter::Iterator"
        ],
        "<raw::RawIterRange<T> as core::clone::Clone>::clone": [
            "clone",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            "core::clone::Clone"
        ],
        "<raw::RawIterRange<T> as core::iter::Iterator>::next": [
            "next",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            "core::iter::Iterator"
        ],
        "<raw::RawIterRange<T> as core::iter::Iterator>::size_hint": [
            "size_hint",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            "core::iter::Iterator"
        ],
        "<raw::RawTable<T, A> as core::clone::Clone>::clone": [
            "clone",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            "core::clone::Clone"
        ],
        "<raw::RawTable<T, A> as core::clone::Clone>::clone_from": [
            "clone_from",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            "core::clone::Clone"
        ],
        "<raw::RawTable<T, A> as core::default::Default>::default": [
            "default",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            "core::default::Default"
        ],
        "<raw::RawTable<T, A> as core::iter::IntoIterator>::into_iter": [
            "into_iter",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            "core::iter::IntoIterator"
        ],
        "<raw::RawTable<T, A> as core::ops::Drop>::drop": [
            "drop",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            "core::ops::Drop"
        ],
        "<raw::RawTable<T, A> as raw::RawTableClone>::clone_from_spec": [
            "clone_from_spec",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            "raw::RawTableClone"
        ],
        "<raw_entry::RawEntryBuilder<'_, K, V, S, A> as core::fmt::Debug>::fmt": [
            "fmt",
            "Real(LocalPath(\"src/raw_entry.rs\"))",
            "core::fmt::Debug"
        ],
        "<raw_entry::RawEntryBuilderMut<'_, K, V, S, A> as core::fmt::Debug>::fmt": [
            "fmt",
            "Real(LocalPath(\"src/raw_entry.rs\"))",
            "core::fmt::Debug"
        ],
        "<raw_entry::RawEntryMut<'_, K, V, S, A> as core::fmt::Debug>::fmt": [
            "fmt",
            "Real(LocalPath(\"src/raw_entry.rs\"))",
            "core::fmt::Debug"
        ],
        "<raw_entry::RawOccupiedEntryMut<'_, K, V, S, A> as core::fmt::Debug>::fmt": [
            "fmt",
            "Real(LocalPath(\"src/raw_entry.rs\"))",
            "core::fmt::Debug"
        ],
        "<raw_entry::RawVacantEntryMut<'_, K, V, S, A> as core::fmt::Debug>::fmt": [
            "fmt",
            "Real(LocalPath(\"src/raw_entry.rs\"))",
            "core::fmt::Debug"
        ],
        "<scopeguard::ScopeGuard<T, F> as core::ops::Deref>::deref": [
            "deref",
            "Real(LocalPath(\"src/scopeguard.rs\"))",
            "core::ops::Deref"
        ],
        "<scopeguard::ScopeGuard<T, F> as core::ops::DerefMut>::deref_mut": [
            "deref_mut",
            "Real(LocalPath(\"src/scopeguard.rs\"))",
            "core::ops::DerefMut"
        ],
        "<scopeguard::ScopeGuard<T, F> as core::ops::Drop>::drop": [
            "drop",
            "Real(LocalPath(\"src/scopeguard.rs\"))",
            "core::ops::Drop"
        ],
        "<set::Difference<'_, T, S, A> as core::clone::Clone>::clone": [
            "clone",
            "Real(LocalPath(\"src/set.rs\"))",
            "core::clone::Clone"
        ],
        "<set::Difference<'_, T, S, A> as core::fmt::Debug>::fmt": [
            "fmt",
            "Real(LocalPath(\"src/set.rs\"))",
            "core::fmt::Debug"
        ],
        "<set::Difference<'a, T, S, A> as core::iter::Iterator>::fold": [
            "fold",
            "Real(LocalPath(\"src/set.rs\"))",
            "core::iter::Iterator"
        ],
        "<set::Difference<'a, T, S, A> as core::iter::Iterator>::next": [
            "next",
            "Real(LocalPath(\"src/set.rs\"))",
            "core::iter::Iterator"
        ],
        "<set::Difference<'a, T, S, A> as core::iter::Iterator>::size_hint": [
            "size_hint",
            "Real(LocalPath(\"src/set.rs\"))",
            "core::iter::Iterator"
        ],
        "<set::Drain<'_, K, A> as core::fmt::Debug>::fmt": [
            "fmt",
            "Real(LocalPath(\"src/set.rs\"))",
            "core::fmt::Debug"
        ],
        "<set::Drain<'_, K, A> as core::iter::ExactSizeIterator>::len": [
            "len",
            "Real(LocalPath(\"src/set.rs\"))",
            "core::iter::ExactSizeIterator"
        ],
        "<set::Drain<'_, K, A> as core::iter::Iterator>::fold": [
            "fold",
            "Real(LocalPath(\"src/set.rs\"))",
            "core::iter::Iterator"
        ],
        "<set::Drain<'_, K, A> as core::iter::Iterator>::next": [
            "next",
            "Real(LocalPath(\"src/set.rs\"))",
            "core::iter::Iterator"
        ],
        "<set::Drain<'_, K, A> as core::iter::Iterator>::size_hint": [
            "size_hint",
            "Real(LocalPath(\"src/set.rs\"))",
            "core::iter::Iterator"
        ],
        "<set::Entry<'_, T, S, A> as core::fmt::Debug>::fmt": [
            "fmt",
            "Real(LocalPath(\"src/set.rs\"))",
            "core::fmt::Debug"
        ],
        "<set::ExtractIf<'_, K, F, A> as core::iter::Iterator>::next": [
            "next",
            "Real(LocalPath(\"src/set.rs\"))",
            "core::iter::Iterator"
        ],
        "<set::ExtractIf<'_, K, F, A> as core::iter::Iterator>::size_hint": [
            "size_hint",
            "Real(LocalPath(\"src/set.rs\"))",
            "core::iter::Iterator"
        ],
        "<set::HashSet<T, S, A> as core::clone::Clone>::clone": [
            "clone",
            "Real(LocalPath(\"src/set.rs\"))",
            "core::clone::Clone"
        ],
        "<set::HashSet<T, S, A> as core::clone::Clone>::clone_from": [
            "clone_from",
            "Real(LocalPath(\"src/set.rs\"))",
            "core::clone::Clone"
        ],
        "<set::HashSet<T, S, A> as core::cmp::PartialEq>::eq": [
            "eq",
            "Real(LocalPath(\"src/set.rs\"))",
            "core::cmp::PartialEq"
        ],
        "<set::HashSet<T, S, A> as core::convert::From<map::HashMap<T, (), S, A>>>::from": [
            "from",
            "Real(LocalPath(\"src/set.rs\"))",
            "core::convert::From"
        ],
        "<set::HashSet<T, S, A> as core::default::Default>::default": [
            "default",
            "Real(LocalPath(\"src/set.rs\"))",
            "core::default::Default"
        ],
        "<set::HashSet<T, S, A> as core::fmt::Debug>::fmt": [
            "fmt",
            "Real(LocalPath(\"src/set.rs\"))",
            "core::fmt::Debug"
        ],
        "<set::HashSet<T, S, A> as core::iter::Extend<&'a T>>::extend": [
            "extend",
            "Real(LocalPath(\"src/set.rs\"))",
            "core::iter::Extend"
        ],
        "<set::HashSet<T, S, A> as core::iter::Extend<T>>::extend": [
            "extend",
            "Real(LocalPath(\"src/set.rs\"))",
            "core::iter::Extend"
        ],
        "<set::HashSet<T, S, A> as core::iter::FromIterator<T>>::from_iter": [
            "from_iter",
            "Real(LocalPath(\"src/set.rs\"))",
            "core::iter::FromIterator"
        ],
        "<set::HashSet<T, S, A> as core::iter::IntoIterator>::into_iter": [
            "into_iter",
            "Real(LocalPath(\"src/set.rs\"))",
            "core::iter::IntoIterator"
        ],
        "<set::HashSet<T, S, A> as core::ops::BitAndAssign<&set::HashSet<T, S, A>>>::bitand_assign": [
            "bitand_assign",
            "Real(LocalPath(\"src/set.rs\"))",
            "core::ops::BitAndAssign"
        ],
        "<set::HashSet<T, S, A> as core::ops::BitOrAssign<&set::HashSet<T, S, A>>>::bitor_assign": [
            "bitor_assign",
            "Real(LocalPath(\"src/set.rs\"))",
            "core::ops::BitOrAssign"
        ],
        "<set::HashSet<T, S, A> as core::ops::BitXorAssign<&set::HashSet<T, S, A>>>::bitxor_assign": [
            "bitxor_assign",
            "Real(LocalPath(\"src/set.rs\"))",
            "core::ops::BitXorAssign"
        ],
        "<set::HashSet<T, S, A> as core::ops::SubAssign<&set::HashSet<T, S, A>>>::sub_assign": [
            "sub_assign",
            "Real(LocalPath(\"src/set.rs\"))",
            "core::ops::SubAssign"
        ],
        "<set::HashSet<T, foldhash::fast::RandomState, A> as core::convert::From<[T; N]>>::from": [
            "from",
            "Real(LocalPath(\"src/set.rs\"))",
            "core::convert::From"
        ],
        "<set::Intersection<'_, T, S, A> as core::clone::Clone>::clone": [
            "clone",
            "Real(LocalPath(\"src/set.rs\"))",
            "core::clone::Clone"
        ],
        "<set::Intersection<'_, T, S, A> as core::fmt::Debug>::fmt": [
            "fmt",
            "Real(LocalPath(\"src/set.rs\"))",
            "core::fmt::Debug"
        ],
        "<set::Intersection<'a, T, S, A> as core::iter::Iterator>::fold": [
            "fold",
            "Real(LocalPath(\"src/set.rs\"))",
            "core::iter::Iterator"
        ],
        "<set::Intersection<'a, T, S, A> as core::iter::Iterator>::next": [
            "next",
            "Real(LocalPath(\"src/set.rs\"))",
            "core::iter::Iterator"
        ],
        "<set::Intersection<'a, T, S, A> as core::iter::Iterator>::size_hint": [
            "size_hint",
            "Real(LocalPath(\"src/set.rs\"))",
            "core::iter::Iterator"
        ],
        "<set::IntoIter<K, A> as core::default::Default>::default": [
            "default",
            "Real(LocalPath(\"src/set.rs\"))",
            "core::default::Default"
        ],
        "<set::IntoIter<K, A> as core::fmt::Debug>::fmt": [
            "fmt",
            "Real(LocalPath(\"src/set.rs\"))",
            "core::fmt::Debug"
        ],
        "<set::IntoIter<K, A> as core::iter::ExactSizeIterator>::len": [
            "len",
            "Real(LocalPath(\"src/set.rs\"))",
            "core::iter::ExactSizeIterator"
        ],
        "<set::IntoIter<K, A> as core::iter::Iterator>::fold": [
            "fold",
            "Real(LocalPath(\"src/set.rs\"))",
            "core::iter::Iterator"
        ],
        "<set::IntoIter<K, A> as core::iter::Iterator>::next": [
            "next",
            "Real(LocalPath(\"src/set.rs\"))",
            "core::iter::Iterator"
        ],
        "<set::IntoIter<K, A> as core::iter::Iterator>::size_hint": [
            "size_hint",
            "Real(LocalPath(\"src/set.rs\"))",
            "core::iter::Iterator"
        ],
        "<set::Iter<'_, K> as core::clone::Clone>::clone": [
            "clone",
            "Real(LocalPath(\"src/set.rs\"))",
            "core::clone::Clone"
        ],
        "<set::Iter<'_, K> as core::default::Default>::default": [
            "default",
            "Real(LocalPath(\"src/set.rs\"))",
            "core::default::Default"
        ],
        "<set::Iter<'_, K> as core::fmt::Debug>::fmt": [
            "fmt",
            "Real(LocalPath(\"src/set.rs\"))",
            "core::fmt::Debug"
        ],
        "<set::Iter<'_, K> as core::iter::ExactSizeIterator>::len": [
            "len",
            "Real(LocalPath(\"src/set.rs\"))",
            "core::iter::ExactSizeIterator"
        ],
        "<set::Iter<'a, K> as core::iter::Iterator>::fold": [
            "fold",
            "Real(LocalPath(\"src/set.rs\"))",
            "core::iter::Iterator"
        ],
        "<set::Iter<'a, K> as core::iter::Iterator>::next": [
            "next",
            "Real(LocalPath(\"src/set.rs\"))",
            "core::iter::Iterator"
        ],
        "<set::Iter<'a, K> as core::iter::Iterator>::size_hint": [
            "size_hint",
            "Real(LocalPath(\"src/set.rs\"))",
            "core::iter::Iterator"
        ],
        "<set::OccupiedEntry<'_, T, S, A> as core::fmt::Debug>::fmt": [
            "fmt",
            "Real(LocalPath(\"src/set.rs\"))",
            "core::fmt::Debug"
        ],
        "<set::SymmetricDifference<'_, T, S, A> as core::clone::Clone>::clone": [
            "clone",
            "Real(LocalPath(\"src/set.rs\"))",
            "core::clone::Clone"
        ],
        "<set::SymmetricDifference<'_, T, S, A> as core::fmt::Debug>::fmt": [
            "fmt",
            "Real(LocalPath(\"src/set.rs\"))",
            "core::fmt::Debug"
        ],
        "<set::SymmetricDifference<'a, T, S, A> as core::iter::Iterator>::fold": [
            "fold",
            "Real(LocalPath(\"src/set.rs\"))",
            "core::iter::Iterator"
        ],
        "<set::SymmetricDifference<'a, T, S, A> as core::iter::Iterator>::next": [
            "next",
            "Real(LocalPath(\"src/set.rs\"))",
            "core::iter::Iterator"
        ],
        "<set::SymmetricDifference<'a, T, S, A> as core::iter::Iterator>::size_hint": [
            "size_hint",
            "Real(LocalPath(\"src/set.rs\"))",
            "core::iter::Iterator"
        ],
        "<set::Union<'_, T, S, A> as core::clone::Clone>::clone": [
            "clone",
            "Real(LocalPath(\"src/set.rs\"))",
            "core::clone::Clone"
        ],
        "<set::Union<'_, T, S, A> as core::fmt::Debug>::fmt": [
            "fmt",
            "Real(LocalPath(\"src/set.rs\"))",
            "core::fmt::Debug"
        ],
        "<set::Union<'a, T, S, A> as core::iter::Iterator>::fold": [
            "fold",
            "Real(LocalPath(\"src/set.rs\"))",
            "core::iter::Iterator"
        ],
        "<set::Union<'a, T, S, A> as core::iter::Iterator>::next": [
            "next",
            "Real(LocalPath(\"src/set.rs\"))",
            "core::iter::Iterator"
        ],
        "<set::Union<'a, T, S, A> as core::iter::Iterator>::size_hint": [
            "size_hint",
            "Real(LocalPath(\"src/set.rs\"))",
            "core::iter::Iterator"
        ],
        "<set::VacantEntry<'_, T, S, A> as core::fmt::Debug>::fmt": [
            "fmt",
            "Real(LocalPath(\"src/set.rs\"))",
            "core::fmt::Debug"
        ],
        "<table::AbsentEntry<'_, T, A> as core::fmt::Debug>::fmt": [
            "fmt",
            "Real(LocalPath(\"src/table.rs\"))",
            "core::fmt::Debug"
        ],
        "<table::Drain<'_, T, A> as core::fmt::Debug>::fmt": [
            "fmt",
            "Real(LocalPath(\"src/table.rs\"))",
            "core::fmt::Debug"
        ],
        "<table::Drain<'_, T, A> as core::iter::ExactSizeIterator>::len": [
            "len",
            "Real(LocalPath(\"src/table.rs\"))",
            "core::iter::ExactSizeIterator"
        ],
        "<table::Drain<'_, T, A> as core::iter::Iterator>::fold": [
            "fold",
            "Real(LocalPath(\"src/table.rs\"))",
            "core::iter::Iterator"
        ],
        "<table::Drain<'_, T, A> as core::iter::Iterator>::next": [
            "next",
            "Real(LocalPath(\"src/table.rs\"))",
            "core::iter::Iterator"
        ],
        "<table::Drain<'_, T, A> as core::iter::Iterator>::size_hint": [
            "size_hint",
            "Real(LocalPath(\"src/table.rs\"))",
            "core::iter::Iterator"
        ],
        "<table::Entry<'_, T, A> as core::fmt::Debug>::fmt": [
            "fmt",
            "Real(LocalPath(\"src/table.rs\"))",
            "core::fmt::Debug"
        ],
        "<table::ExtractIf<'_, T, F, A> as core::iter::Iterator>::next": [
            "next",
            "Real(LocalPath(\"src/table.rs\"))",
            "core::iter::Iterator"
        ],
        "<table::ExtractIf<'_, T, F, A> as core::iter::Iterator>::size_hint": [
            "size_hint",
            "Real(LocalPath(\"src/table.rs\"))",
            "core::iter::Iterator"
        ],
        "<table::HashTable<T, A> as core::clone::Clone>::clone": [
            "clone",
            "Real(LocalPath(\"src/table.rs\"))",
            "core::clone::Clone"
        ],
        "<table::HashTable<T, A> as core::default::Default>::default": [
            "default",
            "Real(LocalPath(\"src/table.rs\"))",
            "core::default::Default"
        ],
        "<table::HashTable<T, A> as core::fmt::Debug>::fmt": [
            "fmt",
            "Real(LocalPath(\"src/table.rs\"))",
            "core::fmt::Debug"
        ],
        "<table::HashTable<T, A> as core::iter::IntoIterator>::into_iter": [
            "into_iter",
            "Real(LocalPath(\"src/table.rs\"))",
            "core::iter::IntoIterator"
        ],
        "<table::IntoIter<T, A> as core::default::Default>::default": [
            "default",
            "Real(LocalPath(\"src/table.rs\"))",
            "core::default::Default"
        ],
        "<table::IntoIter<T, A> as core::fmt::Debug>::fmt": [
            "fmt",
            "Real(LocalPath(\"src/table.rs\"))",
            "core::fmt::Debug"
        ],
        "<table::IntoIter<T, A> as core::iter::ExactSizeIterator>::len": [
            "len",
            "Real(LocalPath(\"src/table.rs\"))",
            "core::iter::ExactSizeIterator"
        ],
        "<table::IntoIter<T, A> as core::iter::Iterator>::fold": [
            "fold",
            "Real(LocalPath(\"src/table.rs\"))",
            "core::iter::Iterator"
        ],
        "<table::IntoIter<T, A> as core::iter::Iterator>::next": [
            "next",
            "Real(LocalPath(\"src/table.rs\"))",
            "core::iter::Iterator"
        ],
        "<table::IntoIter<T, A> as core::iter::Iterator>::size_hint": [
            "size_hint",
            "Real(LocalPath(\"src/table.rs\"))",
            "core::iter::Iterator"
        ],
        "<table::Iter<'_, T> as core::default::Default>::default": [
            "default",
            "Real(LocalPath(\"src/table.rs\"))",
            "core::default::Default"
        ],
        "<table::Iter<'_, T> as core::fmt::Debug>::fmt": [
            "fmt",
            "Real(LocalPath(\"src/table.rs\"))",
            "core::fmt::Debug"
        ],
        "<table::Iter<'_, T> as core::iter::ExactSizeIterator>::len": [
            "len",
            "Real(LocalPath(\"src/table.rs\"))",
            "core::iter::ExactSizeIterator"
        ],
        "<table::Iter<'a, T> as core::clone::Clone>::clone": [
            "clone",
            "Real(LocalPath(\"src/table.rs\"))",
            "core::clone::Clone"
        ],
        "<table::Iter<'a, T> as core::iter::Iterator>::fold": [
            "fold",
            "Real(LocalPath(\"src/table.rs\"))",
            "core::iter::Iterator"
        ],
        "<table::Iter<'a, T> as core::iter::Iterator>::next": [
            "next",
            "Real(LocalPath(\"src/table.rs\"))",
            "core::iter::Iterator"
        ],
        "<table::Iter<'a, T> as core::iter::Iterator>::size_hint": [
            "size_hint",
            "Real(LocalPath(\"src/table.rs\"))",
            "core::iter::Iterator"
        ],
        "<table::IterHash<'_, T> as core::default::Default>::default": [
            "default",
            "Real(LocalPath(\"src/table.rs\"))",
            "core::default::Default"
        ],
        "<table::IterHash<'_, T> as core::fmt::Debug>::fmt": [
            "fmt",
            "Real(LocalPath(\"src/table.rs\"))",
            "core::fmt::Debug"
        ],
        "<table::IterHash<'a, T> as core::clone::Clone>::clone": [
            "clone",
            "Real(LocalPath(\"src/table.rs\"))",
            "core::clone::Clone"
        ],
        "<table::IterHash<'a, T> as core::iter::Iterator>::fold": [
            "fold",
            "Real(LocalPath(\"src/table.rs\"))",
            "core::iter::Iterator"
        ],
        "<table::IterHash<'a, T> as core::iter::Iterator>::next": [
            "next",
            "Real(LocalPath(\"src/table.rs\"))",
            "core::iter::Iterator"
        ],
        "<table::IterHashMut<'_, T> as core::default::Default>::default": [
            "default",
            "Real(LocalPath(\"src/table.rs\"))",
            "core::default::Default"
        ],
        "<table::IterHashMut<'_, T> as core::fmt::Debug>::fmt": [
            "fmt",
            "Real(LocalPath(\"src/table.rs\"))",
            "core::fmt::Debug"
        ],
        "<table::IterHashMut<'a, T> as core::iter::Iterator>::fold": [
            "fold",
            "Real(LocalPath(\"src/table.rs\"))",
            "core::iter::Iterator"
        ],
        "<table::IterHashMut<'a, T> as core::iter::Iterator>::next": [
            "next",
            "Real(LocalPath(\"src/table.rs\"))",
            "core::iter::Iterator"
        ],
        "<table::IterMut<'_, T> as core::default::Default>::default": [
            "default",
            "Real(LocalPath(\"src/table.rs\"))",
            "core::default::Default"
        ],
        "<table::IterMut<'_, T> as core::fmt::Debug>::fmt": [
            "fmt",
            "Real(LocalPath(\"src/table.rs\"))",
            "core::fmt::Debug"
        ],
        "<table::IterMut<'_, T> as core::iter::ExactSizeIterator>::len": [
            "len",
            "Real(LocalPath(\"src/table.rs\"))",
            "core::iter::ExactSizeIterator"
        ],
        "<table::IterMut<'a, T> as core::iter::Iterator>::fold": [
            "fold",
            "Real(LocalPath(\"src/table.rs\"))",
            "core::iter::Iterator"
        ],
        "<table::IterMut<'a, T> as core::iter::Iterator>::next": [
            "next",
            "Real(LocalPath(\"src/table.rs\"))",
            "core::iter::Iterator"
        ],
        "<table::IterMut<'a, T> as core::iter::Iterator>::size_hint": [
            "size_hint",
            "Real(LocalPath(\"src/table.rs\"))",
            "core::iter::Iterator"
        ],
        "<table::OccupiedEntry<'_, T, A> as core::fmt::Debug>::fmt": [
            "fmt",
            "Real(LocalPath(\"src/table.rs\"))",
            "core::fmt::Debug"
        ],
        "<table::VacantEntry<'_, T, A> as core::fmt::Debug>::fmt": [
            "fmt",
            "Real(LocalPath(\"src/table.rs\"))",
            "core::fmt::Debug"
        ],
        "control::bitmask::BitMask::any_bit_set": [
            "any_bit_set",
            "Real(LocalPath(\"src/control/bitmask.rs\"))",
            ""
        ],
        "control::bitmask::BitMask::invert": [
            "invert",
            "Real(LocalPath(\"src/control/bitmask.rs\"))",
            ""
        ],
        "control::bitmask::BitMask::leading_zeros": [
            "leading_zeros",
            "Real(LocalPath(\"src/control/bitmask.rs\"))",
            ""
        ],
        "control::bitmask::BitMask::lowest_set_bit": [
            "lowest_set_bit",
            "Real(LocalPath(\"src/control/bitmask.rs\"))",
            ""
        ],
        "control::bitmask::BitMask::nonzero_trailing_zeros": [
            "nonzero_trailing_zeros",
            "Real(LocalPath(\"src/control/bitmask.rs\"))",
            ""
        ],
        "control::bitmask::BitMask::remove_lowest_bit": [
            "remove_lowest_bit",
            "Real(LocalPath(\"src/control/bitmask.rs\"))",
            ""
        ],
        "control::bitmask::BitMask::trailing_zeros": [
            "trailing_zeros",
            "Real(LocalPath(\"src/control/bitmask.rs\"))",
            ""
        ],
        "control::group::sse2::Group::convert_special_to_empty_and_full_to_deleted": [
            "convert_special_to_empty_and_full_to_deleted",
            "Real(LocalPath(\"src/control/group/sse2.rs\"))",
            ""
        ],
        "control::group::sse2::Group::load": [
            "load",
            "Real(LocalPath(\"src/control/group/sse2.rs\"))",
            ""
        ],
        "control::group::sse2::Group::load_aligned": [
            "load_aligned",
            "Real(LocalPath(\"src/control/group/sse2.rs\"))",
            ""
        ],
        "control::group::sse2::Group::match_empty": [
            "match_empty",
            "Real(LocalPath(\"src/control/group/sse2.rs\"))",
            ""
        ],
        "control::group::sse2::Group::match_empty_or_deleted": [
            "match_empty_or_deleted",
            "Real(LocalPath(\"src/control/group/sse2.rs\"))",
            ""
        ],
        "control::group::sse2::Group::match_full": [
            "match_full",
            "Real(LocalPath(\"src/control/group/sse2.rs\"))",
            ""
        ],
        "control::group::sse2::Group::match_tag": [
            "match_tag",
            "Real(LocalPath(\"src/control/group/sse2.rs\"))",
            ""
        ],
        "control::group::sse2::Group::static_empty": [
            "static_empty",
            "Real(LocalPath(\"src/control/group/sse2.rs\"))",
            ""
        ],
        "control::group::sse2::Group::store_aligned": [
            "store_aligned",
            "Real(LocalPath(\"src/control/group/sse2.rs\"))",
            ""
        ],
        "control::tag::Tag::full": [
            "full",
            "Real(LocalPath(\"src/control/tag.rs\"))",
            ""
        ],
        "control::tag::Tag::is_full": [
            "is_full",
            "Real(LocalPath(\"src/control/tag.rs\"))",
            ""
        ],
        "control::tag::Tag::is_special": [
            "is_special",
            "Real(LocalPath(\"src/control/tag.rs\"))",
            ""
        ],
        "control::tag::Tag::special_is_empty": [
            "special_is_empty",
            "Real(LocalPath(\"src/control/tag.rs\"))",
            ""
        ],
        "control::tag::TagSliceExt::fill_empty": [
            "fill_empty",
            "Real(LocalPath(\"src/control/tag.rs\"))",
            ""
        ],
        "map::Drain::<'_, K, V, A>::iter": [
            "iter",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::Entry::<'a, K, V, S, A>::and_modify": [
            "and_modify",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::Entry::<'a, K, V, S, A>::and_replace_entry_with": [
            "and_replace_entry_with",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::Entry::<'a, K, V, S, A>::insert": [
            "insert",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::Entry::<'a, K, V, S, A>::key": [
            "key",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::Entry::<'a, K, V, S, A>::or_default": [
            "or_default",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::Entry::<'a, K, V, S, A>::or_insert": [
            "or_insert",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::Entry::<'a, K, V, S, A>::or_insert_with": [
            "or_insert_with",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::Entry::<'a, K, V, S, A>::or_insert_with_key": [
            "or_insert_with_key",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::EntryRef::<'a, 'b, K, Q, V, S, A>::and_modify": [
            "and_modify",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::EntryRef::<'a, 'b, K, Q, V, S, A>::insert": [
            "insert",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::EntryRef::<'a, 'b, K, Q, V, S, A>::key": [
            "key",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::EntryRef::<'a, 'b, K, Q, V, S, A>::or_default": [
            "or_default",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::EntryRef::<'a, 'b, K, Q, V, S, A>::or_insert": [
            "or_insert",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::EntryRef::<'a, 'b, K, Q, V, S, A>::or_insert_with": [
            "or_insert_with",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::EntryRef::<'a, 'b, K, Q, V, S, A>::or_insert_with_key": [
            "or_insert_with_key",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::HashMap::<K, V, S, A>::allocation_size": [
            "allocation_size",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::HashMap::<K, V, S, A>::allocator": [
            "allocator",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::HashMap::<K, V, S, A>::build_hashes_inner": [
            "build_hashes_inner",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::HashMap::<K, V, S, A>::capacity": [
            "capacity",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::HashMap::<K, V, S, A>::clear": [
            "clear",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::HashMap::<K, V, S, A>::contains_key": [
            "contains_key",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::HashMap::<K, V, S, A>::drain": [
            "drain",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::HashMap::<K, V, S, A>::entry": [
            "entry",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::HashMap::<K, V, S, A>::entry_ref": [
            "entry_ref",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::HashMap::<K, V, S, A>::extract_if": [
            "extract_if",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::HashMap::<K, V, S, A>::find_or_find_insert_slot": [
            "find_or_find_insert_slot",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::HashMap::<K, V, S, A>::get": [
            "get",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::HashMap::<K, V, S, A>::get_inner": [
            "get_inner",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::HashMap::<K, V, S, A>::get_inner_mut": [
            "get_inner_mut",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::HashMap::<K, V, S, A>::get_key_value": [
            "get_key_value",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::HashMap::<K, V, S, A>::get_key_value_mut": [
            "get_key_value_mut",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::HashMap::<K, V, S, A>::get_many_key_value_mut": [
            "get_many_key_value_mut",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::HashMap::<K, V, S, A>::get_many_key_value_unchecked_mut": [
            "get_many_key_value_unchecked_mut",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::HashMap::<K, V, S, A>::get_many_mut": [
            "get_many_mut",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::HashMap::<K, V, S, A>::get_many_mut_inner": [
            "get_many_mut_inner",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::HashMap::<K, V, S, A>::get_many_unchecked_mut": [
            "get_many_unchecked_mut",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::HashMap::<K, V, S, A>::get_many_unchecked_mut_inner": [
            "get_many_unchecked_mut_inner",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::HashMap::<K, V, S, A>::get_mut": [
            "get_mut",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::HashMap::<K, V, S, A>::hasher": [
            "hasher",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::HashMap::<K, V, S, A>::insert": [
            "insert",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::HashMap::<K, V, S, A>::insert_unique_unchecked": [
            "insert_unique_unchecked",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::HashMap::<K, V, S, A>::into_keys": [
            "into_keys",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::HashMap::<K, V, S, A>::into_values": [
            "into_values",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::HashMap::<K, V, S, A>::is_empty": [
            "is_empty",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::HashMap::<K, V, S, A>::iter": [
            "iter",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::HashMap::<K, V, S, A>::iter_mut": [
            "iter_mut",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::HashMap::<K, V, S, A>::keys": [
            "keys",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::HashMap::<K, V, S, A>::len": [
            "len",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::HashMap::<K, V, S, A>::remove": [
            "remove",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::HashMap::<K, V, S, A>::remove_entry": [
            "remove_entry",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::HashMap::<K, V, S, A>::reserve": [
            "reserve",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::HashMap::<K, V, S, A>::retain": [
            "retain",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::HashMap::<K, V, S, A>::shrink_to": [
            "shrink_to",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::HashMap::<K, V, S, A>::shrink_to_fit": [
            "shrink_to_fit",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::HashMap::<K, V, S, A>::try_insert": [
            "try_insert",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::HashMap::<K, V, S, A>::try_reserve": [
            "try_reserve",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::HashMap::<K, V, S, A>::values": [
            "values",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::HashMap::<K, V, S, A>::values_mut": [
            "values_mut",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::HashMap::<K, V, S, A>::with_capacity_and_hasher_in": [
            "with_capacity_and_hasher_in",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::HashMap::<K, V, S, A>::with_hasher_in": [
            "with_hasher_in",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::HashMap::<K, V, S>::with_capacity_and_hasher": [
            "with_capacity_and_hasher",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::HashMap::<K, V, S>::with_hasher": [
            "with_hasher",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::HashMap::<K, V, foldhash::fast::RandomState, A>::new_in": [
            "new_in",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::HashMap::<K, V, foldhash::fast::RandomState, A>::with_capacity_in": [
            "with_capacity_in",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::HashMap::<K, V>::new": [
            "new",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::HashMap::<K, V>::with_capacity": [
            "with_capacity",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::IntoIter::<K, V, A>::iter": [
            "iter",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::IterMut::<'_, K, V>::iter": [
            "iter",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::OccupiedEntry::<'a, K, V, S, A>::get": [
            "get",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::OccupiedEntry::<'a, K, V, S, A>::get_mut": [
            "get_mut",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::OccupiedEntry::<'a, K, V, S, A>::insert": [
            "insert",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::OccupiedEntry::<'a, K, V, S, A>::into_mut": [
            "into_mut",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::OccupiedEntry::<'a, K, V, S, A>::key": [
            "key",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::OccupiedEntry::<'a, K, V, S, A>::remove": [
            "remove",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::OccupiedEntry::<'a, K, V, S, A>::remove_entry": [
            "remove_entry",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::OccupiedEntry::<'a, K, V, S, A>::replace_entry_with": [
            "replace_entry_with",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::VacantEntry::<'a, K, V, S, A>::insert": [
            "insert",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::VacantEntry::<'a, K, V, S, A>::insert_entry": [
            "insert_entry",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::VacantEntry::<'a, K, V, S, A>::into_key": [
            "into_key",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::VacantEntry::<'a, K, V, S, A>::key": [
            "key",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::VacantEntryRef::<'a, 'b, K, Q, V, S, A>::insert": [
            "insert",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::VacantEntryRef::<'a, 'b, K, Q, V, S, A>::insert_entry": [
            "insert_entry",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::VacantEntryRef::<'a, 'b, K, Q, V, S, A>::key": [
            "key",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::assert_covariance": [
            "assert_covariance",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::assert_covariance::drain": [
            "drain",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::assert_covariance::into_iter_key": [
            "into_iter_key",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::assert_covariance::into_iter_val": [
            "into_iter_val",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::assert_covariance::iter_key": [
            "iter_key",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::assert_covariance::iter_val": [
            "iter_val",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::assert_covariance::keys_key": [
            "keys_key",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::assert_covariance::keys_val": [
            "keys_val",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::assert_covariance::map_key": [
            "map_key",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::assert_covariance::map_val": [
            "map_val",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::assert_covariance::values_key": [
            "values_key",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::assert_covariance::values_val": [
            "values_val",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::equivalent": [
            "equivalent",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::equivalent_key": [
            "equivalent_key",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::make_hash": [
            "make_hash",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "map::make_hasher": [
            "make_hasher",
            "Real(LocalPath(\"src/map.rs\"))",
            ""
        ],
        "raw::Bucket::<T>::as_mut": [
            "as_mut",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::Bucket::<T>::as_non_null": [
            "as_non_null",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::Bucket::<T>::as_ptr": [
            "as_ptr",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::Bucket::<T>::as_ref": [
            "as_ref",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::Bucket::<T>::drop": [
            "drop",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::Bucket::<T>::from_base_index": [
            "from_base_index",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::Bucket::<T>::next_n": [
            "next_n",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::Bucket::<T>::read": [
            "read",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::Bucket::<T>::to_base_index": [
            "to_base_index",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::Bucket::<T>::write": [
            "write",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::Fallibility::alloc_err": [
            "alloc_err",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::Fallibility::capacity_overflow": [
            "capacity_overflow",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::FullBucketsIndices::next_impl": [
            "next_impl",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::ProbeSeq::move_next": [
            "move_next",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawDrain::<'_, T, A>::iter": [
            "iter",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawExtractIf::<'_, T, A>::next": [
            "next",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawIntoIter::<T, A>::iter": [
            "iter",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawIter::<T>::drop_elements": [
            "drop_elements",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawIterHash::<T>::new": [
            "new",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawIterHashInner::new": [
            "new",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawIterRange::<T>::fold_impl": [
            "fold_impl",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawIterRange::<T>::new": [
            "new",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawIterRange::<T>::next_impl": [
            "next_impl",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTable::<T, A>::allocation_size": [
            "allocation_size",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTable::<T, A>::allocator": [
            "allocator",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTable::<T, A>::bucket": [
            "bucket",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTable::<T, A>::bucket_index": [
            "bucket_index",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTable::<T, A>::buckets": [
            "buckets",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTable::<T, A>::capacity": [
            "capacity",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTable::<T, A>::clear": [
            "clear",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTable::<T, A>::clear_no_drop": [
            "clear_no_drop",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTable::<T, A>::clone_from_impl": [
            "clone_from_impl",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTable::<T, A>::data_end": [
            "data_end",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTable::<T, A>::drain": [
            "drain",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTable::<T, A>::drain_iter_from": [
            "drain_iter_from",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTable::<T, A>::erase": [
            "erase",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTable::<T, A>::erase_no_drop": [
            "erase_no_drop",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTable::<T, A>::find": [
            "find",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTable::<T, A>::find_or_find_insert_slot": [
            "find_or_find_insert_slot",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTable::<T, A>::get": [
            "get",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTable::<T, A>::get_many_mut": [
            "get_many_mut",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTable::<T, A>::get_many_mut_pointers": [
            "get_many_mut_pointers",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTable::<T, A>::get_many_unchecked_mut": [
            "get_many_unchecked_mut",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTable::<T, A>::get_mut": [
            "get_mut",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTable::<T, A>::insert": [
            "insert",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTable::<T, A>::insert_entry": [
            "insert_entry",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTable::<T, A>::insert_in_slot": [
            "insert_in_slot",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTable::<T, A>::into_allocation": [
            "into_allocation",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTable::<T, A>::into_iter_from": [
            "into_iter_from",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTable::<T, A>::is_bucket_full": [
            "is_bucket_full",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTable::<T, A>::is_empty": [
            "is_empty",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTable::<T, A>::iter": [
            "iter",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTable::<T, A>::iter_hash": [
            "iter_hash",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTable::<T, A>::len": [
            "len",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTable::<T, A>::new_in": [
            "new_in",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTable::<T, A>::new_uninitialized": [
            "new_uninitialized",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTable::<T, A>::remove": [
            "remove",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTable::<T, A>::remove_entry": [
            "remove_entry",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTable::<T, A>::replace_bucket_with": [
            "replace_bucket_with",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTable::<T, A>::reserve": [
            "reserve",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTable::<T, A>::reserve_rehash": [
            "reserve_rehash",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTable::<T, A>::resize": [
            "resize",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTable::<T, A>::shrink_to": [
            "shrink_to",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTable::<T, A>::try_reserve": [
            "try_reserve",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTable::<T, A>::with_capacity_in": [
            "with_capacity_in",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTable::<T>::new": [
            "new",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTable::<T>::with_capacity": [
            "with_capacity",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTableInner::allocation_info": [
            "allocation_info",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTableInner::allocation_size_or_zero": [
            "allocation_size_or_zero",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTableInner::bucket": [
            "bucket",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTableInner::bucket_ptr": [
            "bucket_ptr",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTableInner::buckets": [
            "buckets",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTableInner::clear_no_drop": [
            "clear_no_drop",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTableInner::ctrl": [
            "ctrl",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTableInner::ctrl_slice": [
            "ctrl_slice",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTableInner::data_end": [
            "data_end",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTableInner::drop_elements": [
            "drop_elements",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTableInner::drop_inner_table": [
            "drop_inner_table",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTableInner::erase": [
            "erase",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTableInner::fallible_with_capacity": [
            "fallible_with_capacity",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTableInner::find_inner": [
            "find_inner",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTableInner::find_insert_slot": [
            "find_insert_slot",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTableInner::find_insert_slot_in_group": [
            "find_insert_slot_in_group",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTableInner::find_or_find_insert_slot_inner": [
            "find_or_find_insert_slot_inner",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTableInner::fix_insert_slot": [
            "fix_insert_slot",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTableInner::free_buckets": [
            "free_buckets",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTableInner::full_buckets_indices": [
            "full_buckets_indices",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTableInner::is_bucket_full": [
            "is_bucket_full",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTableInner::is_empty_singleton": [
            "is_empty_singleton",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTableInner::is_in_same_group": [
            "is_in_same_group",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTableInner::iter": [
            "iter",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTableInner::new": [
            "new",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTableInner::new_uninitialized": [
            "new_uninitialized",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTableInner::num_ctrl_bytes": [
            "num_ctrl_bytes",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTableInner::prepare_insert_slot": [
            "prepare_insert_slot",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTableInner::prepare_rehash_in_place": [
            "prepare_rehash_in_place",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTableInner::prepare_resize": [
            "prepare_resize",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTableInner::probe_seq": [
            "probe_seq",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTableInner::record_item_insert_at": [
            "record_item_insert_at",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTableInner::rehash_in_place": [
            "rehash_in_place",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTableInner::replace_ctrl_hash": [
            "replace_ctrl_hash",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTableInner::reserve_rehash_inner": [
            "reserve_rehash_inner",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTableInner::resize_inner": [
            "resize_inner",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTableInner::set_ctrl": [
            "set_ctrl",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTableInner::set_ctrl_hash": [
            "set_ctrl_hash",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::RawTableInner::with_capacity": [
            "with_capacity",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::TableLayout::calculate_layout_for": [
            "calculate_layout_for",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::TableLayout::new": [
            "new",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::alloc::inner::do_alloc": [
            "do_alloc",
            "Real(LocalPath(\"src/raw/alloc.rs\"))",
            ""
        ],
        "raw::bucket_mask_to_capacity": [
            "bucket_mask_to_capacity",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::capacity_to_buckets": [
            "capacity_to_buckets",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::h1": [
            "h1",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw::offset_from": [
            "offset_from",
            "Real(LocalPath(\"src/raw/mod.rs\"))",
            ""
        ],
        "raw_entry::<impl map::HashMap<K, V, S, A>>::raw_entry": [
            "raw_entry",
            "Real(LocalPath(\"src/raw_entry.rs\"))",
            ""
        ],
        "raw_entry::<impl map::HashMap<K, V, S, A>>::raw_entry_mut": [
            "raw_entry_mut",
            "Real(LocalPath(\"src/raw_entry.rs\"))",
            ""
        ],
        "raw_entry::RawEntryBuilder::<'a, K, V, S, A>::from_hash": [
            "from_hash",
            "Real(LocalPath(\"src/raw_entry.rs\"))",
            ""
        ],
        "raw_entry::RawEntryBuilder::<'a, K, V, S, A>::from_key": [
            "from_key",
            "Real(LocalPath(\"src/raw_entry.rs\"))",
            ""
        ],
        "raw_entry::RawEntryBuilder::<'a, K, V, S, A>::from_key_hashed_nocheck": [
            "from_key_hashed_nocheck",
            "Real(LocalPath(\"src/raw_entry.rs\"))",
            ""
        ],
        "raw_entry::RawEntryBuilder::<'a, K, V, S, A>::search": [
            "search",
            "Real(LocalPath(\"src/raw_entry.rs\"))",
            ""
        ],
        "raw_entry::RawEntryBuilderMut::<'a, K, V, S, A>::from_hash": [
            "from_hash",
            "Real(LocalPath(\"src/raw_entry.rs\"))",
            ""
        ],
        "raw_entry::RawEntryBuilderMut::<'a, K, V, S, A>::from_key": [
            "from_key",
            "Real(LocalPath(\"src/raw_entry.rs\"))",
            ""
        ],
        "raw_entry::RawEntryBuilderMut::<'a, K, V, S, A>::from_key_hashed_nocheck": [
            "from_key_hashed_nocheck",
            "Real(LocalPath(\"src/raw_entry.rs\"))",
            ""
        ],
        "raw_entry::RawEntryBuilderMut::<'a, K, V, S, A>::search": [
            "search",
            "Real(LocalPath(\"src/raw_entry.rs\"))",
            ""
        ],
        "raw_entry::RawEntryMut::<'a, K, V, S, A>::and_modify": [
            "and_modify",
            "Real(LocalPath(\"src/raw_entry.rs\"))",
            ""
        ],
        "raw_entry::RawEntryMut::<'a, K, V, S, A>::and_replace_entry_with": [
            "and_replace_entry_with",
            "Real(LocalPath(\"src/raw_entry.rs\"))",
            ""
        ],
        "raw_entry::RawEntryMut::<'a, K, V, S, A>::insert": [
            "insert",
            "Real(LocalPath(\"src/raw_entry.rs\"))",
            ""
        ],
        "raw_entry::RawEntryMut::<'a, K, V, S, A>::or_insert": [
            "or_insert",
            "Real(LocalPath(\"src/raw_entry.rs\"))",
            ""
        ],
        "raw_entry::RawEntryMut::<'a, K, V, S, A>::or_insert_with": [
            "or_insert_with",
            "Real(LocalPath(\"src/raw_entry.rs\"))",
            ""
        ],
        "raw_entry::RawOccupiedEntryMut::<'a, K, V, S, A>::get": [
            "get",
            "Real(LocalPath(\"src/raw_entry.rs\"))",
            ""
        ],
        "raw_entry::RawOccupiedEntryMut::<'a, K, V, S, A>::get_key_value": [
            "get_key_value",
            "Real(LocalPath(\"src/raw_entry.rs\"))",
            ""
        ],
        "raw_entry::RawOccupiedEntryMut::<'a, K, V, S, A>::get_key_value_mut": [
            "get_key_value_mut",
            "Real(LocalPath(\"src/raw_entry.rs\"))",
            ""
        ],
        "raw_entry::RawOccupiedEntryMut::<'a, K, V, S, A>::get_mut": [
            "get_mut",
            "Real(LocalPath(\"src/raw_entry.rs\"))",
            ""
        ],
        "raw_entry::RawOccupiedEntryMut::<'a, K, V, S, A>::insert": [
            "insert",
            "Real(LocalPath(\"src/raw_entry.rs\"))",
            ""
        ],
        "raw_entry::RawOccupiedEntryMut::<'a, K, V, S, A>::insert_key": [
            "insert_key",
            "Real(LocalPath(\"src/raw_entry.rs\"))",
            ""
        ],
        "raw_entry::RawOccupiedEntryMut::<'a, K, V, S, A>::into_key": [
            "into_key",
            "Real(LocalPath(\"src/raw_entry.rs\"))",
            ""
        ],
        "raw_entry::RawOccupiedEntryMut::<'a, K, V, S, A>::into_key_value": [
            "into_key_value",
            "Real(LocalPath(\"src/raw_entry.rs\"))",
            ""
        ],
        "raw_entry::RawOccupiedEntryMut::<'a, K, V, S, A>::into_mut": [
            "into_mut",
            "Real(LocalPath(\"src/raw_entry.rs\"))",
            ""
        ],
        "raw_entry::RawOccupiedEntryMut::<'a, K, V, S, A>::key": [
            "key",
            "Real(LocalPath(\"src/raw_entry.rs\"))",
            ""
        ],
        "raw_entry::RawOccupiedEntryMut::<'a, K, V, S, A>::key_mut": [
            "key_mut",
            "Real(LocalPath(\"src/raw_entry.rs\"))",
            ""
        ],
        "raw_entry::RawOccupiedEntryMut::<'a, K, V, S, A>::remove": [
            "remove",
            "Real(LocalPath(\"src/raw_entry.rs\"))",
            ""
        ],
        "raw_entry::RawOccupiedEntryMut::<'a, K, V, S, A>::remove_entry": [
            "remove_entry",
            "Real(LocalPath(\"src/raw_entry.rs\"))",
            ""
        ],
        "raw_entry::RawOccupiedEntryMut::<'a, K, V, S, A>::replace_entry_with": [
            "replace_entry_with",
            "Real(LocalPath(\"src/raw_entry.rs\"))",
            ""
        ],
        "raw_entry::RawVacantEntryMut::<'a, K, V, S, A>::insert": [
            "insert",
            "Real(LocalPath(\"src/raw_entry.rs\"))",
            ""
        ],
        "raw_entry::RawVacantEntryMut::<'a, K, V, S, A>::insert_entry": [
            "insert_entry",
            "Real(LocalPath(\"src/raw_entry.rs\"))",
            ""
        ],
        "raw_entry::RawVacantEntryMut::<'a, K, V, S, A>::insert_hashed_nocheck": [
            "insert_hashed_nocheck",
            "Real(LocalPath(\"src/raw_entry.rs\"))",
            ""
        ],
        "raw_entry::RawVacantEntryMut::<'a, K, V, S, A>::insert_with_hasher": [
            "insert_with_hasher",
            "Real(LocalPath(\"src/raw_entry.rs\"))",
            ""
        ],
        "scopeguard::ScopeGuard::<T, F>::into_inner": [
            "into_inner",
            "Real(LocalPath(\"src/scopeguard.rs\"))",
            ""
        ],
        "scopeguard::guard": [
            "guard",
            "Real(LocalPath(\"src/scopeguard.rs\"))",
            ""
        ],
        "set::Entry::<'a, T, S, A>::get": [
            "get",
            "Real(LocalPath(\"src/set.rs\"))",
            ""
        ],
        "set::Entry::<'a, T, S, A>::insert": [
            "insert",
            "Real(LocalPath(\"src/set.rs\"))",
            ""
        ],
        "set::Entry::<'a, T, S, A>::or_insert": [
            "or_insert",
            "Real(LocalPath(\"src/set.rs\"))",
            ""
        ],
        "set::HashSet::<T, S, A>::allocation_size": [
            "allocation_size",
            "Real(LocalPath(\"src/set.rs\"))",
            ""
        ],
        "set::HashSet::<T, S, A>::allocator": [
            "allocator",
            "Real(LocalPath(\"src/set.rs\"))",
            ""
        ],
        "set::HashSet::<T, S, A>::capacity": [
            "capacity",
            "Real(LocalPath(\"src/set.rs\"))",
            ""
        ],
        "set::HashSet::<T, S, A>::clear": [
            "clear",
            "Real(LocalPath(\"src/set.rs\"))",
            ""
        ],
        "set::HashSet::<T, S, A>::contains": [
            "contains",
            "Real(LocalPath(\"src/set.rs\"))",
            ""
        ],
        "set::HashSet::<T, S, A>::difference": [
            "difference",
            "Real(LocalPath(\"src/set.rs\"))",
            ""
        ],
        "set::HashSet::<T, S, A>::drain": [
            "drain",
            "Real(LocalPath(\"src/set.rs\"))",
            ""
        ],
        "set::HashSet::<T, S, A>::entry": [
            "entry",
            "Real(LocalPath(\"src/set.rs\"))",
            ""
        ],
        "set::HashSet::<T, S, A>::extract_if": [
            "extract_if",
            "Real(LocalPath(\"src/set.rs\"))",
            ""
        ],
        "set::HashSet::<T, S, A>::get": [
            "get",
            "Real(LocalPath(\"src/set.rs\"))",
            ""
        ],
        "set::HashSet::<T, S, A>::get_or_insert": [
            "get_or_insert",
            "Real(LocalPath(\"src/set.rs\"))",
            ""
        ],
        "set::HashSet::<T, S, A>::get_or_insert_with": [
            "get_or_insert_with",
            "Real(LocalPath(\"src/set.rs\"))",
            ""
        ],
        "set::HashSet::<T, S, A>::hasher": [
            "hasher",
            "Real(LocalPath(\"src/set.rs\"))",
            ""
        ],
        "set::HashSet::<T, S, A>::insert": [
            "insert",
            "Real(LocalPath(\"src/set.rs\"))",
            ""
        ],
        "set::HashSet::<T, S, A>::insert_unique_unchecked": [
            "insert_unique_unchecked",
            "Real(LocalPath(\"src/set.rs\"))",
            ""
        ],
        "set::HashSet::<T, S, A>::intersection": [
            "intersection",
            "Real(LocalPath(\"src/set.rs\"))",
            ""
        ],
        "set::HashSet::<T, S, A>::is_disjoint": [
            "is_disjoint",
            "Real(LocalPath(\"src/set.rs\"))",
            ""
        ],
        "set::HashSet::<T, S, A>::is_empty": [
            "is_empty",
            "Real(LocalPath(\"src/set.rs\"))",
            ""
        ],
        "set::HashSet::<T, S, A>::is_subset": [
            "is_subset",
            "Real(LocalPath(\"src/set.rs\"))",
            ""
        ],
        "set::HashSet::<T, S, A>::is_superset": [
            "is_superset",
            "Real(LocalPath(\"src/set.rs\"))",
            ""
        ],
        "set::HashSet::<T, S, A>::iter": [
            "iter",
            "Real(LocalPath(\"src/set.rs\"))",
            ""
        ],
        "set::HashSet::<T, S, A>::len": [
            "len",
            "Real(LocalPath(\"src/set.rs\"))",
            ""
        ],
        "set::HashSet::<T, S, A>::remove": [
            "remove",
            "Real(LocalPath(\"src/set.rs\"))",
            ""
        ],
        "set::HashSet::<T, S, A>::replace": [
            "replace",
            "Real(LocalPath(\"src/set.rs\"))",
            ""
        ],
        "set::HashSet::<T, S, A>::reserve": [
            "reserve",
            "Real(LocalPath(\"src/set.rs\"))",
            ""
        ],
        "set::HashSet::<T, S, A>::retain": [
            "retain",
            "Real(LocalPath(\"src/set.rs\"))",
            ""
        ],
        "set::HashSet::<T, S, A>::shrink_to": [
            "shrink_to",
            "Real(LocalPath(\"src/set.rs\"))",
            ""
        ],
        "set::HashSet::<T, S, A>::shrink_to_fit": [
            "shrink_to_fit",
            "Real(LocalPath(\"src/set.rs\"))",
            ""
        ],
        "set::HashSet::<T, S, A>::symmetric_difference": [
            "symmetric_difference",
            "Real(LocalPath(\"src/set.rs\"))",
            ""
        ],
        "set::HashSet::<T, S, A>::take": [
            "take",
            "Real(LocalPath(\"src/set.rs\"))",
            ""
        ],
        "set::HashSet::<T, S, A>::try_reserve": [
            "try_reserve",
            "Real(LocalPath(\"src/set.rs\"))",
            ""
        ],
        "set::HashSet::<T, S, A>::union": [
            "union",
            "Real(LocalPath(\"src/set.rs\"))",
            ""
        ],
        "set::HashSet::<T, S, A>::with_capacity_and_hasher_in": [
            "with_capacity_and_hasher_in",
            "Real(LocalPath(\"src/set.rs\"))",
            ""
        ],
        "set::HashSet::<T, S, A>::with_hasher_in": [
            "with_hasher_in",
            "Real(LocalPath(\"src/set.rs\"))",
            ""
        ],
        "set::HashSet::<T, S>::with_capacity_and_hasher": [
            "with_capacity_and_hasher",
            "Real(LocalPath(\"src/set.rs\"))",
            ""
        ],
        "set::HashSet::<T, S>::with_hasher": [
            "with_hasher",
            "Real(LocalPath(\"src/set.rs\"))",
            ""
        ],
        "set::HashSet::<T, foldhash::fast::RandomState, A>::new_in": [
            "new_in",
            "Real(LocalPath(\"src/set.rs\"))",
            ""
        ],
        "set::HashSet::<T, foldhash::fast::RandomState, A>::with_capacity_in": [
            "with_capacity_in",
            "Real(LocalPath(\"src/set.rs\"))",
            ""
        ],
        "set::HashSet::<T>::new": [
            "new",
            "Real(LocalPath(\"src/set.rs\"))",
            ""
        ],
        "set::HashSet::<T>::with_capacity": [
            "with_capacity",
            "Real(LocalPath(\"src/set.rs\"))",
            ""
        ],
        "set::OccupiedEntry::<'_, T, S, A>::get": [
            "get",
            "Real(LocalPath(\"src/set.rs\"))",
            ""
        ],
        "set::OccupiedEntry::<'_, T, S, A>::remove": [
            "remove",
            "Real(LocalPath(\"src/set.rs\"))",
            ""
        ],
        "set::VacantEntry::<'a, T, S, A>::get": [
            "get",
            "Real(LocalPath(\"src/set.rs\"))",
            ""
        ],
        "set::VacantEntry::<'a, T, S, A>::insert": [
            "insert",
            "Real(LocalPath(\"src/set.rs\"))",
            ""
        ],
        "set::VacantEntry::<'a, T, S, A>::into_value": [
            "into_value",
            "Real(LocalPath(\"src/set.rs\"))",
            ""
        ],
        "set::assert_covariance": [
            "assert_covariance",
            "Real(LocalPath(\"src/set.rs\"))",
            ""
        ],
        "set::assert_covariance::difference": [
            "difference",
            "Real(LocalPath(\"src/set.rs\"))",
            ""
        ],
        "set::assert_covariance::drain": [
            "drain",
            "Real(LocalPath(\"src/set.rs\"))",
            ""
        ],
        "set::assert_covariance::intersection": [
            "intersection",
            "Real(LocalPath(\"src/set.rs\"))",
            ""
        ],
        "set::assert_covariance::into_iter": [
            "into_iter",
            "Real(LocalPath(\"src/set.rs\"))",
            ""
        ],
        "set::assert_covariance::iter": [
            "iter",
            "Real(LocalPath(\"src/set.rs\"))",
            ""
        ],
        "set::assert_covariance::set": [
            "set",
            "Real(LocalPath(\"src/set.rs\"))",
            ""
        ],
        "set::assert_covariance::symmetric_difference": [
            "symmetric_difference",
            "Real(LocalPath(\"src/set.rs\"))",
            ""
        ],
        "set::assert_covariance::union": [
            "union",
            "Real(LocalPath(\"src/set.rs\"))",
            ""
        ],
        "table::AbsentEntry::<'a, T, A>::into_table": [
            "into_table",
            "Real(LocalPath(\"src/table.rs\"))",
            ""
        ],
        "table::Entry::<'a, T, A>::and_modify": [
            "and_modify",
            "Real(LocalPath(\"src/table.rs\"))",
            ""
        ],
        "table::Entry::<'a, T, A>::insert": [
            "insert",
            "Real(LocalPath(\"src/table.rs\"))",
            ""
        ],
        "table::Entry::<'a, T, A>::or_insert": [
            "or_insert",
            "Real(LocalPath(\"src/table.rs\"))",
            ""
        ],
        "table::Entry::<'a, T, A>::or_insert_with": [
            "or_insert_with",
            "Real(LocalPath(\"src/table.rs\"))",
            ""
        ],
        "table::HashTable::<T, A>::allocation_size": [
            "allocation_size",
            "Real(LocalPath(\"src/table.rs\"))",
            ""
        ],
        "table::HashTable::<T, A>::allocator": [
            "allocator",
            "Real(LocalPath(\"src/table.rs\"))",
            ""
        ],
        "table::HashTable::<T, A>::capacity": [
            "capacity",
            "Real(LocalPath(\"src/table.rs\"))",
            ""
        ],
        "table::HashTable::<T, A>::clear": [
            "clear",
            "Real(LocalPath(\"src/table.rs\"))",
            ""
        ],
        "table::HashTable::<T, A>::drain": [
            "drain",
            "Real(LocalPath(\"src/table.rs\"))",
            ""
        ],
        "table::HashTable::<T, A>::entry": [
            "entry",
            "Real(LocalPath(\"src/table.rs\"))",
            ""
        ],
        "table::HashTable::<T, A>::extract_if": [
            "extract_if",
            "Real(LocalPath(\"src/table.rs\"))",
            ""
        ],
        "table::HashTable::<T, A>::find": [
            "find",
            "Real(LocalPath(\"src/table.rs\"))",
            ""
        ],
        "table::HashTable::<T, A>::find_entry": [
            "find_entry",
            "Real(LocalPath(\"src/table.rs\"))",
            ""
        ],
        "table::HashTable::<T, A>::find_mut": [
            "find_mut",
            "Real(LocalPath(\"src/table.rs\"))",
            ""
        ],
        "table::HashTable::<T, A>::get_many_mut": [
            "get_many_mut",
            "Real(LocalPath(\"src/table.rs\"))",
            ""
        ],
        "table::HashTable::<T, A>::get_many_unchecked_mut": [
            "get_many_unchecked_mut",
            "Real(LocalPath(\"src/table.rs\"))",
            ""
        ],
        "table::HashTable::<T, A>::insert_unique": [
            "insert_unique",
            "Real(LocalPath(\"src/table.rs\"))",
            ""
        ],
        "table::HashTable::<T, A>::is_empty": [
            "is_empty",
            "Real(LocalPath(\"src/table.rs\"))",
            ""
        ],
        "table::HashTable::<T, A>::iter": [
            "iter",
            "Real(LocalPath(\"src/table.rs\"))",
            ""
        ],
        "table::HashTable::<T, A>::iter_hash": [
            "iter_hash",
            "Real(LocalPath(\"src/table.rs\"))",
            ""
        ],
        "table::HashTable::<T, A>::iter_hash_mut": [
            "iter_hash_mut",
            "Real(LocalPath(\"src/table.rs\"))",
            ""
        ],
        "table::HashTable::<T, A>::iter_mut": [
            "iter_mut",
            "Real(LocalPath(\"src/table.rs\"))",
            ""
        ],
        "table::HashTable::<T, A>::len": [
            "len",
            "Real(LocalPath(\"src/table.rs\"))",
            ""
        ],
        "table::HashTable::<T, A>::new_in": [
            "new_in",
            "Real(LocalPath(\"src/table.rs\"))",
            ""
        ],
        "table::HashTable::<T, A>::reserve": [
            "reserve",
            "Real(LocalPath(\"src/table.rs\"))",
            ""
        ],
        "table::HashTable::<T, A>::retain": [
            "retain",
            "Real(LocalPath(\"src/table.rs\"))",
            ""
        ],
        "table::HashTable::<T, A>::shrink_to": [
            "shrink_to",
            "Real(LocalPath(\"src/table.rs\"))",
            ""
        ],
        "table::HashTable::<T, A>::shrink_to_fit": [
            "shrink_to_fit",
            "Real(LocalPath(\"src/table.rs\"))",
            ""
        ],
        "table::HashTable::<T, A>::try_reserve": [
            "try_reserve",
            "Real(LocalPath(\"src/table.rs\"))",
            ""
        ],
        "table::HashTable::<T, A>::with_capacity_in": [
            "with_capacity_in",
            "Real(LocalPath(\"src/table.rs\"))",
            ""
        ],
        "table::HashTable::<T>::new": [
            "new",
            "Real(LocalPath(\"src/table.rs\"))",
            ""
        ],
        "table::HashTable::<T>::with_capacity": [
            "with_capacity",
            "Real(LocalPath(\"src/table.rs\"))",
            ""
        ],
        "table::OccupiedEntry::<'a, T, A>::get": [
            "get",
            "Real(LocalPath(\"src/table.rs\"))",
            ""
        ],
        "table::OccupiedEntry::<'a, T, A>::get_mut": [
            "get_mut",
            "Real(LocalPath(\"src/table.rs\"))",
            ""
        ],
        "table::OccupiedEntry::<'a, T, A>::into_mut": [
            "into_mut",
            "Real(LocalPath(\"src/table.rs\"))",
            ""
        ],
        "table::OccupiedEntry::<'a, T, A>::into_table": [
            "into_table",
            "Real(LocalPath(\"src/table.rs\"))",
            ""
        ],
        "table::OccupiedEntry::<'a, T, A>::remove": [
            "remove",
            "Real(LocalPath(\"src/table.rs\"))",
            ""
        ],
        "table::VacantEntry::<'a, T, A>::insert": [
            "insert",
            "Real(LocalPath(\"src/table.rs\"))",
            ""
        ],
        "table::VacantEntry::<'a, T, A>::into_table": [
            "into_table",
            "Real(LocalPath(\"src/table.rs\"))",
            ""
        ],
        "util::invalid_mut": [
            "invalid_mut",
            "Real(LocalPath(\"src/util.rs\"))",
            ""
        ]
    },
    "trait_to_struct": {
        "core::clone::Clone": [
            "TryReserveError",
            "control::bitmask::BitMask",
            "control::bitmask::BitMaskIter",
            "control::group::sse2::Group",
            "control::tag::Tag",
            "map::HashMap",
            "map::Iter",
            "map::Keys",
            "map::Values",
            "raw::Bucket",
            "raw::Fallibility",
            "raw::ProbeSeq",
            "raw::RawIter",
            "raw::RawIterHash",
            "raw::RawIterHashInner",
            "raw::RawIterRange",
            "raw::RawTable",
            "raw::TableLayout",
            "set::Difference",
            "set::HashSet",
            "set::Intersection",
            "set::Iter",
            "set::SymmetricDifference",
            "set::Union",
            "table::HashTable",
            "table::Iter",
            "table::IterHash"
        ],
        "core::cmp::Eq": [
            "TryReserveError",
            "control::tag::Tag",
            "map::HashMap",
            "set::HashSet"
        ],
        "core::cmp::PartialEq": [
            "TryReserveError",
            "control::tag::Tag",
            "map::HashMap",
            "set::HashSet"
        ],
        "core::convert::From": [
            "map::HashMap",
            "set::HashSet"
        ],
        "core::default::Default": [
            "map::HashMap",
            "map::IntoIter",
            "map::IntoKeys",
            "map::IntoValues",
            "map::Iter",
            "map::IterMut",
            "map::Keys",
            "map::Values",
            "map::ValuesMut",
            "raw::RawIntoIter",
            "raw::RawIter",
            "raw::RawIterHash",
            "raw::RawTable",
            "set::HashSet",
            "set::IntoIter",
            "set::Iter",
            "table::HashTable",
            "table::IntoIter",
            "table::Iter",
            "table::IterHash",
            "table::IterHashMut",
            "table::IterMut"
        ],
        "core::fmt::Debug": [
            "TryReserveError",
            "control::tag::Tag",
            "map::Drain",
            "map::Entry",
            "map::EntryRef",
            "map::HashMap",
            "map::IntoIter",
            "map::IntoKeys",
            "map::IntoValues",
            "map::Iter",
            "map::IterMut",
            "map::Keys",
            "map::OccupiedEntry",
            "map::OccupiedError",
            "map::VacantEntry",
            "map::VacantEntryRef",
            "map::Values",
            "map::ValuesMut",
            "raw_entry::RawEntryBuilder",
            "raw_entry::RawEntryBuilderMut",
            "raw_entry::RawEntryMut",
            "raw_entry::RawOccupiedEntryMut",
            "raw_entry::RawVacantEntryMut",
            "set::Difference",
            "set::Drain",
            "set::Entry",
            "set::HashSet",
            "set::Intersection",
            "set::IntoIter",
            "set::Iter",
            "set::OccupiedEntry",
            "set::SymmetricDifference",
            "set::Union",
            "set::VacantEntry",
            "table::AbsentEntry",
            "table::Drain",
            "table::Entry",
            "table::HashTable",
            "table::IntoIter",
            "table::Iter",
            "table::IterHash",
            "table::IterHashMut",
            "table::IterMut",
            "table::OccupiedEntry",
            "table::VacantEntry"
        ],
        "core::fmt::Display": [
            "map::OccupiedError"
        ],
        "core::iter::ExactSizeIterator": [
            "map::Drain",
            "map::IntoIter",
            "map::IntoKeys",
            "map::IntoValues",
            "map::Iter",
            "map::IterMut",
            "map::Keys",
            "map::Values",
            "map::ValuesMut",
            "raw::FullBucketsIndices",
            "raw::RawDrain",
            "raw::RawIntoIter",
            "raw::RawIter",
            "set::Drain",
            "set::IntoIter",
            "set::Iter",
            "table::Drain",
            "table::IntoIter",
            "table::Iter",
            "table::IterMut"
        ],
        "core::iter::Extend": [
            "map::HashMap",
            "set::HashSet"
        ],
        "core::iter::FromIterator": [
            "map::HashMap",
            "set::HashSet"
        ],
        "core::iter::FusedIterator": [
            "map::Drain",
            "map::ExtractIf",
            "map::IntoIter",
            "map::IntoKeys",
            "map::IntoValues",
            "map::Iter",
            "map::IterMut",
            "map::Keys",
            "map::Values",
            "map::ValuesMut",
            "raw::FullBucketsIndices",
            "raw::RawDrain",
            "raw::RawIntoIter",
            "raw::RawIter",
            "raw::RawIterRange",
            "set::Difference",
            "set::Drain",
            "set::ExtractIf",
            "set::Intersection",
            "set::IntoIter",
            "set::Iter",
            "set::SymmetricDifference",
            "set::Union",
            "table::Drain",
            "table::ExtractIf",
            "table::IntoIter",
            "table::Iter",
            "table::IterHash",
            "table::IterHashMut",
            "table::IterMut"
        ],
        "core::iter::IntoIterator": [
            "control::bitmask::BitMask",
            "map::HashMap",
            "raw::RawTable",
            "set::HashSet",
            "table::HashTable"
        ],
        "core::iter::Iterator": [
            "control::bitmask::BitMaskIter",
            "map::Drain",
            "map::ExtractIf",
            "map::IntoIter",
            "map::IntoKeys",
            "map::IntoValues",
            "map::Iter",
            "map::IterMut",
            "map::Keys",
            "map::Values",
            "map::ValuesMut",
            "raw::FullBucketsIndices",
            "raw::RawDrain",
            "raw::RawIntoIter",
            "raw::RawIter",
            "raw::RawIterHash",
            "raw::RawIterHashInner",
            "raw::RawIterRange",
            "set::Difference",
            "set::Drain",
            "set::ExtractIf",
            "set::Intersection",
            "set::IntoIter",
            "set::Iter",
            "set::SymmetricDifference",
            "set::Union",
            "table::Drain",
            "table::ExtractIf",
            "table::IntoIter",
            "table::Iter",
            "table::IterHash",
            "table::IterHashMut",
            "table::IterMut"
        ],
        "core::marker::Copy": [
            "control::bitmask::BitMask",
            "control::group::sse2::Group",
            "control::tag::Tag",
            "raw::Fallibility",
            "raw::TableLayout"
        ],
        "core::marker::Send": [
            "map::IterMut",
            "map::OccupiedEntry",
            "raw::Bucket",
            "raw::RawDrain",
            "raw::RawIntoIter",
            "raw::RawIterRange",
            "raw::RawTable",
            "raw_entry::RawOccupiedEntryMut",
            "table::OccupiedEntry"
        ],
        "core::marker::StructuralPartialEq": [
            "TryReserveError",
            "control::tag::Tag"
        ],
        "core::marker::Sync": [
            "map::OccupiedEntry",
            "raw::RawDrain",
            "raw::RawIntoIter",
            "raw::RawIterRange",
            "raw::RawTable",
            "raw_entry::RawOccupiedEntryMut",
            "table::OccupiedEntry"
        ],
        "core::ops::BitAndAssign": [
            "set::HashSet"
        ],
        "core::ops::BitOrAssign": [
            "set::HashSet"
        ],
        "core::ops::BitXorAssign": [
            "set::HashSet"
        ],
        "core::ops::Deref": [
            "scopeguard::ScopeGuard"
        ],
        "core::ops::DerefMut": [
            "scopeguard::ScopeGuard"
        ],
        "core::ops::Drop": [
            "raw::RawDrain",
            "raw::RawIntoIter",
            "raw::RawTable",
            "scopeguard::ScopeGuard"
        ],
        "core::ops::Index": [
            "map::HashMap"
        ],
        "core::ops::SubAssign": [
            "set::HashSet"
        ],
        "raw::RawTableClone": [
            "raw::RawTable"
        ],
        "raw::SizedTypeProperties": [
            "<T as raw::SizedTypeProperties>::T"
        ]
    },
    "type_to_def_path": {
        "TryReserveError": "TryReserveError",
        "control::bitmask::BitMask": "control::bitmask::BitMask",
        "control::bitmask::BitMaskIter": "control::bitmask::BitMaskIter",
        "control::group::sse2::Group": "control::group::sse2::Group",
        "control::group::sse2::Group::static_empty::AlignedTags": "control::group::sse2::Group::static_empty::AlignedTags",
        "control::tag::Tag": "control::tag::Tag",
        "map::Drain<'a, K, V, A>": "map::Drain",
        "map::Entry<'a, K, V, S, A>": "map::Entry",
        "map::EntryRef<'a, 'b, K, Q, V, S, A>": "map::EntryRef",
        "map::ExtractIf<'a, K, V, F, A>": "map::ExtractIf",
        "map::HashMap<K, V, S, A>": "map::HashMap",
        "map::IntoIter<K, V, A>": "map::IntoIter",
        "map::IntoKeys<K, V, A>": "map::IntoKeys",
        "map::IntoValues<K, V, A>": "map::IntoValues",
        "map::Iter<'a, K, V>": "map::Iter",
        "map::IterMut<'a, K, V>": "map::IterMut",
        "map::Keys<'a, K, V>": "map::Keys",
        "map::OccupiedEntry<'a, K, V, S, A>": "map::OccupiedEntry",
        "map::OccupiedError<'a, K, V, S, A>": "map::OccupiedError",
        "map::VacantEntry<'a, K, V, S, A>": "map::VacantEntry",
        "map::VacantEntryRef<'a, 'b, K, Q, V, S, A>": "map::VacantEntryRef",
        "map::Values<'a, K, V>": "map::Values",
        "map::ValuesMut<'a, K, V>": "map::ValuesMut",
        "raw::Bucket<T>": "raw::Bucket",
        "raw::Fallibility": "raw::Fallibility",
        "raw::FullBucketsIndices": "raw::FullBucketsIndices",
        "raw::InsertSlot": "raw::InsertSlot",
        "raw::ProbeSeq": "raw::ProbeSeq",
        "raw::RawDrain<'a, T, A>": "raw::RawDrain",
        "raw::RawExtractIf<'a, T, A>": "raw::RawExtractIf",
        "raw::RawIntoIter<T, A>": "raw::RawIntoIter",
        "raw::RawIter<T>": "raw::RawIter",
        "raw::RawIterHash<T>": "raw::RawIterHash",
        "raw::RawIterHashInner": "raw::RawIterHashInner",
        "raw::RawIterRange<T>": "raw::RawIterRange",
        "raw::RawTable<T, A>": "raw::RawTable",
        "raw::RawTableInner": "raw::RawTableInner",
        "raw::TableLayout": "raw::TableLayout",
        "raw_entry::RawEntryBuilder<'a, K, V, S, A>": "raw_entry::RawEntryBuilder",
        "raw_entry::RawEntryBuilderMut<'a, K, V, S, A>": "raw_entry::RawEntryBuilderMut",
        "raw_entry::RawEntryMut<'a, K, V, S, A>": "raw_entry::RawEntryMut",
        "raw_entry::RawOccupiedEntryMut<'a, K, V, S, A>": "raw_entry::RawOccupiedEntryMut",
        "raw_entry::RawVacantEntryMut<'a, K, V, S, A>": "raw_entry::RawVacantEntryMut",
        "scopeguard::ScopeGuard<T, F>": "scopeguard::ScopeGuard",
        "set::Difference<'a, T, S, A>": "set::Difference",
        "set::Drain<'a, K, A>": "set::Drain",
        "set::Entry<'a, T, S, A>": "set::Entry",
        "set::ExtractIf<'a, K, F, A>": "set::ExtractIf",
        "set::HashSet<T, S, A>": "set::HashSet",
        "set::Intersection<'a, T, S, A>": "set::Intersection",
        "set::IntoIter<K, A>": "set::IntoIter",
        "set::Iter<'a, K>": "set::Iter",
        "set::OccupiedEntry<'a, T, S, A>": "set::OccupiedEntry",
        "set::SymmetricDifference<'a, T, S, A>": "set::SymmetricDifference",
        "set::Union<'a, T, S, A>": "set::Union",
        "set::VacantEntry<'a, T, S, A>": "set::VacantEntry",
        "table::AbsentEntry<'a, T, A>": "table::AbsentEntry",
        "table::Drain<'a, T, A>": "table::Drain",
        "table::Entry<'a, T, A>": "table::Entry",
        "table::ExtractIf<'a, T, F, A>": "table::ExtractIf",
        "table::HashTable<T, A>": "table::HashTable",
        "table::IntoIter<T, A>": "table::IntoIter",
        "table::Iter<'a, T>": "table::Iter",
        "table::IterHash<'a, T>": "table::IterHash",
        "table::IterHashMut<'a, T>": "table::IterHashMut",
        "table::IterMut<'a, T>": "table::IterMut",
        "table::OccupiedEntry<'a, T, A>": "table::OccupiedEntry",
        "table::VacantEntry<'a, T, A>": "table::VacantEntry"
    }
}