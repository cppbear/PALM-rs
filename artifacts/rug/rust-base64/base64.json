{"dependencies":{"<&mut S as write::encoder_string_writer::StrConsumer>::consume":[],"<alphabet::Alphabet as std::clone::Clone>::clone":["alphabet::Alphabet"],"<alphabet::Alphabet as std::cmp::Eq>::assert_receiver_is_total_eq":["alphabet::Alphabet"],"<alphabet::Alphabet as std::cmp::PartialEq>::eq":["alphabet::Alphabet"],"<alphabet::Alphabet as std::convert::TryFrom<&str>>::try_from":["std::marker::Sized","std::result::Result"],"<alphabet::Alphabet as std::fmt::Debug>::fmt":["alphabet::Alphabet","std::fmt::Formatter","std::marker::Sized","std::result::Result"],"<alphabet::ParseAlphabetError as std::cmp::Eq>::assert_receiver_is_total_eq":["alphabet::ParseAlphabetError"],"<alphabet::ParseAlphabetError as std::cmp::PartialEq>::eq":["alphabet::ParseAlphabetError"],"<alphabet::ParseAlphabetError as std::fmt::Debug>::fmt":["alphabet::ParseAlphabetError","std::fmt::Formatter","std::marker::Sized","std::result::Result"],"<alphabet::ParseAlphabetError as std::fmt::Display>::fmt":["alphabet::ParseAlphabetError","std::fmt::Formatter","std::marker::Sized","std::result::Result"],"<chunked_encoder::StringSink<'a> as chunked_encoder::Sink>::write_encoded_bytes":["chunked_encoder::StringSink","std::marker::Sized","std::result::Result","std::string::String"],"<decode::DecodeError as std::clone::Clone>::clone":["decode::DecodeError"],"<decode::DecodeError as std::cmp::Eq>::assert_receiver_is_total_eq":["decode::DecodeError"],"<decode::DecodeError as std::cmp::PartialEq>::eq":["decode::DecodeError"],"<decode::DecodeError as std::fmt::Debug>::fmt":["decode::DecodeError","std::fmt::Formatter","std::marker::Sized","std::result::Result"],"<decode::DecodeError as std::fmt::Display>::fmt":["decode::DecodeError","std::fmt::Formatter","std::marker::Sized","std::result::Result"],"<decode::DecodeSliceError as std::clone::Clone>::clone":["decode::DecodeError","decode::DecodeSliceError"],"<decode::DecodeSliceError as std::cmp::Eq>::assert_receiver_is_total_eq":["decode::DecodeError","decode::DecodeSliceError"],"<decode::DecodeSliceError as std::cmp::PartialEq>::eq":["decode::DecodeError","decode::DecodeSliceError"],"<decode::DecodeSliceError as std::convert::From<decode::DecodeError>>::from":["decode::DecodeError","decode::DecodeSliceError"],"<decode::DecodeSliceError as std::error::Error>::source":["decode::DecodeError","decode::DecodeSliceError","std::marker::Sized","std::option::Option"],"<decode::DecodeSliceError as std::fmt::Debug>::fmt":["decode::DecodeError","decode::DecodeSliceError","std::fmt::Formatter","std::marker::Sized","std::result::Result"],"<decode::DecodeSliceError as std::fmt::Display>::fmt":["decode::DecodeError","decode::DecodeSliceError","std::fmt::Formatter","std::marker::Sized","std::result::Result"],"<display::Base64Display<'a, 'e, E> as std::fmt::Display>::fmt":["chunked_encoder::ChunkedEncoder","display::Base64Display","engine::DecodePaddingMode","engine::Engine","engine::general_purpose::GeneralPurpose","engine::general_purpose::GeneralPurposeConfig","std::fmt::Formatter","std::marker::Send","std::marker::Sized","std::marker::Sync","std::result::Result"],"<display::FormatterSink<'a, 'b> as chunked_encoder::Sink>::write_encoded_bytes":["display::FormatterSink","std::fmt::Formatter","std::marker::Sized","std::result::Result"],"<encode::EncodeSliceError as std::clone::Clone>::clone":["encode::EncodeSliceError"],"<encode::EncodeSliceError as std::cmp::Eq>::assert_receiver_is_total_eq":["encode::EncodeSliceError"],"<encode::EncodeSliceError as std::cmp::PartialEq>::eq":["encode::EncodeSliceError"],"<encode::EncodeSliceError as std::fmt::Debug>::fmt":["encode::EncodeSliceError","std::fmt::Formatter","std::marker::Sized","std::result::Result"],"<encode::EncodeSliceError as std::fmt::Display>::fmt":["encode::EncodeSliceError","std::fmt::Formatter","std::marker::Sized","std::result::Result"],"<engine::DecodeMetadata as std::cmp::Eq>::assert_receiver_is_total_eq":["engine::DecodeMetadata","std::marker::Sized","std::option::Option"],"<engine::DecodeMetadata as std::cmp::PartialEq>::eq":["engine::DecodeMetadata","std::marker::Sized","std::option::Option"],"<engine::DecodeMetadata as std::fmt::Debug>::fmt":["engine::DecodeMetadata","std::fmt::Formatter","std::marker::Sized","std::option::Option","std::result::Result"],"<engine::DecodePaddingMode as std::clone::Clone>::clone":["engine::DecodePaddingMode"],"<engine::DecodePaddingMode as std::cmp::Eq>::assert_receiver_is_total_eq":["engine::DecodePaddingMode"],"<engine::DecodePaddingMode as std::cmp::PartialEq>::eq":["engine::DecodePaddingMode"],"<engine::DecodePaddingMode as std::fmt::Debug>::fmt":["engine::DecodePaddingMode","std::fmt::Formatter","std::marker::Sized","std::result::Result"],"<engine::general_purpose::GeneralPurpose as engine::Engine>::config":["engine::DecodePaddingMode","engine::general_purpose::GeneralPurpose","engine::general_purpose::GeneralPurposeConfig"],"<engine::general_purpose::GeneralPurpose as engine::Engine>::internal_decode":["engine::DecodePaddingMode","engine::general_purpose::GeneralPurpose","engine::general_purpose::GeneralPurposeConfig","std::marker::Sized","std::result::Result"],"<engine::general_purpose::GeneralPurpose as engine::Engine>::internal_decoded_len_estimate":["engine::DecodePaddingMode","engine::general_purpose::GeneralPurpose","engine::general_purpose::GeneralPurposeConfig"],"<engine::general_purpose::GeneralPurpose as engine::Engine>::internal_encode":["engine::DecodePaddingMode","engine::general_purpose::GeneralPurpose","engine::general_purpose::GeneralPurposeConfig"],"<engine::general_purpose::GeneralPurpose as std::clone::Clone>::clone":["engine::DecodePaddingMode","engine::general_purpose::GeneralPurpose","engine::general_purpose::GeneralPurposeConfig"],"<engine::general_purpose::GeneralPurpose as std::fmt::Debug>::fmt":["engine::DecodePaddingMode","engine::general_purpose::GeneralPurpose","engine::general_purpose::GeneralPurposeConfig","std::fmt::Formatter","std::marker::Sized","std::result::Result"],"<engine::general_purpose::GeneralPurposeConfig as engine::Config>::encode_padding":["engine::DecodePaddingMode","engine::general_purpose::GeneralPurposeConfig"],"<engine::general_purpose::GeneralPurposeConfig as std::clone::Clone>::clone":["engine::DecodePaddingMode","engine::general_purpose::GeneralPurposeConfig"],"<engine::general_purpose::GeneralPurposeConfig as std::default::Default>::default":["engine::DecodePaddingMode","engine::general_purpose::GeneralPurposeConfig"],"<engine::general_purpose::GeneralPurposeConfig as std::fmt::Debug>::fmt":["engine::DecodePaddingMode","engine::general_purpose::GeneralPurposeConfig","std::fmt::Formatter","std::marker::Sized","std::result::Result"],"<engine::general_purpose::decode::GeneralPurposeEstimate as engine::DecodeEstimate>::decoded_len_estimate":["engine::general_purpose::decode::GeneralPurposeEstimate"],"<read::decoder::DecoderReader<'e, E, R> as std::fmt::Debug>::fmt":["engine::DecodePaddingMode","engine::Engine","engine::general_purpose::GeneralPurpose","engine::general_purpose::GeneralPurposeConfig","read::decoder::DecoderReader","std::fmt::Formatter","std::io::Read","std::marker::Send","std::marker::Sized","std::marker::Sync","std::option::Option","std::result::Result"],"<read::decoder::DecoderReader<'e, E, R> as std::io::Read>::read":["engine::DecodePaddingMode","engine::Engine","engine::general_purpose::GeneralPurpose","engine::general_purpose::GeneralPurposeConfig","read::decoder::DecoderReader","std::io::Read","std::marker::Send","std::marker::Sized","std::marker::Sync","std::option::Option","std::result::Result"],"<std::string::String as write::encoder_string_writer::StrConsumer>::consume":["std::string::String"],"<write::encoder::EncoderWriter<'e, E, W> as std::fmt::Debug>::fmt":["engine::DecodePaddingMode","engine::Engine","engine::general_purpose::GeneralPurpose","engine::general_purpose::GeneralPurposeConfig","std::fmt::Formatter","std::io::Write","std::marker::Send","std::marker::Sized","std::marker::Sync","std::option::Option","std::result::Result","write::encoder::EncoderWriter"],"<write::encoder::EncoderWriter<'e, E, W> as std::io::Write>::flush":["engine::DecodePaddingMode","engine::Engine","engine::general_purpose::GeneralPurpose","engine::general_purpose::GeneralPurposeConfig","std::io::Write","std::marker::Send","std::marker::Sized","std::marker::Sync","std::option::Option","std::result::Result","write::encoder::EncoderWriter"],"<write::encoder::EncoderWriter<'e, E, W> as std::io::Write>::write":["engine::DecodePaddingMode","engine::Engine","engine::general_purpose::GeneralPurpose","engine::general_purpose::GeneralPurposeConfig","std::io::Write","std::marker::Send","std::marker::Sized","std::marker::Sync","std::option::Option","std::result::Result","write::encoder::EncoderWriter"],"<write::encoder::EncoderWriter<'e, E, W> as std::ops::Drop>::drop":["engine::DecodePaddingMode","engine::Engine","engine::general_purpose::GeneralPurpose","engine::general_purpose::GeneralPurposeConfig","std::io::Write","std::marker::Send","std::marker::Sized","std::marker::Sync","std::option::Option","write::encoder::EncoderWriter"],"<write::encoder_string_writer::EncoderStringWriter<'e, E, S> as std::io::Write>::flush":["engine::DecodePaddingMode","engine::Engine","engine::general_purpose::GeneralPurpose","engine::general_purpose::GeneralPurposeConfig","std::io::Write","std::marker::Send","std::marker::Sized","std::marker::Sync","std::option::Option","std::result::Result","std::string::String","write::encoder::EncoderWriter","write::encoder_string_writer::EncoderStringWriter","write::encoder_string_writer::StrConsumer"],"<write::encoder_string_writer::EncoderStringWriter<'e, E, S> as std::io::Write>::write":["engine::DecodePaddingMode","engine::Engine","engine::general_purpose::GeneralPurpose","engine::general_purpose::GeneralPurposeConfig","std::io::Write","std::marker::Send","std::marker::Sized","std::marker::Sync","std::option::Option","std::result::Result","std::string::String","write::encoder::EncoderWriter","write::encoder_string_writer::EncoderStringWriter","write::encoder_string_writer::StrConsumer"],"<write::encoder_string_writer::Utf8SingleCodeUnitWriter<S> as std::io::Write>::flush":["std::marker::Sized","std::result::Result","std::string::String","write::encoder_string_writer::StrConsumer","write::encoder_string_writer::Utf8SingleCodeUnitWriter"],"<write::encoder_string_writer::Utf8SingleCodeUnitWriter<S> as std::io::Write>::write":["std::marker::Sized","std::result::Result","std::string::String","write::encoder_string_writer::StrConsumer","write::encoder_string_writer::Utf8SingleCodeUnitWriter"],"alphabet::Alphabet":["alphabet::Alphabet"],"alphabet::Alphabet::as_str":["alphabet::Alphabet"],"alphabet::Alphabet::from_str_unchecked":["alphabet::Alphabet"],"alphabet::Alphabet::new":["std::marker::Sized","std::result::Result"],"alphabet::ParseAlphabetError":["alphabet::ParseAlphabetError"],"chunked_encoder::ChunkedEncoder":["chunked_encoder::ChunkedEncoder","engine::DecodePaddingMode","engine::Engine","engine::general_purpose::GeneralPurpose","engine::general_purpose::GeneralPurposeConfig","std::marker::Send","std::marker::Sync"],"chunked_encoder::ChunkedEncoder::<'e, E>::encode":["chunked_encoder::ChunkedEncoder","chunked_encoder::Sink","chunked_encoder::StringSink","engine::DecodePaddingMode","engine::Engine","engine::general_purpose::GeneralPurpose","engine::general_purpose::GeneralPurposeConfig","std::marker::Send","std::marker::Sized","std::marker::Sync","std::result::Result","std::string::String"],"chunked_encoder::ChunkedEncoder::<'e, E>::new":["chunked_encoder::ChunkedEncoder","engine::DecodePaddingMode","engine::Engine","engine::general_purpose::GeneralPurpose","engine::general_purpose::GeneralPurposeConfig","std::marker::Send","std::marker::Sync"],"chunked_encoder::Sink::write_encoded_bytes":["std::marker::Sized","std::result::Result"],"chunked_encoder::StringSink":["chunked_encoder::StringSink","std::string::String"],"chunked_encoder::StringSink::<'a>::new":["chunked_encoder::StringSink","std::string::String"],"decode::DecodeError":["decode::DecodeError"],"decode::DecodeSliceError":["decode::DecodeError","decode::DecodeSliceError"],"decode::decode":["std::convert::AsRef","std::marker::Sized","std::result::Result"],"decode::decode_engine":["engine::DecodePaddingMode","engine::Engine","engine::general_purpose::GeneralPurpose","engine::general_purpose::GeneralPurposeConfig","std::convert::AsRef","std::marker::Sized","std::result::Result"],"decode::decode_engine_slice":["engine::DecodePaddingMode","engine::Engine","engine::general_purpose::GeneralPurpose","engine::general_purpose::GeneralPurposeConfig","std::convert::AsRef","std::marker::Sized","std::result::Result"],"decode::decode_engine_vec":["engine::DecodePaddingMode","engine::Engine","engine::general_purpose::GeneralPurpose","engine::general_purpose::GeneralPurposeConfig","std::alloc::Allocator","std::convert::AsRef","std::marker::Sized","std::result::Result","std::vec::Vec"],"decode::decoded_len_estimate":[],"display::Base64Display":["chunked_encoder::ChunkedEncoder","display::Base64Display","engine::DecodePaddingMode","engine::Engine","engine::general_purpose::GeneralPurpose","engine::general_purpose::GeneralPurposeConfig","std::marker::Send","std::marker::Sized","std::marker::Sync"],"display::Base64Display::<'a, 'e, E>::new":["chunked_encoder::ChunkedEncoder","display::Base64Display","engine::DecodePaddingMode","engine::Engine","engine::general_purpose::GeneralPurpose","engine::general_purpose::GeneralPurposeConfig","std::marker::Send","std::marker::Sized","std::marker::Sync"],"display::FormatterSink":["display::FormatterSink","std::fmt::Formatter"],"encode::EncodeSliceError":["encode::EncodeSliceError"],"encode::add_padding":[],"encode::encode":["std::convert::AsRef","std::marker::Sized","std::string::String"],"encode::encode_engine":["engine::DecodePaddingMode","engine::Engine","engine::general_purpose::GeneralPurpose","engine::general_purpose::GeneralPurposeConfig","std::convert::AsRef","std::marker::Sized","std::string::String"],"encode::encode_engine_slice":["engine::DecodePaddingMode","engine::Engine","engine::general_purpose::GeneralPurpose","engine::general_purpose::GeneralPurposeConfig","std::convert::AsRef","std::marker::Sized","std::result::Result"],"encode::encode_engine_string":["engine::DecodePaddingMode","engine::Engine","engine::general_purpose::GeneralPurpose","engine::general_purpose::GeneralPurposeConfig","std::convert::AsRef","std::marker::Sized","std::string::String"],"encode::encode_with_padding":["engine::DecodePaddingMode","engine::Engine","engine::general_purpose::GeneralPurpose","engine::general_purpose::GeneralPurposeConfig"],"encode::encoded_len":["std::marker::Sized","std::option::Option"],"engine::Config::encode_padding":[],"engine::DecodeEstimate::decoded_len_estimate":[],"engine::DecodeMetadata":["engine::DecodeMetadata","std::marker::Sized","std::option::Option"],"engine::DecodeMetadata::new":["engine::DecodeMetadata","std::marker::Sized","std::option::Option"],"engine::DecodePaddingMode":["engine::DecodePaddingMode"],"engine::Engine::config":[],"engine::Engine::decode":["std::convert::AsRef","std::marker::Sized","std::result::Result"],"engine::Engine::decode::inner":["engine::DecodePaddingMode","engine::Engine","engine::general_purpose::GeneralPurpose","engine::general_purpose::GeneralPurposeConfig","std::marker::Sized","std::result::Result"],"engine::Engine::decode_slice":["std::convert::AsRef","std::marker::Sized","std::result::Result"],"engine::Engine::decode_slice::inner":["engine::DecodePaddingMode","engine::Engine","engine::general_purpose::GeneralPurpose","engine::general_purpose::GeneralPurposeConfig","std::marker::Sized","std::result::Result"],"engine::Engine::decode_slice_unchecked":["std::convert::AsRef","std::marker::Sized","std::result::Result"],"engine::Engine::decode_slice_unchecked::inner":["engine::DecodePaddingMode","engine::Engine","engine::general_purpose::GeneralPurpose","engine::general_purpose::GeneralPurposeConfig","std::marker::Sized","std::result::Result"],"engine::Engine::decode_vec":["std::alloc::Allocator","std::convert::AsRef","std::marker::Sized","std::result::Result","std::vec::Vec"],"engine::Engine::decode_vec::inner":["engine::DecodePaddingMode","engine::Engine","engine::general_purpose::GeneralPurpose","engine::general_purpose::GeneralPurposeConfig","std::alloc::Allocator","std::marker::Sized","std::result::Result","std::vec::Vec"],"engine::Engine::encode":["std::convert::AsRef","std::marker::Sized","std::string::String"],"engine::Engine::encode::inner":["engine::DecodePaddingMode","engine::Engine","engine::general_purpose::GeneralPurpose","engine::general_purpose::GeneralPurposeConfig","std::string::String"],"engine::Engine::encode_slice":["std::convert::AsRef","std::marker::Sized","std::result::Result"],"engine::Engine::encode_slice::inner":["engine::DecodePaddingMode","engine::Engine","engine::general_purpose::GeneralPurpose","engine::general_purpose::GeneralPurposeConfig","std::marker::Sized","std::result::Result"],"engine::Engine::encode_string":["std::convert::AsRef","std::marker::Sized","std::string::String"],"engine::Engine::encode_string::inner":["engine::DecodePaddingMode","engine::Engine","engine::general_purpose::GeneralPurpose","engine::general_purpose::GeneralPurposeConfig","std::string::String"],"engine::Engine::internal_decode":["std::marker::Sized","std::result::Result"],"engine::Engine::internal_decoded_len_estimate":[],"engine::Engine::internal_encode":[],"engine::general_purpose::GeneralPurpose":["engine::DecodePaddingMode","engine::general_purpose::GeneralPurpose","engine::general_purpose::GeneralPurposeConfig"],"engine::general_purpose::GeneralPurpose::new":["alphabet::Alphabet","engine::DecodePaddingMode","engine::general_purpose::GeneralPurpose","engine::general_purpose::GeneralPurposeConfig"],"engine::general_purpose::GeneralPurposeConfig":["engine::DecodePaddingMode","engine::general_purpose::GeneralPurposeConfig"],"engine::general_purpose::GeneralPurposeConfig::new":["engine::DecodePaddingMode","engine::general_purpose::GeneralPurposeConfig"],"engine::general_purpose::GeneralPurposeConfig::with_decode_allow_trailing_bits":["engine::DecodePaddingMode","engine::general_purpose::GeneralPurposeConfig"],"engine::general_purpose::GeneralPurposeConfig::with_decode_padding_mode":["engine::DecodePaddingMode","engine::general_purpose::GeneralPurposeConfig"],"engine::general_purpose::GeneralPurposeConfig::with_encode_padding":["engine::DecodePaddingMode","engine::general_purpose::GeneralPurposeConfig"],"engine::general_purpose::decode::GeneralPurposeEstimate":["engine::general_purpose::decode::GeneralPurposeEstimate"],"engine::general_purpose::decode::GeneralPurposeEstimate::new":["engine::general_purpose::decode::GeneralPurposeEstimate"],"engine::general_purpose::decode::complete_quads_len":["std::marker::Sized","std::result::Result"],"engine::general_purpose::decode::decode_chunk_4":["std::marker::Sized","std::result::Result"],"engine::general_purpose::decode::decode_chunk_8":["std::marker::Sized","std::result::Result"],"engine::general_purpose::decode::decode_helper":["engine::DecodePaddingMode","engine::general_purpose::decode::GeneralPurposeEstimate","std::marker::Sized","std::result::Result"],"engine::general_purpose::decode_suffix::decode_suffix":["engine::DecodePaddingMode","std::marker::Sized","std::result::Result"],"engine::general_purpose::decode_table":["alphabet::Alphabet"],"engine::general_purpose::encode_table":["alphabet::Alphabet"],"engine::general_purpose::read_u64":[],"read::decoder::DecoderReader":["engine::DecodePaddingMode","engine::Engine","engine::general_purpose::GeneralPurpose","engine::general_purpose::GeneralPurposeConfig","read::decoder::DecoderReader","std::io::Read","std::marker::Send","std::marker::Sized","std::marker::Sync","std::option::Option"],"read::decoder::DecoderReader::<'e, E, R>::decode_to_buf":["engine::DecodePaddingMode","engine::Engine","engine::general_purpose::GeneralPurpose","engine::general_purpose::GeneralPurposeConfig","read::decoder::DecoderReader","std::io::Read","std::marker::Send","std::marker::Sized","std::marker::Sync","std::option::Option","std::result::Result"],"read::decoder::DecoderReader::<'e, E, R>::flush_decoded_buf":["engine::DecodePaddingMode","engine::Engine","engine::general_purpose::GeneralPurpose","engine::general_purpose::GeneralPurposeConfig","read::decoder::DecoderReader","std::io::Read","std::marker::Send","std::marker::Sized","std::marker::Sync","std::option::Option","std::result::Result"],"read::decoder::DecoderReader::<'e, E, R>::into_inner":["engine::DecodePaddingMode","engine::Engine","engine::general_purpose::GeneralPurpose","engine::general_purpose::GeneralPurposeConfig","read::decoder::DecoderReader","std::io::Read","std::marker::Send","std::marker::Sized","std::marker::Sync","std::option::Option"],"read::decoder::DecoderReader::<'e, E, R>::new":["engine::DecodePaddingMode","engine::Engine","engine::general_purpose::GeneralPurpose","engine::general_purpose::GeneralPurposeConfig","read::decoder::DecoderReader","std::io::Read","std::marker::Send","std::marker::Sized","std::marker::Sync","std::option::Option"],"read::decoder::DecoderReader::<'e, E, R>::read_from_delegate":["engine::DecodePaddingMode","engine::Engine","engine::general_purpose::GeneralPurpose","engine::general_purpose::GeneralPurposeConfig","read::decoder::DecoderReader","std::io::Read","std::marker::Send","std::marker::Sized","std::marker::Sync","std::option::Option","std::result::Result"],"write::encoder::EncoderWriter":["engine::DecodePaddingMode","engine::Engine","engine::general_purpose::GeneralPurpose","engine::general_purpose::GeneralPurposeConfig","std::io::Write","std::marker::Send","std::marker::Sized","std::marker::Sync","std::option::Option","write::encoder::EncoderWriter"],"write::encoder::EncoderWriter::<'e, E, W>::finish":["engine::DecodePaddingMode","engine::Engine","engine::general_purpose::GeneralPurpose","engine::general_purpose::GeneralPurposeConfig","std::io::Write","std::marker::Send","std::marker::Sized","std::marker::Sync","std::option::Option","std::result::Result","write::encoder::EncoderWriter"],"write::encoder::EncoderWriter::<'e, E, W>::into_inner":["engine::DecodePaddingMode","engine::Engine","engine::general_purpose::GeneralPurpose","engine::general_purpose::GeneralPurposeConfig","std::io::Write","std::marker::Send","std::marker::Sized","std::marker::Sync","std::option::Option","write::encoder::EncoderWriter"],"write::encoder::EncoderWriter::<'e, E, W>::new":["engine::DecodePaddingMode","engine::Engine","engine::general_purpose::GeneralPurpose","engine::general_purpose::GeneralPurposeConfig","std::io::Write","std::marker::Send","std::marker::Sized","std::marker::Sync","std::option::Option","write::encoder::EncoderWriter"],"write::encoder::EncoderWriter::<'e, E, W>::write_all_encoded_output":["engine::DecodePaddingMode","engine::Engine","engine::general_purpose::GeneralPurpose","engine::general_purpose::GeneralPurposeConfig","std::io::Write","std::marker::Send","std::marker::Sized","std::marker::Sync","std::option::Option","std::result::Result","write::encoder::EncoderWriter"],"write::encoder::EncoderWriter::<'e, E, W>::write_final_leftovers":["engine::DecodePaddingMode","engine::Engine","engine::general_purpose::GeneralPurpose","engine::general_purpose::GeneralPurposeConfig","std::io::Write","std::marker::Send","std::marker::Sized","std::marker::Sync","std::option::Option","std::result::Result","write::encoder::EncoderWriter"],"write::encoder::EncoderWriter::<'e, E, W>::write_to_delegate":["engine::DecodePaddingMode","engine::Engine","engine::general_purpose::GeneralPurpose","engine::general_purpose::GeneralPurposeConfig","std::io::Write","std::marker::Send","std::marker::Sized","std::marker::Sync","std::option::Option","std::result::Result","write::encoder::EncoderWriter"],"write::encoder_string_writer::EncoderStringWriter":["engine::DecodePaddingMode","engine::Engine","engine::general_purpose::GeneralPurpose","engine::general_purpose::GeneralPurposeConfig","std::io::Write","std::marker::Send","std::marker::Sized","std::marker::Sync","std::option::Option","std::string::String","write::encoder::EncoderWriter","write::encoder_string_writer::EncoderStringWriter","write::encoder_string_writer::StrConsumer"],"write::encoder_string_writer::EncoderStringWriter::<'e, E, S>::from_consumer":["engine::DecodePaddingMode","engine::Engine","engine::general_purpose::GeneralPurpose","engine::general_purpose::GeneralPurposeConfig","std::io::Write","std::marker::Send","std::marker::Sized","std::marker::Sync","std::option::Option","std::string::String","write::encoder::EncoderWriter","write::encoder_string_writer::EncoderStringWriter","write::encoder_string_writer::StrConsumer"],"write::encoder_string_writer::EncoderStringWriter::<'e, E, S>::into_inner":["engine::DecodePaddingMode","engine::Engine","engine::general_purpose::GeneralPurpose","engine::general_purpose::GeneralPurposeConfig","std::io::Write","std::marker::Send","std::marker::Sized","std::marker::Sync","std::option::Option","std::string::String","write::encoder::EncoderWriter","write::encoder_string_writer::EncoderStringWriter","write::encoder_string_writer::StrConsumer"],"write::encoder_string_writer::EncoderStringWriter::<'e, E, std::string::String>::new":["engine::DecodePaddingMode","engine::Engine","engine::general_purpose::GeneralPurpose","engine::general_purpose::GeneralPurposeConfig","std::io::Write","std::marker::Send","std::marker::Sized","std::marker::Sync","std::option::Option","std::string::String","write::encoder::EncoderWriter","write::encoder_string_writer::EncoderStringWriter","write::encoder_string_writer::StrConsumer"],"write::encoder_string_writer::StrConsumer::consume":[],"write::encoder_string_writer::Utf8SingleCodeUnitWriter":["std::marker::Sized","std::string::String","write::encoder_string_writer::StrConsumer","write::encoder_string_writer::Utf8SingleCodeUnitWriter"]},"glob_path_import":{},"self_to_fn":{"alphabet::Alphabet":["Clone","Debug","Eq","PartialEq","impl Alphabet {\n    /// Performs no checks so that it can be const.\n    /// Used only for known-valid strings.\n    const fn from_str_unchecked(alphabet: &str) -> Self {\n        let mut symbols = [0_u8; ALPHABET_SIZE];\n        let source_bytes = alphabet.as_bytes();\n\n        // a way to copy that's allowed in const fn\n        let mut index = 0;\n        while index < ALPHABET_SIZE {\n            symbols[index] = source_bytes[index];\n            index += 1;\n        }\n\n        Self { symbols }\n    }\n\n    /// Create an `Alphabet` from a string of 64 unique printable ASCII bytes.\n    ///\n    /// The `=` byte is not allowed as it is used for padding.\n    pub const fn new(alphabet: &str) -> Result<Self, ParseAlphabetError> {\n        let bytes = alphabet.as_bytes();\n        if bytes.len() != ALPHABET_SIZE {\n            return Err(ParseAlphabetError::InvalidLength);\n        }\n\n        {\n            let mut index = 0;\n            while index < ALPHABET_SIZE {\n                let byte = bytes[index];\n\n                // must be ascii printable. 127 (DEL) is commonly considered printable\n                // for some reason but clearly unsuitable for base64.\n                if !(byte >= 32_u8 && byte <= 126_u8) {\n                    return Err(ParseAlphabetError::UnprintableByte(byte));\n                }\n                // = is assumed to be padding, so cannot be used as a symbol\n                if byte == PAD_BYTE {\n                    return Err(ParseAlphabetError::ReservedByte(byte));\n                }\n\n                // Check for duplicates while staying within what const allows.\n                // It's n^2, but only over 64 hot bytes, and only once, so it's likely in the single digit\n                // microsecond range.\n\n                let mut probe_index = 0;\n                while probe_index < ALPHABET_SIZE {\n                    if probe_index == index {\n                        probe_index += 1;\n                        continue;\n                    }\n\n                    let probe_byte = bytes[probe_index];\n\n                    if byte == probe_byte {\n                        return Err(ParseAlphabetError::DuplicatedByte(byte));\n                    }\n\n                    probe_index += 1;\n                }\n\n                index += 1;\n            }\n        }\n\n        Ok(Self::from_str_unchecked(alphabet))\n    }\n\n    /// Create a `&str` from the symbols in the `Alphabet`\n    #[must_use]\n    pub fn as_str(&self) -> &str {\n        core::str::from_utf8(&self.symbols).unwrap()\n    }\n}","impl convert::TryFrom<&str> for Alphabet {\n    type Error = ParseAlphabetError;\n\n    fn try_from(value: &str) -> Result<Self, Self::Error> {\n        Self::new(value)\n    }\n}"],"alphabet::ParseAlphabetError":["Debug","Eq","PartialEq","impl error::Error for ParseAlphabetError {}","impl fmt::Display for ParseAlphabetError {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        match self {\n            Self::InvalidLength => write!(f, \"Invalid length - must be 64 bytes\"),\n            Self::DuplicatedByte(b) => write!(f, \"Duplicated byte: {:#04x}\", b),\n            Self::UnprintableByte(b) => write!(f, \"Unprintable byte: {:#04x}\", b),\n            Self::ReservedByte(b) => write!(f, \"Reserved byte: {:#04x}\", b),\n        }\n    }\n}"],"chunked_encoder::ChunkedEncoder":["impl<'e, E: Engine + ?Sized> ChunkedEncoder<'e, E> {\n    pub fn new(engine: &'e E) -> ChunkedEncoder<'e, E> {\n        ChunkedEncoder { engine }\n    }\n\n    pub fn encode<S: Sink>(&self, bytes: &[u8], sink: &mut S) -> Result<(), S::Error> {\n        const BUF_SIZE: usize = 1024;\n        const CHUNK_SIZE: usize = BUF_SIZE / 4 * 3;\n\n        let mut buf = [0; BUF_SIZE];\n        for chunk in bytes.chunks(CHUNK_SIZE) {\n            let mut len = self.engine.internal_encode(chunk, &mut buf);\n            if chunk.len() != CHUNK_SIZE && self.engine.config().encode_padding() {\n                // Final, potentially partial, chunk.\n                // Only need to consider if padding is needed on a partial chunk since full chunk\n                // is a multiple of 3, which therefore won't be padded.\n                // Pad output to multiple of four bytes if required by config.\n                len += add_padding(len, &mut buf[len..]);\n            }\n            sink.write_encoded_bytes(&buf[..len])?;\n        }\n\n        Ok(())\n    }\n}"],"chunked_encoder::StringSink":["impl<'a> Sink for StringSink<'a> {\n    type Error = ();\n\n    fn write_encoded_bytes(&mut self, s: &[u8]) -> Result<(), Self::Error> {\n        self.string.push_str(str::from_utf8(s).unwrap());\n\n        Ok(())\n    }\n}","impl<'a> StringSink<'a> {\n    pub(crate) fn new(s: &mut String) -> StringSink {\n        StringSink { string: s }\n    }\n}"],"decode::DecodeError":["Clone","Debug","Eq","PartialEq","impl error::Error for DecodeError {}","impl fmt::Display for DecodeError {\n    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n        match *self {\n            Self::InvalidByte(index, byte) => {\n                write!(f, \"Invalid symbol {}, offset {}.\", byte, index)\n            }\n            Self::InvalidLength(len) => write!(f, \"Invalid input length: {}\", len),\n            Self::InvalidLastSymbol(index, byte) => {\n                write!(f, \"Invalid last symbol {}, offset {}.\", byte, index)\n            }\n            Self::InvalidPadding => write!(f, \"Invalid padding\"),\n        }\n    }\n}"],"decode::DecodeSliceError":["Clone","Debug","Eq","PartialEq","impl From<DecodeError> for DecodeSliceError {\n    fn from(e: DecodeError) -> Self {\n        DecodeSliceError::DecodeError(e)\n    }\n}","impl error::Error for DecodeSliceError {\n    fn source(&self) -> Option<&(dyn error::Error + 'static)> {\n        match self {\n            DecodeSliceError::DecodeError(e) => Some(e),\n            DecodeSliceError::OutputSliceTooSmall => None,\n        }\n    }\n}","impl fmt::Display for DecodeSliceError {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        match self {\n            Self::DecodeError(e) => write!(f, \"DecodeError: {}\", e),\n            Self::OutputSliceTooSmall => write!(f, \"Output slice too small\"),\n        }\n    }\n}"],"display::Base64Display":["impl<'a, 'e, E: Engine> Base64Display<'a, 'e, E> {\n    /// Create a `Base64Display` with the provided engine.\n    pub fn new(bytes: &'a [u8], engine: &'e E) -> Base64Display<'a, 'e, E> {\n        Base64Display {\n            bytes,\n            chunked_encoder: ChunkedEncoder::new(engine),\n        }\n    }\n}","impl<'a, 'e, E: Engine> Display for Base64Display<'a, 'e, E> {\n    fn fmt(&self, formatter: &mut Formatter) -> Result<(), fmt::Error> {\n        let mut sink = FormatterSink { f: formatter };\n        self.chunked_encoder.encode(self.bytes, &mut sink)\n    }\n}"],"display::FormatterSink":["impl<'a, 'b: 'a> super::chunked_encoder::Sink for FormatterSink<'a, 'b> {\n    type Error = fmt::Error;\n\n    fn write_encoded_bytes(&mut self, encoded: &[u8]) -> Result<(), Self::Error> {\n        // Avoid unsafe. If max performance is needed, write your own display wrapper that uses\n        // unsafe here to gain about 10-15%.\n        self.f\n            .write_str(str::from_utf8(encoded).expect(\"base64 data was not utf8\"))\n    }\n}"],"encode::EncodeSliceError":["Clone","Debug","Eq","PartialEq","impl error::Error for EncodeSliceError {}","impl fmt::Display for EncodeSliceError {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        match self {\n            Self::OutputSliceTooSmall => write!(f, \"Output slice too small\"),\n        }\n    }\n}"],"engine::DecodeMetadata":["Debug","Eq","PartialEq","impl DecodeMetadata {\n    pub(crate) fn new(decoded_bytes: usize, padding_index: Option<usize>) -> Self {\n        Self {\n            decoded_len: decoded_bytes,\n            padding_offset: padding_index,\n        }\n    }\n}"],"engine::DecodePaddingMode":["Clone","Copy","Debug","Eq","PartialEq"],"engine::general_purpose::GeneralPurpose":["Clone","Debug","impl GeneralPurpose {\n    /// Create a `GeneralPurpose` engine from an [Alphabet].\n    ///\n    /// While not very expensive to initialize, ideally these should be cached\n    /// if the engine will be used repeatedly.\n    #[must_use]\n    pub const fn new(alphabet: &Alphabet, config: GeneralPurposeConfig) -> Self {\n        Self {\n            encode_table: encode_table(alphabet),\n            decode_table: decode_table(alphabet),\n            config,\n        }\n    }\n}","impl super::Engine for GeneralPurpose {\n    type Config = GeneralPurposeConfig;\n    type DecodeEstimate = GeneralPurposeEstimate;\n\n    fn internal_encode(&self, input: &[u8], output: &mut [u8]) -> usize {\n        let mut input_index: usize = 0;\n\n        const BLOCKS_PER_FAST_LOOP: usize = 4;\n        const LOW_SIX_BITS: u64 = 0x3F;\n\n        // we read 8 bytes at a time (u64) but only actually consume 6 of those bytes. Thus, we need\n        // 2 trailing bytes to be available to read..\n        let last_fast_index = input.len().saturating_sub(BLOCKS_PER_FAST_LOOP * 6 + 2);\n        let mut output_index = 0;\n\n        if last_fast_index > 0 {\n            while input_index <= last_fast_index {\n                // Major performance wins from letting the optimizer do the bounds check once, mostly\n                // on the output side\n                let input_chunk =\n                    &input[input_index..(input_index + (BLOCKS_PER_FAST_LOOP * 6 + 2))];\n                let output_chunk =\n                    &mut output[output_index..(output_index + BLOCKS_PER_FAST_LOOP * 8)];\n\n                // Hand-unrolling for 32 vs 16 or 8 bytes produces yields performance about equivalent\n                // to unsafe pointer code on a Xeon E5-1650v3. 64 byte unrolling was slightly better for\n                // large inputs but significantly worse for 50-byte input, unsurprisingly. I suspect\n                // that it's a not uncommon use case to encode smallish chunks of data (e.g. a 64-byte\n                // SHA-512 digest), so it would be nice if that fit in the unrolled loop at least once.\n                // Plus, single-digit percentage performance differences might well be quite different\n                // on different hardware.\n\n                let input_u64 = read_u64(&input_chunk[0..]);\n\n                output_chunk[0] = self.encode_table[((input_u64 >> 58) & LOW_SIX_BITS) as usize];\n                output_chunk[1] = self.encode_table[((input_u64 >> 52) & LOW_SIX_BITS) as usize];\n                output_chunk[2] = self.encode_table[((input_u64 >> 46) & LOW_SIX_BITS) as usize];\n                output_chunk[3] = self.encode_table[((input_u64 >> 40) & LOW_SIX_BITS) as usize];\n                output_chunk[4] = self.encode_table[((input_u64 >> 34) & LOW_SIX_BITS) as usize];\n                output_chunk[5] = self.encode_table[((input_u64 >> 28) & LOW_SIX_BITS) as usize];\n                output_chunk[6] = self.encode_table[((input_u64 >> 22) & LOW_SIX_BITS) as usize];\n                output_chunk[7] = self.encode_table[((input_u64 >> 16) & LOW_SIX_BITS) as usize];\n\n                let input_u64 = read_u64(&input_chunk[6..]);\n\n                output_chunk[8] = self.encode_table[((input_u64 >> 58) & LOW_SIX_BITS) as usize];\n                output_chunk[9] = self.encode_table[((input_u64 >> 52) & LOW_SIX_BITS) as usize];\n                output_chunk[10] = self.encode_table[((input_u64 >> 46) & LOW_SIX_BITS) as usize];\n                output_chunk[11] = self.encode_table[((input_u64 >> 40) & LOW_SIX_BITS) as usize];\n                output_chunk[12] = self.encode_table[((input_u64 >> 34) & LOW_SIX_BITS) as usize];\n                output_chunk[13] = self.encode_table[((input_u64 >> 28) & LOW_SIX_BITS) as usize];\n                output_chunk[14] = self.encode_table[((input_u64 >> 22) & LOW_SIX_BITS) as usize];\n                output_chunk[15] = self.encode_table[((input_u64 >> 16) & LOW_SIX_BITS) as usize];\n\n                let input_u64 = read_u64(&input_chunk[12..]);\n\n                output_chunk[16] = self.encode_table[((input_u64 >> 58) & LOW_SIX_BITS) as usize];\n                output_chunk[17] = self.encode_table[((input_u64 >> 52) & LOW_SIX_BITS) as usize];\n                output_chunk[18] = self.encode_table[((input_u64 >> 46) & LOW_SIX_BITS) as usize];\n                output_chunk[19] = self.encode_table[((input_u64 >> 40) & LOW_SIX_BITS) as usize];\n                output_chunk[20] = self.encode_table[((input_u64 >> 34) & LOW_SIX_BITS) as usize];\n                output_chunk[21] = self.encode_table[((input_u64 >> 28) & LOW_SIX_BITS) as usize];\n                output_chunk[22] = self.encode_table[((input_u64 >> 22) & LOW_SIX_BITS) as usize];\n                output_chunk[23] = self.encode_table[((input_u64 >> 16) & LOW_SIX_BITS) as usize];\n\n                let input_u64 = read_u64(&input_chunk[18..]);\n\n                output_chunk[24] = self.encode_table[((input_u64 >> 58) & LOW_SIX_BITS) as usize];\n                output_chunk[25] = self.encode_table[((input_u64 >> 52) & LOW_SIX_BITS) as usize];\n                output_chunk[26] = self.encode_table[((input_u64 >> 46) & LOW_SIX_BITS) as usize];\n                output_chunk[27] = self.encode_table[((input_u64 >> 40) & LOW_SIX_BITS) as usize];\n                output_chunk[28] = self.encode_table[((input_u64 >> 34) & LOW_SIX_BITS) as usize];\n                output_chunk[29] = self.encode_table[((input_u64 >> 28) & LOW_SIX_BITS) as usize];\n                output_chunk[30] = self.encode_table[((input_u64 >> 22) & LOW_SIX_BITS) as usize];\n                output_chunk[31] = self.encode_table[((input_u64 >> 16) & LOW_SIX_BITS) as usize];\n\n                output_index += BLOCKS_PER_FAST_LOOP * 8;\n                input_index += BLOCKS_PER_FAST_LOOP * 6;\n            }\n        }\n\n        // Encode what's left after the fast loop.\n\n        const LOW_SIX_BITS_U8: u8 = 0x3F;\n\n        let rem = input.len() % 3;\n        let start_of_rem = input.len() - rem;\n\n        // start at the first index not handled by fast loop, which may be 0.\n\n        while input_index < start_of_rem {\n            let input_chunk = &input[input_index..(input_index + 3)];\n            let output_chunk = &mut output[output_index..(output_index + 4)];\n\n            output_chunk[0] = self.encode_table[(input_chunk[0] >> 2) as usize];\n            output_chunk[1] = self.encode_table\n                [((input_chunk[0] << 4 | input_chunk[1] >> 4) & LOW_SIX_BITS_U8) as usize];\n            output_chunk[2] = self.encode_table\n                [((input_chunk[1] << 2 | input_chunk[2] >> 6) & LOW_SIX_BITS_U8) as usize];\n            output_chunk[3] = self.encode_table[(input_chunk[2] & LOW_SIX_BITS_U8) as usize];\n\n            input_index += 3;\n            output_index += 4;\n        }\n\n        if rem == 2 {\n            output[output_index] = self.encode_table[(input[start_of_rem] >> 2) as usize];\n            output[output_index + 1] =\n                self.encode_table[((input[start_of_rem] << 4 | input[start_of_rem + 1] >> 4)\n                    & LOW_SIX_BITS_U8) as usize];\n            output[output_index + 2] =\n                self.encode_table[((input[start_of_rem + 1] << 2) & LOW_SIX_BITS_U8) as usize];\n            output_index += 3;\n        } else if rem == 1 {\n            output[output_index] = self.encode_table[(input[start_of_rem] >> 2) as usize];\n            output[output_index + 1] =\n                self.encode_table[((input[start_of_rem] << 4) & LOW_SIX_BITS_U8) as usize];\n            output_index += 2;\n        }\n\n        output_index\n    }\n\n    fn internal_decoded_len_estimate(&self, input_len: usize) -> Self::DecodeEstimate {\n        GeneralPurposeEstimate::new(input_len)\n    }\n\n    fn internal_decode(\n        &self,\n        input: &[u8],\n        output: &mut [u8],\n        estimate: Self::DecodeEstimate,\n    ) -> Result<DecodeMetadata, DecodeSliceError> {\n        decode::decode_helper(\n            input,\n            &estimate,\n            output,\n            &self.decode_table,\n            self.config.decode_allow_trailing_bits,\n            self.config.decode_padding_mode,\n        )\n    }\n\n    fn config(&self) -> &Self::Config {\n        &self.config\n    }\n}"],"engine::general_purpose::GeneralPurposeConfig":["Clone","Copy","Debug","impl Config for GeneralPurposeConfig {\n    fn encode_padding(&self) -> bool {\n        self.encode_padding\n    }\n}","impl Default for GeneralPurposeConfig {\n    /// Delegates to [`GeneralPurposeConfig::new`].\n    fn default() -> Self {\n        Self::new()\n    }\n}","impl GeneralPurposeConfig {\n    /// Create a new config with `padding` = `true`, `decode_allow_trailing_bits` = `false`, and\n    /// `decode_padding_mode = DecodePaddingMode::RequireCanonicalPadding`.\n    ///\n    /// This probably matches most people's expectations, but consider disabling padding to save\n    /// a few bytes unless you specifically need it for compatibility with some legacy system.\n    #[must_use]\n    pub const fn new() -> Self {\n        Self {\n            // RFC states that padding must be applied by default\n            encode_padding: true,\n            decode_allow_trailing_bits: false,\n            decode_padding_mode: DecodePaddingMode::RequireCanonical,\n        }\n    }\n\n    /// Create a new config based on `self` with an updated `padding` setting.\n    ///\n    /// If `padding` is `true`, encoding will append either 1 or 2 `=` padding characters as needed\n    /// to produce an output whose length is a multiple of 4.\n    ///\n    /// Padding is not needed for correct decoding and only serves to waste bytes, but it's in the\n    /// [spec](https://datatracker.ietf.org/doc/html/rfc4648#section-3.2).\n    ///\n    /// For new applications, consider not using padding if the decoders you're using don't require\n    /// padding to be present.\n    #[must_use]\n    pub const fn with_encode_padding(self, padding: bool) -> Self {\n        Self {\n            encode_padding: padding,\n            ..self\n        }\n    }\n\n    /// Create a new config based on `self` with an updated `decode_allow_trailing_bits` setting.\n    ///\n    /// Most users will not need to configure this. It's useful if you need to decode base64\n    /// produced by a buggy encoder that has bits set in the unused space on the last base64\n    /// character as per [forgiving-base64 decode](https://infra.spec.whatwg.org/#forgiving-base64-decode).\n    /// If invalid trailing bits are present and this is `true`, those bits will\n    /// be silently ignored, else `DecodeError::InvalidLastSymbol` will be emitted.\n    #[must_use]\n    pub const fn with_decode_allow_trailing_bits(self, allow: bool) -> Self {\n        Self {\n            decode_allow_trailing_bits: allow,\n            ..self\n        }\n    }\n\n    /// Create a new config based on `self` with an updated `decode_padding_mode` setting.\n    ///\n    /// Padding is not useful in terms of representing encoded data -- it makes no difference to\n    /// the decoder if padding is present or not, so if you have some un-padded input to decode, it\n    /// is perfectly fine to use `DecodePaddingMode::Indifferent` to prevent errors from being\n    /// emitted.\n    ///\n    /// However, since in practice\n    /// [people who learned nothing from BER vs DER seem to expect base64 to have one canonical encoding](https://eprint.iacr.org/2022/361),\n    /// the default setting is the stricter `DecodePaddingMode::RequireCanonicalPadding`.\n    ///\n    /// Or, if \"canonical\" in your circumstance means _no_ padding rather than padding to the\n    /// next multiple of four, there's `DecodePaddingMode::RequireNoPadding`.\n    #[must_use]\n    pub const fn with_decode_padding_mode(self, mode: DecodePaddingMode) -> Self {\n        Self {\n            decode_padding_mode: mode,\n            ..self\n        }\n    }\n}"],"engine::general_purpose::decode::GeneralPurposeEstimate":["impl DecodeEstimate for GeneralPurposeEstimate {\n    fn decoded_len_estimate(&self) -> usize {\n        self.conservative_decoded_len\n    }\n}","impl GeneralPurposeEstimate {\n    pub(crate) fn new(encoded_len: usize) -> Self {\n        let rem = encoded_len % 4;\n        Self {\n            rem,\n            conservative_decoded_len: (encoded_len / 4 + usize::from(rem > 0)) * 3,\n        }\n    }\n}"],"read::decoder::DecoderReader":["impl<'e, E: Engine, R: io::Read> DecoderReader<'e, E, R> {\n    /// Create a new decoder that will read from the provided reader `r`.\n    pub fn new(reader: R, engine: &'e E) -> Self {\n        DecoderReader {\n            engine,\n            inner: reader,\n            b64_buffer: [0; BUF_SIZE],\n            b64_offset: 0,\n            b64_len: 0,\n            decoded_chunk_buffer: [0; DECODED_CHUNK_SIZE],\n            decoded_offset: 0,\n            decoded_len: 0,\n            input_consumed_len: 0,\n            padding_offset: None,\n        }\n    }\n\n    /// Write as much as possible of the decoded buffer into the target buffer.\n    /// Must only be called when there is something to write and space to write into.\n    /// Returns a Result with the number of (decoded) bytes copied.\n    fn flush_decoded_buf(&mut self, buf: &mut [u8]) -> io::Result<usize> {\n        debug_assert!(self.decoded_len > 0);\n        debug_assert!(!buf.is_empty());\n\n        let copy_len = cmp::min(self.decoded_len, buf.len());\n        debug_assert!(copy_len > 0);\n        debug_assert!(copy_len <= self.decoded_len);\n\n        buf[..copy_len].copy_from_slice(\n            &self.decoded_chunk_buffer[self.decoded_offset..self.decoded_offset + copy_len],\n        );\n\n        self.decoded_offset += copy_len;\n        self.decoded_len -= copy_len;\n\n        debug_assert!(self.decoded_len < DECODED_CHUNK_SIZE);\n\n        Ok(copy_len)\n    }\n\n    /// Read into the remaining space in the buffer after the current contents.\n    /// Must only be called when there is space to read into in the buffer.\n    /// Returns the number of bytes read.\n    fn read_from_delegate(&mut self) -> io::Result<usize> {\n        debug_assert!(self.b64_offset + self.b64_len < BUF_SIZE);\n\n        let read = self\n            .inner\n            .read(&mut self.b64_buffer[self.b64_offset + self.b64_len..])?;\n        self.b64_len += read;\n\n        debug_assert!(self.b64_offset + self.b64_len <= BUF_SIZE);\n\n        Ok(read)\n    }\n\n    /// Decode the requested number of bytes from the b64 buffer into the provided buffer. It's the\n    /// caller's responsibility to choose the number of b64 bytes to decode correctly.\n    ///\n    /// Returns a Result with the number of decoded bytes written to `buf`.\n    ///\n    /// # Panics\n    ///\n    /// panics if `buf` is too small\n    fn decode_to_buf(&mut self, b64_len_to_decode: usize, buf: &mut [u8]) -> io::Result<usize> {\n        debug_assert!(self.b64_len >= b64_len_to_decode);\n        debug_assert!(self.b64_offset + self.b64_len <= BUF_SIZE);\n        debug_assert!(!buf.is_empty());\n\n        let b64_to_decode = &self.b64_buffer[self.b64_offset..self.b64_offset + b64_len_to_decode];\n        let decode_metadata = self\n            .engine\n            .internal_decode(\n                b64_to_decode,\n                buf,\n                self.engine.internal_decoded_len_estimate(b64_len_to_decode),\n            )\n            .map_err(|dse| match dse {\n                DecodeSliceError::DecodeError(de) => {\n                    match de {\n                        DecodeError::InvalidByte(offset, byte) => {\n                            match (byte, self.padding_offset) {\n                                // if there was padding in a previous block of decoding that happened to\n                                // be correct, and we now find more padding that happens to be incorrect,\n                                // to be consistent with non-reader decodes, record the error at the first\n                                // padding\n                                (PAD_BYTE, Some(first_pad_offset)) => {\n                                    DecodeError::InvalidByte(first_pad_offset, PAD_BYTE)\n                                }\n                                _ => {\n                                    DecodeError::InvalidByte(self.input_consumed_len + offset, byte)\n                                }\n                            }\n                        }\n                        DecodeError::InvalidLength(len) => {\n                            DecodeError::InvalidLength(self.input_consumed_len + len)\n                        }\n                        DecodeError::InvalidLastSymbol(offset, byte) => {\n                            DecodeError::InvalidLastSymbol(self.input_consumed_len + offset, byte)\n                        }\n                        DecodeError::InvalidPadding => DecodeError::InvalidPadding,\n                    }\n                }\n                DecodeSliceError::OutputSliceTooSmall => {\n                    unreachable!(\"buf is sized correctly in calling code\")\n                }\n            })\n            .map_err(|e| io::Error::new(io::ErrorKind::InvalidData, e))?;\n\n        if let Some(offset) = self.padding_offset {\n            // we've already seen padding\n            if decode_metadata.decoded_len > 0 {\n                // we read more after already finding padding; report error at first padding byte\n                return Err(io::Error::new(\n                    io::ErrorKind::InvalidData,\n                    DecodeError::InvalidByte(offset, PAD_BYTE),\n                ));\n            }\n        }\n\n        self.padding_offset = self.padding_offset.or(decode_metadata\n            .padding_offset\n            .map(|offset| self.input_consumed_len + offset));\n        self.input_consumed_len += b64_len_to_decode;\n        self.b64_offset += b64_len_to_decode;\n        self.b64_len -= b64_len_to_decode;\n\n        debug_assert!(self.b64_offset + self.b64_len <= BUF_SIZE);\n\n        Ok(decode_metadata.decoded_len)\n    }\n\n    /// Unwraps this `DecoderReader`, returning the base reader which it reads base64 encoded\n    /// input from.\n    ///\n    /// Because `DecoderReader` performs internal buffering, the state of the inner reader is\n    /// unspecified. This function is mainly provided because the inner reader type may provide\n    /// additional functionality beyond the `Read` implementation which may still be useful.\n    pub fn into_inner(self) -> R {\n        self.inner\n    }\n}","impl<'e, E: Engine, R: io::Read> fmt::Debug for DecoderReader<'e, E, R> {\n    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n        f.debug_struct(\"DecoderReader\")\n            .field(\"b64_offset\", &self.b64_offset)\n            .field(\"b64_len\", &self.b64_len)\n            .field(\"decoded_chunk_buffer\", &self.decoded_chunk_buffer)\n            .field(\"decoded_offset\", &self.decoded_offset)\n            .field(\"decoded_len\", &self.decoded_len)\n            .field(\"input_consumed_len\", &self.input_consumed_len)\n            .field(\"padding_offset\", &self.padding_offset)\n            .finish()\n    }\n}","impl<'e, E: Engine, R: io::Read> io::Read for DecoderReader<'e, E, R> {\n    /// Decode input from the wrapped reader.\n    ///\n    /// Under non-error circumstances, this returns `Ok` with the value being the number of bytes\n    /// written in `buf`.\n    ///\n    /// Where possible, this function buffers base64 to minimize the number of `read()` calls to the\n    /// delegate reader.\n    ///\n    /// # Errors\n    ///\n    /// Any errors emitted by the delegate reader are returned. Decoding errors due to invalid\n    /// base64 are also possible, and will have `io::ErrorKind::InvalidData`.\n    fn read(&mut self, buf: &mut [u8]) -> io::Result<usize> {\n        if buf.is_empty() {\n            return Ok(0);\n        }\n\n        // offset == BUF_SIZE when we copied it all last time\n        debug_assert!(self.b64_offset <= BUF_SIZE);\n        debug_assert!(self.b64_offset + self.b64_len <= BUF_SIZE);\n        debug_assert!(if self.b64_offset == BUF_SIZE {\n            self.b64_len == 0\n        } else {\n            self.b64_len <= BUF_SIZE\n        });\n\n        debug_assert!(if self.decoded_len == 0 {\n            // can be = when we were able to copy the complete chunk\n            self.decoded_offset <= DECODED_CHUNK_SIZE\n        } else {\n            self.decoded_offset < DECODED_CHUNK_SIZE\n        });\n\n        // We shouldn't ever decode into decoded_buffer when we can't immediately write at least one\n        // byte into the provided buf, so the effective length should only be 3 momentarily between\n        // when we decode and when we copy into the target buffer.\n        debug_assert!(self.decoded_len < DECODED_CHUNK_SIZE);\n        debug_assert!(self.decoded_len + self.decoded_offset <= DECODED_CHUNK_SIZE);\n\n        if self.decoded_len > 0 {\n            // we have a few leftover decoded bytes; flush that rather than pull in more b64\n            self.flush_decoded_buf(buf)\n        } else {\n            let mut at_eof = false;\n            while self.b64_len < BASE64_CHUNK_SIZE {\n                // Copy any bytes we have to the start of the buffer.\n                self.b64_buffer\n                    .copy_within(self.b64_offset..self.b64_offset + self.b64_len, 0);\n                self.b64_offset = 0;\n\n                // then fill in more data\n                let read = self.read_from_delegate()?;\n                if read == 0 {\n                    // we never read into an empty buf, so 0 => we've hit EOF\n                    at_eof = true;\n                    break;\n                }\n            }\n\n            if self.b64_len == 0 {\n                debug_assert!(at_eof);\n                // we must be at EOF, and we have no data left to decode\n                return Ok(0);\n            };\n\n            debug_assert!(if at_eof {\n                // if we are at eof, we may not have a complete chunk\n                self.b64_len > 0\n            } else {\n                // otherwise, we must have at least one chunk\n                self.b64_len >= BASE64_CHUNK_SIZE\n            });\n\n            debug_assert_eq!(0, self.decoded_len);\n\n            if buf.len() < DECODED_CHUNK_SIZE {\n                // caller requested an annoyingly short read\n                // have to write to a tmp buf first to avoid double mutable borrow\n                let mut decoded_chunk = [0_u8; DECODED_CHUNK_SIZE];\n                // if we are at eof, could have less than BASE64_CHUNK_SIZE, in which case we have\n                // to assume that these last few tokens are, in fact, valid (i.e. must be 2-4 b64\n                // tokens, not 1, since 1 token can't decode to 1 byte).\n                let to_decode = cmp::min(self.b64_len, BASE64_CHUNK_SIZE);\n\n                let decoded = self.decode_to_buf(to_decode, &mut decoded_chunk[..])?;\n                self.decoded_chunk_buffer[..decoded].copy_from_slice(&decoded_chunk[..decoded]);\n\n                self.decoded_offset = 0;\n                self.decoded_len = decoded;\n\n                // can be less than 3 on last block due to padding\n                debug_assert!(decoded <= 3);\n\n                self.flush_decoded_buf(buf)\n            } else {\n                let b64_bytes_that_can_decode_into_buf = (buf.len() / DECODED_CHUNK_SIZE)\n                    .checked_mul(BASE64_CHUNK_SIZE)\n                    .expect(\"too many chunks\");\n                debug_assert!(b64_bytes_that_can_decode_into_buf >= BASE64_CHUNK_SIZE);\n\n                let b64_bytes_available_to_decode = if at_eof {\n                    self.b64_len\n                } else {\n                    // only use complete chunks\n                    self.b64_len - self.b64_len % 4\n                };\n\n                let actual_decode_len = cmp::min(\n                    b64_bytes_that_can_decode_into_buf,\n                    b64_bytes_available_to_decode,\n                );\n                self.decode_to_buf(actual_decode_len, buf)\n            }\n        }\n    }\n}"],"std::string::String":["impl StrConsumer for String {\n    fn consume(&mut self, buf: &str) {\n        self.push_str(buf);\n    }\n}"],"write::encoder::EncoderWriter":["impl<'e, E: Engine, W: io::Write> Drop for EncoderWriter<'e, E, W> {\n    fn drop(&mut self) {\n        if !self.panicked {\n            // like `BufWriter`, ignore errors during drop\n            let _ = self.write_final_leftovers();\n        }\n    }\n}","impl<'e, E: Engine, W: io::Write> EncoderWriter<'e, E, W> {\n    /// Create a new encoder that will write to the provided delegate writer.\n    pub fn new(delegate: W, engine: &'e E) -> EncoderWriter<'e, E, W> {\n        EncoderWriter {\n            engine,\n            delegate: Some(delegate),\n            extra_input: [0u8; MIN_ENCODE_CHUNK_SIZE],\n            extra_input_occupied_len: 0,\n            output: [0u8; BUF_SIZE],\n            output_occupied_len: 0,\n            panicked: false,\n        }\n    }\n\n    /// Encode all remaining buffered data and write it, including any trailing incomplete input\n    /// triples and associated padding.\n    ///\n    /// Once this succeeds, no further writes or calls to this method are allowed.\n    ///\n    /// This may write to the delegate writer multiple times if the delegate writer does not accept\n    /// all input provided to its `write` each invocation.\n    ///\n    /// If you don't care about error handling, it is not necessary to call this function, as the\n    /// equivalent finalization is done by the Drop impl.\n    ///\n    /// Returns the writer that this was constructed around.\n    ///\n    /// # Errors\n    ///\n    /// The first error that is not of `ErrorKind::Interrupted` will be returned.\n    pub fn finish(&mut self) -> Result<W> {\n        // If we could consume self in finish(), we wouldn't have to worry about this case, but\n        // finish() is retryable in the face of I/O errors, so we can't consume here.\n        assert!(\n            self.delegate.is_some(),\n            \"Encoder has already had finish() called\"\n        );\n\n        self.write_final_leftovers()?;\n\n        let writer = self.delegate.take().expect(\"Writer must be present\");\n\n        Ok(writer)\n    }\n\n    /// Write any remaining buffered data to the delegate writer.\n    fn write_final_leftovers(&mut self) -> Result<()> {\n        if self.delegate.is_none() {\n            // finish() has already successfully called this, and we are now in drop() with a None\n            // writer, so just no-op\n            return Ok(());\n        }\n\n        self.write_all_encoded_output()?;\n\n        if self.extra_input_occupied_len > 0 {\n            let encoded_len = self\n                .engine\n                .encode_slice(\n                    &self.extra_input[..self.extra_input_occupied_len],\n                    &mut self.output[..],\n                )\n                .expect(\"buffer is large enough\");\n\n            self.output_occupied_len = encoded_len;\n\n            self.write_all_encoded_output()?;\n\n            // write succeeded, do not write the encoding of extra again if finish() is retried\n            self.extra_input_occupied_len = 0;\n        }\n\n        Ok(())\n    }\n\n    /// Write as much of the encoded output to the delegate writer as it will accept, and store the\n    /// leftovers to be attempted at the next `write()` call. Updates `self.output_occupied_len`.\n    ///\n    /// # Errors\n    ///\n    /// Errors from the delegate writer are returned. In the case of an error,\n    /// `self.output_occupied_len` will not be updated, as errors from `write` are specified to mean\n    /// that no write took place.\n    fn write_to_delegate(&mut self, current_output_len: usize) -> Result<()> {\n        self.panicked = true;\n        let res = self\n            .delegate\n            .as_mut()\n            .expect(\"Writer must be present\")\n            .write(&self.output[..current_output_len]);\n        self.panicked = false;\n\n        res.map(|consumed| {\n            debug_assert!(consumed <= current_output_len);\n\n            if consumed < current_output_len {\n                self.output_occupied_len = current_output_len.checked_sub(consumed).unwrap();\n                // If we're blocking on I/O, the minor inefficiency of copying bytes to the\n                // start of the buffer is the least of our concerns...\n                // TODO Rotate moves more than we need to; copy_within now stable.\n                self.output.rotate_left(consumed);\n            } else {\n                self.output_occupied_len = 0;\n            }\n        })\n    }\n\n    /// Write all buffered encoded output. If this returns `Ok`, `self.output_occupied_len` is `0`.\n    ///\n    /// This is basically `write_all` for the remaining buffered data but without the undesirable\n    /// abort-on-`Ok(0)` behavior.\n    ///\n    /// # Errors\n    ///\n    /// Any error emitted by the delegate writer abort the write loop and is returned, unless it's\n    /// `Interrupted`, in which case the error is ignored and writes will continue.\n    fn write_all_encoded_output(&mut self) -> Result<()> {\n        while self.output_occupied_len > 0 {\n            let remaining_len = self.output_occupied_len;\n            match self.write_to_delegate(remaining_len) {\n                // try again on interrupts ala write_all\n                Err(ref e) if e.kind() == ErrorKind::Interrupted => {}\n                // other errors return\n                Err(e) => return Err(e),\n                // success no-ops because remaining length is already updated\n                Ok(()) => {}\n            };\n        }\n\n        debug_assert_eq!(0, self.output_occupied_len);\n        Ok(())\n    }\n\n    /// Unwraps this `EncoderWriter`, returning the base writer it writes base64 encoded output\n    /// to.\n    ///\n    /// Normally this method should not be needed, since `finish()` returns the inner writer if\n    /// it completes successfully. That will also ensure all data has been flushed, which the\n    /// `into_inner()` function does *not* do.\n    ///\n    /// Calling this method after `finish()` has completed successfully will panic, since the\n    /// writer has already been returned.\n    ///\n    /// This method may be useful if the writer implements additional APIs beyond the `Write`\n    /// trait. Note that the inner writer might be in an error state or have an incomplete\n    /// base64 string written to it.\n    pub fn into_inner(mut self) -> W {\n        self.delegate\n            .take()\n            .expect(\"Encoder has already had finish() called\")\n    }\n}","impl<'e, E: Engine, W: io::Write> fmt::Debug for EncoderWriter<'e, E, W> {\n    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n        write!(\n            f,\n            \"extra_input: {:?} extra_input_occupied_len:{:?} output[..5]: {:?} output_occupied_len: {:?}\",\n            self.extra_input,\n            self.extra_input_occupied_len,\n            &self.output[0..5],\n            self.output_occupied_len\n        )\n    }\n}","impl<'e, E: Engine, W: io::Write> io::Write for EncoderWriter<'e, E, W> {\n    /// Encode input and then write to the delegate writer.\n    ///\n    /// Under non-error circumstances, this returns `Ok` with the value being the number of bytes\n    /// of `input` consumed. The value may be `0`, which interacts poorly with `write_all`, which\n    /// interprets `Ok(0)` as an error, despite it being allowed by the contract of `write`. See\n    /// <https://github.com/rust-lang/rust/issues/56889> for more on that.\n    ///\n    /// If the previous call to `write` provided more (encoded) data than the delegate writer could\n    /// accept in a single call to its `write`, the remaining data is buffered. As long as buffered\n    /// data is present, subsequent calls to `write` will try to write the remaining buffered data\n    /// to the delegate and return either `Ok(0)` -- and therefore not consume any of `input` -- or\n    /// an error.\n    ///\n    /// # Errors\n    ///\n    /// Any errors emitted by the delegate writer are returned.\n    fn write(&mut self, input: &[u8]) -> Result<usize> {\n        assert!(\n            self.delegate.is_some(),\n            \"Cannot write more after calling finish()\"\n        );\n\n        if input.is_empty() {\n            return Ok(0);\n        }\n\n        // The contract of `Write::write` places some constraints on this implementation:\n        // - a call to `write()` represents at most one call to a wrapped `Write`, so we can't\n        // iterate over the input and encode multiple chunks.\n        // - Errors mean that \"no bytes were written to this writer\", so we need to reset the\n        // internal state to what it was before the error occurred\n\n        // before reading any input, write any leftover encoded output from last time\n        if self.output_occupied_len > 0 {\n            let current_len = self.output_occupied_len;\n            return self\n                .write_to_delegate(current_len)\n                // did not read any input\n                .map(|()| 0);\n        }\n\n        debug_assert_eq!(0, self.output_occupied_len);\n\n        // how many bytes, if any, were read into `extra` to create a triple to encode\n        let mut extra_input_read_len = 0;\n        let mut input = input;\n\n        let orig_extra_len = self.extra_input_occupied_len;\n\n        let mut encoded_size = 0;\n        // always a multiple of MIN_ENCODE_CHUNK_SIZE\n        let mut max_input_len = MAX_INPUT_LEN;\n\n        // process leftover un-encoded input from last write\n        if self.extra_input_occupied_len > 0 {\n            debug_assert!(self.extra_input_occupied_len < 3);\n            if input.len() + self.extra_input_occupied_len >= MIN_ENCODE_CHUNK_SIZE {\n                // Fill up `extra`, encode that into `output`, and consume as much of the rest of\n                // `input` as possible.\n                // We could write just the encoding of `extra` by itself but then we'd have to\n                // return after writing only 4 bytes, which is inefficient if the underlying writer\n                // would make a syscall.\n                extra_input_read_len = MIN_ENCODE_CHUNK_SIZE - self.extra_input_occupied_len;\n                debug_assert!(extra_input_read_len > 0);\n                // overwrite only bytes that weren't already used. If we need to rollback extra_len\n                // (when the subsequent write errors), the old leading bytes will still be there.\n                self.extra_input[self.extra_input_occupied_len..MIN_ENCODE_CHUNK_SIZE]\n                    .copy_from_slice(&input[0..extra_input_read_len]);\n\n                let len = self.engine.internal_encode(\n                    &self.extra_input[0..MIN_ENCODE_CHUNK_SIZE],\n                    &mut self.output[..],\n                );\n                debug_assert_eq!(4, len);\n\n                input = &input[extra_input_read_len..];\n\n                // consider extra to be used up, since we encoded it\n                self.extra_input_occupied_len = 0;\n                // don't clobber where we just encoded to\n                encoded_size = 4;\n                // and don't read more than can be encoded\n                max_input_len = MAX_INPUT_LEN - MIN_ENCODE_CHUNK_SIZE;\n\n            // fall through to normal encoding\n            } else {\n                // `extra` and `input` are non empty, but `|extra| + |input| < 3`, so there must be\n                // 1 byte in each.\n                debug_assert_eq!(1, input.len());\n                debug_assert_eq!(1, self.extra_input_occupied_len);\n\n                self.extra_input[self.extra_input_occupied_len] = input[0];\n                self.extra_input_occupied_len += 1;\n                return Ok(1);\n            };\n        } else if input.len() < MIN_ENCODE_CHUNK_SIZE {\n            // `extra` is empty, and `input` fits inside it\n            self.extra_input[0..input.len()].copy_from_slice(input);\n            self.extra_input_occupied_len = input.len();\n            return Ok(input.len());\n        };\n\n        // either 0 or 1 complete chunks encoded from extra\n        debug_assert!(encoded_size == 0 || encoded_size == 4);\n        debug_assert!(\n            // didn't encode extra input\n            MAX_INPUT_LEN == max_input_len\n                // encoded one triple\n                || MAX_INPUT_LEN == max_input_len + MIN_ENCODE_CHUNK_SIZE\n        );\n\n        // encode complete triples only\n        let input_complete_chunks_len = input.len() - (input.len() % MIN_ENCODE_CHUNK_SIZE);\n        let input_chunks_to_encode_len = cmp::min(input_complete_chunks_len, max_input_len);\n        debug_assert_eq!(0, max_input_len % MIN_ENCODE_CHUNK_SIZE);\n        debug_assert_eq!(0, input_chunks_to_encode_len % MIN_ENCODE_CHUNK_SIZE);\n\n        encoded_size += self.engine.internal_encode(\n            &input[..(input_chunks_to_encode_len)],\n            &mut self.output[encoded_size..],\n        );\n\n        // not updating `self.output_occupied_len` here because if the below write fails, it should\n        // \"never take place\" -- the buffer contents we encoded are ignored and perhaps retried\n        // later, if the consumer chooses.\n\n        self.write_to_delegate(encoded_size)\n            // no matter whether we wrote the full encoded buffer or not, we consumed the same\n            // input\n            .map(|()| extra_input_read_len + input_chunks_to_encode_len)\n            .map_err(|e| {\n                // in case we filled and encoded `extra`, reset extra_len\n                self.extra_input_occupied_len = orig_extra_len;\n\n                e\n            })\n    }\n\n    /// Because this is usually treated as OK to call multiple times, it will *not* flush any\n    /// incomplete chunks of input or write padding.\n    /// # Errors\n    ///\n    /// The first error that is not of [`ErrorKind::Interrupted`] will be returned.\n    fn flush(&mut self) -> Result<()> {\n        self.write_all_encoded_output()?;\n        self.delegate\n            .as_mut()\n            .expect(\"Writer must be present\")\n            .flush()\n    }\n}"],"write::encoder_string_writer::EncoderStringWriter":["impl<'e, E: Engine, S: StrConsumer> EncoderStringWriter<'e, E, S> {\n    /// Create a `EncoderStringWriter` that will append to the provided `StrConsumer`.\n    pub fn from_consumer(str_consumer: S, engine: &'e E) -> Self {\n        EncoderStringWriter {\n            encoder: EncoderWriter::new(Utf8SingleCodeUnitWriter { str_consumer }, engine),\n        }\n    }\n\n    /// Encode all remaining buffered data, including any trailing incomplete input triples and\n    /// associated padding.\n    ///\n    /// Returns the base64-encoded form of the accumulated written data.\n    pub fn into_inner(mut self) -> S {\n        self.encoder\n            .finish()\n            .expect(\"Writing to a consumer should never fail\")\n            .str_consumer\n    }\n}","impl<'e, E: Engine, S: StrConsumer> io::Write for EncoderStringWriter<'e, E, S> {\n    fn write(&mut self, buf: &[u8]) -> io::Result<usize> {\n        self.encoder.write(buf)\n    }\n\n    fn flush(&mut self) -> io::Result<()> {\n        self.encoder.flush()\n    }\n}","impl<'e, E: Engine> EncoderStringWriter<'e, E, String> {\n    /// Create a `EncoderStringWriter` that will encode into a new `String` with the provided config.\n    pub fn new(engine: &'e E) -> Self {\n        EncoderStringWriter::from_consumer(String::new(), engine)\n    }\n}"],"write::encoder_string_writer::Utf8SingleCodeUnitWriter":["impl<S: StrConsumer> io::Write for Utf8SingleCodeUnitWriter<S> {\n    fn write(&mut self, buf: &[u8]) -> io::Result<usize> {\n        // Because we expect all input to be valid utf-8 individual bytes, we can encode any buffer\n        // length\n        let s = std::str::from_utf8(buf).expect(\"Input must be valid UTF-8\");\n\n        self.str_consumer.consume(s);\n\n        Ok(buf.len())\n    }\n\n    fn flush(&mut self) -> io::Result<()> {\n        // no op\n        Ok(())\n    }\n}"]},"single_path_import":{"decode::DecodeError":"DecodeError","decode::DecodeSliceError":"DecodeSliceError","decode::decode":"decode","decode::decode_engine":"decode_engine","decode::decode_engine_slice":"decode_engine_slice","decode::decode_engine_vec":"decode_engine_vec","decode::decoded_len_estimate":"decoded_len_estimate","encode::EncodeSliceError":"EncodeSliceError","encode::encode":"encode","encode::encode_engine":"encode_engine","encode::encode_engine_slice":"encode_engine_slice","encode::encode_engine_string":"encode_engine_string","encode::encoded_len":"encoded_len","engine::Engine":"prelude::Engine","engine::general_purpose::GeneralPurpose":"engine::GeneralPurpose","engine::general_purpose::GeneralPurposeConfig":"engine::GeneralPurposeConfig","engine::general_purpose::STANDARD":"prelude::STANDARD","engine::general_purpose::STANDARD_NO_PAD":"prelude::STANDARD_NO_PAD","engine::general_purpose::URL_SAFE":"prelude::URL_SAFE","engine::general_purpose::URL_SAFE_NO_PAD":"prelude::URL_SAFE_NO_PAD","engine::general_purpose::decode::GeneralPurposeEstimate":"engine::general_purpose::GeneralPurposeEstimate","read::decoder::DecoderReader":"read::DecoderReader","write::encoder::EncoderWriter":"write::EncoderWriter","write::encoder_string_writer::EncoderStringWriter":"write::EncoderStringWriter","write::encoder_string_writer::StrConsumer":"write::StrConsumer"},"srcs":{"<&mut S as write::encoder_string_writer::StrConsumer>::consume":["fn consume(&mut self, buf: &str){\n        (**self).consume(buf);\n    }","Real(LocalPath(\"src/write/encoder_string_writer.rs\"))"],"<alphabet::Alphabet as std::convert::TryFrom<&str>>::try_from":["fn try_from(value: &str) -> Result<Self, Self::Error>{\n        Self::new(value)\n    }","Real(LocalPath(\"src/alphabet.rs\"))"],"<alphabet::ParseAlphabetError as std::fmt::Display>::fmt":["fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result{\n        match self {\n            Self::InvalidLength => write!(f, \"Invalid length - must be 64 bytes\"),\n            Self::DuplicatedByte(b) => write!(f, \"Duplicated byte: {:#04x}\", b),\n            Self::UnprintableByte(b) => write!(f, \"Unprintable byte: {:#04x}\", b),\n            Self::ReservedByte(b) => write!(f, \"Reserved byte: {:#04x}\", b),\n        }\n    }","Real(LocalPath(\"src/alphabet.rs\"))"],"<chunked_encoder::StringSink<'a> as chunked_encoder::Sink>::write_encoded_bytes":["fn write_encoded_bytes(&mut self, s: &[u8]) -> Result<(), Self::Error>{\n        self.string.push_str(str::from_utf8(s).unwrap());\n\n        Ok(())\n    }","Real(LocalPath(\"src/chunked_encoder.rs\"))"],"<decode::DecodeError as std::fmt::Display>::fmt":["fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result{\n        match *self {\n            Self::InvalidByte(index, byte) => {\n                write!(f, \"Invalid symbol {}, offset {}.\", byte, index)\n            }\n            Self::InvalidLength(len) => write!(f, \"Invalid input length: {}\", len),\n            Self::InvalidLastSymbol(index, byte) => {\n                write!(f, \"Invalid last symbol {}, offset {}.\", byte, index)\n            }\n            Self::InvalidPadding => write!(f, \"Invalid padding\"),\n        }\n    }","Real(LocalPath(\"src/decode.rs\"))"],"<decode::DecodeSliceError as std::convert::From<decode::DecodeError>>::from":["fn from(e: DecodeError) -> Self{\n        DecodeSliceError::DecodeError(e)\n    }","Real(LocalPath(\"src/decode.rs\"))"],"<decode::DecodeSliceError as std::error::Error>::source":["fn source(&self) -> Option<&(dyn error::Error + 'static)>{\n        match self {\n            DecodeSliceError::DecodeError(e) => Some(e),\n            DecodeSliceError::OutputSliceTooSmall => None,\n        }\n    }","Real(LocalPath(\"src/decode.rs\"))"],"<decode::DecodeSliceError as std::fmt::Display>::fmt":["fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result{\n        match self {\n            Self::DecodeError(e) => write!(f, \"DecodeError: {}\", e),\n            Self::OutputSliceTooSmall => write!(f, \"Output slice too small\"),\n        }\n    }","Real(LocalPath(\"src/decode.rs\"))"],"<display::Base64Display<'a, 'e, E> as std::fmt::Display>::fmt":["fn fmt(&self, formatter: &mut Formatter) -> Result<(), fmt::Error>{\n        let mut sink = FormatterSink { f: formatter };\n        self.chunked_encoder.encode(self.bytes, &mut sink)\n    }","Real(LocalPath(\"src/display.rs\"))"],"<display::FormatterSink<'a, 'b> as chunked_encoder::Sink>::write_encoded_bytes":["fn write_encoded_bytes(&mut self, encoded: &[u8]) -> Result<(), Self::Error>{\n        // Avoid unsafe. If max performance is needed, write your own display wrapper that uses\n        // unsafe here to gain about 10-15%.\n        self.f\n            .write_str(str::from_utf8(encoded).expect(\"base64 data was not utf8\"))\n    }","Real(LocalPath(\"src/display.rs\"))"],"<encode::EncodeSliceError as std::fmt::Display>::fmt":["fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result{\n        match self {\n            Self::OutputSliceTooSmall => write!(f, \"Output slice too small\"),\n        }\n    }","Real(LocalPath(\"src/encode.rs\"))"],"<engine::general_purpose::GeneralPurpose as engine::Engine>::config":["fn config(&self) -> &Self::Config{\n        &self.config\n    }","Real(LocalPath(\"src/engine/general_purpose/mod.rs\"))"],"<engine::general_purpose::GeneralPurpose as engine::Engine>::internal_decode":["fn internal_decode(\n        &self,\n        input: &[u8],\n        output: &mut [u8],\n        estimate: Self::DecodeEstimate,\n    ) -> Result<DecodeMetadata, DecodeSliceError>{\n        decode::decode_helper(\n            input,\n            &estimate,\n            output,\n            &self.decode_table,\n            self.config.decode_allow_trailing_bits,\n            self.config.decode_padding_mode,\n        )\n    }","Real(LocalPath(\"src/engine/general_purpose/mod.rs\"))"],"<engine::general_purpose::GeneralPurpose as engine::Engine>::internal_decoded_len_estimate":["fn internal_decoded_len_estimate(&self, input_len: usize) -> Self::DecodeEstimate{\n        GeneralPurposeEstimate::new(input_len)\n    }","Real(LocalPath(\"src/engine/general_purpose/mod.rs\"))"],"<engine::general_purpose::GeneralPurpose as engine::Engine>::internal_encode":["fn internal_encode(&self, input: &[u8], output: &mut [u8]) -> usize{\n        let mut input_index: usize = 0;\n\n        const BLOCKS_PER_FAST_LOOP: usize = 4;\n        const LOW_SIX_BITS: u64 = 0x3F;\n\n        // we read 8 bytes at a time (u64) but only actually consume 6 of those bytes. Thus, we need\n        // 2 trailing bytes to be available to read..\n        let last_fast_index = input.len().saturating_sub(BLOCKS_PER_FAST_LOOP * 6 + 2);\n        let mut output_index = 0;\n\n        if last_fast_index > 0 {\n            while input_index <= last_fast_index {\n                // Major performance wins from letting the optimizer do the bounds check once, mostly\n                // on the output side\n                let input_chunk =\n                    &input[input_index..(input_index + (BLOCKS_PER_FAST_LOOP * 6 + 2))];\n                let output_chunk =\n                    &mut output[output_index..(output_index + BLOCKS_PER_FAST_LOOP * 8)];\n\n                // Hand-unrolling for 32 vs 16 or 8 bytes produces yields performance about equivalent\n                // to unsafe pointer code on a Xeon E5-1650v3. 64 byte unrolling was slightly better for\n                // large inputs but significantly worse for 50-byte input, unsurprisingly. I suspect\n                // that it's a not uncommon use case to encode smallish chunks of data (e.g. a 64-byte\n                // SHA-512 digest), so it would be nice if that fit in the unrolled loop at least once.\n                // Plus, single-digit percentage performance differences might well be quite different\n                // on different hardware.\n\n                let input_u64 = read_u64(&input_chunk[0..]);\n\n                output_chunk[0] = self.encode_table[((input_u64 >> 58) & LOW_SIX_BITS) as usize];\n                output_chunk[1] = self.encode_table[((input_u64 >> 52) & LOW_SIX_BITS) as usize];\n                output_chunk[2] = self.encode_table[((input_u64 >> 46) & LOW_SIX_BITS) as usize];\n                output_chunk[3] = self.encode_table[((input_u64 >> 40) & LOW_SIX_BITS) as usize];\n                output_chunk[4] = self.encode_table[((input_u64 >> 34) & LOW_SIX_BITS) as usize];\n                output_chunk[5] = self.encode_table[((input_u64 >> 28) & LOW_SIX_BITS) as usize];\n                output_chunk[6] = self.encode_table[((input_u64 >> 22) & LOW_SIX_BITS) as usize];\n                output_chunk[7] = self.encode_table[((input_u64 >> 16) & LOW_SIX_BITS) as usize];\n\n                let input_u64 = read_u64(&input_chunk[6..]);\n\n                output_chunk[8] = self.encode_table[((input_u64 >> 58) & LOW_SIX_BITS) as usize];\n                output_chunk[9] = self.encode_table[((input_u64 >> 52) & LOW_SIX_BITS) as usize];\n                output_chunk[10] = self.encode_table[((input_u64 >> 46) & LOW_SIX_BITS) as usize];\n                output_chunk[11] = self.encode_table[((input_u64 >> 40) & LOW_SIX_BITS) as usize];\n                output_chunk[12] = self.encode_table[((input_u64 >> 34) & LOW_SIX_BITS) as usize];\n                output_chunk[13] = self.encode_table[((input_u64 >> 28) & LOW_SIX_BITS) as usize];\n                output_chunk[14] = self.encode_table[((input_u64 >> 22) & LOW_SIX_BITS) as usize];\n                output_chunk[15] = self.encode_table[((input_u64 >> 16) & LOW_SIX_BITS) as usize];\n\n                let input_u64 = read_u64(&input_chunk[12..]);\n\n                output_chunk[16] = self.encode_table[((input_u64 >> 58) & LOW_SIX_BITS) as usize];\n                output_chunk[17] = self.encode_table[((input_u64 >> 52) & LOW_SIX_BITS) as usize];\n                output_chunk[18] = self.encode_table[((input_u64 >> 46) & LOW_SIX_BITS) as usize];\n                output_chunk[19] = self.encode_table[((input_u64 >> 40) & LOW_SIX_BITS) as usize];\n                output_chunk[20] = self.encode_table[((input_u64 >> 34) & LOW_SIX_BITS) as usize];\n                output_chunk[21] = self.encode_table[((input_u64 >> 28) & LOW_SIX_BITS) as usize];\n                output_chunk[22] = self.encode_table[((input_u64 >> 22) & LOW_SIX_BITS) as usize];\n                output_chunk[23] = self.encode_table[((input_u64 >> 16) & LOW_SIX_BITS) as usize];\n\n                let input_u64 = read_u64(&input_chunk[18..]);\n\n                output_chunk[24] = self.encode_table[((input_u64 >> 58) & LOW_SIX_BITS) as usize];\n                output_chunk[25] = self.encode_table[((input_u64 >> 52) & LOW_SIX_BITS) as usize];\n                output_chunk[26] = self.encode_table[((input_u64 >> 46) & LOW_SIX_BITS) as usize];\n                output_chunk[27] = self.encode_table[((input_u64 >> 40) & LOW_SIX_BITS) as usize];\n                output_chunk[28] = self.encode_table[((input_u64 >> 34) & LOW_SIX_BITS) as usize];\n                output_chunk[29] = self.encode_table[((input_u64 >> 28) & LOW_SIX_BITS) as usize];\n                output_chunk[30] = self.encode_table[((input_u64 >> 22) & LOW_SIX_BITS) as usize];\n                output_chunk[31] = self.encode_table[((input_u64 >> 16) & LOW_SIX_BITS) as usize];\n\n                output_index += BLOCKS_PER_FAST_LOOP * 8;\n                input_index += BLOCKS_PER_FAST_LOOP * 6;\n            }\n        }\n\n        // Encode what's left after the fast loop.\n\n        const LOW_SIX_BITS_U8: u8 = 0x3F;\n\n        let rem = input.len() % 3;\n        let start_of_rem = input.len() - rem;\n\n        // start at the first index not handled by fast loop, which may be 0.\n\n        while input_index < start_of_rem {\n            let input_chunk = &input[input_index..(input_index + 3)];\n            let output_chunk = &mut output[output_index..(output_index + 4)];\n\n            output_chunk[0] = self.encode_table[(input_chunk[0] >> 2) as usize];\n            output_chunk[1] = self.encode_table\n                [((input_chunk[0] << 4 | input_chunk[1] >> 4) & LOW_SIX_BITS_U8) as usize];\n            output_chunk[2] = self.encode_table\n                [((input_chunk[1] << 2 | input_chunk[2] >> 6) & LOW_SIX_BITS_U8) as usize];\n            output_chunk[3] = self.encode_table[(input_chunk[2] & LOW_SIX_BITS_U8) as usize];\n\n            input_index += 3;\n            output_index += 4;\n        }\n\n        if rem == 2 {\n            output[output_index] = self.encode_table[(input[start_of_rem] >> 2) as usize];\n            output[output_index + 1] =\n                self.encode_table[((input[start_of_rem] << 4 | input[start_of_rem + 1] >> 4)\n                    & LOW_SIX_BITS_U8) as usize];\n            output[output_index + 2] =\n                self.encode_table[((input[start_of_rem + 1] << 2) & LOW_SIX_BITS_U8) as usize];\n            output_index += 3;\n        } else if rem == 1 {\n            output[output_index] = self.encode_table[(input[start_of_rem] >> 2) as usize];\n            output[output_index + 1] =\n                self.encode_table[((input[start_of_rem] << 4) & LOW_SIX_BITS_U8) as usize];\n            output_index += 2;\n        }\n\n        output_index\n    }","Real(LocalPath(\"src/engine/general_purpose/mod.rs\"))"],"<engine::general_purpose::GeneralPurposeConfig as engine::Config>::encode_padding":["fn encode_padding(&self) -> bool{\n        self.encode_padding\n    }","Real(LocalPath(\"src/engine/general_purpose/mod.rs\"))"],"<engine::general_purpose::GeneralPurposeConfig as std::default::Default>::default":["/// Delegates to [`GeneralPurposeConfig::new`].\nfn default() -> Self{\n        Self::new()\n    }","Real(LocalPath(\"src/engine/general_purpose/mod.rs\"))"],"<engine::general_purpose::decode::GeneralPurposeEstimate as engine::DecodeEstimate>::decoded_len_estimate":["fn decoded_len_estimate(&self) -> usize{\n        self.conservative_decoded_len\n    }","Real(LocalPath(\"src/engine/general_purpose/decode.rs\"))"],"<read::decoder::DecoderReader<'e, E, R> as std::fmt::Debug>::fmt":["fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result{\n        f.debug_struct(\"DecoderReader\")\n            .field(\"b64_offset\", &self.b64_offset)\n            .field(\"b64_len\", &self.b64_len)\n            .field(\"decoded_chunk_buffer\", &self.decoded_chunk_buffer)\n            .field(\"decoded_offset\", &self.decoded_offset)\n            .field(\"decoded_len\", &self.decoded_len)\n            .field(\"input_consumed_len\", &self.input_consumed_len)\n            .field(\"padding_offset\", &self.padding_offset)\n            .finish()\n    }","Real(LocalPath(\"src/read/decoder.rs\"))"],"<read::decoder::DecoderReader<'e, E, R> as std::io::Read>::read":["/// Decode input from the wrapped reader.\n///\n/// Under non-error circumstances, this returns `Ok` with the value being the number of bytes\n/// written in `buf`.\n///\n/// Where possible, this function buffers base64 to minimize the number of `read()` calls to the\n/// delegate reader.\n///\n/// # Errors\n///\n/// Any errors emitted by the delegate reader are returned. Decoding errors due to invalid\n/// base64 are also possible, and will have `io::ErrorKind::InvalidData`.\nfn read(&mut self, buf: &mut [u8]) -> io::Result<usize>{\n        if buf.is_empty() {\n            return Ok(0);\n        }\n\n        // offset == BUF_SIZE when we copied it all last time\n        debug_assert!(self.b64_offset <= BUF_SIZE);\n        debug_assert!(self.b64_offset + self.b64_len <= BUF_SIZE);\n        debug_assert!(if self.b64_offset == BUF_SIZE {\n            self.b64_len == 0\n        } else {\n            self.b64_len <= BUF_SIZE\n        });\n\n        debug_assert!(if self.decoded_len == 0 {\n            // can be = when we were able to copy the complete chunk\n            self.decoded_offset <= DECODED_CHUNK_SIZE\n        } else {\n            self.decoded_offset < DECODED_CHUNK_SIZE\n        });\n\n        // We shouldn't ever decode into decoded_buffer when we can't immediately write at least one\n        // byte into the provided buf, so the effective length should only be 3 momentarily between\n        // when we decode and when we copy into the target buffer.\n        debug_assert!(self.decoded_len < DECODED_CHUNK_SIZE);\n        debug_assert!(self.decoded_len + self.decoded_offset <= DECODED_CHUNK_SIZE);\n\n        if self.decoded_len > 0 {\n            // we have a few leftover decoded bytes; flush that rather than pull in more b64\n            self.flush_decoded_buf(buf)\n        } else {\n            let mut at_eof = false;\n            while self.b64_len < BASE64_CHUNK_SIZE {\n                // Copy any bytes we have to the start of the buffer.\n                self.b64_buffer\n                    .copy_within(self.b64_offset..self.b64_offset + self.b64_len, 0);\n                self.b64_offset = 0;\n\n                // then fill in more data\n                let read = self.read_from_delegate()?;\n                if read == 0 {\n                    // we never read into an empty buf, so 0 => we've hit EOF\n                    at_eof = true;\n                    break;\n                }\n            }\n\n            if self.b64_len == 0 {\n                debug_assert!(at_eof);\n                // we must be at EOF, and we have no data left to decode\n                return Ok(0);\n            };\n\n            debug_assert!(if at_eof {\n                // if we are at eof, we may not have a complete chunk\n                self.b64_len > 0\n            } else {\n                // otherwise, we must have at least one chunk\n                self.b64_len >= BASE64_CHUNK_SIZE\n            });\n\n            debug_assert_eq!(0, self.decoded_len);\n\n            if buf.len() < DECODED_CHUNK_SIZE {\n                // caller requested an annoyingly short read\n                // have to write to a tmp buf first to avoid double mutable borrow\n                let mut decoded_chunk = [0_u8; DECODED_CHUNK_SIZE];\n                // if we are at eof, could have less than BASE64_CHUNK_SIZE, in which case we have\n                // to assume that these last few tokens are, in fact, valid (i.e. must be 2-4 b64\n                // tokens, not 1, since 1 token can't decode to 1 byte).\n                let to_decode = cmp::min(self.b64_len, BASE64_CHUNK_SIZE);\n\n                let decoded = self.decode_to_buf(to_decode, &mut decoded_chunk[..])?;\n                self.decoded_chunk_buffer[..decoded].copy_from_slice(&decoded_chunk[..decoded]);\n\n                self.decoded_offset = 0;\n                self.decoded_len = decoded;\n\n                // can be less than 3 on last block due to padding\n                debug_assert!(decoded <= 3);\n\n                self.flush_decoded_buf(buf)\n            } else {\n                let b64_bytes_that_can_decode_into_buf = (buf.len() / DECODED_CHUNK_SIZE)\n                    .checked_mul(BASE64_CHUNK_SIZE)\n                    .expect(\"too many chunks\");\n                debug_assert!(b64_bytes_that_can_decode_into_buf >= BASE64_CHUNK_SIZE);\n\n                let b64_bytes_available_to_decode = if at_eof {\n                    self.b64_len\n                } else {\n                    // only use complete chunks\n                    self.b64_len - self.b64_len % 4\n                };\n\n                let actual_decode_len = cmp::min(\n                    b64_bytes_that_can_decode_into_buf,\n                    b64_bytes_available_to_decode,\n                );\n                self.decode_to_buf(actual_decode_len, buf)\n            }\n        }\n    }","Real(LocalPath(\"src/read/decoder.rs\"))"],"<std::string::String as write::encoder_string_writer::StrConsumer>::consume":["fn consume(&mut self, buf: &str){\n        self.push_str(buf);\n    }","Real(LocalPath(\"src/write/encoder_string_writer.rs\"))"],"<write::encoder::EncoderWriter<'e, E, W> as std::fmt::Debug>::fmt":["fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result{\n        write!(\n            f,\n            \"extra_input: {:?} extra_input_occupied_len:{:?} output[..5]: {:?} output_occupied_len: {:?}\",\n            self.extra_input,\n            self.extra_input_occupied_len,\n            &self.output[0..5],\n            self.output_occupied_len\n        )\n    }","Real(LocalPath(\"src/write/encoder.rs\"))"],"<write::encoder::EncoderWriter<'e, E, W> as std::io::Write>::flush":["/// Because this is usually treated as OK to call multiple times, it will *not* flush any\n/// incomplete chunks of input or write padding.\n/// # Errors\n///\n/// The first error that is not of [`ErrorKind::Interrupted`] will be returned.\nfn flush(&mut self) -> Result<()>{\n        self.write_all_encoded_output()?;\n        self.delegate\n            .as_mut()\n            .expect(\"Writer must be present\")\n            .flush()\n    }","Real(LocalPath(\"src/write/encoder.rs\"))"],"<write::encoder::EncoderWriter<'e, E, W> as std::io::Write>::write":["/// Encode input and then write to the delegate writer.\n///\n/// Under non-error circumstances, this returns `Ok` with the value being the number of bytes\n/// of `input` consumed. The value may be `0`, which interacts poorly with `write_all`, which\n/// interprets `Ok(0)` as an error, despite it being allowed by the contract of `write`. See\n/// <https://github.com/rust-lang/rust/issues/56889> for more on that.\n///\n/// If the previous call to `write` provided more (encoded) data than the delegate writer could\n/// accept in a single call to its `write`, the remaining data is buffered. As long as buffered\n/// data is present, subsequent calls to `write` will try to write the remaining buffered data\n/// to the delegate and return either `Ok(0)` -- and therefore not consume any of `input` -- or\n/// an error.\n///\n/// # Errors\n///\n/// Any errors emitted by the delegate writer are returned.\nfn write(&mut self, input: &[u8]) -> Result<usize>{\n        assert!(\n            self.delegate.is_some(),\n            \"Cannot write more after calling finish()\"\n        );\n\n        if input.is_empty() {\n            return Ok(0);\n        }\n\n        // The contract of `Write::write` places some constraints on this implementation:\n        // - a call to `write()` represents at most one call to a wrapped `Write`, so we can't\n        // iterate over the input and encode multiple chunks.\n        // - Errors mean that \"no bytes were written to this writer\", so we need to reset the\n        // internal state to what it was before the error occurred\n\n        // before reading any input, write any leftover encoded output from last time\n        if self.output_occupied_len > 0 {\n            let current_len = self.output_occupied_len;\n            return self\n                .write_to_delegate(current_len)\n                // did not read any input\n                .map(|()| 0);\n        }\n\n        debug_assert_eq!(0, self.output_occupied_len);\n\n        // how many bytes, if any, were read into `extra` to create a triple to encode\n        let mut extra_input_read_len = 0;\n        let mut input = input;\n\n        let orig_extra_len = self.extra_input_occupied_len;\n\n        let mut encoded_size = 0;\n        // always a multiple of MIN_ENCODE_CHUNK_SIZE\n        let mut max_input_len = MAX_INPUT_LEN;\n\n        // process leftover un-encoded input from last write\n        if self.extra_input_occupied_len > 0 {\n            debug_assert!(self.extra_input_occupied_len < 3);\n            if input.len() + self.extra_input_occupied_len >= MIN_ENCODE_CHUNK_SIZE {\n                // Fill up `extra`, encode that into `output`, and consume as much of the rest of\n                // `input` as possible.\n                // We could write just the encoding of `extra` by itself but then we'd have to\n                // return after writing only 4 bytes, which is inefficient if the underlying writer\n                // would make a syscall.\n                extra_input_read_len = MIN_ENCODE_CHUNK_SIZE - self.extra_input_occupied_len;\n                debug_assert!(extra_input_read_len > 0);\n                // overwrite only bytes that weren't already used. If we need to rollback extra_len\n                // (when the subsequent write errors), the old leading bytes will still be there.\n                self.extra_input[self.extra_input_occupied_len..MIN_ENCODE_CHUNK_SIZE]\n                    .copy_from_slice(&input[0..extra_input_read_len]);\n\n                let len = self.engine.internal_encode(\n                    &self.extra_input[0..MIN_ENCODE_CHUNK_SIZE],\n                    &mut self.output[..],\n                );\n                debug_assert_eq!(4, len);\n\n                input = &input[extra_input_read_len..];\n\n                // consider extra to be used up, since we encoded it\n                self.extra_input_occupied_len = 0;\n                // don't clobber where we just encoded to\n                encoded_size = 4;\n                // and don't read more than can be encoded\n                max_input_len = MAX_INPUT_LEN - MIN_ENCODE_CHUNK_SIZE;\n\n            // fall through to normal encoding\n            } else {\n                // `extra` and `input` are non empty, but `|extra| + |input| < 3`, so there must be\n                // 1 byte in each.\n                debug_assert_eq!(1, input.len());\n                debug_assert_eq!(1, self.extra_input_occupied_len);\n\n                self.extra_input[self.extra_input_occupied_len] = input[0];\n                self.extra_input_occupied_len += 1;\n                return Ok(1);\n            };\n        } else if input.len() < MIN_ENCODE_CHUNK_SIZE {\n            // `extra` is empty, and `input` fits inside it\n            self.extra_input[0..input.len()].copy_from_slice(input);\n            self.extra_input_occupied_len = input.len();\n            return Ok(input.len());\n        };\n\n        // either 0 or 1 complete chunks encoded from extra\n        debug_assert!(encoded_size == 0 || encoded_size == 4);\n        debug_assert!(\n            // didn't encode extra input\n            MAX_INPUT_LEN == max_input_len\n                // encoded one triple\n                || MAX_INPUT_LEN == max_input_len + MIN_ENCODE_CHUNK_SIZE\n        );\n\n        // encode complete triples only\n        let input_complete_chunks_len = input.len() - (input.len() % MIN_ENCODE_CHUNK_SIZE);\n        let input_chunks_to_encode_len = cmp::min(input_complete_chunks_len, max_input_len);\n        debug_assert_eq!(0, max_input_len % MIN_ENCODE_CHUNK_SIZE);\n        debug_assert_eq!(0, input_chunks_to_encode_len % MIN_ENCODE_CHUNK_SIZE);\n\n        encoded_size += self.engine.internal_encode(\n            &input[..(input_chunks_to_encode_len)],\n            &mut self.output[encoded_size..],\n        );\n\n        // not updating `self.output_occupied_len` here because if the below write fails, it should\n        // \"never take place\" -- the buffer contents we encoded are ignored and perhaps retried\n        // later, if the consumer chooses.\n\n        self.write_to_delegate(encoded_size)\n            // no matter whether we wrote the full encoded buffer or not, we consumed the same\n            // input\n            .map(|()| extra_input_read_len + input_chunks_to_encode_len)\n            .map_err(|e| {\n                // in case we filled and encoded `extra`, reset extra_len\n                self.extra_input_occupied_len = orig_extra_len;\n\n                e\n            })\n    }","Real(LocalPath(\"src/write/encoder.rs\"))"],"<write::encoder::EncoderWriter<'e, E, W> as std::ops::Drop>::drop":["fn drop(&mut self){\n        if !self.panicked {\n            // like `BufWriter`, ignore errors during drop\n            let _ = self.write_final_leftovers();\n        }\n    }","Real(LocalPath(\"src/write/encoder.rs\"))"],"<write::encoder_string_writer::EncoderStringWriter<'e, E, S> as std::io::Write>::flush":["fn flush(&mut self) -> io::Result<()>{\n        self.encoder.flush()\n    }","Real(LocalPath(\"src/write/encoder_string_writer.rs\"))"],"<write::encoder_string_writer::EncoderStringWriter<'e, E, S> as std::io::Write>::write":["fn write(&mut self, buf: &[u8]) -> io::Result<usize>{\n        self.encoder.write(buf)\n    }","Real(LocalPath(\"src/write/encoder_string_writer.rs\"))"],"<write::encoder_string_writer::Utf8SingleCodeUnitWriter<S> as std::io::Write>::flush":["fn flush(&mut self) -> io::Result<()>{\n        // no op\n        Ok(())\n    }","Real(LocalPath(\"src/write/encoder_string_writer.rs\"))"],"<write::encoder_string_writer::Utf8SingleCodeUnitWriter<S> as std::io::Write>::write":["fn write(&mut self, buf: &[u8]) -> io::Result<usize>{\n        // Because we expect all input to be valid utf-8 individual bytes, we can encode any buffer\n        // length\n        let s = std::str::from_utf8(buf).expect(\"Input must be valid UTF-8\");\n\n        self.str_consumer.consume(s);\n\n        Ok(buf.len())\n    }","Real(LocalPath(\"src/write/encoder_string_writer.rs\"))"],"alphabet::Alphabet":["/// An alphabet defines the 64 ASCII characters (symbols) used for base64.\n///\n/// Common alphabets are provided as constants, and custom alphabets\n/// can be made via `from_str` or the `TryFrom<str>` implementation.\n///\n/// # Examples\n///\n/// Building and using a custom Alphabet:\n///\n/// ```\n/// let custom = base64::alphabet::Alphabet::new(\"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/\").unwrap();\n///\n/// let engine = base64::engine::GeneralPurpose::new(\n///     &custom,\n///     base64::engine::general_purpose::PAD);\n/// ```\n///\n/// Building a const:\n///\n/// ```\n/// use base64::alphabet::Alphabet;\n///\n/// static CUSTOM: Alphabet = {\n///     // Result::unwrap() isn't const yet, but panic!() is OK\n///     match Alphabet::new(\"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/\") {\n///         Ok(x) => x,\n///         Err(_) => panic!(\"creation of alphabet failed\"),\n///     }\n/// };\n/// ```\n///\n/// Building lazily:\n///\n/// ```\n/// use base64::{\n///     alphabet::Alphabet,\n///     engine::{general_purpose::GeneralPurpose, GeneralPurposeConfig},\n/// };\n/// use once_cell::sync::Lazy;\n///\n/// static CUSTOM: Lazy<Alphabet> = Lazy::new(||\n///     Alphabet::new(\"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/\").unwrap()\n/// );\n/// ```\npub struct Alphabet {\n    pub(crate) symbols: [u8; ALPHABET_SIZE],\n}","Real(LocalPath(\"src/alphabet.rs\"))"],"alphabet::Alphabet::as_str":["/// Create a `&str` from the symbols in the `Alphabet`\n#[must_use]\npub fn as_str(&self) -> &str{\n        core::str::from_utf8(&self.symbols).unwrap()\n    }","Real(LocalPath(\"src/alphabet.rs\"))"],"alphabet::Alphabet::from_str_unchecked":["/// Performs no checks so that it can be const.\n/// Used only for known-valid strings.\nconst fn from_str_unchecked(alphabet: &str) -> Self{\n        let mut symbols = [0_u8; ALPHABET_SIZE];\n        let source_bytes = alphabet.as_bytes();\n\n        // a way to copy that's allowed in const fn\n        let mut index = 0;\n        while index < ALPHABET_SIZE {\n            symbols[index] = source_bytes[index];\n            index += 1;\n        }\n\n        Self { symbols }\n    }","Real(LocalPath(\"src/alphabet.rs\"))"],"alphabet::Alphabet::new":["/// Create an `Alphabet` from a string of 64 unique printable ASCII bytes.\n///\n/// The `=` byte is not allowed as it is used for padding.\npub const fn new(alphabet: &str) -> Result<Self, ParseAlphabetError>{\n        let bytes = alphabet.as_bytes();\n        if bytes.len() != ALPHABET_SIZE {\n            return Err(ParseAlphabetError::InvalidLength);\n        }\n\n        {\n            let mut index = 0;\n            while index < ALPHABET_SIZE {\n                let byte = bytes[index];\n\n                // must be ascii printable. 127 (DEL) is commonly considered printable\n                // for some reason but clearly unsuitable for base64.\n                if !(byte >= 32_u8 && byte <= 126_u8) {\n                    return Err(ParseAlphabetError::UnprintableByte(byte));\n                }\n                // = is assumed to be padding, so cannot be used as a symbol\n                if byte == PAD_BYTE {\n                    return Err(ParseAlphabetError::ReservedByte(byte));\n                }\n\n                // Check for duplicates while staying within what const allows.\n                // It's n^2, but only over 64 hot bytes, and only once, so it's likely in the single digit\n                // microsecond range.\n\n                let mut probe_index = 0;\n                while probe_index < ALPHABET_SIZE {\n                    if probe_index == index {\n                        probe_index += 1;\n                        continue;\n                    }\n\n                    let probe_byte = bytes[probe_index];\n\n                    if byte == probe_byte {\n                        return Err(ParseAlphabetError::DuplicatedByte(byte));\n                    }\n\n                    probe_index += 1;\n                }\n\n                index += 1;\n            }\n        }\n\n        Ok(Self::from_str_unchecked(alphabet))\n    }","Real(LocalPath(\"src/alphabet.rs\"))"],"alphabet::ParseAlphabetError":["/// Possible errors when constructing an [Alphabet] from a `str`.\npub enum ParseAlphabetError {\n    /// Alphabets must be 64 ASCII bytes\n    InvalidLength,\n    /// All bytes must be unique\n    DuplicatedByte(u8),\n    /// All bytes must be printable (in the range `[32, 126]`).\n    UnprintableByte(u8),\n    /// `=` cannot be used\n    ReservedByte(u8),\n}","Real(LocalPath(\"src/alphabet.rs\"))"],"chunked_encoder::ChunkedEncoder":["/// A base64 encoder that emits encoded bytes in chunks without heap allocation.\npub struct ChunkedEncoder<'e, E: Engine + ?Sized> {\n    engine: &'e E,\n}","Real(LocalPath(\"src/chunked_encoder.rs\"))"],"chunked_encoder::ChunkedEncoder::<'e, E>::encode":["pub fn encode<S: Sink>(&self, bytes: &[u8], sink: &mut S) -> Result<(), S::Error>{\n        const BUF_SIZE: usize = 1024;\n        const CHUNK_SIZE: usize = BUF_SIZE / 4 * 3;\n\n        let mut buf = [0; BUF_SIZE];\n        for chunk in bytes.chunks(CHUNK_SIZE) {\n            let mut len = self.engine.internal_encode(chunk, &mut buf);\n            if chunk.len() != CHUNK_SIZE && self.engine.config().encode_padding() {\n                // Final, potentially partial, chunk.\n                // Only need to consider if padding is needed on a partial chunk since full chunk\n                // is a multiple of 3, which therefore won't be padded.\n                // Pad output to multiple of four bytes if required by config.\n                len += add_padding(len, &mut buf[len..]);\n            }\n            sink.write_encoded_bytes(&buf[..len])?;\n        }\n\n        Ok(())\n    }","Real(LocalPath(\"src/chunked_encoder.rs\"))"],"chunked_encoder::ChunkedEncoder::<'e, E>::new":["pub fn new(engine: &'e E) -> ChunkedEncoder<'e, E>{\n        ChunkedEncoder { engine }\n    }","Real(LocalPath(\"src/chunked_encoder.rs\"))"],"chunked_encoder::Sink":["/// The output mechanism for `ChunkedEncoder`'s encoded bytes.\npub trait Sink {\n    type Error;\n\n    /// Handle a chunk of encoded base64 data (as UTF-8 bytes)\n    fn write_encoded_bytes(&mut self, encoded: &[u8]) -> Result<(), Self::Error>;\n}","Real(LocalPath(\"src/chunked_encoder.rs\"))"],"chunked_encoder::StringSink":["#[cfg(any(feature = \"alloc\", test))]\npub(crate) struct StringSink<'a> {\n    string: &'a mut String,\n}","Real(LocalPath(\"src/chunked_encoder.rs\"))"],"chunked_encoder::StringSink::<'a>::new":["pub(crate) fn new(s: &mut String) -> StringSink{\n        StringSink { string: s }\n    }","Real(LocalPath(\"src/chunked_encoder.rs\"))"],"decode::DecodeError":["/// Errors that can occur while decoding.\npub enum DecodeError {\n    /// An invalid byte was found in the input. The offset and offending byte are provided.\n    ///\n    /// Padding characters (`=`) interspersed in the encoded form are invalid, as they may only\n    /// be present as the last 0-2 bytes of input.\n    ///\n    /// This error may also indicate that extraneous trailing input bytes are present, causing\n    /// otherwise valid padding to no longer be the last bytes of input.\n    InvalidByte(usize, u8),\n    /// The length of the input, as measured in valid base64 symbols, is invalid.\n    /// There must be 2-4 symbols in the last input quad.\n    InvalidLength(usize),\n    /// The last non-padding input symbol's encoded 6 bits have nonzero bits that will be discarded.\n    /// This is indicative of corrupted or truncated Base64.\n    /// Unlike [`DecodeError::InvalidByte`], which reports symbols that aren't in the alphabet,\n    /// this error is for symbols that are in the alphabet but represent nonsensical encodings.\n    InvalidLastSymbol(usize, u8),\n    /// The nature of the padding was not as configured: absent or incorrect when it must be\n    /// canonical, or present when it must be absent, etc.\n    InvalidPadding,\n}","Real(LocalPath(\"src/decode.rs\"))"],"decode::DecodeSliceError":["/// Errors that can occur while decoding into a slice.\npub enum DecodeSliceError {\n    /// A [`DecodeError`] occurred\n    DecodeError(DecodeError),\n    /// The provided slice is too small.\n    OutputSliceTooSmall,\n}","Real(LocalPath(\"src/decode.rs\"))"],"decode::decode":["/// Decode base64 using the [`STANDARD` engine](STANDARD).\n///\n/// See [`Engine::decode`].\n#[deprecated(since = \"0.21.0\", note = \"Use Engine::decode\")]\n#[cfg(any(feature = \"alloc\", test))]\npub fn decode<T: AsRef<[u8]>>(input: T) -> Result<Vec<u8>, DecodeError>{\n    STANDARD.decode(input)\n}","Real(LocalPath(\"src/decode.rs\"))"],"decode::decode_engine":["/// Decode from string reference as octets using the specified [Engine].\n///\n/// See [`Engine::decode`].\n///Returns a `Result` containing a `Vec<u8>`.\n#[deprecated(since = \"0.21.0\", note = \"Use Engine::decode\")]\n#[cfg(any(feature = \"alloc\", test))]\npub fn decode_engine<E: Engine, T: AsRef<[u8]>>(\n    input: T,\n    engine: &E,\n) -> Result<Vec<u8>, DecodeError>{\n    engine.decode(input)\n}","Real(LocalPath(\"src/decode.rs\"))"],"decode::decode_engine_slice":["/// Decode the input into the provided output slice.\n///\n/// See [`Engine::decode_slice`].\n#[deprecated(since = \"0.21.0\", note = \"Use Engine::decode_slice\")]\npub fn decode_engine_slice<E: Engine, T: AsRef<[u8]>>(\n    input: T,\n    output: &mut [u8],\n    engine: &E,\n) -> Result<usize, DecodeSliceError>{\n    engine.decode_slice(input, output)\n}","Real(LocalPath(\"src/decode.rs\"))"],"decode::decode_engine_vec":["/// Decode from string reference as octets.\n///\n/// See [`Engine::decode_vec`].\n#[cfg(any(feature = \"alloc\", test))]\n#[deprecated(since = \"0.21.0\", note = \"Use Engine::decode_vec\")]\npub fn decode_engine_vec<E: Engine, T: AsRef<[u8]>>(\n    input: T,\n    buffer: &mut Vec<u8>,\n    engine: &E,\n) -> Result<(), DecodeError>{\n    engine.decode_vec(input, buffer)\n}","Real(LocalPath(\"src/decode.rs\"))"],"decode::decoded_len_estimate":["/// Returns a conservative estimate of the decoded size of `encoded_len` base64 symbols (rounded up\n/// to the next group of 3 decoded bytes).\n///\n/// The resulting length will be a safe choice for the size of a decode buffer, but may have up to\n/// 2 trailing bytes that won't end up being needed.\n///\n/// # Examples\n///\n/// ```\n/// use base64::decoded_len_estimate;\n///\n/// assert_eq!(3, decoded_len_estimate(1));\n/// assert_eq!(3, decoded_len_estimate(2));\n/// assert_eq!(3, decoded_len_estimate(3));\n/// assert_eq!(3, decoded_len_estimate(4));\n/// // start of the next quad of encoded symbols\n/// assert_eq!(6, decoded_len_estimate(5));\n/// ```\n#[must_use]\npub fn decoded_len_estimate(encoded_len: usize) -> usize{\n    STANDARD\n        .internal_decoded_len_estimate(encoded_len)\n        .decoded_len_estimate()\n}","Real(LocalPath(\"src/decode.rs\"))"],"display::Base64Display":["/// A convenience wrapper for base64'ing bytes into a format string without heap allocation.\npub struct Base64Display<'a, 'e, E: Engine> {\n    bytes: &'a [u8],\n    chunked_encoder: ChunkedEncoder<'e, E>,\n}","Real(LocalPath(\"src/display.rs\"))"],"display::Base64Display::<'a, 'e, E>::new":["/// Create a `Base64Display` with the provided engine.\npub fn new(bytes: &'a [u8], engine: &'e E) -> Base64Display<'a, 'e, E>{\n        Base64Display {\n            bytes,\n            chunked_encoder: ChunkedEncoder::new(engine),\n        }\n    }","Real(LocalPath(\"src/display.rs\"))"],"display::FormatterSink":["struct FormatterSink<'a, 'b: 'a> {\n    f: &'a mut Formatter<'b>,\n}","Real(LocalPath(\"src/display.rs\"))"],"encode::EncodeSliceError":["/// Errors that can occur while encoding into a slice.\npub enum EncodeSliceError {\n    /// The provided slice is too small.\n    OutputSliceTooSmall,\n}","Real(LocalPath(\"src/encode.rs\"))"],"encode::add_padding":["/// Write padding characters.\n/// `unpadded_output_len` is the size of the unpadded but base64 encoded data.\n/// `output` is the slice where padding should be written, of length at least 2.\n///\n/// Returns the number of padding bytes written.\npub(crate) fn add_padding(unpadded_output_len: usize, output: &mut [u8]) -> usize{\n    let pad_bytes = (4 - (unpadded_output_len % 4)) % 4;\n    // for just a couple bytes, this has better performance than using\n    // .fill(), or iterating over mutable refs, which call memset()\n    #[allow(clippy::needless_range_loop)]\n    for i in 0..pad_bytes {\n        output[i] = PAD_BYTE;\n    }\n\n    pad_bytes\n}","Real(LocalPath(\"src/encode.rs\"))"],"encode::encode":["/// Encode arbitrary octets as base64 using the [`STANDARD` engine](STANDARD).\n///\n/// See [`Engine::encode`].\n#[allow(unused)]\n#[deprecated(since = \"0.21.0\", note = \"Use Engine::encode\")]\n#[cfg(any(feature = \"alloc\", test))]\npub fn encode<T: AsRef<[u8]>>(input: T) -> String{\n    STANDARD.encode(input)\n}","Real(LocalPath(\"src/encode.rs\"))"],"encode::encode_engine":["///Encode arbitrary octets as base64 using the provided `Engine` into a new `String`.\n///\n/// See [`Engine::encode`].\n#[allow(unused)]\n#[deprecated(since = \"0.21.0\", note = \"Use Engine::encode\")]\n#[cfg(any(feature = \"alloc\", test))]\npub fn encode_engine<E: Engine, T: AsRef<[u8]>>(input: T, engine: &E) -> String{\n    engine.encode(input)\n}","Real(LocalPath(\"src/encode.rs\"))"],"encode::encode_engine_slice":["/// Encode arbitrary octets as base64 into a supplied slice.\n///\n/// See [`Engine::encode_slice`].\n#[allow(unused)]\n#[deprecated(since = \"0.21.0\", note = \"Use Engine::encode_slice\")]\npub fn encode_engine_slice<E: Engine, T: AsRef<[u8]>>(\n    input: T,\n    output_buf: &mut [u8],\n    engine: &E,\n) -> Result<usize, EncodeSliceError>{\n    engine.encode_slice(input, output_buf)\n}","Real(LocalPath(\"src/encode.rs\"))"],"encode::encode_engine_string":["///Encode arbitrary octets as base64 into a supplied `String`.\n///\n/// See [`Engine::encode_string`].\n#[allow(unused)]\n#[deprecated(since = \"0.21.0\", note = \"Use Engine::encode_string\")]\n#[cfg(any(feature = \"alloc\", test))]\npub fn encode_engine_string<E: Engine, T: AsRef<[u8]>>(\n    input: T,\n    output_buf: &mut String,\n    engine: &E,\n){\n    engine.encode_string(input, output_buf);\n}","Real(LocalPath(\"src/encode.rs\"))"],"encode::encode_with_padding":["/// B64-encode and pad (if configured).\n///\n/// This helper exists to avoid recalculating `encoded_size`, which is relatively expensive on short\n/// inputs.\n///\n/// `encoded_size` is the encoded size calculated for `input`.\n///\n/// `output` must be of size `encoded_size`.\n///\n/// All bytes in `output` will be written to since it is exactly the size of the output.\npub(crate) fn encode_with_padding<E: Engine + ?Sized>(\n    input: &[u8],\n    output: &mut [u8],\n    engine: &E,\n    expected_encoded_size: usize,\n){\n    debug_assert_eq!(expected_encoded_size, output.len());\n\n    let b64_bytes_written = engine.internal_encode(input, output);\n\n    let padding_bytes = if engine.config().encode_padding() {\n        add_padding(b64_bytes_written, &mut output[b64_bytes_written..])\n    } else {\n        0\n    };\n\n    let encoded_bytes = b64_bytes_written\n        .checked_add(padding_bytes)\n        .expect(\"usize overflow when calculating b64 length\");\n\n    debug_assert_eq!(expected_encoded_size, encoded_bytes);\n}","Real(LocalPath(\"src/encode.rs\"))"],"encode::encoded_len":["/// Calculate the base64 encoded length for a given input length, optionally including any\n/// appropriate padding bytes.\n///\n/// Returns `None` if the encoded length can't be represented in `usize`. This will happen for\n/// input lengths in approximately the top quarter of the range of `usize`.\n#[must_use]\npub const fn encoded_len(bytes_len: usize, padding: bool) -> Option<usize>{\n    let rem = bytes_len % 3;\n\n    let complete_input_chunks = bytes_len / 3;\n    // `?` is disallowed in const, and `let Some(_) = _ else` requires 1.65.0, whereas this\n    // messier syntax works on 1.48\n    let complete_chunk_output =\n        if let Some(complete_chunk_output) = complete_input_chunks.checked_mul(4) {\n            complete_chunk_output\n        } else {\n            return None;\n        };\n\n    if rem > 0 {\n        if padding {\n            complete_chunk_output.checked_add(4)\n        } else {\n            let encoded_rem = match rem {\n                1 => 2,\n                // only other possible remainder is 2\n                // can't use a separate _ => unreachable!() in const fns in ancient rust versions\n                _ => 3,\n            };\n            complete_chunk_output.checked_add(encoded_rem)\n        }\n    } else {\n        Some(complete_chunk_output)\n    }\n}","Real(LocalPath(\"src/encode.rs\"))"],"engine::Config":["/// The minimal level of configuration that engines must support.\npub trait Config {\n    /// Returns `true` if padding should be added after the encoded output.\n    ///\n    /// Padding is added outside the engine's `encode()` since the engine may be used\n    /// to encode only a chunk of the overall output, so it can't always know when\n    /// the output is \"done\" and would therefore need padding (if configured).\n    // It could be provided as a separate parameter when encoding, but that feels like\n    // leaking an implementation detail to the user, and it's hopefully more convenient\n    // to have to only pass one thing (the engine) to any part of the API.\n    fn encode_padding(&self) -> bool;\n}","Real(LocalPath(\"src/engine/mod.rs\"))"],"engine::DecodeEstimate":["/// The decode estimate used by an engine implementation. Users do not need to interact with this;\n/// it is only for engine implementors.\n///\n/// Implementors may store relevant data here when constructing this to avoid having to calculate\n/// them again during actual decoding.\npub trait DecodeEstimate {\n    /// Returns a conservative (err on the side of too big) estimate of the decoded length to use\n    /// for pre-allocating buffers, etc.\n    ///\n    /// The estimate must be no larger than the next largest complete triple of decoded bytes.\n    /// That is, the final quad of tokens to decode may be assumed to be complete with no padding.\n    fn decoded_len_estimate(&self) -> usize;\n}","Real(LocalPath(\"src/engine/mod.rs\"))"],"engine::DecodeMetadata":["/// Metadata about the result of a decode operation\npub struct DecodeMetadata {\n    /// Number of decoded bytes output\n    pub(crate) decoded_len: usize,\n    /// Offset of the first padding byte in the input, if any\n    pub(crate) padding_offset: Option<usize>,\n}","Real(LocalPath(\"src/engine/mod.rs\"))"],"engine::DecodeMetadata::new":["pub(crate) fn new(decoded_bytes: usize, padding_index: Option<usize>) -> Self{\n        Self {\n            decoded_len: decoded_bytes,\n            padding_offset: padding_index,\n        }\n    }","Real(LocalPath(\"src/engine/mod.rs\"))"],"engine::DecodePaddingMode":["/// Controls how pad bytes are handled when decoding.\n///\n/// Each [Engine] must support at least the behavior indicated by\n/// [`DecodePaddingMode::RequireCanonical`], and may support other modes.\npub enum DecodePaddingMode {\n    /// Canonical padding is allowed, but any fewer padding bytes than that is also allowed.\n    Indifferent,\n    /// Padding must be canonical (0, 1, or 2 `=` as needed to produce a 4 byte suffix).\n    RequireCanonical,\n    /// Padding must be absent -- for when you want predictable padding, without any wasted bytes.\n    RequireNone,\n}","Real(LocalPath(\"src/engine/mod.rs\"))"],"engine::Engine":["/// An `Engine` provides low-level encoding and decoding operations that all other higher-level parts of the API use. Users of the library will generally not need to implement this.\n///\n/// Different implementations offer different characteristics. The library currently ships with\n/// [`GeneralPurpose`] that offers good speed and works on any CPU, with more choices\n/// coming later, like a constant-time one when side channel resistance is called for, and vendor-specific vectorized ones for more speed.\n///\n/// See [`general_purpose::STANDARD_NO_PAD`] if you just want standard base64. Otherwise, when possible, it's\n/// recommended to store the engine in a `const` so that references to it won't pose any lifetime\n/// issues, and to avoid repeating the cost of engine setup.\n///\n/// Since almost nobody will need to implement `Engine`, docs for internal methods are hidden.\npub trait Engine: Send + Sync {\n    /// The config type used by this engine\n    type Config: Config;\n    /// The decode estimate used by this engine\n    type DecodeEstimate: DecodeEstimate;\n\n    /// This is not meant to be called directly; it is only for `Engine` implementors.\n    /// See the other `encode*` functions on this trait.\n    ///\n    /// Encode the `input` bytes into the `output` buffer based on the mapping in `encode_table`.\n    ///\n    /// `output` will be long enough to hold the encoded data.\n    ///\n    /// Returns the number of bytes written.\n    ///\n    /// No padding should be written; that is handled separately.\n    ///\n    /// Must not write any bytes into the output slice other than the encoded data.\n    #[doc(hidden)]\n    fn internal_encode(&self, input: &[u8], output: &mut [u8]) -> usize;\n\n    /// This is not meant to be called directly; it is only for `Engine` implementors.\n    ///\n    /// As an optimization to prevent the decoded length from being calculated twice, it is\n    /// sometimes helpful to have a conservative estimate of the decoded size before doing the\n    /// decoding, so this calculation is done separately and passed to [Engine::decode()] as needed.\n    #[doc(hidden)]\n    fn internal_decoded_len_estimate(&self, input_len: usize) -> Self::DecodeEstimate;\n\n    /// This is not meant to be called directly; it is only for `Engine` implementors.\n    /// See the other `decode*` functions on this trait.\n    ///\n    /// Decode `input` base64 bytes into the `output` buffer.\n    ///\n    /// `decode_estimate` is the result of [Engine::internal_decoded_len_estimate()], which is passed in to avoid\n    /// calculating it again (expensive on short inputs).`\n    ///\n    /// Each complete 4-byte chunk of encoded data decodes to 3 bytes of decoded data, but this\n    /// function must also handle the final possibly partial chunk.\n    /// If the input length is not a multiple of 4, or uses padding bytes to reach a multiple of 4,\n    /// the trailing 2 or 3 bytes must decode to 1 or 2 bytes, respectively, as per the\n    /// [RFC](https://tools.ietf.org/html/rfc4648#section-3.5).\n    ///\n    /// Decoding must not write any bytes into the output slice other than the decoded data.\n    ///\n    /// Non-canonical trailing bits in the final tokens or non-canonical padding must be reported as\n    /// errors unless the engine is configured otherwise.\n    #[doc(hidden)]\n    fn internal_decode(\n        &self,\n        input: &[u8],\n        output: &mut [u8],\n        decode_estimate: Self::DecodeEstimate,\n    ) -> Result<DecodeMetadata, DecodeSliceError>;\n\n    /// Returns the config for this engine.\n    fn config(&self) -> &Self::Config;\n\n    /// Encode arbitrary octets as base64 using the provided `Engine`.\n    /// Returns a `String`.\n    ///\n    /// # Example\n    ///\n    /// ```rust\n    /// use base64::{Engine as _, engine::{self, general_purpose}, alphabet};\n    ///\n    /// let b64 = general_purpose::STANDARD.encode(b\"hello world~\");\n    /// println!(\"{}\", b64);\n    ///\n    /// const CUSTOM_ENGINE: engine::GeneralPurpose =\n    ///     engine::GeneralPurpose::new(&alphabet::URL_SAFE, general_purpose::NO_PAD);\n    ///\n    /// let b64_url = CUSTOM_ENGINE.encode(b\"hello internet~\");\n    /// ```\n    #[cfg(any(feature = \"alloc\", test))]\n    #[inline]\n    fn encode<T: AsRef<[u8]>>(&self, input: T) -> String {\n        fn inner<E>(engine: &E, input_bytes: &[u8]) -> String\n        where\n            E: Engine + ?Sized,\n        {\n            let encoded_size = encoded_len(input_bytes.len(), engine.config().encode_padding())\n                .expect(\"integer overflow when calculating buffer size\");\n\n            let mut buf = vec![0; encoded_size];\n\n            encode_with_padding(input_bytes, &mut buf[..], engine, encoded_size);\n\n            String::from_utf8(buf).expect(\"Invalid UTF8\")\n        }\n\n        inner(self, input.as_ref())\n    }\n\n    /// Encode arbitrary octets as base64 into a supplied `String`.\n    /// Writes into the supplied `String`, which may allocate if its internal buffer isn't big enough.\n    ///\n    /// # Example\n    ///\n    /// ```rust\n    /// use base64::{Engine as _, engine::{self, general_purpose}, alphabet};\n    /// const CUSTOM_ENGINE: engine::GeneralPurpose =\n    ///     engine::GeneralPurpose::new(&alphabet::URL_SAFE, general_purpose::NO_PAD);\n    ///\n    /// fn main() {\n    ///     let mut buf = String::new();\n    ///     general_purpose::STANDARD.encode_string(b\"hello world~\", &mut buf);\n    ///     println!(\"{}\", buf);\n    ///\n    ///     buf.clear();\n    ///     CUSTOM_ENGINE.encode_string(b\"hello internet~\", &mut buf);\n    ///     println!(\"{}\", buf);\n    /// }\n    /// ```\n    #[cfg(any(feature = \"alloc\", test))]\n    #[inline]\n    fn encode_string<T: AsRef<[u8]>>(&self, input: T, output_buf: &mut String) {\n        fn inner<E>(engine: &E, input_bytes: &[u8], output_buf: &mut String)\n        where\n            E: Engine + ?Sized,\n        {\n            let mut sink = chunked_encoder::StringSink::new(output_buf);\n\n            chunked_encoder::ChunkedEncoder::new(engine)\n                .encode(input_bytes, &mut sink)\n                .expect(\"Writing to a String shouldn't fail\");\n        }\n\n        inner(self, input.as_ref(), output_buf);\n    }\n\n    /// Encode arbitrary octets as base64 into a supplied slice.\n    /// Writes into the supplied output buffer.\n    ///\n    /// This is useful if you wish to avoid allocation entirely (e.g. encoding into a stack-resident\n    /// or statically-allocated buffer).\n    ///\n    /// # Example\n    ///\n    #[cfg_attr(feature = \"alloc\", doc = \"```\")]\n    #[cfg_attr(not(feature = \"alloc\"), doc = \"```ignore\")]\n    /// use base64::{Engine as _, engine::general_purpose};\n    /// let s = b\"hello internet!\";\n    /// let mut buf = Vec::new();\n    /// // make sure we'll have a slice big enough for base64 + padding\n    /// buf.resize(s.len() * 4 / 3 + 4, 0);\n    ///\n    /// let bytes_written = general_purpose::STANDARD.encode_slice(s, &mut buf).unwrap();\n    ///\n    /// // shorten our vec down to just what was written\n    /// buf.truncate(bytes_written);\n    ///\n    /// assert_eq!(s, general_purpose::STANDARD.decode(&buf).unwrap().as_slice());\n    /// ```\n    #[inline]\n    fn encode_slice<T: AsRef<[u8]>>(\n        &self,\n        input: T,\n        output_buf: &mut [u8],\n    ) -> Result<usize, EncodeSliceError> {\n        fn inner<E>(\n            engine: &E,\n            input_bytes: &[u8],\n            output_buf: &mut [u8],\n        ) -> Result<usize, EncodeSliceError>\n        where\n            E: Engine + ?Sized,\n        {\n            let encoded_size = encoded_len(input_bytes.len(), engine.config().encode_padding())\n                .expect(\"usize overflow when calculating buffer size\");\n\n            if output_buf.len() < encoded_size {\n                return Err(EncodeSliceError::OutputSliceTooSmall);\n            }\n\n            let b64_output = &mut output_buf[0..encoded_size];\n\n            encode_with_padding(input_bytes, b64_output, engine, encoded_size);\n\n            Ok(encoded_size)\n        }\n\n        inner(self, input.as_ref(), output_buf)\n    }\n\n    /// Decode the input into a new `Vec`.\n    ///\n    /// # Example\n    ///\n    /// ```rust\n    /// use base64::{Engine as _, alphabet, engine::{self, general_purpose}};\n    ///\n    /// let bytes = general_purpose::STANDARD\n    ///     .decode(\"aGVsbG8gd29ybGR+Cg==\").unwrap();\n    /// println!(\"{:?}\", bytes);\n    ///\n    /// // custom engine setup\n    /// let bytes_url = engine::GeneralPurpose::new(\n    ///              &alphabet::URL_SAFE,\n    ///              general_purpose::NO_PAD)\n    ///     .decode(\"aGVsbG8gaW50ZXJuZXR-Cg\").unwrap();\n    /// println!(\"{:?}\", bytes_url);\n    /// ```\n    #[cfg(any(feature = \"alloc\", test))]\n    #[inline]\n    fn decode<T: AsRef<[u8]>>(&self, input: T) -> Result<Vec<u8>, DecodeError> {\n        fn inner<E>(engine: &E, input_bytes: &[u8]) -> Result<Vec<u8>, DecodeError>\n        where\n            E: Engine + ?Sized,\n        {\n            let estimate = engine.internal_decoded_len_estimate(input_bytes.len());\n            let mut buffer = vec![0; estimate.decoded_len_estimate()];\n\n            let bytes_written = engine\n                .internal_decode(input_bytes, &mut buffer, estimate)\n                .map_err(|e| match e {\n                    DecodeSliceError::DecodeError(e) => e,\n                    DecodeSliceError::OutputSliceTooSmall => {\n                        unreachable!(\"Vec is sized conservatively\")\n                    }\n                })?\n                .decoded_len;\n\n            buffer.truncate(bytes_written);\n\n            Ok(buffer)\n        }\n\n        inner(self, input.as_ref())\n    }\n\n    /// Decode the `input` into the supplied `buffer`.\n    ///\n    /// Writes into the supplied `Vec`, which may allocate if its internal buffer isn't big enough.\n    /// Returns a `Result` containing an empty tuple, aka `()`.\n    ///\n    /// # Example\n    ///\n    /// ```rust\n    /// use base64::{Engine as _, alphabet, engine::{self, general_purpose}};\n    /// const CUSTOM_ENGINE: engine::GeneralPurpose =\n    ///     engine::GeneralPurpose::new(&alphabet::URL_SAFE, general_purpose::PAD);\n    ///\n    /// fn main() {\n    ///     use base64::Engine;\n    ///     let mut buffer = Vec::<u8>::new();\n    ///     // with the default engine\n    ///     general_purpose::STANDARD\n    ///         .decode_vec(\"aGVsbG8gd29ybGR+Cg==\", &mut buffer,).unwrap();\n    ///     println!(\"{:?}\", buffer);\n    ///\n    ///     buffer.clear();\n    ///\n    ///     // with a custom engine\n    ///     CUSTOM_ENGINE.decode_vec(\n    ///         \"aGVsbG8gaW50ZXJuZXR-Cg==\",\n    ///         &mut buffer,\n    ///     ).unwrap();\n    ///     println!(\"{:?}\", buffer);\n    /// }\n    /// ```\n    #[cfg(any(feature = \"alloc\", test))]\n    #[inline]\n    fn decode_vec<T: AsRef<[u8]>>(\n        &self,\n        input: T,\n        buffer: &mut Vec<u8>,\n    ) -> Result<(), DecodeError> {\n        fn inner<E>(engine: &E, input_bytes: &[u8], buffer: &mut Vec<u8>) -> Result<(), DecodeError>\n        where\n            E: Engine + ?Sized,\n        {\n            let starting_output_len = buffer.len();\n            let estimate = engine.internal_decoded_len_estimate(input_bytes.len());\n\n            let total_len_estimate = estimate\n                .decoded_len_estimate()\n                .checked_add(starting_output_len)\n                .expect(\"Overflow when calculating output buffer length\");\n\n            buffer.resize(total_len_estimate, 0);\n\n            let buffer_slice = &mut buffer.as_mut_slice()[starting_output_len..];\n\n            let bytes_written = engine\n                .internal_decode(input_bytes, buffer_slice, estimate)\n                .map_err(|e| match e {\n                    DecodeSliceError::DecodeError(e) => e,\n                    DecodeSliceError::OutputSliceTooSmall => {\n                        unreachable!(\"Vec is sized conservatively\")\n                    }\n                })?\n                .decoded_len;\n\n            buffer.truncate(starting_output_len + bytes_written);\n\n            Ok(())\n        }\n\n        inner(self, input.as_ref(), buffer)\n    }\n\n    /// Decode the input into the provided output slice.\n    ///\n    /// Returns the number of bytes written to the slice, or an error if `output` is smaller than\n    /// the estimated decoded length.\n    ///\n    /// This will not write any bytes past exactly what is decoded (no stray garbage bytes at the end).\n    ///\n    /// See [`crate::decoded_len_estimate`] for calculating buffer sizes.\n    ///\n    /// See [`Engine::decode_slice_unchecked`] for a version that panics instead of returning an error\n    /// if the output buffer is too small.\n    #[inline]\n    fn decode_slice<T: AsRef<[u8]>>(\n        &self,\n        input: T,\n        output: &mut [u8],\n    ) -> Result<usize, DecodeSliceError> {\n        fn inner<E>(\n            engine: &E,\n            input_bytes: &[u8],\n            output: &mut [u8],\n        ) -> Result<usize, DecodeSliceError>\n        where\n            E: Engine + ?Sized,\n        {\n            engine\n                .internal_decode(\n                    input_bytes,\n                    output,\n                    engine.internal_decoded_len_estimate(input_bytes.len()),\n                )\n                .map(|dm| dm.decoded_len)\n        }\n\n        inner(self, input.as_ref(), output)\n    }\n\n    /// Decode the input into the provided output slice.\n    ///\n    /// Returns the number of bytes written to the slice.\n    ///\n    /// This will not write any bytes past exactly what is decoded (no stray garbage bytes at the end).\n    ///\n    /// See [`crate::decoded_len_estimate`] for calculating buffer sizes.\n    ///\n    /// See [`Engine::decode_slice`] for a version that returns an error instead of panicking if the output\n    /// buffer is too small.\n    ///\n    /// # Panics\n    ///\n    /// Panics if the provided output buffer is too small for the decoded data.\n    #[inline]\n    fn decode_slice_unchecked<T: AsRef<[u8]>>(\n        &self,\n        input: T,\n        output: &mut [u8],\n    ) -> Result<usize, DecodeError> {\n        fn inner<E>(engine: &E, input_bytes: &[u8], output: &mut [u8]) -> Result<usize, DecodeError>\n        where\n            E: Engine + ?Sized,\n        {\n            engine\n                .internal_decode(\n                    input_bytes,\n                    output,\n                    engine.internal_decoded_len_estimate(input_bytes.len()),\n                )\n                .map(|dm| dm.decoded_len)\n                .map_err(|e| match e {\n                    DecodeSliceError::DecodeError(e) => e,\n                    DecodeSliceError::OutputSliceTooSmall => {\n                        panic!(\"Output slice is too small\")\n                    }\n                })\n        }\n\n        inner(self, input.as_ref(), output)\n    }\n}","Real(LocalPath(\"src/engine/mod.rs\"))"],"engine::Engine::decode":["/// Decode the input into a new `Vec`.\n///\n/// # Example\n///\n/// ```rust\n/// use base64::{Engine as _, alphabet, engine::{self, general_purpose}};\n///\n/// let bytes = general_purpose::STANDARD\n///     .decode(\"aGVsbG8gd29ybGR+Cg==\").unwrap();\n/// println!(\"{:?}\", bytes);\n///\n/// // custom engine setup\n/// let bytes_url = engine::GeneralPurpose::new(\n///              &alphabet::URL_SAFE,\n///              general_purpose::NO_PAD)\n///     .decode(\"aGVsbG8gaW50ZXJuZXR-Cg\").unwrap();\n/// println!(\"{:?}\", bytes_url);\n/// ```\n#[cfg(any(feature = \"alloc\", test))]\n#[inline]\nfn decode<T: AsRef<[u8]>>(&self, input: T) -> Result<Vec<u8>, DecodeError>{\n        fn inner<E>(engine: &E, input_bytes: &[u8]) -> Result<Vec<u8>, DecodeError>\n        where\n            E: Engine + ?Sized,\n        {\n            let estimate = engine.internal_decoded_len_estimate(input_bytes.len());\n            let mut buffer = vec![0; estimate.decoded_len_estimate()];\n\n            let bytes_written = engine\n                .internal_decode(input_bytes, &mut buffer, estimate)\n                .map_err(|e| match e {\n                    DecodeSliceError::DecodeError(e) => e,\n                    DecodeSliceError::OutputSliceTooSmall => {\n                        unreachable!(\"Vec is sized conservatively\")\n                    }\n                })?\n                .decoded_len;\n\n            buffer.truncate(bytes_written);\n\n            Ok(buffer)\n        }\n\n        inner(self, input.as_ref())\n    }","Real(LocalPath(\"src/engine/mod.rs\"))"],"engine::Engine::decode::inner":["fn inner<E>(engine: &E, input_bytes: &[u8]) -> Result<Vec<u8>, DecodeError>\n        where\n            E: Engine + ?Sized,{\n            let estimate = engine.internal_decoded_len_estimate(input_bytes.len());\n            let mut buffer = vec![0; estimate.decoded_len_estimate()];\n\n            let bytes_written = engine\n                .internal_decode(input_bytes, &mut buffer, estimate)\n                .map_err(|e| match e {\n                    DecodeSliceError::DecodeError(e) => e,\n                    DecodeSliceError::OutputSliceTooSmall => {\n                        unreachable!(\"Vec is sized conservatively\")\n                    }\n                })?\n                .decoded_len;\n\n            buffer.truncate(bytes_written);\n\n            Ok(buffer)\n        }","Real(LocalPath(\"src/engine/mod.rs\"))"],"engine::Engine::decode_slice":["/// Decode the input into the provided output slice.\n///\n/// Returns the number of bytes written to the slice, or an error if `output` is smaller than\n/// the estimated decoded length.\n///\n/// This will not write any bytes past exactly what is decoded (no stray garbage bytes at the end).\n///\n/// See [`crate::decoded_len_estimate`] for calculating buffer sizes.\n///\n/// See [`Engine::decode_slice_unchecked`] for a version that panics instead of returning an error\n/// if the output buffer is too small.\n#[inline]\nfn decode_slice<T: AsRef<[u8]>>(\n        &self,\n        input: T,\n        output: &mut [u8],\n    ) -> Result<usize, DecodeSliceError>{\n        fn inner<E>(\n            engine: &E,\n            input_bytes: &[u8],\n            output: &mut [u8],\n        ) -> Result<usize, DecodeSliceError>\n        where\n            E: Engine + ?Sized,\n        {\n            engine\n                .internal_decode(\n                    input_bytes,\n                    output,\n                    engine.internal_decoded_len_estimate(input_bytes.len()),\n                )\n                .map(|dm| dm.decoded_len)\n        }\n\n        inner(self, input.as_ref(), output)\n    }","Real(LocalPath(\"src/engine/mod.rs\"))"],"engine::Engine::decode_slice::inner":["fn inner<E>(\n            engine: &E,\n            input_bytes: &[u8],\n            output: &mut [u8],\n        ) -> Result<usize, DecodeSliceError>\n        where\n            E: Engine + ?Sized,{\n            engine\n                .internal_decode(\n                    input_bytes,\n                    output,\n                    engine.internal_decoded_len_estimate(input_bytes.len()),\n                )\n                .map(|dm| dm.decoded_len)\n        }","Real(LocalPath(\"src/engine/mod.rs\"))"],"engine::Engine::decode_slice_unchecked":["/// Decode the input into the provided output slice.\n///\n/// Returns the number of bytes written to the slice.\n///\n/// This will not write any bytes past exactly what is decoded (no stray garbage bytes at the end).\n///\n/// See [`crate::decoded_len_estimate`] for calculating buffer sizes.\n///\n/// See [`Engine::decode_slice`] for a version that returns an error instead of panicking if the output\n/// buffer is too small.\n///\n/// # Panics\n///\n/// Panics if the provided output buffer is too small for the decoded data.\n#[inline]\nfn decode_slice_unchecked<T: AsRef<[u8]>>(\n        &self,\n        input: T,\n        output: &mut [u8],\n    ) -> Result<usize, DecodeError>{\n        fn inner<E>(engine: &E, input_bytes: &[u8], output: &mut [u8]) -> Result<usize, DecodeError>\n        where\n            E: Engine + ?Sized,\n        {\n            engine\n                .internal_decode(\n                    input_bytes,\n                    output,\n                    engine.internal_decoded_len_estimate(input_bytes.len()),\n                )\n                .map(|dm| dm.decoded_len)\n                .map_err(|e| match e {\n                    DecodeSliceError::DecodeError(e) => e,\n                    DecodeSliceError::OutputSliceTooSmall => {\n                        panic!(\"Output slice is too small\")\n                    }\n                })\n        }\n\n        inner(self, input.as_ref(), output)\n    }","Real(LocalPath(\"src/engine/mod.rs\"))"],"engine::Engine::decode_slice_unchecked::inner":["fn inner<E>(engine: &E, input_bytes: &[u8], output: &mut [u8]) -> Result<usize, DecodeError>\n        where\n            E: Engine + ?Sized,{\n            engine\n                .internal_decode(\n                    input_bytes,\n                    output,\n                    engine.internal_decoded_len_estimate(input_bytes.len()),\n                )\n                .map(|dm| dm.decoded_len)\n                .map_err(|e| match e {\n                    DecodeSliceError::DecodeError(e) => e,\n                    DecodeSliceError::OutputSliceTooSmall => {\n                        panic!(\"Output slice is too small\")\n                    }\n                })\n        }","Real(LocalPath(\"src/engine/mod.rs\"))"],"engine::Engine::decode_vec":["/// Decode the `input` into the supplied `buffer`.\n///\n/// Writes into the supplied `Vec`, which may allocate if its internal buffer isn't big enough.\n/// Returns a `Result` containing an empty tuple, aka `()`.\n///\n/// # Example\n///\n/// ```rust\n/// use base64::{Engine as _, alphabet, engine::{self, general_purpose}};\n/// const CUSTOM_ENGINE: engine::GeneralPurpose =\n///     engine::GeneralPurpose::new(&alphabet::URL_SAFE, general_purpose::PAD);\n///\n/// fn main() {\n///     use base64::Engine;\n///     let mut buffer = Vec::<u8>::new();\n///     // with the default engine\n///     general_purpose::STANDARD\n///         .decode_vec(\"aGVsbG8gd29ybGR+Cg==\", &mut buffer,).unwrap();\n///     println!(\"{:?}\", buffer);\n///\n///     buffer.clear();\n///\n///     // with a custom engine\n///     CUSTOM_ENGINE.decode_vec(\n///         \"aGVsbG8gaW50ZXJuZXR-Cg==\",\n///         &mut buffer,\n///     ).unwrap();\n///     println!(\"{:?}\", buffer);\n/// }\n/// ```\n#[cfg(any(feature = \"alloc\", test))]\n#[inline]\nfn decode_vec<T: AsRef<[u8]>>(\n        &self,\n        input: T,\n        buffer: &mut Vec<u8>,\n    ) -> Result<(), DecodeError>{\n        fn inner<E>(engine: &E, input_bytes: &[u8], buffer: &mut Vec<u8>) -> Result<(), DecodeError>\n        where\n            E: Engine + ?Sized,\n        {\n            let starting_output_len = buffer.len();\n            let estimate = engine.internal_decoded_len_estimate(input_bytes.len());\n\n            let total_len_estimate = estimate\n                .decoded_len_estimate()\n                .checked_add(starting_output_len)\n                .expect(\"Overflow when calculating output buffer length\");\n\n            buffer.resize(total_len_estimate, 0);\n\n            let buffer_slice = &mut buffer.as_mut_slice()[starting_output_len..];\n\n            let bytes_written = engine\n                .internal_decode(input_bytes, buffer_slice, estimate)\n                .map_err(|e| match e {\n                    DecodeSliceError::DecodeError(e) => e,\n                    DecodeSliceError::OutputSliceTooSmall => {\n                        unreachable!(\"Vec is sized conservatively\")\n                    }\n                })?\n                .decoded_len;\n\n            buffer.truncate(starting_output_len + bytes_written);\n\n            Ok(())\n        }\n\n        inner(self, input.as_ref(), buffer)\n    }","Real(LocalPath(\"src/engine/mod.rs\"))"],"engine::Engine::decode_vec::inner":["fn inner<E>(engine: &E, input_bytes: &[u8], buffer: &mut Vec<u8>) -> Result<(), DecodeError>\n        where\n            E: Engine + ?Sized,{\n            let starting_output_len = buffer.len();\n            let estimate = engine.internal_decoded_len_estimate(input_bytes.len());\n\n            let total_len_estimate = estimate\n                .decoded_len_estimate()\n                .checked_add(starting_output_len)\n                .expect(\"Overflow when calculating output buffer length\");\n\n            buffer.resize(total_len_estimate, 0);\n\n            let buffer_slice = &mut buffer.as_mut_slice()[starting_output_len..];\n\n            let bytes_written = engine\n                .internal_decode(input_bytes, buffer_slice, estimate)\n                .map_err(|e| match e {\n                    DecodeSliceError::DecodeError(e) => e,\n                    DecodeSliceError::OutputSliceTooSmall => {\n                        unreachable!(\"Vec is sized conservatively\")\n                    }\n                })?\n                .decoded_len;\n\n            buffer.truncate(starting_output_len + bytes_written);\n\n            Ok(())\n        }","Real(LocalPath(\"src/engine/mod.rs\"))"],"engine::Engine::encode":["/// Encode arbitrary octets as base64 using the provided `Engine`.\n/// Returns a `String`.\n///\n/// # Example\n///\n/// ```rust\n/// use base64::{Engine as _, engine::{self, general_purpose}, alphabet};\n///\n/// let b64 = general_purpose::STANDARD.encode(b\"hello world~\");\n/// println!(\"{}\", b64);\n///\n/// const CUSTOM_ENGINE: engine::GeneralPurpose =\n///     engine::GeneralPurpose::new(&alphabet::URL_SAFE, general_purpose::NO_PAD);\n///\n/// let b64_url = CUSTOM_ENGINE.encode(b\"hello internet~\");\n/// ```\n#[cfg(any(feature = \"alloc\", test))]\n#[inline]\nfn encode<T: AsRef<[u8]>>(&self, input: T) -> String{\n        fn inner<E>(engine: &E, input_bytes: &[u8]) -> String\n        where\n            E: Engine + ?Sized,\n        {\n            let encoded_size = encoded_len(input_bytes.len(), engine.config().encode_padding())\n                .expect(\"integer overflow when calculating buffer size\");\n\n            let mut buf = vec![0; encoded_size];\n\n            encode_with_padding(input_bytes, &mut buf[..], engine, encoded_size);\n\n            String::from_utf8(buf).expect(\"Invalid UTF8\")\n        }\n\n        inner(self, input.as_ref())\n    }","Real(LocalPath(\"src/engine/mod.rs\"))"],"engine::Engine::encode::inner":["fn inner<E>(engine: &E, input_bytes: &[u8]) -> String\n        where\n            E: Engine + ?Sized,{\n            let encoded_size = encoded_len(input_bytes.len(), engine.config().encode_padding())\n                .expect(\"integer overflow when calculating buffer size\");\n\n            let mut buf = vec![0; encoded_size];\n\n            encode_with_padding(input_bytes, &mut buf[..], engine, encoded_size);\n\n            String::from_utf8(buf).expect(\"Invalid UTF8\")\n        }","Real(LocalPath(\"src/engine/mod.rs\"))"],"engine::Engine::encode_slice":["/// Encode arbitrary octets as base64 into a supplied slice.\n/// Writes into the supplied output buffer.\n///\n/// This is useful if you wish to avoid allocation entirely (e.g. encoding into a stack-resident\n/// or statically-allocated buffer).\n///\n/// # Example\n///\ndoc = \"```\"\n/// use base64::{Engine as _, engine::general_purpose};\n/// let s = b\"hello internet!\";\n/// let mut buf = Vec::new();\n/// // make sure we'll have a slice big enough for base64 + padding\n/// buf.resize(s.len() * 4 / 3 + 4, 0);\n///\n/// let bytes_written = general_purpose::STANDARD.encode_slice(s, &mut buf).unwrap();\n///\n/// // shorten our vec down to just what was written\n/// buf.truncate(bytes_written);\n///\n/// assert_eq!(s, general_purpose::STANDARD.decode(&buf).unwrap().as_slice());\n/// ```\n#[inline]\nfn encode_slice<T: AsRef<[u8]>>(\n        &self,\n        input: T,\n        output_buf: &mut [u8],\n    ) -> Result<usize, EncodeSliceError>{\n        fn inner<E>(\n            engine: &E,\n            input_bytes: &[u8],\n            output_buf: &mut [u8],\n        ) -> Result<usize, EncodeSliceError>\n        where\n            E: Engine + ?Sized,\n        {\n            let encoded_size = encoded_len(input_bytes.len(), engine.config().encode_padding())\n                .expect(\"usize overflow when calculating buffer size\");\n\n            if output_buf.len() < encoded_size {\n                return Err(EncodeSliceError::OutputSliceTooSmall);\n            }\n\n            let b64_output = &mut output_buf[0..encoded_size];\n\n            encode_with_padding(input_bytes, b64_output, engine, encoded_size);\n\n            Ok(encoded_size)\n        }\n\n        inner(self, input.as_ref(), output_buf)\n    }","Real(LocalPath(\"src/engine/mod.rs\"))"],"engine::Engine::encode_slice::inner":["fn inner<E>(\n            engine: &E,\n            input_bytes: &[u8],\n            output_buf: &mut [u8],\n        ) -> Result<usize, EncodeSliceError>\n        where\n            E: Engine + ?Sized,{\n            let encoded_size = encoded_len(input_bytes.len(), engine.config().encode_padding())\n                .expect(\"usize overflow when calculating buffer size\");\n\n            if output_buf.len() < encoded_size {\n                return Err(EncodeSliceError::OutputSliceTooSmall);\n            }\n\n            let b64_output = &mut output_buf[0..encoded_size];\n\n            encode_with_padding(input_bytes, b64_output, engine, encoded_size);\n\n            Ok(encoded_size)\n        }","Real(LocalPath(\"src/engine/mod.rs\"))"],"engine::Engine::encode_string":["/// Encode arbitrary octets as base64 into a supplied `String`.\n/// Writes into the supplied `String`, which may allocate if its internal buffer isn't big enough.\n///\n/// # Example\n///\n/// ```rust\n/// use base64::{Engine as _, engine::{self, general_purpose}, alphabet};\n/// const CUSTOM_ENGINE: engine::GeneralPurpose =\n///     engine::GeneralPurpose::new(&alphabet::URL_SAFE, general_purpose::NO_PAD);\n///\n/// fn main() {\n///     let mut buf = String::new();\n///     general_purpose::STANDARD.encode_string(b\"hello world~\", &mut buf);\n///     println!(\"{}\", buf);\n///\n///     buf.clear();\n///     CUSTOM_ENGINE.encode_string(b\"hello internet~\", &mut buf);\n///     println!(\"{}\", buf);\n/// }\n/// ```\n#[cfg(any(feature = \"alloc\", test))]\n#[inline]\nfn encode_string<T: AsRef<[u8]>>(&self, input: T, output_buf: &mut String){\n        fn inner<E>(engine: &E, input_bytes: &[u8], output_buf: &mut String)\n        where\n            E: Engine + ?Sized,\n        {\n            let mut sink = chunked_encoder::StringSink::new(output_buf);\n\n            chunked_encoder::ChunkedEncoder::new(engine)\n                .encode(input_bytes, &mut sink)\n                .expect(\"Writing to a String shouldn't fail\");\n        }\n\n        inner(self, input.as_ref(), output_buf);\n    }","Real(LocalPath(\"src/engine/mod.rs\"))"],"engine::Engine::encode_string::inner":["fn inner<E>(engine: &E, input_bytes: &[u8], output_buf: &mut String)\n        where\n            E: Engine + ?Sized,{\n            let mut sink = chunked_encoder::StringSink::new(output_buf);\n\n            chunked_encoder::ChunkedEncoder::new(engine)\n                .encode(input_bytes, &mut sink)\n                .expect(\"Writing to a String shouldn't fail\");\n        }","Real(LocalPath(\"src/engine/mod.rs\"))"],"engine::general_purpose::GeneralPurpose":["/// A general-purpose base64 engine.\n///\n/// - It uses no vector CPU instructions, so it will work on any system.\n/// - It is reasonably fast (~2-3GiB/s).\n/// - It is not constant-time, though, so it is vulnerable to timing side-channel attacks. For loading cryptographic keys, etc, it is suggested to use the forthcoming constant-time implementation.\npub struct GeneralPurpose {\n    encode_table: [u8; 64],\n    decode_table: [u8; 256],\n    config: GeneralPurposeConfig,\n}","Real(LocalPath(\"src/engine/general_purpose/mod.rs\"))"],"engine::general_purpose::GeneralPurpose::new":["/// Create a `GeneralPurpose` engine from an [Alphabet].\n///\n/// While not very expensive to initialize, ideally these should be cached\n/// if the engine will be used repeatedly.\n#[must_use]\npub const fn new(alphabet: &Alphabet, config: GeneralPurposeConfig) -> Self{\n        Self {\n            encode_table: encode_table(alphabet),\n            decode_table: decode_table(alphabet),\n            config,\n        }\n    }","Real(LocalPath(\"src/engine/general_purpose/mod.rs\"))"],"engine::general_purpose::GeneralPurposeConfig":["/// Contains configuration parameters for base64 encoding and decoding.\n///\n/// ```\n/// # use base64::engine::GeneralPurposeConfig;\n/// let config = GeneralPurposeConfig::new()\n///     .with_encode_padding(false);\n///     // further customize using `.with_*` methods as needed\n/// ```\n///\n/// The constants [PAD] and [`NO_PAD`] cover most use cases.\n///\n/// To specify the characters used, see [Alphabet].\npub struct GeneralPurposeConfig {\n    encode_padding: bool,\n    decode_allow_trailing_bits: bool,\n    decode_padding_mode: DecodePaddingMode,\n}","Real(LocalPath(\"src/engine/general_purpose/mod.rs\"))"],"engine::general_purpose::GeneralPurposeConfig::new":["/// Create a new config with `padding` = `true`, `decode_allow_trailing_bits` = `false`, and\n/// `decode_padding_mode = DecodePaddingMode::RequireCanonicalPadding`.\n///\n/// This probably matches most people's expectations, but consider disabling padding to save\n/// a few bytes unless you specifically need it for compatibility with some legacy system.\n#[must_use]\npub const fn new() -> Self{\n        Self {\n            // RFC states that padding must be applied by default\n            encode_padding: true,\n            decode_allow_trailing_bits: false,\n            decode_padding_mode: DecodePaddingMode::RequireCanonical,\n        }\n    }","Real(LocalPath(\"src/engine/general_purpose/mod.rs\"))"],"engine::general_purpose::GeneralPurposeConfig::with_decode_allow_trailing_bits":["/// Create a new config based on `self` with an updated `decode_allow_trailing_bits` setting.\n///\n/// Most users will not need to configure this. It's useful if you need to decode base64\n/// produced by a buggy encoder that has bits set in the unused space on the last base64\n/// character as per [forgiving-base64 decode](https://infra.spec.whatwg.org/#forgiving-base64-decode).\n/// If invalid trailing bits are present and this is `true`, those bits will\n/// be silently ignored, else `DecodeError::InvalidLastSymbol` will be emitted.\n#[must_use]\npub const fn with_decode_allow_trailing_bits(self, allow: bool) -> Self{\n        Self {\n            decode_allow_trailing_bits: allow,\n            ..self\n        }\n    }","Real(LocalPath(\"src/engine/general_purpose/mod.rs\"))"],"engine::general_purpose::GeneralPurposeConfig::with_decode_padding_mode":["/// Create a new config based on `self` with an updated `decode_padding_mode` setting.\n///\n/// Padding is not useful in terms of representing encoded data -- it makes no difference to\n/// the decoder if padding is present or not, so if you have some un-padded input to decode, it\n/// is perfectly fine to use `DecodePaddingMode::Indifferent` to prevent errors from being\n/// emitted.\n///\n/// However, since in practice\n/// [people who learned nothing from BER vs DER seem to expect base64 to have one canonical encoding](https://eprint.iacr.org/2022/361),\n/// the default setting is the stricter `DecodePaddingMode::RequireCanonicalPadding`.\n///\n/// Or, if \"canonical\" in your circumstance means _no_ padding rather than padding to the\n/// next multiple of four, there's `DecodePaddingMode::RequireNoPadding`.\n#[must_use]\npub const fn with_decode_padding_mode(self, mode: DecodePaddingMode) -> Self{\n        Self {\n            decode_padding_mode: mode,\n            ..self\n        }\n    }","Real(LocalPath(\"src/engine/general_purpose/mod.rs\"))"],"engine::general_purpose::GeneralPurposeConfig::with_encode_padding":["/// Create a new config based on `self` with an updated `padding` setting.\n///\n/// If `padding` is `true`, encoding will append either 1 or 2 `=` padding characters as needed\n/// to produce an output whose length is a multiple of 4.\n///\n/// Padding is not needed for correct decoding and only serves to waste bytes, but it's in the\n/// [spec](https://datatracker.ietf.org/doc/html/rfc4648#section-3.2).\n///\n/// For new applications, consider not using padding if the decoders you're using don't require\n/// padding to be present.\n#[must_use]\npub const fn with_encode_padding(self, padding: bool) -> Self{\n        Self {\n            encode_padding: padding,\n            ..self\n        }\n    }","Real(LocalPath(\"src/engine/general_purpose/mod.rs\"))"],"engine::general_purpose::decode::GeneralPurposeEstimate":["#[doc(hidden)]\npub struct GeneralPurposeEstimate {\n    /// input len % 4\n    rem: usize,\n    conservative_decoded_len: usize,\n}","Real(LocalPath(\"src/engine/general_purpose/decode.rs\"))"],"engine::general_purpose::decode::GeneralPurposeEstimate::new":["pub(crate) fn new(encoded_len: usize) -> Self{\n        let rem = encoded_len % 4;\n        Self {\n            rem,\n            conservative_decoded_len: (encoded_len / 4 + usize::from(rem > 0)) * 3,\n        }\n    }","Real(LocalPath(\"src/engine/general_purpose/decode.rs\"))"],"engine::general_purpose::decode::complete_quads_len":["/// Returns the length of complete quads, except for the last one, even if it is complete.\n///\n/// Returns an error if the output len is not big enough for decoding those complete quads, or if\n/// the input % 4 == 1, and that last byte is an invalid value other than a pad byte.\n///\n/// - `input` is the base64 input\n/// - `input_len_rem` is input len % 4\n/// - `output_len` is the length of the output slice\npub(crate) fn complete_quads_len(\n    input: &[u8],\n    input_len_rem: usize,\n    output_len: usize,\n    decode_table: &[u8; 256],\n) -> Result<usize, DecodeSliceError>{\n    debug_assert!(input.len() % 4 == input_len_rem);\n\n    // detect a trailing invalid byte, like a newline, as a user convenience\n    if input_len_rem == 1 {\n        let last_byte = input[input.len() - 1];\n        // exclude pad bytes; might be part of padding that extends from earlier in the input\n        if last_byte != PAD_BYTE && decode_table[usize::from(last_byte)] == INVALID_VALUE {\n            return Err(DecodeError::InvalidByte(input.len() - 1, last_byte).into());\n        }\n    };\n\n    // skip last quad, even if it's complete, as it may have padding\n    let input_complete_nonterminal_quads_len = input\n        .len()\n        .saturating_sub(input_len_rem)\n        // if rem was 0, subtract 4 to avoid padding\n        .saturating_sub(usize::from(input_len_rem == 0) * 4);\n    debug_assert!(\n        input.is_empty() || (1..=4).contains(&(input.len() - input_complete_nonterminal_quads_len))\n    );\n\n    // check that everything except the last quad handled by decode_suffix will fit\n    if output_len < input_complete_nonterminal_quads_len / 4 * 3 {\n        return Err(DecodeSliceError::OutputSliceTooSmall);\n    };\n    Ok(input_complete_nonterminal_quads_len)\n}","Real(LocalPath(\"src/engine/general_purpose/decode.rs\"))"],"engine::general_purpose::decode::decode_chunk_4":["/// Like [`decode_chunk_8`] but for 4 bytes of input and 3 bytes of output.\n#[inline(always)]\nfn decode_chunk_4(\n    input: &[u8],\n    index_at_start_of_input: usize,\n    decode_table: &[u8; 256],\n    output: &mut [u8],\n) -> Result<(), DecodeError>{\n    let morsel = decode_table[usize::from(input[0])];\n    if morsel == INVALID_VALUE {\n        return Err(DecodeError::InvalidByte(index_at_start_of_input, input[0]));\n    }\n    let mut accum = u32::from(morsel) << 26;\n\n    let morsel = decode_table[usize::from(input[1])];\n    if morsel == INVALID_VALUE {\n        return Err(DecodeError::InvalidByte(\n            index_at_start_of_input + 1,\n            input[1],\n        ));\n    }\n    accum |= u32::from(morsel) << 20;\n\n    let morsel = decode_table[usize::from(input[2])];\n    if morsel == INVALID_VALUE {\n        return Err(DecodeError::InvalidByte(\n            index_at_start_of_input + 2,\n            input[2],\n        ));\n    }\n    accum |= u32::from(morsel) << 14;\n\n    let morsel = decode_table[usize::from(input[3])];\n    if morsel == INVALID_VALUE {\n        return Err(DecodeError::InvalidByte(\n            index_at_start_of_input + 3,\n            input[3],\n        ));\n    }\n    accum |= u32::from(morsel) << 8;\n\n    output[..3].copy_from_slice(&accum.to_be_bytes()[..3]);\n\n    Ok(())\n}","Real(LocalPath(\"src/engine/general_purpose/decode.rs\"))"],"engine::general_purpose::decode::decode_chunk_8":["/// Decode 8 bytes of input into 6 bytes of output.\n///\n/// `input` is the 8 bytes to decode.\n/// `index_at_start_of_input` is the offset in the overall input (used for reporting errors\n/// accurately)\n/// `decode_table` is the lookup table for the particular base64 alphabet.\n/// `output` will have its first 6 bytes overwritten\n#[inline(always)]\nfn decode_chunk_8(\n    input: &[u8],\n    index_at_start_of_input: usize,\n    decode_table: &[u8; 256],\n    output: &mut [u8],\n) -> Result<(), DecodeError>{\n    let morsel = decode_table[usize::from(input[0])];\n    if morsel == INVALID_VALUE {\n        return Err(DecodeError::InvalidByte(index_at_start_of_input, input[0]));\n    }\n    let mut accum = u64::from(morsel) << 58;\n\n    let morsel = decode_table[usize::from(input[1])];\n    if morsel == INVALID_VALUE {\n        return Err(DecodeError::InvalidByte(\n            index_at_start_of_input + 1,\n            input[1],\n        ));\n    }\n    accum |= u64::from(morsel) << 52;\n\n    let morsel = decode_table[usize::from(input[2])];\n    if morsel == INVALID_VALUE {\n        return Err(DecodeError::InvalidByte(\n            index_at_start_of_input + 2,\n            input[2],\n        ));\n    }\n    accum |= u64::from(morsel) << 46;\n\n    let morsel = decode_table[usize::from(input[3])];\n    if morsel == INVALID_VALUE {\n        return Err(DecodeError::InvalidByte(\n            index_at_start_of_input + 3,\n            input[3],\n        ));\n    }\n    accum |= u64::from(morsel) << 40;\n\n    let morsel = decode_table[usize::from(input[4])];\n    if morsel == INVALID_VALUE {\n        return Err(DecodeError::InvalidByte(\n            index_at_start_of_input + 4,\n            input[4],\n        ));\n    }\n    accum |= u64::from(morsel) << 34;\n\n    let morsel = decode_table[usize::from(input[5])];\n    if morsel == INVALID_VALUE {\n        return Err(DecodeError::InvalidByte(\n            index_at_start_of_input + 5,\n            input[5],\n        ));\n    }\n    accum |= u64::from(morsel) << 28;\n\n    let morsel = decode_table[usize::from(input[6])];\n    if morsel == INVALID_VALUE {\n        return Err(DecodeError::InvalidByte(\n            index_at_start_of_input + 6,\n            input[6],\n        ));\n    }\n    accum |= u64::from(morsel) << 22;\n\n    let morsel = decode_table[usize::from(input[7])];\n    if morsel == INVALID_VALUE {\n        return Err(DecodeError::InvalidByte(\n            index_at_start_of_input + 7,\n            input[7],\n        ));\n    }\n    accum |= u64::from(morsel) << 16;\n\n    output[..6].copy_from_slice(&accum.to_be_bytes()[..6]);\n\n    Ok(())\n}","Real(LocalPath(\"src/engine/general_purpose/decode.rs\"))"],"engine::general_purpose::decode::decode_helper":["/// Helper to avoid duplicating `num_chunks` calculation, which is costly on short inputs.\n/// Returns the decode metadata, or an error.\n#[inline]\npub(crate) fn decode_helper(\n    input: &[u8],\n    estimate: &GeneralPurposeEstimate,\n    output: &mut [u8],\n    decode_table: &[u8; 256],\n    decode_allow_trailing_bits: bool,\n    padding_mode: DecodePaddingMode,\n) -> Result<DecodeMetadata, DecodeSliceError>{\n    let input_complete_nonterminal_quads_len =\n        complete_quads_len(input, estimate.rem, output.len(), decode_table)?;\n\n    const UNROLLED_INPUT_CHUNK_SIZE: usize = 32;\n    const UNROLLED_OUTPUT_CHUNK_SIZE: usize = UNROLLED_INPUT_CHUNK_SIZE / 4 * 3;\n\n    let input_complete_quads_after_unrolled_chunks_len =\n        input_complete_nonterminal_quads_len % UNROLLED_INPUT_CHUNK_SIZE;\n\n    let input_unrolled_loop_len =\n        input_complete_nonterminal_quads_len - input_complete_quads_after_unrolled_chunks_len;\n\n    // chunks of 32 bytes\n    for (chunk_index, chunk) in input[..input_unrolled_loop_len]\n        .chunks_exact(UNROLLED_INPUT_CHUNK_SIZE)\n        .enumerate()\n    {\n        let input_index = chunk_index * UNROLLED_INPUT_CHUNK_SIZE;\n        let chunk_output = &mut output[chunk_index * UNROLLED_OUTPUT_CHUNK_SIZE\n            ..(chunk_index + 1) * UNROLLED_OUTPUT_CHUNK_SIZE];\n\n        decode_chunk_8(\n            &chunk[0..8],\n            input_index,\n            decode_table,\n            &mut chunk_output[0..6],\n        )?;\n        decode_chunk_8(\n            &chunk[8..16],\n            input_index + 8,\n            decode_table,\n            &mut chunk_output[6..12],\n        )?;\n        decode_chunk_8(\n            &chunk[16..24],\n            input_index + 16,\n            decode_table,\n            &mut chunk_output[12..18],\n        )?;\n        decode_chunk_8(\n            &chunk[24..32],\n            input_index + 24,\n            decode_table,\n            &mut chunk_output[18..24],\n        )?;\n    }\n\n    // remaining quads, except for the last possibly partial one, as it may have padding\n    let output_unrolled_loop_len = input_unrolled_loop_len / 4 * 3;\n    let output_complete_quad_len = input_complete_nonterminal_quads_len / 4 * 3;\n    {\n        let output_after_unroll = &mut output[output_unrolled_loop_len..output_complete_quad_len];\n\n        for (chunk_index, chunk) in input\n            [input_unrolled_loop_len..input_complete_nonterminal_quads_len]\n            .chunks_exact(4)\n            .enumerate()\n        {\n            let chunk_output = &mut output_after_unroll[chunk_index * 3..chunk_index * 3 + 3];\n\n            decode_chunk_4(\n                chunk,\n                input_unrolled_loop_len + chunk_index * 4,\n                decode_table,\n                chunk_output,\n            )?;\n        }\n    }\n\n    super::decode_suffix::decode_suffix(\n        input,\n        input_complete_nonterminal_quads_len,\n        output,\n        output_complete_quad_len,\n        decode_table,\n        decode_allow_trailing_bits,\n        padding_mode,\n    )\n}","Real(LocalPath(\"src/engine/general_purpose/decode.rs\"))"],"engine::general_purpose::decode_suffix::decode_suffix":["/// Decode the last 0-4 bytes, checking for trailing set bits and padding per the provided\n/// parameters.\n///\n/// Returns the decode metadata representing the total number of bytes decoded, including the ones\n/// indicated as already written by `output_index`.\npub(crate) fn decode_suffix(\n    input: &[u8],\n    input_index: usize,\n    output: &mut [u8],\n    mut output_index: usize,\n    decode_table: &[u8; 256],\n    decode_allow_trailing_bits: bool,\n    padding_mode: DecodePaddingMode,\n) -> Result<DecodeMetadata, DecodeSliceError>{\n    debug_assert!((input.len() - input_index) <= 4);\n\n    // Decode any leftovers that might not be a complete input chunk of 4 bytes.\n    // Use a u32 as a stack-resident 4 byte buffer.\n    let mut morsels_in_leftover = 0;\n    let mut padding_bytes_count = 0;\n    // offset from input_index\n    let mut first_padding_offset: usize = 0;\n    let mut last_symbol = 0_u8;\n    let mut morsels = [0_u8; 4];\n\n    for (leftover_index, &b) in input[input_index..].iter().enumerate() {\n        // '=' padding\n        if b == PAD_BYTE {\n            // There can be bad padding bytes in a few ways:\n            // 1 - Padding with non-padding characters after it\n            // 2 - Padding after zero or one characters in the current quad (should only\n            //     be after 2 or 3 chars)\n            // 3 - More than two characters of padding. If 3 or 4 padding chars\n            //     are in the same quad, that implies it will be caught by #2.\n            //     If it spreads from one quad to another, it will be an invalid byte\n            //     in the first quad.\n            // 4 - Non-canonical padding -- 1 byte when it should be 2, etc.\n            //     Per config, non-canonical but still functional non- or partially-padded base64\n            //     may be treated as an error condition.\n\n            if leftover_index < 2 {\n                // Check for error #2.\n                // Either the previous byte was padding, in which case we would have already hit\n                // this case, or it wasn't, in which case this is the first such error.\n                debug_assert!(\n                    leftover_index == 0 || (leftover_index == 1 && padding_bytes_count == 0)\n                );\n                let bad_padding_index = input_index + leftover_index;\n                return Err(DecodeError::InvalidByte(bad_padding_index, b).into());\n            }\n\n            if padding_bytes_count == 0 {\n                first_padding_offset = leftover_index;\n            }\n\n            padding_bytes_count += 1;\n            continue;\n        }\n\n        // Check for case #1.\n        // To make '=' handling consistent with the main loop, don't allow\n        // non-suffix '=' in trailing chunk either. Report error as first\n        // erroneous padding.\n        if padding_bytes_count > 0 {\n            return Err(\n                DecodeError::InvalidByte(input_index + first_padding_offset, PAD_BYTE).into(),\n            );\n        }\n\n        last_symbol = b;\n\n        // can use up to 8 * 6 = 48 bits of the u64, if last chunk has no padding.\n        // Pack the leftovers from left to right.\n        let morsel = decode_table[b as usize];\n        if morsel == INVALID_VALUE {\n            return Err(DecodeError::InvalidByte(input_index + leftover_index, b).into());\n        }\n\n        morsels[morsels_in_leftover] = morsel;\n        morsels_in_leftover += 1;\n    }\n\n    // If there was 1 trailing byte, and it was valid, and we got to this point without hitting\n    // an invalid byte, now we can report invalid length\n    if !input.is_empty() && morsels_in_leftover < 2 {\n        return Err(DecodeError::InvalidLength(input_index + morsels_in_leftover).into());\n    }\n\n    match padding_mode {\n        DecodePaddingMode::Indifferent => { /* everything we care about was already checked */ }\n        DecodePaddingMode::RequireCanonical => {\n            // allow empty input\n            if (padding_bytes_count + morsels_in_leftover) % 4 != 0 {\n                return Err(DecodeError::InvalidPadding.into());\n            }\n        }\n        DecodePaddingMode::RequireNone => {\n            if padding_bytes_count > 0 {\n                // check at the end to make sure we let the cases of padding that should be InvalidByte\n                // get hit\n                return Err(DecodeError::InvalidPadding.into());\n            }\n        }\n    }\n\n    // When encoding 1 trailing byte (e.g. 0xFF), 2 base64 bytes (\"/w\") are needed.\n    // / is the symbol for 63 (0x3F, bottom 6 bits all set) and w is 48 (0x30, top 2 bits\n    // of bottom 6 bits set).\n    // When decoding two symbols back to one trailing byte, any final symbol higher than\n    // w would still decode to the original byte because we only care about the top two\n    // bits in the bottom 6, but would be a non-canonical encoding. So, we calculate a\n    // mask based on how many bits are used for just the canonical encoding, and optionally\n    // error if any other bits are set. In the example of one encoded byte -> 2 symbols,\n    // 2 symbols can technically encode 12 bits, but the last 4 are non-canonical, and\n    // useless since there are no more symbols to provide the necessary 4 additional bits\n    // to finish the second original byte.\n\n    let leftover_bytes_to_append = morsels_in_leftover * 6 / 8;\n    // Put the up to 6 complete bytes as the high bytes.\n    // Gain a couple percent speedup from nudging these ORs to use more ILP with a two-way split.\n    let mut leftover_num = (u32::from(morsels[0]) << 26)\n        | (u32::from(morsels[1]) << 20)\n        | (u32::from(morsels[2]) << 14)\n        | (u32::from(morsels[3]) << 8);\n\n    // if there are bits set outside the bits we care about, last symbol encodes trailing bits that\n    // will not be included in the output\n    let mask = !0_u32 >> (leftover_bytes_to_append * 8);\n    if !decode_allow_trailing_bits && (leftover_num & mask) != 0 {\n        // last morsel is at `morsels_in_leftover` - 1\n        return Err(DecodeError::InvalidLastSymbol(\n            input_index + morsels_in_leftover - 1,\n            last_symbol,\n        )\n        .into());\n    }\n\n    // Strangely, this approach benchmarks better than writing bytes one at a time,\n    // or copy_from_slice into output.\n    for _ in 0..leftover_bytes_to_append {\n        let hi_byte = (leftover_num >> 24) as u8;\n        leftover_num <<= 8;\n        *output\n            .get_mut(output_index)\n            .ok_or(DecodeSliceError::OutputSliceTooSmall)? = hi_byte;\n        output_index += 1;\n    }\n\n    Ok(DecodeMetadata::new(\n        output_index,\n        if padding_bytes_count > 0 {\n            Some(input_index + first_padding_offset)\n        } else {\n            None\n        },\n    ))\n}","Real(LocalPath(\"src/engine/general_purpose/decode_suffix.rs\"))"],"engine::general_purpose::decode_table":["/// Returns a table mapping base64 bytes as the lookup index to either:\n/// - [`INVALID_VALUE`] for bytes that aren't members of the alphabet\n/// - a byte whose lower 6 bits are the value that was encoded into the index byte\npub(crate) const fn decode_table(alphabet: &Alphabet) -> [u8; 256]{\n    let mut decode_table = [INVALID_VALUE; 256];\n\n    // Since the table is full of `INVALID_VALUE` already, we only need to overwrite\n    // the parts that are valid.\n    let mut index = 0;\n    while index < 64 {\n        // The index in the alphabet is the 6-bit value we care about.\n        // Since the index is in 0-63, it is safe to cast to u8.\n        decode_table[alphabet.symbols[index] as usize] = index as u8;\n        index += 1;\n    }\n\n    decode_table\n}","Real(LocalPath(\"src/engine/general_purpose/mod.rs\"))"],"engine::general_purpose::encode_table":["/// Returns a table mapping a 6-bit index to the ASCII byte encoding of the index\npub(crate) const fn encode_table(alphabet: &Alphabet) -> [u8; 64]{\n    // the encode table is just the alphabet:\n    // 6-bit index lookup -> printable byte\n    let mut encode_table = [0_u8; 64];\n    {\n        let mut index = 0;\n        while index < 64 {\n            encode_table[index] = alphabet.symbols[index];\n            index += 1;\n        }\n    }\n\n    encode_table\n}","Real(LocalPath(\"src/engine/general_purpose/mod.rs\"))"],"engine::general_purpose::read_u64":["#[inline]\nfn read_u64(s: &[u8]) -> u64{\n    u64::from_be_bytes(s[..8].try_into().unwrap())\n}","Real(LocalPath(\"src/engine/general_purpose/mod.rs\"))"],"read::decoder::DecoderReader":["/// A `Read` implementation that decodes base64 data read from an underlying reader.\n///\n/// # Examples\n///\n/// ```\n/// use std::io::Read;\n/// use std::io::Cursor;\n/// use base64::engine::general_purpose;\n///\n/// // use a cursor as the simplest possible `Read` -- in real code this is probably a file, etc.\n/// let mut wrapped_reader = Cursor::new(b\"YXNkZg==\");\n/// let mut decoder = base64::read::DecoderReader::new(\n///     &mut wrapped_reader,\n///     &general_purpose::STANDARD);\n///\n/// // handle errors as you normally would\n/// let mut result = Vec::new();\n/// decoder.read_to_end(&mut result).unwrap();\n///\n/// assert_eq!(b\"asdf\", &result[..]);\n///\n/// ```\npub struct DecoderReader<'e, E: Engine, R: io::Read> {\n    engine: &'e E,\n    /// Where b64 data is read from\n    inner: R,\n\n    /// Holds b64 data read from the delegate reader.\n    b64_buffer: [u8; BUF_SIZE],\n    /// The start of the pending buffered data in `b64_buffer`.\n    b64_offset: usize,\n    /// The amount of buffered b64 data after `b64_offset` in `b64_len`.\n    b64_len: usize,\n    /// Since the caller may provide us with a buffer of size 1 or 2 that's too small to copy a\n    /// decoded chunk in to, we have to be able to hang on to a few decoded bytes.\n    /// Technically we only need to hold 2 bytes, but then we'd need a separate temporary buffer to\n    /// decode 3 bytes into and then juggle copying one byte into the provided read buf and the rest\n    /// into here, which seems like a lot of complexity for 1 extra byte of storage.\n    decoded_chunk_buffer: [u8; DECODED_CHUNK_SIZE],\n    /// Index of start of decoded data in `decoded_chunk_buffer`\n    decoded_offset: usize,\n    /// Length of decoded data after `decoded_offset` in `decoded_chunk_buffer`\n    decoded_len: usize,\n    /// Input length consumed so far.\n    /// Used to provide accurate offsets in errors\n    input_consumed_len: usize,\n    /// offset of previously seen padding, if any\n    padding_offset: Option<usize>,\n}","Real(LocalPath(\"src/read/decoder.rs\"))"],"read::decoder::DecoderReader::<'e, E, R>::decode_to_buf":["/// Decode the requested number of bytes from the b64 buffer into the provided buffer. It's the\n/// caller's responsibility to choose the number of b64 bytes to decode correctly.\n///\n/// Returns a Result with the number of decoded bytes written to `buf`.\n///\n/// # Panics\n///\n/// panics if `buf` is too small\nfn decode_to_buf(&mut self, b64_len_to_decode: usize, buf: &mut [u8]) -> io::Result<usize>{\n        debug_assert!(self.b64_len >= b64_len_to_decode);\n        debug_assert!(self.b64_offset + self.b64_len <= BUF_SIZE);\n        debug_assert!(!buf.is_empty());\n\n        let b64_to_decode = &self.b64_buffer[self.b64_offset..self.b64_offset + b64_len_to_decode];\n        let decode_metadata = self\n            .engine\n            .internal_decode(\n                b64_to_decode,\n                buf,\n                self.engine.internal_decoded_len_estimate(b64_len_to_decode),\n            )\n            .map_err(|dse| match dse {\n                DecodeSliceError::DecodeError(de) => {\n                    match de {\n                        DecodeError::InvalidByte(offset, byte) => {\n                            match (byte, self.padding_offset) {\n                                // if there was padding in a previous block of decoding that happened to\n                                // be correct, and we now find more padding that happens to be incorrect,\n                                // to be consistent with non-reader decodes, record the error at the first\n                                // padding\n                                (PAD_BYTE, Some(first_pad_offset)) => {\n                                    DecodeError::InvalidByte(first_pad_offset, PAD_BYTE)\n                                }\n                                _ => {\n                                    DecodeError::InvalidByte(self.input_consumed_len + offset, byte)\n                                }\n                            }\n                        }\n                        DecodeError::InvalidLength(len) => {\n                            DecodeError::InvalidLength(self.input_consumed_len + len)\n                        }\n                        DecodeError::InvalidLastSymbol(offset, byte) => {\n                            DecodeError::InvalidLastSymbol(self.input_consumed_len + offset, byte)\n                        }\n                        DecodeError::InvalidPadding => DecodeError::InvalidPadding,\n                    }\n                }\n                DecodeSliceError::OutputSliceTooSmall => {\n                    unreachable!(\"buf is sized correctly in calling code\")\n                }\n            })\n            .map_err(|e| io::Error::new(io::ErrorKind::InvalidData, e))?;\n\n        if let Some(offset) = self.padding_offset {\n            // we've already seen padding\n            if decode_metadata.decoded_len > 0 {\n                // we read more after already finding padding; report error at first padding byte\n                return Err(io::Error::new(\n                    io::ErrorKind::InvalidData,\n                    DecodeError::InvalidByte(offset, PAD_BYTE),\n                ));\n            }\n        }\n\n        self.padding_offset = self.padding_offset.or(decode_metadata\n            .padding_offset\n            .map(|offset| self.input_consumed_len + offset));\n        self.input_consumed_len += b64_len_to_decode;\n        self.b64_offset += b64_len_to_decode;\n        self.b64_len -= b64_len_to_decode;\n\n        debug_assert!(self.b64_offset + self.b64_len <= BUF_SIZE);\n\n        Ok(decode_metadata.decoded_len)\n    }","Real(LocalPath(\"src/read/decoder.rs\"))"],"read::decoder::DecoderReader::<'e, E, R>::flush_decoded_buf":["/// Write as much as possible of the decoded buffer into the target buffer.\n/// Must only be called when there is something to write and space to write into.\n/// Returns a Result with the number of (decoded) bytes copied.\nfn flush_decoded_buf(&mut self, buf: &mut [u8]) -> io::Result<usize>{\n        debug_assert!(self.decoded_len > 0);\n        debug_assert!(!buf.is_empty());\n\n        let copy_len = cmp::min(self.decoded_len, buf.len());\n        debug_assert!(copy_len > 0);\n        debug_assert!(copy_len <= self.decoded_len);\n\n        buf[..copy_len].copy_from_slice(\n            &self.decoded_chunk_buffer[self.decoded_offset..self.decoded_offset + copy_len],\n        );\n\n        self.decoded_offset += copy_len;\n        self.decoded_len -= copy_len;\n\n        debug_assert!(self.decoded_len < DECODED_CHUNK_SIZE);\n\n        Ok(copy_len)\n    }","Real(LocalPath(\"src/read/decoder.rs\"))"],"read::decoder::DecoderReader::<'e, E, R>::into_inner":["/// Unwraps this `DecoderReader`, returning the base reader which it reads base64 encoded\n/// input from.\n///\n/// Because `DecoderReader` performs internal buffering, the state of the inner reader is\n/// unspecified. This function is mainly provided because the inner reader type may provide\n/// additional functionality beyond the `Read` implementation which may still be useful.\npub fn into_inner(self) -> R{\n        self.inner\n    }","Real(LocalPath(\"src/read/decoder.rs\"))"],"read::decoder::DecoderReader::<'e, E, R>::new":["/// Create a new decoder that will read from the provided reader `r`.\npub fn new(reader: R, engine: &'e E) -> Self{\n        DecoderReader {\n            engine,\n            inner: reader,\n            b64_buffer: [0; BUF_SIZE],\n            b64_offset: 0,\n            b64_len: 0,\n            decoded_chunk_buffer: [0; DECODED_CHUNK_SIZE],\n            decoded_offset: 0,\n            decoded_len: 0,\n            input_consumed_len: 0,\n            padding_offset: None,\n        }\n    }","Real(LocalPath(\"src/read/decoder.rs\"))"],"read::decoder::DecoderReader::<'e, E, R>::read_from_delegate":["/// Read into the remaining space in the buffer after the current contents.\n/// Must only be called when there is space to read into in the buffer.\n/// Returns the number of bytes read.\nfn read_from_delegate(&mut self) -> io::Result<usize>{\n        debug_assert!(self.b64_offset + self.b64_len < BUF_SIZE);\n\n        let read = self\n            .inner\n            .read(&mut self.b64_buffer[self.b64_offset + self.b64_len..])?;\n        self.b64_len += read;\n\n        debug_assert!(self.b64_offset + self.b64_len <= BUF_SIZE);\n\n        Ok(read)\n    }","Real(LocalPath(\"src/read/decoder.rs\"))"],"write::encoder::EncoderWriter":["/// A `Write` implementation that base64 encodes data before delegating to the wrapped writer.\n///\n/// Because base64 has special handling for the end of the input data (padding, etc), there's a\n/// `finish()` method on this type that encodes any leftover input bytes and adds padding if\n/// appropriate. It's called automatically when deallocated (see the `Drop` implementation), but\n/// any error that occurs when invoking the underlying writer will be suppressed. If you want to\n/// handle such errors, call `finish()` yourself.\n///\n/// # Examples\n///\n/// ```\n/// use std::io::Write;\n/// use base64::engine::general_purpose;\n///\n/// // use a vec as the simplest possible `Write` -- in real code this is probably a file, etc.\n/// let mut enc = base64::write::EncoderWriter::new(Vec::new(), &general_purpose::STANDARD);\n///\n/// // handle errors as you normally would\n/// enc.write_all(b\"asdf\").unwrap();\n///\n/// // could leave this out to be called by Drop, if you don't care\n/// // about handling errors or getting the delegate writer back\n/// let delegate = enc.finish().unwrap();\n///\n/// // base64 was written to the writer\n/// assert_eq!(b\"YXNkZg==\", &delegate[..]);\n///\n/// ```\n///\n/// # Panics\n///\n/// Calling `write()` (or related methods) or `finish()` after `finish()` has completed without\n/// error is invalid and will panic.\n///\n/// # Errors\n///\n/// Base64 encoding itself does not generate errors, but errors from the wrapped writer will be\n/// returned as per the contract of `Write`.\n///\n/// # Performance\n///\n/// It has some minor performance loss compared to encoding slices (a couple percent).\n/// It does not do any heap allocation.\n///\n/// # Limitations\n///\n/// Owing to the specification of the `write` and `flush` methods on the `Write` trait and their\n/// implications for a buffering implementation, these methods may not behave as expected. In\n/// particular, calling `write_all` on this interface may fail with `io::ErrorKind::WriteZero`.\n/// See the documentation of the `Write` trait implementation for further details.\npub struct EncoderWriter<'e, E: Engine, W: io::Write> {\n    engine: &'e E,\n    /// Where encoded data is written to. It's an Option as it's None immediately before Drop is\n    /// called so that `finish()` can return the underlying writer. None implies that `finish()` has\n    /// been called successfully.\n    delegate: Option<W>,\n    /// Holds a partial chunk, if any, after the last `write()`, so that we may then fill the chunk\n    /// with the next `write()`, encode it, then proceed with the rest of the input normally.\n    extra_input: [u8; MIN_ENCODE_CHUNK_SIZE],\n    /// How much of `extra` is occupied, in `[0, MIN_ENCODE_CHUNK_SIZE]`.\n    extra_input_occupied_len: usize,\n    /// Buffer to encode into. May hold leftover encoded bytes from a previous write call that the underlying writer\n    /// did not write last time.\n    output: [u8; BUF_SIZE],\n    /// How much of `output` is occupied with encoded data that couldn't be written last time\n    output_occupied_len: usize,\n    /// panic safety: don't write again in destructor if writer panicked while we were writing to it\n    panicked: bool,\n}","Real(LocalPath(\"src/write/encoder.rs\"))"],"write::encoder::EncoderWriter::<'e, E, W>::finish":["/// Encode all remaining buffered data and write it, including any trailing incomplete input\n/// triples and associated padding.\n///\n/// Once this succeeds, no further writes or calls to this method are allowed.\n///\n/// This may write to the delegate writer multiple times if the delegate writer does not accept\n/// all input provided to its `write` each invocation.\n///\n/// If you don't care about error handling, it is not necessary to call this function, as the\n/// equivalent finalization is done by the Drop impl.\n///\n/// Returns the writer that this was constructed around.\n///\n/// # Errors\n///\n/// The first error that is not of `ErrorKind::Interrupted` will be returned.\npub fn finish(&mut self) -> Result<W>{\n        // If we could consume self in finish(), we wouldn't have to worry about this case, but\n        // finish() is retryable in the face of I/O errors, so we can't consume here.\n        assert!(\n            self.delegate.is_some(),\n            \"Encoder has already had finish() called\"\n        );\n\n        self.write_final_leftovers()?;\n\n        let writer = self.delegate.take().expect(\"Writer must be present\");\n\n        Ok(writer)\n    }","Real(LocalPath(\"src/write/encoder.rs\"))"],"write::encoder::EncoderWriter::<'e, E, W>::into_inner":["/// Unwraps this `EncoderWriter`, returning the base writer it writes base64 encoded output\n/// to.\n///\n/// Normally this method should not be needed, since `finish()` returns the inner writer if\n/// it completes successfully. That will also ensure all data has been flushed, which the\n/// `into_inner()` function does *not* do.\n///\n/// Calling this method after `finish()` has completed successfully will panic, since the\n/// writer has already been returned.\n///\n/// This method may be useful if the writer implements additional APIs beyond the `Write`\n/// trait. Note that the inner writer might be in an error state or have an incomplete\n/// base64 string written to it.\npub fn into_inner(mut self) -> W{\n        self.delegate\n            .take()\n            .expect(\"Encoder has already had finish() called\")\n    }","Real(LocalPath(\"src/write/encoder.rs\"))"],"write::encoder::EncoderWriter::<'e, E, W>::new":["/// Create a new encoder that will write to the provided delegate writer.\npub fn new(delegate: W, engine: &'e E) -> EncoderWriter<'e, E, W>{\n        EncoderWriter {\n            engine,\n            delegate: Some(delegate),\n            extra_input: [0u8; MIN_ENCODE_CHUNK_SIZE],\n            extra_input_occupied_len: 0,\n            output: [0u8; BUF_SIZE],\n            output_occupied_len: 0,\n            panicked: false,\n        }\n    }","Real(LocalPath(\"src/write/encoder.rs\"))"],"write::encoder::EncoderWriter::<'e, E, W>::write_all_encoded_output":["/// Write all buffered encoded output. If this returns `Ok`, `self.output_occupied_len` is `0`.\n///\n/// This is basically `write_all` for the remaining buffered data but without the undesirable\n/// abort-on-`Ok(0)` behavior.\n///\n/// # Errors\n///\n/// Any error emitted by the delegate writer abort the write loop and is returned, unless it's\n/// `Interrupted`, in which case the error is ignored and writes will continue.\nfn write_all_encoded_output(&mut self) -> Result<()>{\n        while self.output_occupied_len > 0 {\n            let remaining_len = self.output_occupied_len;\n            match self.write_to_delegate(remaining_len) {\n                // try again on interrupts ala write_all\n                Err(ref e) if e.kind() == ErrorKind::Interrupted => {}\n                // other errors return\n                Err(e) => return Err(e),\n                // success no-ops because remaining length is already updated\n                Ok(()) => {}\n            };\n        }\n\n        debug_assert_eq!(0, self.output_occupied_len);\n        Ok(())\n    }","Real(LocalPath(\"src/write/encoder.rs\"))"],"write::encoder::EncoderWriter::<'e, E, W>::write_final_leftovers":["/// Write any remaining buffered data to the delegate writer.\nfn write_final_leftovers(&mut self) -> Result<()>{\n        if self.delegate.is_none() {\n            // finish() has already successfully called this, and we are now in drop() with a None\n            // writer, so just no-op\n            return Ok(());\n        }\n\n        self.write_all_encoded_output()?;\n\n        if self.extra_input_occupied_len > 0 {\n            let encoded_len = self\n                .engine\n                .encode_slice(\n                    &self.extra_input[..self.extra_input_occupied_len],\n                    &mut self.output[..],\n                )\n                .expect(\"buffer is large enough\");\n\n            self.output_occupied_len = encoded_len;\n\n            self.write_all_encoded_output()?;\n\n            // write succeeded, do not write the encoding of extra again if finish() is retried\n            self.extra_input_occupied_len = 0;\n        }\n\n        Ok(())\n    }","Real(LocalPath(\"src/write/encoder.rs\"))"],"write::encoder::EncoderWriter::<'e, E, W>::write_to_delegate":["/// Write as much of the encoded output to the delegate writer as it will accept, and store the\n/// leftovers to be attempted at the next `write()` call. Updates `self.output_occupied_len`.\n///\n/// # Errors\n///\n/// Errors from the delegate writer are returned. In the case of an error,\n/// `self.output_occupied_len` will not be updated, as errors from `write` are specified to mean\n/// that no write took place.\nfn write_to_delegate(&mut self, current_output_len: usize) -> Result<()>{\n        self.panicked = true;\n        let res = self\n            .delegate\n            .as_mut()\n            .expect(\"Writer must be present\")\n            .write(&self.output[..current_output_len]);\n        self.panicked = false;\n\n        res.map(|consumed| {\n            debug_assert!(consumed <= current_output_len);\n\n            if consumed < current_output_len {\n                self.output_occupied_len = current_output_len.checked_sub(consumed).unwrap();\n                // If we're blocking on I/O, the minor inefficiency of copying bytes to the\n                // start of the buffer is the least of our concerns...\n                // TODO Rotate moves more than we need to; copy_within now stable.\n                self.output.rotate_left(consumed);\n            } else {\n                self.output_occupied_len = 0;\n            }\n        })\n    }","Real(LocalPath(\"src/write/encoder.rs\"))"],"write::encoder_string_writer::EncoderStringWriter":["/// A `Write` implementation that base64-encodes data using the provided config and accumulates the\n/// resulting base64 utf8 `&str` in a [`StrConsumer`] implementation (typically `String`), which is\n/// then exposed via `into_inner()`.\n///\n/// # Examples\n///\n/// Buffer base64 in a new String:\n///\n/// ```\n/// use std::io::Write;\n/// use base64::engine::general_purpose;\n///\n/// let mut enc = base64::write::EncoderStringWriter::new(&general_purpose::STANDARD);\n///\n/// enc.write_all(b\"asdf\").unwrap();\n///\n/// // get the resulting String\n/// let b64_string = enc.into_inner();\n///\n/// assert_eq!(\"YXNkZg==\", &b64_string);\n/// ```\n///\n/// Or, append to an existing `String`, which implements `StrConsumer`:\n///\n/// ```\n/// use std::io::Write;\n/// use base64::engine::general_purpose;\n///\n/// let mut buf = String::from(\"base64: \");\n///\n/// let mut enc = base64::write::EncoderStringWriter::from_consumer(\n///     &mut buf,\n///     &general_purpose::STANDARD);\n///\n/// enc.write_all(b\"asdf\").unwrap();\n///\n/// // release the &mut reference on buf\n/// let _ = enc.into_inner();\n///\n/// assert_eq!(\"base64: YXNkZg==\", &buf);\n/// ```\n///\n/// # Performance\n///\n/// Because it has to validate that the base64 is UTF-8, it is about 80% as fast as writing plain\n/// bytes to a `io::Write`.\npub struct EncoderStringWriter<'e, E: Engine, S: StrConsumer> {\n    encoder: EncoderWriter<'e, E, Utf8SingleCodeUnitWriter<S>>,\n}","Real(LocalPath(\"src/write/encoder_string_writer.rs\"))"],"write::encoder_string_writer::EncoderStringWriter::<'e, E, S>::from_consumer":["/// Create a `EncoderStringWriter` that will append to the provided `StrConsumer`.\npub fn from_consumer(str_consumer: S, engine: &'e E) -> Self{\n        EncoderStringWriter {\n            encoder: EncoderWriter::new(Utf8SingleCodeUnitWriter { str_consumer }, engine),\n        }\n    }","Real(LocalPath(\"src/write/encoder_string_writer.rs\"))"],"write::encoder_string_writer::EncoderStringWriter::<'e, E, S>::into_inner":["/// Encode all remaining buffered data, including any trailing incomplete input triples and\n/// associated padding.\n///\n/// Returns the base64-encoded form of the accumulated written data.\npub fn into_inner(mut self) -> S{\n        self.encoder\n            .finish()\n            .expect(\"Writing to a consumer should never fail\")\n            .str_consumer\n    }","Real(LocalPath(\"src/write/encoder_string_writer.rs\"))"],"write::encoder_string_writer::EncoderStringWriter::<'e, E, std::string::String>::new":["/// Create a `EncoderStringWriter` that will encode into a new `String` with the provided config.\npub fn new(engine: &'e E) -> Self{\n        EncoderStringWriter::from_consumer(String::new(), engine)\n    }","Real(LocalPath(\"src/write/encoder_string_writer.rs\"))"],"write::encoder_string_writer::StrConsumer":["/// An abstraction around consuming `str`s produced by base64 encoding.\npub trait StrConsumer {\n    /// Consume the base64 encoded data in `buf`\n    fn consume(&mut self, buf: &str);\n}","Real(LocalPath(\"src/write/encoder_string_writer.rs\"))"],"write::encoder_string_writer::Utf8SingleCodeUnitWriter":["/// A `Write` that only can handle bytes that are valid single-byte UTF-8 code units.\n///\n/// This is safe because we only use it when writing base64, which is always valid UTF-8.\nstruct Utf8SingleCodeUnitWriter<S: StrConsumer> {\n    str_consumer: S,\n}","Real(LocalPath(\"src/write/encoder_string_writer.rs\"))"]},"struct_constructor":{"&'^0.Named(DefId(0:684 ~ base64[4822]::engine::general_purpose::{impl#1}::config::'_), \"'_\") Alias(Projection, AliasTy { args: [engine::general_purpose::GeneralPurpose], def_id: DefId(0:328 ~ base64[4822]::engine::Engine::Config) })":["config"],"&'^0.Named(DefId(0:696 ~ base64[4822]::engine::Engine::config::'_), \"'_\") Alias(Projection, AliasTy { args: [Self/#0], def_id: DefId(0:328 ~ base64[4822]::engine::Engine::Config) })":["config"],"&'^0.Named(DefId(0:733 ~ base64[4822]::alphabet::{impl#0}::as_str::'_), \"'_\") str":["as_str"],"&'^0.Named(DefId(0:757 ~ base64[4822]::decode::{impl#3}::source::'_), \"'_\") dyn [Binder { value: Trait(std::error::Error), bound_vars: [] }] + 'static":["source"],"Alias(Projection, AliasTy { args: [Self/#0], def_id: DefId(0:329 ~ base64[4822]::engine::Engine::DecodeEstimate) })":["internal_decoded_len_estimate"],"Alias(Projection, AliasTy { args: [engine::general_purpose::GeneralPurpose], def_id: DefId(0:329 ~ base64[4822]::engine::Engine::DecodeEstimate) })":["internal_decoded_len_estimate"],"[u8; 256_usize]":["decode_table"],"[u8; 64_usize]":["encode_table"],"alphabet::Alphabet":["clone","from_str_unchecked","new","try_from"],"bool":["encode_padding","eq"],"chunked_encoder::ChunkedEncoder":["new"],"chunked_encoder::StringSink":["new"],"decode::DecodeError":["clone"],"decode::DecodeSliceError":["clone","from"],"display::Base64Display":["new"],"encode::EncodeSliceError":["clone"],"engine::DecodeMetadata":["decode_helper","decode_suffix","internal_decode","new"],"engine::DecodePaddingMode":["clone"],"engine::general_purpose::GeneralPurpose":["clone","new"],"engine::general_purpose::GeneralPurposeConfig":["clone","default","new"],"engine::general_purpose::decode::GeneralPurposeEstimate":["new"],"read::decoder::DecoderReader":["new"],"std::string::String":["encode","encode_engine","inner"],"std::vec::Vec":["decode","decode_engine","inner"],"u64":["read_u64"],"usize":["decode_engine_slice","decode_slice","decode_slice_unchecked","decoded_len_estimate","encode_engine_slice","encode_slice","flush_decoded_buf","inner","internal_encode","read","read_from_delegate","write"],"write::encoder::EncoderWriter":["new"],"write::encoder_string_writer::EncoderStringWriter":["from_consumer","new"]},"struct_to_trait":{"alphabet::Alphabet":["std::clone::Clone","std::cmp::Eq","std::cmp::PartialEq","std::convert::TryFrom","std::fmt::Debug","std::marker::StructuralPartialEq"],"alphabet::ParseAlphabetError":["std::cmp::Eq","std::cmp::PartialEq","std::error::Error","std::fmt::Debug","std::fmt::Display","std::marker::StructuralPartialEq"],"chunked_encoder::StringSink":["chunked_encoder::Sink"],"decode::DecodeError":["std::clone::Clone","std::cmp::Eq","std::cmp::PartialEq","std::error::Error","std::fmt::Debug","std::fmt::Display","std::marker::StructuralPartialEq"],"decode::DecodeSliceError":["std::clone::Clone","std::cmp::Eq","std::cmp::PartialEq","std::convert::From","std::error::Error","std::fmt::Debug","std::fmt::Display","std::marker::StructuralPartialEq"],"display::Base64Display":["std::fmt::Display"],"display::FormatterSink":["chunked_encoder::Sink"],"encode::EncodeSliceError":["std::clone::Clone","std::cmp::Eq","std::cmp::PartialEq","std::error::Error","std::fmt::Debug","std::fmt::Display","std::marker::StructuralPartialEq"],"engine::DecodeMetadata":["std::cmp::Eq","std::cmp::PartialEq","std::fmt::Debug","std::marker::StructuralPartialEq"],"engine::DecodePaddingMode":["std::clone::Clone","std::cmp::Eq","std::cmp::PartialEq","std::fmt::Debug","std::marker::Copy","std::marker::StructuralPartialEq"],"engine::general_purpose::GeneralPurpose":["engine::Engine","std::clone::Clone","std::fmt::Debug"],"engine::general_purpose::GeneralPurposeConfig":["engine::Config","std::clone::Clone","std::default::Default","std::fmt::Debug","std::marker::Copy"],"engine::general_purpose::decode::GeneralPurposeEstimate":["engine::DecodeEstimate"],"read::decoder::DecoderReader":["std::fmt::Debug","std::io::Read"],"std::string::String":["write::encoder_string_writer::StrConsumer"],"write::encoder::EncoderWriter":["std::fmt::Debug","std::io::Write","std::ops::Drop"],"write::encoder_string_writer::EncoderStringWriter":["std::io::Write"],"write::encoder_string_writer::Utf8SingleCodeUnitWriter":["std::io::Write"]},"targets":{"<&mut S as write::encoder_string_writer::StrConsumer>::consume":["consume","Real(LocalPath(\"src/write/encoder_string_writer.rs\"))","write::encoder_string_writer::StrConsumer"],"<alphabet::Alphabet as std::convert::TryFrom<&str>>::try_from":["try_from","Real(LocalPath(\"src/alphabet.rs\"))","std::convert::TryFrom"],"<alphabet::ParseAlphabetError as std::fmt::Display>::fmt":["fmt","Real(LocalPath(\"src/alphabet.rs\"))","std::fmt::Display"],"<chunked_encoder::StringSink<'a> as chunked_encoder::Sink>::write_encoded_bytes":["write_encoded_bytes","Real(LocalPath(\"src/chunked_encoder.rs\"))","chunked_encoder::Sink"],"<decode::DecodeError as std::fmt::Display>::fmt":["fmt","Real(LocalPath(\"src/decode.rs\"))","std::fmt::Display"],"<decode::DecodeSliceError as std::convert::From<decode::DecodeError>>::from":["from","Real(LocalPath(\"src/decode.rs\"))","std::convert::From"],"<decode::DecodeSliceError as std::error::Error>::source":["source","Real(LocalPath(\"src/decode.rs\"))","std::error::Error"],"<decode::DecodeSliceError as std::fmt::Display>::fmt":["fmt","Real(LocalPath(\"src/decode.rs\"))","std::fmt::Display"],"<display::Base64Display<'a, 'e, E> as std::fmt::Display>::fmt":["fmt","Real(LocalPath(\"src/display.rs\"))","std::fmt::Display"],"<display::FormatterSink<'a, 'b> as chunked_encoder::Sink>::write_encoded_bytes":["write_encoded_bytes","Real(LocalPath(\"src/display.rs\"))","chunked_encoder::Sink"],"<encode::EncodeSliceError as std::fmt::Display>::fmt":["fmt","Real(LocalPath(\"src/encode.rs\"))","std::fmt::Display"],"<engine::general_purpose::GeneralPurpose as engine::Engine>::config":["config","Real(LocalPath(\"src/engine/general_purpose/mod.rs\"))","engine::Engine"],"<engine::general_purpose::GeneralPurpose as engine::Engine>::internal_decode":["internal_decode","Real(LocalPath(\"src/engine/general_purpose/mod.rs\"))","engine::Engine"],"<engine::general_purpose::GeneralPurpose as engine::Engine>::internal_decoded_len_estimate":["internal_decoded_len_estimate","Real(LocalPath(\"src/engine/general_purpose/mod.rs\"))","engine::Engine"],"<engine::general_purpose::GeneralPurpose as engine::Engine>::internal_encode":["internal_encode","Real(LocalPath(\"src/engine/general_purpose/mod.rs\"))","engine::Engine"],"<engine::general_purpose::GeneralPurposeConfig as engine::Config>::encode_padding":["encode_padding","Real(LocalPath(\"src/engine/general_purpose/mod.rs\"))","engine::Config"],"<engine::general_purpose::GeneralPurposeConfig as std::default::Default>::default":["default","Real(LocalPath(\"src/engine/general_purpose/mod.rs\"))","std::default::Default"],"<engine::general_purpose::decode::GeneralPurposeEstimate as engine::DecodeEstimate>::decoded_len_estimate":["decoded_len_estimate","Real(LocalPath(\"src/engine/general_purpose/decode.rs\"))","engine::DecodeEstimate"],"<read::decoder::DecoderReader<'e, E, R> as std::fmt::Debug>::fmt":["fmt","Real(LocalPath(\"src/read/decoder.rs\"))","std::fmt::Debug"],"<read::decoder::DecoderReader<'e, E, R> as std::io::Read>::read":["read","Real(LocalPath(\"src/read/decoder.rs\"))","std::io::Read"],"<std::string::String as write::encoder_string_writer::StrConsumer>::consume":["consume","Real(LocalPath(\"src/write/encoder_string_writer.rs\"))","write::encoder_string_writer::StrConsumer"],"<write::encoder::EncoderWriter<'e, E, W> as std::fmt::Debug>::fmt":["fmt","Real(LocalPath(\"src/write/encoder.rs\"))","std::fmt::Debug"],"<write::encoder::EncoderWriter<'e, E, W> as std::io::Write>::flush":["flush","Real(LocalPath(\"src/write/encoder.rs\"))","std::io::Write"],"<write::encoder::EncoderWriter<'e, E, W> as std::io::Write>::write":["write","Real(LocalPath(\"src/write/encoder.rs\"))","std::io::Write"],"<write::encoder::EncoderWriter<'e, E, W> as std::ops::Drop>::drop":["drop","Real(LocalPath(\"src/write/encoder.rs\"))","std::ops::Drop"],"<write::encoder_string_writer::EncoderStringWriter<'e, E, S> as std::io::Write>::flush":["flush","Real(LocalPath(\"src/write/encoder_string_writer.rs\"))","std::io::Write"],"<write::encoder_string_writer::EncoderStringWriter<'e, E, S> as std::io::Write>::write":["write","Real(LocalPath(\"src/write/encoder_string_writer.rs\"))","std::io::Write"],"<write::encoder_string_writer::Utf8SingleCodeUnitWriter<S> as std::io::Write>::flush":["flush","Real(LocalPath(\"src/write/encoder_string_writer.rs\"))","std::io::Write"],"<write::encoder_string_writer::Utf8SingleCodeUnitWriter<S> as std::io::Write>::write":["write","Real(LocalPath(\"src/write/encoder_string_writer.rs\"))","std::io::Write"],"alphabet::Alphabet::as_str":["as_str","Real(LocalPath(\"src/alphabet.rs\"))",""],"alphabet::Alphabet::from_str_unchecked":["from_str_unchecked","Real(LocalPath(\"src/alphabet.rs\"))",""],"alphabet::Alphabet::new":["new","Real(LocalPath(\"src/alphabet.rs\"))",""],"chunked_encoder::ChunkedEncoder::<'e, E>::encode":["encode","Real(LocalPath(\"src/chunked_encoder.rs\"))",""],"chunked_encoder::ChunkedEncoder::<'e, E>::new":["new","Real(LocalPath(\"src/chunked_encoder.rs\"))",""],"chunked_encoder::StringSink::<'a>::new":["new","Real(LocalPath(\"src/chunked_encoder.rs\"))",""],"decode::decode":["decode","Real(LocalPath(\"src/decode.rs\"))",""],"decode::decode_engine":["decode_engine","Real(LocalPath(\"src/decode.rs\"))",""],"decode::decode_engine_slice":["decode_engine_slice","Real(LocalPath(\"src/decode.rs\"))",""],"decode::decode_engine_vec":["decode_engine_vec","Real(LocalPath(\"src/decode.rs\"))",""],"decode::decoded_len_estimate":["decoded_len_estimate","Real(LocalPath(\"src/decode.rs\"))",""],"display::Base64Display::<'a, 'e, E>::new":["new","Real(LocalPath(\"src/display.rs\"))",""],"encode::add_padding":["add_padding","Real(LocalPath(\"src/encode.rs\"))",""],"encode::encode":["encode","Real(LocalPath(\"src/encode.rs\"))",""],"encode::encode_engine":["encode_engine","Real(LocalPath(\"src/encode.rs\"))",""],"encode::encode_engine_slice":["encode_engine_slice","Real(LocalPath(\"src/encode.rs\"))",""],"encode::encode_engine_string":["encode_engine_string","Real(LocalPath(\"src/encode.rs\"))",""],"encode::encode_with_padding":["encode_with_padding","Real(LocalPath(\"src/encode.rs\"))",""],"encode::encoded_len":["encoded_len","Real(LocalPath(\"src/encode.rs\"))",""],"engine::DecodeMetadata::new":["new","Real(LocalPath(\"src/engine/mod.rs\"))",""],"engine::Engine::decode":["decode","Real(LocalPath(\"src/engine/mod.rs\"))",""],"engine::Engine::decode::inner":["inner","Real(LocalPath(\"src/engine/mod.rs\"))",""],"engine::Engine::decode_slice":["decode_slice","Real(LocalPath(\"src/engine/mod.rs\"))",""],"engine::Engine::decode_slice::inner":["inner","Real(LocalPath(\"src/engine/mod.rs\"))",""],"engine::Engine::decode_slice_unchecked":["decode_slice_unchecked","Real(LocalPath(\"src/engine/mod.rs\"))",""],"engine::Engine::decode_slice_unchecked::inner":["inner","Real(LocalPath(\"src/engine/mod.rs\"))",""],"engine::Engine::decode_vec":["decode_vec","Real(LocalPath(\"src/engine/mod.rs\"))",""],"engine::Engine::decode_vec::inner":["inner","Real(LocalPath(\"src/engine/mod.rs\"))",""],"engine::Engine::encode":["encode","Real(LocalPath(\"src/engine/mod.rs\"))",""],"engine::Engine::encode::inner":["inner","Real(LocalPath(\"src/engine/mod.rs\"))",""],"engine::Engine::encode_slice":["encode_slice","Real(LocalPath(\"src/engine/mod.rs\"))",""],"engine::Engine::encode_slice::inner":["inner","Real(LocalPath(\"src/engine/mod.rs\"))",""],"engine::Engine::encode_string":["encode_string","Real(LocalPath(\"src/engine/mod.rs\"))",""],"engine::Engine::encode_string::inner":["inner","Real(LocalPath(\"src/engine/mod.rs\"))",""],"engine::general_purpose::GeneralPurpose::new":["new","Real(LocalPath(\"src/engine/general_purpose/mod.rs\"))",""],"engine::general_purpose::GeneralPurposeConfig::new":["new","Real(LocalPath(\"src/engine/general_purpose/mod.rs\"))",""],"engine::general_purpose::GeneralPurposeConfig::with_decode_allow_trailing_bits":["with_decode_allow_trailing_bits","Real(LocalPath(\"src/engine/general_purpose/mod.rs\"))",""],"engine::general_purpose::GeneralPurposeConfig::with_decode_padding_mode":["with_decode_padding_mode","Real(LocalPath(\"src/engine/general_purpose/mod.rs\"))",""],"engine::general_purpose::GeneralPurposeConfig::with_encode_padding":["with_encode_padding","Real(LocalPath(\"src/engine/general_purpose/mod.rs\"))",""],"engine::general_purpose::decode::GeneralPurposeEstimate::new":["new","Real(LocalPath(\"src/engine/general_purpose/decode.rs\"))",""],"engine::general_purpose::decode::complete_quads_len":["complete_quads_len","Real(LocalPath(\"src/engine/general_purpose/decode.rs\"))",""],"engine::general_purpose::decode::decode_chunk_4":["decode_chunk_4","Real(LocalPath(\"src/engine/general_purpose/decode.rs\"))",""],"engine::general_purpose::decode::decode_chunk_8":["decode_chunk_8","Real(LocalPath(\"src/engine/general_purpose/decode.rs\"))",""],"engine::general_purpose::decode::decode_helper":["decode_helper","Real(LocalPath(\"src/engine/general_purpose/decode.rs\"))",""],"engine::general_purpose::decode_suffix::decode_suffix":["decode_suffix","Real(LocalPath(\"src/engine/general_purpose/decode_suffix.rs\"))",""],"engine::general_purpose::decode_table":["decode_table","Real(LocalPath(\"src/engine/general_purpose/mod.rs\"))",""],"engine::general_purpose::encode_table":["encode_table","Real(LocalPath(\"src/engine/general_purpose/mod.rs\"))",""],"engine::general_purpose::read_u64":["read_u64","Real(LocalPath(\"src/engine/general_purpose/mod.rs\"))",""],"read::decoder::DecoderReader::<'e, E, R>::decode_to_buf":["decode_to_buf","Real(LocalPath(\"src/read/decoder.rs\"))",""],"read::decoder::DecoderReader::<'e, E, R>::flush_decoded_buf":["flush_decoded_buf","Real(LocalPath(\"src/read/decoder.rs\"))",""],"read::decoder::DecoderReader::<'e, E, R>::into_inner":["into_inner","Real(LocalPath(\"src/read/decoder.rs\"))",""],"read::decoder::DecoderReader::<'e, E, R>::new":["new","Real(LocalPath(\"src/read/decoder.rs\"))",""],"read::decoder::DecoderReader::<'e, E, R>::read_from_delegate":["read_from_delegate","Real(LocalPath(\"src/read/decoder.rs\"))",""],"write::encoder::EncoderWriter::<'e, E, W>::finish":["finish","Real(LocalPath(\"src/write/encoder.rs\"))",""],"write::encoder::EncoderWriter::<'e, E, W>::into_inner":["into_inner","Real(LocalPath(\"src/write/encoder.rs\"))",""],"write::encoder::EncoderWriter::<'e, E, W>::new":["new","Real(LocalPath(\"src/write/encoder.rs\"))",""],"write::encoder::EncoderWriter::<'e, E, W>::write_all_encoded_output":["write_all_encoded_output","Real(LocalPath(\"src/write/encoder.rs\"))",""],"write::encoder::EncoderWriter::<'e, E, W>::write_final_leftovers":["write_final_leftovers","Real(LocalPath(\"src/write/encoder.rs\"))",""],"write::encoder::EncoderWriter::<'e, E, W>::write_to_delegate":["write_to_delegate","Real(LocalPath(\"src/write/encoder.rs\"))",""],"write::encoder_string_writer::EncoderStringWriter::<'e, E, S>::from_consumer":["from_consumer","Real(LocalPath(\"src/write/encoder_string_writer.rs\"))",""],"write::encoder_string_writer::EncoderStringWriter::<'e, E, S>::into_inner":["into_inner","Real(LocalPath(\"src/write/encoder_string_writer.rs\"))",""],"write::encoder_string_writer::EncoderStringWriter::<'e, E, std::string::String>::new":["new","Real(LocalPath(\"src/write/encoder_string_writer.rs\"))",""]},"trait_to_struct":{"chunked_encoder::Sink":["chunked_encoder::StringSink","display::FormatterSink"],"engine::Config":["engine::general_purpose::GeneralPurposeConfig"],"engine::DecodeEstimate":["engine::general_purpose::decode::GeneralPurposeEstimate"],"engine::Engine":["engine::general_purpose::GeneralPurpose"],"std::clone::Clone":["alphabet::Alphabet","decode::DecodeError","decode::DecodeSliceError","encode::EncodeSliceError","engine::DecodePaddingMode","engine::general_purpose::GeneralPurpose","engine::general_purpose::GeneralPurposeConfig"],"std::cmp::Eq":["alphabet::Alphabet","alphabet::ParseAlphabetError","decode::DecodeError","decode::DecodeSliceError","encode::EncodeSliceError","engine::DecodeMetadata","engine::DecodePaddingMode"],"std::cmp::PartialEq":["alphabet::Alphabet","alphabet::ParseAlphabetError","decode::DecodeError","decode::DecodeSliceError","encode::EncodeSliceError","engine::DecodeMetadata","engine::DecodePaddingMode"],"std::convert::From":["decode::DecodeSliceError"],"std::convert::TryFrom":["alphabet::Alphabet"],"std::default::Default":["engine::general_purpose::GeneralPurposeConfig"],"std::error::Error":["alphabet::ParseAlphabetError","decode::DecodeError","decode::DecodeSliceError","encode::EncodeSliceError"],"std::fmt::Debug":["alphabet::Alphabet","alphabet::ParseAlphabetError","decode::DecodeError","decode::DecodeSliceError","encode::EncodeSliceError","engine::DecodeMetadata","engine::DecodePaddingMode","engine::general_purpose::GeneralPurpose","engine::general_purpose::GeneralPurposeConfig","read::decoder::DecoderReader","write::encoder::EncoderWriter"],"std::fmt::Display":["alphabet::ParseAlphabetError","decode::DecodeError","decode::DecodeSliceError","display::Base64Display","encode::EncodeSliceError"],"std::io::Read":["read::decoder::DecoderReader"],"std::io::Write":["write::encoder::EncoderWriter","write::encoder_string_writer::EncoderStringWriter","write::encoder_string_writer::Utf8SingleCodeUnitWriter"],"std::marker::Copy":["engine::DecodePaddingMode","engine::general_purpose::GeneralPurposeConfig"],"std::marker::StructuralPartialEq":["alphabet::Alphabet","alphabet::ParseAlphabetError","decode::DecodeError","decode::DecodeSliceError","encode::EncodeSliceError","engine::DecodeMetadata","engine::DecodePaddingMode"],"std::ops::Drop":["write::encoder::EncoderWriter"],"write::encoder_string_writer::StrConsumer":["std::string::String"]},"type_to_def_path":{"alphabet::Alphabet":"alphabet::Alphabet","alphabet::ParseAlphabetError":"alphabet::ParseAlphabetError","chunked_encoder::ChunkedEncoder<'e, E>":"chunked_encoder::ChunkedEncoder","chunked_encoder::StringSink<'a>":"chunked_encoder::StringSink","decode::DecodeError":"decode::DecodeError","decode::DecodeSliceError":"decode::DecodeSliceError","display::Base64Display<'a, 'e, E>":"display::Base64Display","display::FormatterSink<'a, 'b>":"display::FormatterSink","encode::EncodeSliceError":"encode::EncodeSliceError","engine::DecodeMetadata":"engine::DecodeMetadata","engine::DecodePaddingMode":"engine::DecodePaddingMode","engine::general_purpose::GeneralPurpose":"engine::general_purpose::GeneralPurpose","engine::general_purpose::GeneralPurposeConfig":"engine::general_purpose::GeneralPurposeConfig","engine::general_purpose::decode::GeneralPurposeEstimate":"engine::general_purpose::decode::GeneralPurposeEstimate","read::decoder::DecoderReader<'e, E, R>":"read::decoder::DecoderReader","write::encoder::EncoderWriter<'e, E, W>":"write::encoder::EncoderWriter","write::encoder_string_writer::EncoderStringWriter<'e, E, S>":"write::encoder_string_writer::EncoderStringWriter","write::encoder_string_writer::Utf8SingleCodeUnitWriter<S>":"write::encoder_string_writer::Utf8SingleCodeUnitWriter"}}