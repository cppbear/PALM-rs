{
  "system_pt": "As a software testing expert, please generate accurate test oracles code based on the provided information. Follow these guidelines:\n1. Generate executable test oracle codes in plain text format, one per line. Do not output complete test functions, do not repeat provided test prefixes, avoid additional explanations, and do not use Markdown.\n2. Generate necessary test oracles solely for the provided test prefixes.\n3. Each test oracle's assertions are independent and have no dependencies between them.\n4. Group all non-assertion statements first, followed by all assertion statements.\n5. Generate test oracles by interpreting the behavior of the test function through the provided test prefixes, context, and documentation.\n",
  "static_pt": "The context for the focal function is as follows:\n// src/raw/mod.rs\n// crate name is hashbrown\nuse crate::alloc::alloc::{handle_alloc_error, Layout};\nuse crate::scopeguard::{guard, ScopeGuard};\nuse crate::TryReserveError;\nuse core::array;\nuse core::iter::FusedIterator;\nuse core::marker::PhantomData;\nuse core::mem;\nuse core::ptr::NonNull;\nuse core::{hint, ptr};\npub(crate) use self::alloc::{do_alloc, Allocator, Global};\nuse self::bitmask::BitMaskIter;\nuse self::imp::Group;\n#[cfg(not(feature = \"nightly\"))]\nuse core::convert::{identity as likely, identity as unlikely};\n#[cfg(feature = \"nightly\")]\nuse core::intrinsics::{likely, unlikely};\ncfg_if! {\n    if #[cfg(all(target_feature = \"sse2\", any(target_arch = \"x86\", target_arch =\n    \"x86_64\"), not(miri),))] { mod sse2; use sse2 as imp; } else if #[cfg(all(target_arch\n    = \"aarch64\", target_feature = \"neon\", target_endian = \"little\", not(miri),))] { mod\n    neon; use neon as imp; } else { mod generic; use generic as imp; }\n}\npub struct Bucket<T> {\n    ptr: NonNull<T>,\n}\nimpl<T> Bucket<T> {\n    #[inline]\n    unsafe fn from_base_index(base: NonNull<T>, index: usize) -> Self {\n        let ptr = if T::IS_ZERO_SIZED {\n            invalid_mut(index + 1)\n        } else {\n            base.as_ptr().sub(index)\n        };\n        Self {\n            ptr: NonNull::new_unchecked(ptr),\n        }\n    }\n    #[inline]\n    unsafe fn to_base_index(&self, base: NonNull<T>) -> usize {}\n    #[inline]\n    pub fn as_ptr(&self) -> *mut T {}\n    #[inline]\n    fn as_non_null(&self) -> NonNull<T> {}\n    #[inline]\n    unsafe fn next_n(&self, offset: usize) -> Self {\n        let ptr = if T::IS_ZERO_SIZED {\n            invalid_mut(self.ptr.as_ptr() as usize + offset)\n        } else {\n            self.ptr.as_ptr().sub(offset)\n        };\n        Self {\n            ptr: NonNull::new_unchecked(ptr),\n        }\n    }\n    #[cfg_attr(feature = \"inline-more\", inline)]\n    pub(crate) unsafe fn drop(&self) {}\n    #[inline]\n    pub(crate) unsafe fn read(&self) -> T {}\n    #[inline]\n    pub(crate) unsafe fn write(&self, val: T) {}\n    #[inline]\n    pub unsafe fn as_ref<'a>(&self) -> &'a T {}\n    #[inline]\n    pub unsafe fn as_mut<'a>(&self) -> &'a mut T {}\n}\n#[inline(always)]\n#[allow(clippy::useless_transmute)]\nfn invalid_mut<T>(addr: usize) -> *mut T {\n    unsafe { core::mem::transmute(addr) }\n}\n\nThe function to be tested is presented as follows:\n/// Create a new [`Bucket`] that is offset from the `self` by the given\n/// `offset`. The pointer calculation is performed by calculating the\n/// offset from `self` pointer (convenience for `self.ptr.as_ptr().sub(offset)`).\n/// This function is used for iterators.\n///\n/// `offset` is in units of `T`; e.g., a `offset` of 3 represents a pointer\n/// offset of `3 * size_of::<T>()` bytes.\n///\n/// # Safety\n///\n/// If `mem::size_of::<T>() != 0`, then the safety rules are directly derived\n/// from the safety rules for [`<*mut T>::sub`] method of `*mut T` and safety\n/// rules of [`NonNull::new_unchecked`] function.\n///\n/// Thus, in order to uphold the safety contracts for [`<*mut T>::sub`] method\n/// and [`NonNull::new_unchecked`] function, as well as for the correct\n/// logic of the work of this crate, the following rules are necessary and\n/// sufficient:\n///\n/// * `self` contained pointer must not be `dangling`;\n///\n/// * `self.to_base_index() + offset` must not be greater than `RawTableInner.bucket_mask`,\n///   i.e. `(self.to_base_index() + offset) <= RawTableInner.bucket_mask` or, in other\n///   words, `self.to_base_index() + offset + 1` must be no greater than the number returned\n///   by the function [`RawTable::buckets`] or [`RawTableInner::buckets`].\n///\n/// If `mem::size_of::<T>() == 0`, then the only requirement is that the\n/// `self.to_base_index() + offset` must not be greater than `RawTableInner.bucket_mask`,\n/// i.e. `(self.to_base_index() + offset) <= RawTableInner.bucket_mask` or, in other words,\n/// `self.to_base_index() + offset + 1` must be no greater than the number returned by the\n/// function [`RawTable::buckets`] or [`RawTableInner::buckets`].\n///\n/// [`Bucket`]: crate::raw::Bucket\n/// [`<*mut T>::sub`]: https://doc.rust-lang.org/core/primitive.pointer.html#method.sub-1\n/// [`NonNull::new_unchecked`]: https://doc.rust-lang.org/stable/std/ptr/struct.NonNull.html#method.new_unchecked\n/// [`RawTable::buckets`]: crate::raw::RawTable::buckets\n/// [`RawTableInner::buckets`]: RawTableInner::buckets\nunsafe fn next_n(&self, offset: usize) -> Self {\n    let ptr = if T::IS_ZERO_SIZED {\n        // invalid pointer is good enough for ZST\n        invalid_mut(self.ptr.as_ptr() as usize + offset)\n    } else {\n        self.ptr.as_ptr().sub(offset)\n    };\n    Self {\n        ptr: NonNull::new_unchecked(ptr),\n    }\n}\n",
  "depend_pt": ""
}