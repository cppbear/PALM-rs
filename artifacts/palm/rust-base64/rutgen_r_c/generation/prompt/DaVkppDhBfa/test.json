{
  "system_pt": "As a software testing expert, please generate Rust test functions based on the following guidelines:\n1. Provide the code in plain text format, without explanations or Markdown.\n2. If the method under test belongs to a trait, construct appropriate structs within the test function, but avoid method overrides. If the method under test uses generics, instantiate them with suitable types based on the context.\n3. Generate test code with minimal scope: avoid creating external structures or implementations. Instead, define any necessary helper structures or implementations directly within the test function when required.\n4. Whenever possible, initialize the corresponding data structures using the initialization methods provided in the context if exist.\n5. Ensure the generated function is fully implemented and can be compiled and executed directly without any missing parts.\n6. Create a minimal yet complete set of test functions, ensuring they adhere to all provided preconditions and cover boundary conditions.\n7. Do not create a test module, but include intrinsic attributes like #[test] or #[should_panic] where necessary.\n",
  "static_pt": "The context for the focal function is as follows:\n// src/engine/general_purpose/mod.rs\n// crate name is base64\nuse crate::{\n    alphabet, alphabet::Alphabet, engine::{Config, DecodeMetadata, DecodePaddingMode},\n    DecodeSliceError,\n};\nuse core::convert::TryInto;\npub use decode::GeneralPurposeEstimate;\npub(crate) const INVALID_VALUE: u8 = 255;\npub const STANDARD: GeneralPurpose = GeneralPurpose::new(&alphabet::STANDARD, PAD);\npub const STANDARD_PAD_INDIFFERENT: GeneralPurpose = GeneralPurpose::new(\n    &alphabet::STANDARD,\n    PAD_INDIFFERENT,\n);\npub const STANDARD_NO_PAD: GeneralPurpose = GeneralPurpose::new(\n    &alphabet::STANDARD,\n    NO_PAD,\n);\npub const STANDARD_NO_PAD_INDIFFERENT: GeneralPurpose = GeneralPurpose::new(\n    &alphabet::STANDARD,\n    NO_PAD_INDIFFERENT,\n);\npub const URL_SAFE: GeneralPurpose = GeneralPurpose::new(&alphabet::URL_SAFE, PAD);\npub const URL_SAFE_PAD_INDIFFERENT: GeneralPurpose = GeneralPurpose::new(\n    &alphabet::URL_SAFE,\n    PAD_INDIFFERENT,\n);\npub const URL_SAFE_NO_PAD: GeneralPurpose = GeneralPurpose::new(\n    &alphabet::URL_SAFE,\n    NO_PAD,\n);\npub const URL_SAFE_NO_PAD_INDIFFERENT: GeneralPurpose = GeneralPurpose::new(\n    &alphabet::URL_SAFE,\n    NO_PAD_INDIFFERENT,\n);\npub const PAD: GeneralPurposeConfig = GeneralPurposeConfig::new();\npub const PAD_INDIFFERENT: GeneralPurposeConfig = GeneralPurposeConfig::new()\n    .with_encode_padding(true)\n    .with_decode_padding_mode(DecodePaddingMode::Indifferent);\npub const NO_PAD: GeneralPurposeConfig = GeneralPurposeConfig::new()\n    .with_encode_padding(false)\n    .with_decode_padding_mode(DecodePaddingMode::RequireNone);\npub const NO_PAD_INDIFFERENT: GeneralPurposeConfig = GeneralPurposeConfig::new()\n    .with_encode_padding(false)\n    .with_decode_padding_mode(DecodePaddingMode::Indifferent);\npub trait Engine: Send + Sync {\n    type Config: Config;\n    type DecodeEstimate: DecodeEstimate;\n    fn internal_encode(&self, input: &[u8], output: &mut [u8]) -> usize;\n    fn internal_decoded_len_estimate(&self, input_len: usize) -> Self::DecodeEstimate;\n    fn internal_decode(\n        &self,\n        input: &[u8],\n        output: &mut [u8],\n        decode_estimate: Self::DecodeEstimate,\n    ) -> Result<DecodeMetadata, DecodeSliceError>;\n    fn config(&self) -> &Self::Config;\n    #[cfg(any(feature = \"alloc\", test))]\n    #[inline]\n    fn encode<T: AsRef<[u8]>>(&self, input: T) -> String {\n        fn inner<E>(engine: &E, input_bytes: &[u8]) -> String\n        where\n            E: Engine + ?Sized,\n        {\n            let encoded_size = encoded_len(\n                    input_bytes.len(),\n                    engine.config().encode_padding(),\n                )\n                .expect(\"integer overflow when calculating buffer size\");\n            let mut buf = vec![0; encoded_size];\n            encode_with_padding(input_bytes, &mut buf[..], engine, encoded_size);\n            String::from_utf8(buf).expect(\"Invalid UTF8\")\n        }\n        inner(self, input.as_ref())\n    }\n    #[cfg(any(feature = \"alloc\", test))]\n    #[inline]\n    fn encode_string<T: AsRef<[u8]>>(&self, input: T, output_buf: &mut String) {\n        fn inner<E>(engine: &E, input_bytes: &[u8], output_buf: &mut String)\n        where\n            E: Engine + ?Sized,\n        {\n            let mut sink = chunked_encoder::StringSink::new(output_buf);\n            chunked_encoder::ChunkedEncoder::new(engine)\n                .encode(input_bytes, &mut sink)\n                .expect(\"Writing to a String shouldn't fail\");\n        }\n        inner(self, input.as_ref(), output_buf);\n    }\n    #[cfg_attr(feature = \"alloc\", doc = \"```\")]\n    #[cfg_attr(not(feature = \"alloc\"), doc = \"```ignore\")]\n    #[inline]\n    fn encode_slice<T: AsRef<[u8]>>(\n        &self,\n        input: T,\n        output_buf: &mut [u8],\n    ) -> Result<usize, EncodeSliceError> {\n        fn inner<E>(\n            engine: &E,\n            input_bytes: &[u8],\n            output_buf: &mut [u8],\n        ) -> Result<usize, EncodeSliceError>\n        where\n            E: Engine + ?Sized,\n        {\n            let encoded_size = encoded_len(\n                    input_bytes.len(),\n                    engine.config().encode_padding(),\n                )\n                .expect(\"usize overflow when calculating buffer size\");\n            if output_buf.len() < encoded_size {\n                return Err(EncodeSliceError::OutputSliceTooSmall);\n            }\n            let b64_output = &mut output_buf[0..encoded_size];\n            encode_with_padding(input_bytes, b64_output, engine, encoded_size);\n            Ok(encoded_size)\n        }\n        inner(self, input.as_ref(), output_buf)\n    }\n    #[cfg(any(feature = \"alloc\", test))]\n    #[inline]\n    fn decode<T: AsRef<[u8]>>(&self, input: T) -> Result<Vec<u8>, DecodeError> {\n        fn inner<E>(engine: &E, input_bytes: &[u8]) -> Result<Vec<u8>, DecodeError>\n        where\n            E: Engine + ?Sized,\n        {\n            let estimate = engine.internal_decoded_len_estimate(input_bytes.len());\n            let mut buffer = vec![0; estimate.decoded_len_estimate()];\n            let bytes_written = engine\n                .internal_decode(input_bytes, &mut buffer, estimate)\n                .map_err(|e| match e {\n                    DecodeSliceError::DecodeError(e) => e,\n                    DecodeSliceError::OutputSliceTooSmall => {\n                        unreachable!(\"Vec is sized conservatively\")\n                    }\n                })?\n                .decoded_len;\n            buffer.truncate(bytes_written);\n            Ok(buffer)\n        }\n        inner(self, input.as_ref())\n    }\n    #[cfg(any(feature = \"alloc\", test))]\n    #[inline]\n    fn decode_vec<T: AsRef<[u8]>>(\n        &self,\n        input: T,\n        buffer: &mut Vec<u8>,\n    ) -> Result<(), DecodeError> {\n        fn inner<E>(\n            engine: &E,\n            input_bytes: &[u8],\n            buffer: &mut Vec<u8>,\n        ) -> Result<(), DecodeError>\n        where\n            E: Engine + ?Sized,\n        {\n            let starting_output_len = buffer.len();\n            let estimate = engine.internal_decoded_len_estimate(input_bytes.len());\n            let total_len_estimate = estimate\n                .decoded_len_estimate()\n                .checked_add(starting_output_len)\n                .expect(\"Overflow when calculating output buffer length\");\n            buffer.resize(total_len_estimate, 0);\n            let buffer_slice = &mut buffer.as_mut_slice()[starting_output_len..];\n            let bytes_written = engine\n                .internal_decode(input_bytes, buffer_slice, estimate)\n                .map_err(|e| match e {\n                    DecodeSliceError::DecodeError(e) => e,\n                    DecodeSliceError::OutputSliceTooSmall => {\n                        unreachable!(\"Vec is sized conservatively\")\n                    }\n                })?\n                .decoded_len;\n            buffer.truncate(starting_output_len + bytes_written);\n            Ok(())\n        }\n        inner(self, input.as_ref(), buffer)\n    }\n    #[inline]\n    fn decode_slice<T: AsRef<[u8]>>(\n        &self,\n        input: T,\n        output: &mut [u8],\n    ) -> Result<usize, DecodeSliceError> {\n        fn inner<E>(\n            engine: &E,\n            input_bytes: &[u8],\n            output: &mut [u8],\n        ) -> Result<usize, DecodeSliceError>\n        where\n            E: Engine + ?Sized,\n        {\n            engine\n                .internal_decode(\n                    input_bytes,\n                    output,\n                    engine.internal_decoded_len_estimate(input_bytes.len()),\n                )\n                .map(|dm| dm.decoded_len)\n        }\n        inner(self, input.as_ref(), output)\n    }\n    #[inline]\n    fn decode_slice_unchecked<T: AsRef<[u8]>>(\n        &self,\n        input: T,\n        output: &mut [u8],\n    ) -> Result<usize, DecodeError> {\n        fn inner<E>(\n            engine: &E,\n            input_bytes: &[u8],\n            output: &mut [u8],\n        ) -> Result<usize, DecodeError>\n        where\n            E: Engine + ?Sized,\n        {\n            engine\n                .internal_decode(\n                    input_bytes,\n                    output,\n                    engine.internal_decoded_len_estimate(input_bytes.len()),\n                )\n                .map(|dm| dm.decoded_len)\n                .map_err(|e| match e {\n                    DecodeSliceError::DecodeError(e) => e,\n                    DecodeSliceError::OutputSliceTooSmall => {\n                        panic!(\"Output slice is too small\")\n                    }\n                })\n        }\n        inner(self, input.as_ref(), output)\n    }\n}\n#[derive(Debug, Clone)]\npub struct GeneralPurpose {\n    encode_table: [u8; 64],\n    decode_table: [u8; 256],\n    config: GeneralPurposeConfig,\n}\npub struct GeneralPurposeEstimate {\n    /// input len % 4\n    rem: usize,\n    conservative_decoded_len: usize,\n}\n#[derive(Clone, Copy, Debug)]\npub struct GeneralPurposeConfig {\n    encode_padding: bool,\n    decode_allow_trailing_bits: bool,\n    decode_padding_mode: DecodePaddingMode,\n}\nimpl super::Engine for GeneralPurpose {\n    type Config = GeneralPurposeConfig;\n    type DecodeEstimate = GeneralPurposeEstimate;\n    fn internal_encode(&self, input: &[u8], output: &mut [u8]) -> usize {\n        let mut input_index: usize = 0;\n        const BLOCKS_PER_FAST_LOOP: usize = 4;\n        const LOW_SIX_BITS: u64 = 0x3F;\n        let last_fast_index = input.len().saturating_sub(BLOCKS_PER_FAST_LOOP * 6 + 2);\n        let mut output_index = 0;\n        if last_fast_index > 0 {\n            while input_index <= last_fast_index {\n                let input_chunk = &input[input_index..(input_index\n                    + (BLOCKS_PER_FAST_LOOP * 6 + 2))];\n                let output_chunk = &mut output[output_index..(output_index\n                    + BLOCKS_PER_FAST_LOOP * 8)];\n                let input_u64 = read_u64(&input_chunk[0..]);\n                output_chunk[0] = self\n                    .encode_table[((input_u64 >> 58) & LOW_SIX_BITS) as usize];\n                output_chunk[1] = self\n                    .encode_table[((input_u64 >> 52) & LOW_SIX_BITS) as usize];\n                output_chunk[2] = self\n                    .encode_table[((input_u64 >> 46) & LOW_SIX_BITS) as usize];\n                output_chunk[3] = self\n                    .encode_table[((input_u64 >> 40) & LOW_SIX_BITS) as usize];\n                output_chunk[4] = self\n                    .encode_table[((input_u64 >> 34) & LOW_SIX_BITS) as usize];\n                output_chunk[5] = self\n                    .encode_table[((input_u64 >> 28) & LOW_SIX_BITS) as usize];\n                output_chunk[6] = self\n                    .encode_table[((input_u64 >> 22) & LOW_SIX_BITS) as usize];\n                output_chunk[7] = self\n                    .encode_table[((input_u64 >> 16) & LOW_SIX_BITS) as usize];\n                let input_u64 = read_u64(&input_chunk[6..]);\n                output_chunk[8] = self\n                    .encode_table[((input_u64 >> 58) & LOW_SIX_BITS) as usize];\n                output_chunk[9] = self\n                    .encode_table[((input_u64 >> 52) & LOW_SIX_BITS) as usize];\n                output_chunk[10] = self\n                    .encode_table[((input_u64 >> 46) & LOW_SIX_BITS) as usize];\n                output_chunk[11] = self\n                    .encode_table[((input_u64 >> 40) & LOW_SIX_BITS) as usize];\n                output_chunk[12] = self\n                    .encode_table[((input_u64 >> 34) & LOW_SIX_BITS) as usize];\n                output_chunk[13] = self\n                    .encode_table[((input_u64 >> 28) & LOW_SIX_BITS) as usize];\n                output_chunk[14] = self\n                    .encode_table[((input_u64 >> 22) & LOW_SIX_BITS) as usize];\n                output_chunk[15] = self\n                    .encode_table[((input_u64 >> 16) & LOW_SIX_BITS) as usize];\n                let input_u64 = read_u64(&input_chunk[12..]);\n                output_chunk[16] = self\n                    .encode_table[((input_u64 >> 58) & LOW_SIX_BITS) as usize];\n                output_chunk[17] = self\n                    .encode_table[((input_u64 >> 52) & LOW_SIX_BITS) as usize];\n                output_chunk[18] = self\n                    .encode_table[((input_u64 >> 46) & LOW_SIX_BITS) as usize];\n                output_chunk[19] = self\n                    .encode_table[((input_u64 >> 40) & LOW_SIX_BITS) as usize];\n                output_chunk[20] = self\n                    .encode_table[((input_u64 >> 34) & LOW_SIX_BITS) as usize];\n                output_chunk[21] = self\n                    .encode_table[((input_u64 >> 28) & LOW_SIX_BITS) as usize];\n                output_chunk[22] = self\n                    .encode_table[((input_u64 >> 22) & LOW_SIX_BITS) as usize];\n                output_chunk[23] = self\n                    .encode_table[((input_u64 >> 16) & LOW_SIX_BITS) as usize];\n                let input_u64 = read_u64(&input_chunk[18..]);\n                output_chunk[24] = self\n                    .encode_table[((input_u64 >> 58) & LOW_SIX_BITS) as usize];\n                output_chunk[25] = self\n                    .encode_table[((input_u64 >> 52) & LOW_SIX_BITS) as usize];\n                output_chunk[26] = self\n                    .encode_table[((input_u64 >> 46) & LOW_SIX_BITS) as usize];\n                output_chunk[27] = self\n                    .encode_table[((input_u64 >> 40) & LOW_SIX_BITS) as usize];\n                output_chunk[28] = self\n                    .encode_table[((input_u64 >> 34) & LOW_SIX_BITS) as usize];\n                output_chunk[29] = self\n                    .encode_table[((input_u64 >> 28) & LOW_SIX_BITS) as usize];\n                output_chunk[30] = self\n                    .encode_table[((input_u64 >> 22) & LOW_SIX_BITS) as usize];\n                output_chunk[31] = self\n                    .encode_table[((input_u64 >> 16) & LOW_SIX_BITS) as usize];\n                output_index += BLOCKS_PER_FAST_LOOP * 8;\n                input_index += BLOCKS_PER_FAST_LOOP * 6;\n            }\n        }\n        const LOW_SIX_BITS_U8: u8 = 0x3F;\n        let rem = input.len() % 3;\n        let start_of_rem = input.len() - rem;\n        while input_index < start_of_rem {\n            let input_chunk = &input[input_index..(input_index + 3)];\n            let output_chunk = &mut output[output_index..(output_index + 4)];\n            output_chunk[0] = self.encode_table[(input_chunk[0] >> 2) as usize];\n            output_chunk[1] = self\n                .encode_table[((input_chunk[0] << 4 | input_chunk[1] >> 4)\n                & LOW_SIX_BITS_U8) as usize];\n            output_chunk[2] = self\n                .encode_table[((input_chunk[1] << 2 | input_chunk[2] >> 6)\n                & LOW_SIX_BITS_U8) as usize];\n            output_chunk[3] = self\n                .encode_table[(input_chunk[2] & LOW_SIX_BITS_U8) as usize];\n            input_index += 3;\n            output_index += 4;\n        }\n        if rem == 2 {\n            output[output_index] = self\n                .encode_table[(input[start_of_rem] >> 2) as usize];\n            output[output_index + 1] = self\n                .encode_table[((input[start_of_rem] << 4 | input[start_of_rem + 1] >> 4)\n                & LOW_SIX_BITS_U8) as usize];\n            output[output_index + 2] = self\n                .encode_table[((input[start_of_rem + 1] << 2) & LOW_SIX_BITS_U8)\n                as usize];\n            output_index += 3;\n        } else if rem == 1 {\n            output[output_index] = self\n                .encode_table[(input[start_of_rem] >> 2) as usize];\n            output[output_index + 1] = self\n                .encode_table[((input[start_of_rem] << 4) & LOW_SIX_BITS_U8) as usize];\n            output_index += 2;\n        }\n        output_index\n    }\n    fn internal_decoded_len_estimate(&self, input_len: usize) -> Self::DecodeEstimate {\n        GeneralPurposeEstimate::new(input_len)\n    }\n    fn internal_decode(\n        &self,\n        input: &[u8],\n        output: &mut [u8],\n        estimate: Self::DecodeEstimate,\n    ) -> Result<DecodeMetadata, DecodeSliceError> {}\n    fn config(&self) -> &Self::Config {\n        &self.config\n    }\n}\n#[inline]\nfn read_u64(s: &[u8]) -> u64 {\n    u64::from_be_bytes(s[..8].try_into().unwrap())\n}\n\nThe function to be tested is presented as follows:\nfn internal_encode(&self, input: &[u8], output: &mut [u8]) -> usize {\n    let mut input_index: usize = 0;\n\n    const BLOCKS_PER_FAST_LOOP: usize = 4;\n    const LOW_SIX_BITS: u64 = 0x3F;\n\n    // we read 8 bytes at a time (u64) but only actually consume 6 of those bytes. Thus, we need\n    // 2 trailing bytes to be available to read..\n    let last_fast_index = input.len().saturating_sub(BLOCKS_PER_FAST_LOOP * 6 + 2);\n    let mut output_index = 0;\n\n    if last_fast_index > 0 {\n        while input_index <= last_fast_index {\n            // Major performance wins from letting the optimizer do the bounds check once, mostly\n            // on the output side\n            let input_chunk =\n                &input[input_index..(input_index + (BLOCKS_PER_FAST_LOOP * 6 + 2))];\n            let output_chunk =\n                &mut output[output_index..(output_index + BLOCKS_PER_FAST_LOOP * 8)];\n\n            // Hand-unrolling for 32 vs 16 or 8 bytes produces yields performance about equivalent\n            // to unsafe pointer code on a Xeon E5-1650v3. 64 byte unrolling was slightly better for\n            // large inputs but significantly worse for 50-byte input, unsurprisingly. I suspect\n            // that it's a not uncommon use case to encode smallish chunks of data (e.g. a 64-byte\n            // SHA-512 digest), so it would be nice if that fit in the unrolled loop at least once.\n            // Plus, single-digit percentage performance differences might well be quite different\n            // on different hardware.\n\n            let input_u64 = read_u64(&input_chunk[0..]);\n\n            output_chunk[0] = self.encode_table[((input_u64 >> 58) & LOW_SIX_BITS) as usize];\n            output_chunk[1] = self.encode_table[((input_u64 >> 52) & LOW_SIX_BITS) as usize];\n            output_chunk[2] = self.encode_table[((input_u64 >> 46) & LOW_SIX_BITS) as usize];\n            output_chunk[3] = self.encode_table[((input_u64 >> 40) & LOW_SIX_BITS) as usize];\n            output_chunk[4] = self.encode_table[((input_u64 >> 34) & LOW_SIX_BITS) as usize];\n            output_chunk[5] = self.encode_table[((input_u64 >> 28) & LOW_SIX_BITS) as usize];\n            output_chunk[6] = self.encode_table[((input_u64 >> 22) & LOW_SIX_BITS) as usize];\n            output_chunk[7] = self.encode_table[((input_u64 >> 16) & LOW_SIX_BITS) as usize];\n\n            let input_u64 = read_u64(&input_chunk[6..]);\n\n            output_chunk[8] = self.encode_table[((input_u64 >> 58) & LOW_SIX_BITS) as usize];\n            output_chunk[9] = self.encode_table[((input_u64 >> 52) & LOW_SIX_BITS) as usize];\n            output_chunk[10] = self.encode_table[((input_u64 >> 46) & LOW_SIX_BITS) as usize];\n            output_chunk[11] = self.encode_table[((input_u64 >> 40) & LOW_SIX_BITS) as usize];\n            output_chunk[12] = self.encode_table[((input_u64 >> 34) & LOW_SIX_BITS) as usize];\n            output_chunk[13] = self.encode_table[((input_u64 >> 28) & LOW_SIX_BITS) as usize];\n            output_chunk[14] = self.encode_table[((input_u64 >> 22) & LOW_SIX_BITS) as usize];\n            output_chunk[15] = self.encode_table[((input_u64 >> 16) & LOW_SIX_BITS) as usize];\n\n            let input_u64 = read_u64(&input_chunk[12..]);\n\n            output_chunk[16] = self.encode_table[((input_u64 >> 58) & LOW_SIX_BITS) as usize];\n            output_chunk[17] = self.encode_table[((input_u64 >> 52) & LOW_SIX_BITS) as usize];\n            output_chunk[18] = self.encode_table[((input_u64 >> 46) & LOW_SIX_BITS) as usize];\n            output_chunk[19] = self.encode_table[((input_u64 >> 40) & LOW_SIX_BITS) as usize];\n            output_chunk[20] = self.encode_table[((input_u64 >> 34) & LOW_SIX_BITS) as usize];\n            output_chunk[21] = self.encode_table[((input_u64 >> 28) & LOW_SIX_BITS) as usize];\n            output_chunk[22] = self.encode_table[((input_u64 >> 22) & LOW_SIX_BITS) as usize];\n            output_chunk[23] = self.encode_table[((input_u64 >> 16) & LOW_SIX_BITS) as usize];\n\n            let input_u64 = read_u64(&input_chunk[18..]);\n\n            output_chunk[24] = self.encode_table[((input_u64 >> 58) & LOW_SIX_BITS) as usize];\n            output_chunk[25] = self.encode_table[((input_u64 >> 52) & LOW_SIX_BITS) as usize];\n            output_chunk[26] = self.encode_table[((input_u64 >> 46) & LOW_SIX_BITS) as usize];\n            output_chunk[27] = self.encode_table[((input_u64 >> 40) & LOW_SIX_BITS) as usize];\n            output_chunk[28] = self.encode_table[((input_u64 >> 34) & LOW_SIX_BITS) as usize];\n            output_chunk[29] = self.encode_table[((input_u64 >> 28) & LOW_SIX_BITS) as usize];\n            output_chunk[30] = self.encode_table[((input_u64 >> 22) & LOW_SIX_BITS) as usize];\n            output_chunk[31] = self.encode_table[((input_u64 >> 16) & LOW_SIX_BITS) as usize];\n\n            output_index += BLOCKS_PER_FAST_LOOP * 8;\n            input_index += BLOCKS_PER_FAST_LOOP * 6;\n        }\n    }\n\n    // Encode what's left after the fast loop.\n\n    const LOW_SIX_BITS_U8: u8 = 0x3F;\n\n    let rem = input.len() % 3;\n    let start_of_rem = input.len() - rem;\n\n    // start at the first index not handled by fast loop, which may be 0.\n\n    while input_index < start_of_rem {\n        let input_chunk = &input[input_index..(input_index + 3)];\n        let output_chunk = &mut output[output_index..(output_index + 4)];\n\n        output_chunk[0] = self.encode_table[(input_chunk[0] >> 2) as usize];\n        output_chunk[1] = self.encode_table\n            [((input_chunk[0] << 4 | input_chunk[1] >> 4) & LOW_SIX_BITS_U8) as usize];\n        output_chunk[2] = self.encode_table\n            [((input_chunk[1] << 2 | input_chunk[2] >> 6) & LOW_SIX_BITS_U8) as usize];\n        output_chunk[3] = self.encode_table[(input_chunk[2] & LOW_SIX_BITS_U8) as usize];\n\n        input_index += 3;\n        output_index += 4;\n    }\n\n    if rem == 2 {\n        output[output_index] = self.encode_table[(input[start_of_rem] >> 2) as usize];\n        output[output_index + 1] =\n            self.encode_table[((input[start_of_rem] << 4 | input[start_of_rem + 1] >> 4)\n                & LOW_SIX_BITS_U8) as usize];\n        output[output_index + 2] =\n            self.encode_table[((input[start_of_rem + 1] << 2) & LOW_SIX_BITS_U8) as usize];\n        output_index += 3;\n    } else if rem == 1 {\n        output[output_index] = self.encode_table[(input[start_of_rem] >> 2) as usize];\n        output[output_index + 1] =\n            self.encode_table[((input[start_of_rem] << 4) & LOW_SIX_BITS_U8) as usize];\n        output_index += 2;\n    }\n\n    output_index\n}\nGiven the following constraints, potential panic-triggering statements, and expected return values/types (all extracted from the function under test).\nGenerate test inputs that maximize the function's runtime satisfaction of all constraints and expected outputs while considering panic conditions:\n",
  "depend_pt": ""
}