{
  "system_pt": "As a software testing expert, infer the test input ranges based on the provided information. Follow these guidelines:\n1. Provide test input ranges in one line in plain text only, without additional explanations or Markdown formatting.\n2. The inferred test input ranges should only satisfy all provided constraints simultaneously.\n3. Ensure the test input ranges cover boundary cases and edge scenarios.\n",
  "static_pt": "The context for the focal function is as follows:\n// src/read/decoder.rs\n// crate name is base64\nuse crate::{engine::Engine, DecodeError, DecodeSliceError, PAD_BYTE};\nuse std::{cmp, fmt, io};\npub(crate) const BUF_SIZE: usize = 1024;\nconst BASE64_CHUNK_SIZE: usize = 4;\nconst DECODED_CHUNK_SIZE: usize = 3;\npub trait Engine: Send + Sync {\n    type Config: Config;\n    type DecodeEstimate: DecodeEstimate;\n    fn internal_encode(&self, input: &[u8], output: &mut [u8]) -> usize;\n    fn internal_decoded_len_estimate(&self, input_len: usize) -> Self::DecodeEstimate;\n    fn internal_decode(\n        &self,\n        input: &[u8],\n        output: &mut [u8],\n        decode_estimate: Self::DecodeEstimate,\n    ) -> Result<DecodeMetadata, DecodeSliceError>;\n    fn config(&self) -> &Self::Config;\n    #[cfg(any(feature = \"alloc\", test))]\n    #[inline]\n    fn encode<T: AsRef<[u8]>>(&self, input: T) -> String;\n    #[cfg(any(feature = \"alloc\", test))]\n    #[inline]\n    fn encode_string<T: AsRef<[u8]>>(&self, input: T, output_buf: &mut String);\n    #[cfg_attr(feature = \"alloc\", doc = \"```\")]\n    #[cfg_attr(not(feature = \"alloc\"), doc = \"```ignore\")]\n    #[inline]\n    fn encode_slice<T: AsRef<[u8]>>(\n        &self,\n        input: T,\n        output_buf: &mut [u8],\n    ) -> Result<usize, EncodeSliceError>;\n    #[cfg(any(feature = \"alloc\", test))]\n    #[inline]\n    fn decode<T: AsRef<[u8]>>(&self, input: T) -> Result<Vec<u8>, DecodeError>;\n    #[cfg(any(feature = \"alloc\", test))]\n    #[inline]\n    fn decode_vec<T: AsRef<[u8]>>(\n        &self,\n        input: T,\n        buffer: &mut Vec<u8>,\n    ) -> Result<(), DecodeError>;\n    #[inline]\n    fn decode_slice<T: AsRef<[u8]>>(\n        &self,\n        input: T,\n        output: &mut [u8],\n    ) -> Result<usize, DecodeSliceError>;\n    #[inline]\n    fn decode_slice_unchecked<T: AsRef<[u8]>>(\n        &self,\n        input: T,\n        output: &mut [u8],\n    ) -> Result<usize, DecodeError>;\n}\npub struct DecoderReader<'e, E: Engine, R: io::Read> {\n    engine: &'e E,\n    /// Where b64 data is read from\n    inner: R,\n    /// Holds b64 data read from the delegate reader.\n    b64_buffer: [u8; BUF_SIZE],\n    /// The start of the pending buffered data in `b64_buffer`.\n    b64_offset: usize,\n    /// The amount of buffered b64 data after `b64_offset` in `b64_len`.\n    b64_len: usize,\n    /// Since the caller may provide us with a buffer of size 1 or 2 that's too small to copy a\n    /// decoded chunk in to, we have to be able to hang on to a few decoded bytes.\n    /// Technically we only need to hold 2 bytes, but then we'd need a separate temporary buffer to\n    /// decode 3 bytes into and then juggle copying one byte into the provided read buf and the rest\n    /// into here, which seems like a lot of complexity for 1 extra byte of storage.\n    decoded_chunk_buffer: [u8; DECODED_CHUNK_SIZE],\n    /// Index of start of decoded data in `decoded_chunk_buffer`\n    decoded_offset: usize,\n    /// Length of decoded data after `decoded_offset` in `decoded_chunk_buffer`\n    decoded_len: usize,\n    /// Input length consumed so far.\n    /// Used to provide accurate offsets in errors\n    input_consumed_len: usize,\n    /// offset of previously seen padding, if any\n    padding_offset: Option<usize>,\n}\nimpl<'e, E: Engine, R: io::Read> io::Read for DecoderReader<'e, E, R> {\n    fn read(&mut self, buf: &mut [u8]) -> io::Result<usize> {\n        if buf.is_empty() {\n            return Ok(0);\n        }\n        debug_assert!(self.b64_offset <= BUF_SIZE);\n        debug_assert!(self.b64_offset + self.b64_len <= BUF_SIZE);\n        debug_assert!(\n            if self.b64_offset == BUF_SIZE { self.b64_len == 0 } else { self.b64_len <=\n            BUF_SIZE }\n        );\n        debug_assert!(\n            if self.decoded_len == 0 { self.decoded_offset <= DECODED_CHUNK_SIZE } else {\n            self.decoded_offset < DECODED_CHUNK_SIZE }\n        );\n        debug_assert!(self.decoded_len < DECODED_CHUNK_SIZE);\n        debug_assert!(self.decoded_len + self.decoded_offset <= DECODED_CHUNK_SIZE);\n        if self.decoded_len > 0 {\n            self.flush_decoded_buf(buf)\n        } else {\n            let mut at_eof = false;\n            while self.b64_len < BASE64_CHUNK_SIZE {\n                self.b64_buffer\n                    .copy_within(self.b64_offset..self.b64_offset + self.b64_len, 0);\n                self.b64_offset = 0;\n                let read = self.read_from_delegate()?;\n                if read == 0 {\n                    at_eof = true;\n                    break;\n                }\n            }\n            if self.b64_len == 0 {\n                debug_assert!(at_eof);\n                return Ok(0);\n            }\n            debug_assert!(\n                if at_eof { self.b64_len > 0 } else { self.b64_len >= BASE64_CHUNK_SIZE }\n            );\n            debug_assert_eq!(0, self.decoded_len);\n            if buf.len() < DECODED_CHUNK_SIZE {\n                let mut decoded_chunk = [0_u8; DECODED_CHUNK_SIZE];\n                let to_decode = cmp::min(self.b64_len, BASE64_CHUNK_SIZE);\n                let decoded = self.decode_to_buf(to_decode, &mut decoded_chunk[..])?;\n                self.decoded_chunk_buffer[..decoded]\n                    .copy_from_slice(&decoded_chunk[..decoded]);\n                self.decoded_offset = 0;\n                self.decoded_len = decoded;\n                debug_assert!(decoded <= 3);\n                self.flush_decoded_buf(buf)\n            } else {\n                let b64_bytes_that_can_decode_into_buf = (buf.len() / DECODED_CHUNK_SIZE)\n                    .checked_mul(BASE64_CHUNK_SIZE)\n                    .expect(\"too many chunks\");\n                debug_assert!(b64_bytes_that_can_decode_into_buf >= BASE64_CHUNK_SIZE);\n                let b64_bytes_available_to_decode = if at_eof {\n                    self.b64_len\n                } else {\n                    self.b64_len - self.b64_len % 4\n                };\n                let actual_decode_len = cmp::min(\n                    b64_bytes_that_can_decode_into_buf,\n                    b64_bytes_available_to_decode,\n                );\n                self.decode_to_buf(actual_decode_len, buf)\n            }\n        }\n    }\n}\nimpl<'e, E: Engine, R: io::Read> DecoderReader<'e, E, R> {\n    pub fn new(reader: R, engine: &'e E) -> Self {\n        DecoderReader {\n            engine,\n            inner: reader,\n            b64_buffer: [0; BUF_SIZE],\n            b64_offset: 0,\n            b64_len: 0,\n            decoded_chunk_buffer: [0; DECODED_CHUNK_SIZE],\n            decoded_offset: 0,\n            decoded_len: 0,\n            input_consumed_len: 0,\n            padding_offset: None,\n        }\n    }\n    fn flush_decoded_buf(&mut self, buf: &mut [u8]) -> io::Result<usize> {\n        debug_assert!(self.decoded_len > 0);\n        debug_assert!(! buf.is_empty());\n        let copy_len = cmp::min(self.decoded_len, buf.len());\n        debug_assert!(copy_len > 0);\n        debug_assert!(copy_len <= self.decoded_len);\n        buf[..copy_len]\n            .copy_from_slice(\n                &self\n                    .decoded_chunk_buffer[self\n                    .decoded_offset..self.decoded_offset + copy_len],\n            );\n        self.decoded_offset += copy_len;\n        self.decoded_len -= copy_len;\n        debug_assert!(self.decoded_len < DECODED_CHUNK_SIZE);\n        Ok(copy_len)\n    }\n    fn read_from_delegate(&mut self) -> io::Result<usize> {\n        debug_assert!(self.b64_offset + self.b64_len < BUF_SIZE);\n        let read = self\n            .inner\n            .read(&mut self.b64_buffer[self.b64_offset + self.b64_len..])?;\n        self.b64_len += read;\n        debug_assert!(self.b64_offset + self.b64_len <= BUF_SIZE);\n        Ok(read)\n    }\n    fn decode_to_buf(\n        &mut self,\n        b64_len_to_decode: usize,\n        buf: &mut [u8],\n    ) -> io::Result<usize> {\n        debug_assert!(self.b64_len >= b64_len_to_decode);\n        debug_assert!(self.b64_offset + self.b64_len <= BUF_SIZE);\n        debug_assert!(! buf.is_empty());\n        let b64_to_decode = &self\n            .b64_buffer[self.b64_offset..self.b64_offset + b64_len_to_decode];\n        let decode_metadata = self\n            .engine\n            .internal_decode(\n                b64_to_decode,\n                buf,\n                self.engine.internal_decoded_len_estimate(b64_len_to_decode),\n            )\n            .map_err(|dse| match dse {\n                DecodeSliceError::DecodeError(de) => {\n                    match de {\n                        DecodeError::InvalidByte(offset, byte) => {\n                            match (byte, self.padding_offset) {\n                                (PAD_BYTE, Some(first_pad_offset)) => {\n                                    DecodeError::InvalidByte(first_pad_offset, PAD_BYTE)\n                                }\n                                _ => {\n                                    DecodeError::InvalidByte(\n                                        self.input_consumed_len + offset,\n                                        byte,\n                                    )\n                                }\n                            }\n                        }\n                        DecodeError::InvalidLength(len) => {\n                            DecodeError::InvalidLength(self.input_consumed_len + len)\n                        }\n                        DecodeError::InvalidLastSymbol(offset, byte) => {\n                            DecodeError::InvalidLastSymbol(\n                                self.input_consumed_len + offset,\n                                byte,\n                            )\n                        }\n                        DecodeError::InvalidPadding => DecodeError::InvalidPadding,\n                    }\n                }\n                DecodeSliceError::OutputSliceTooSmall => {\n                    unreachable!(\"buf is sized correctly in calling code\")\n                }\n            })\n            .map_err(|e| io::Error::new(io::ErrorKind::InvalidData, e))?;\n        if let Some(offset) = self.padding_offset {\n            if decode_metadata.decoded_len > 0 {\n                return Err(\n                    io::Error::new(\n                        io::ErrorKind::InvalidData,\n                        DecodeError::InvalidByte(offset, PAD_BYTE),\n                    ),\n                );\n            }\n        }\n        self.padding_offset = self\n            .padding_offset\n            .or(\n                decode_metadata\n                    .padding_offset\n                    .map(|offset| self.input_consumed_len + offset),\n            );\n        self.input_consumed_len += b64_len_to_decode;\n        self.b64_offset += b64_len_to_decode;\n        self.b64_len -= b64_len_to_decode;\n        debug_assert!(self.b64_offset + self.b64_len <= BUF_SIZE);\n        Ok(decode_metadata.decoded_len)\n    }\n    pub fn into_inner(self) -> R {}\n}\n\nThe function to be tested is presented as follows:\n/// Decode input from the wrapped reader.\n///\n/// Under non-error circumstances, this returns `Ok` with the value being the number of bytes\n/// written in `buf`.\n///\n/// Where possible, this function buffers base64 to minimize the number of `read()` calls to the\n/// delegate reader.\n///\n/// # Errors\n///\n/// Any errors emitted by the delegate reader are returned. Decoding errors due to invalid\n/// base64 are also possible, and will have `io::ErrorKind::InvalidData`.\nfn read(&mut self, buf: &mut [u8]) -> io::Result<usize> {\n    if buf.is_empty() {\n        return Ok(0);\n    }\n\n    // offset == BUF_SIZE when we copied it all last time\n    debug_assert!(self.b64_offset <= BUF_SIZE);\n    debug_assert!(self.b64_offset + self.b64_len <= BUF_SIZE);\n    debug_assert!(if self.b64_offset == BUF_SIZE {\n        self.b64_len == 0\n    } else {\n        self.b64_len <= BUF_SIZE\n    });\n\n    debug_assert!(if self.decoded_len == 0 {\n        // can be = when we were able to copy the complete chunk\n        self.decoded_offset <= DECODED_CHUNK_SIZE\n    } else {\n        self.decoded_offset < DECODED_CHUNK_SIZE\n    });\n\n    // We shouldn't ever decode into decoded_buffer when we can't immediately write at least one\n    // byte into the provided buf, so the effective length should only be 3 momentarily between\n    // when we decode and when we copy into the target buffer.\n    debug_assert!(self.decoded_len < DECODED_CHUNK_SIZE);\n    debug_assert!(self.decoded_len + self.decoded_offset <= DECODED_CHUNK_SIZE);\n\n    if self.decoded_len > 0 {\n        // we have a few leftover decoded bytes; flush that rather than pull in more b64\n        self.flush_decoded_buf(buf)\n    } else {\n        let mut at_eof = false;\n        while self.b64_len < BASE64_CHUNK_SIZE {\n            // Copy any bytes we have to the start of the buffer.\n            self.b64_buffer\n                .copy_within(self.b64_offset..self.b64_offset + self.b64_len, 0);\n            self.b64_offset = 0;\n\n            // then fill in more data\n            let read = self.read_from_delegate()?;\n            if read == 0 {\n                // we never read into an empty buf, so 0 => we've hit EOF\n                at_eof = true;\n                break;\n            }\n        }\n\n        if self.b64_len == 0 {\n            debug_assert!(at_eof);\n            // we must be at EOF, and we have no data left to decode\n            return Ok(0);\n        };\n\n        debug_assert!(if at_eof {\n            // if we are at eof, we may not have a complete chunk\n            self.b64_len > 0\n        } else {\n            // otherwise, we must have at least one chunk\n            self.b64_len >= BASE64_CHUNK_SIZE\n        });\n\n        debug_assert_eq!(0, self.decoded_len);\n\n        if buf.len() < DECODED_CHUNK_SIZE {\n            // caller requested an annoyingly short read\n            // have to write to a tmp buf first to avoid double mutable borrow\n            let mut decoded_chunk = [0_u8; DECODED_CHUNK_SIZE];\n            // if we are at eof, could have less than BASE64_CHUNK_SIZE, in which case we have\n            // to assume that these last few tokens are, in fact, valid (i.e. must be 2-4 b64\n            // tokens, not 1, since 1 token can't decode to 1 byte).\n            let to_decode = cmp::min(self.b64_len, BASE64_CHUNK_SIZE);\n\n            let decoded = self.decode_to_buf(to_decode, &mut decoded_chunk[..])?;\n            self.decoded_chunk_buffer[..decoded].copy_from_slice(&decoded_chunk[..decoded]);\n\n            self.decoded_offset = 0;\n            self.decoded_len = decoded;\n\n            // can be less than 3 on last block due to padding\n            debug_assert!(decoded <= 3);\n\n            self.flush_decoded_buf(buf)\n        } else {\n            let b64_bytes_that_can_decode_into_buf = (buf.len() / DECODED_CHUNK_SIZE)\n                .checked_mul(BASE64_CHUNK_SIZE)\n                .expect(\"too many chunks\");\n            debug_assert!(b64_bytes_that_can_decode_into_buf >= BASE64_CHUNK_SIZE);\n\n            let b64_bytes_available_to_decode = if at_eof {\n                self.b64_len\n            } else {\n                // only use complete chunks\n                self.b64_len - self.b64_len % 4\n            };\n\n            let actual_decode_len = cmp::min(\n                b64_bytes_that_can_decode_into_buf,\n                b64_bytes_available_to_decode,\n            );\n            self.decode_to_buf(actual_decode_len, buf)\n        }\n    }\n}\nGiven the following constraints, potential panic-triggering statements, and expected return values/types (all extracted from the function under test).\nGenerate test inputs that maximize the function's runtime satisfaction of all constraints and expected outputs while considering panic conditions:\n",
  "depend_pt": ""
}