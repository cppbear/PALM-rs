{"function_name":"quote::to_tokens::<proc_macro2::Group as to_tokens::ToTokens>::to_tokens","file_path":"/home/abezbm/rust-utgen-test-crates-new/quote/src/to_tokens.rs","work_dir":"/home/abezbm/rust-utgen-test-crates-new/quote","tests":16,"tests_lines":[9,9,9,9,15,15,15,15,10,14,15,15,11,12,12,12],"oracles":5,"oracles_compiled":3,"oracles_compiled_rate":60.0,"tests_compiled":5,"tests_compiled_rate":31.25,"oracles_run":3,"oracles_passed":1,"oracles_passed_rate":33.33333333333333,"tests_run":5,"tests_passed":1,"tests_passed_rate":20.0,"lines":3,"lines_covered":3,"lines_coveraged_rate":100.0,"branches":1,"branches_covered":1,"branches_coverage_rate":100.0,"codes_lines":[234,235,236],"codes_lines_covered":[[["{","  let delimiter = proc_macro2::Delimiter::Brace; // Set the appropriate delimiter","  let group = Group::new(delimiter, TokenStream::new()); // Provide a new TokenStream","  let mut tokens = TokenStream::new(); // Declare tokens before using it","  group.to_tokens(&mut tokens);","  let group = Group::new(delimiter, TokenStream::new()); // Use TokenStream here as well","  group.to_tokens(&mut tokens);","  assert!(tokens.to_string() == group.to_token_stream().to_string());","}"],[234,235,236]],[["{","  let mut group = TokenStream::new();  ","  group.extend(iter::once(TokenTree::Ident(Ident::new(\"a\", Span::call_site()))));  ","  group.extend(iter::once(TokenTree::Punct(Punct::new('+', proc_macro2::Spacing::Alone))));  ","  group.extend(iter::once(TokenTree::Ident(Ident::new(\"b\", Span::call_site()))));  ","  let mut tokens = TokenStream::new();  ","  Group::new(proc_macro2::Delimiter::Parenthesis, group).to_tokens(&mut tokens);  ","  let mut group = TokenStream::new();  ","  group.extend(iter::once(TokenTree::Ident(Ident::new(\"a\", Span::call_site()))));  ","  group.extend(iter::once(TokenTree::Punct(Punct::new('+', proc_macro2::Spacing::Alone))));  ","  group.extend(iter::once(TokenTree::Ident(Ident::new(\"b\", Span::call_site()))));  ","   let mut tokens = TokenStream::new();  ","   group.to_tokens(&mut tokens);  ","   assert!(tokens.to_string() == \"(a+b)\");  ","}"],[234,235,236]],[["{","  let group = Group::new(proc_macro2::Delimiter::Parenthesis, {","      let mut ts = TokenStream::new();","      ts.extend(vec![","          TokenTree::Ident(Ident::new(\"a\", Span::call_site())),","          TokenTree::Punct(Punct::new('+', proc_macro2::Spacing::Alone)),","          TokenTree::Ident(Ident::new(\"b\", Span::call_site()))","      ]);","      ts","  });","  let mut tokens = TokenStream::new();","   let mut tokens = TokenStream::new();","   group.to_tokens(&mut tokens);","   assert!(tokens.is_empty() == false);","}"],[234,235,236]],[["{","   let mut group = TokenStream::new();","   group.extend(iter::once(TokenTree::Ident(Ident::new(\"a\", Span::call_site()))));","   group.extend(iter::once(TokenTree::Punct(Punct::new('+', proc_macro2::Spacing::Alone))));","   group.extend(iter::once(TokenTree::Ident(Ident::new(\"b\", Span::call_site()))));","   let mut tokens = TokenStream::new();","   group.to_tokens(&mut tokens);","   let mut group = TokenStream::new();","   group.extend(iter::once(TokenTree::Ident(Ident::new(\"a\", Span::call_site()))));","   group.extend(iter::once(TokenTree::Punct(Punct::new('+', proc_macro2::Spacing::Alone))));","   group.extend(iter::once(TokenTree::Ident(Ident::new(\"b\", Span::call_site()))));","   let mut tokens = TokenStream::new();","   group.to_tokens(&mut tokens);","    assert!(tokens.clone().into_iter().count() == 1);","}"],[]],[["{","  let mut tokens = TokenStream::new();  ","  for i in 0..256 {  ","      tokens.append(TokenTree::Ident(Ident::new(&format!(\"token{}\", i), Span::call_site())));  ","  }  ","  let mut tokens2 = TokenStream::new();  ","  tokens2.extend(tokens);  ","  let mut tokens3 = TokenStream::new();  ","  for i in 0..256 {  ","      tokens3.append(TokenTree::Ident(Ident::new(&format!(\"token{}\", i), Span::call_site())));  ","  }  ","  tokens2.extend(tokens3);  ","  assert_eq!(tokens2.to_string(), \"<expected_output_here>\");  ","}"],[]]],"codes_branches":[],"codes_branches_covered":[[["{","  let delimiter = proc_macro2::Delimiter::Brace; // Set the appropriate delimiter","  let group = Group::new(delimiter, TokenStream::new()); // Provide a new TokenStream","  let mut tokens = TokenStream::new(); // Declare tokens before using it","  group.to_tokens(&mut tokens);","  let group = Group::new(delimiter, TokenStream::new()); // Use TokenStream here as well","  group.to_tokens(&mut tokens);","  assert!(tokens.to_string() == group.to_token_stream().to_string());","}"],[]],[["{","  let mut group = TokenStream::new();  ","  group.extend(iter::once(TokenTree::Ident(Ident::new(\"a\", Span::call_site()))));  ","  group.extend(iter::once(TokenTree::Punct(Punct::new('+', proc_macro2::Spacing::Alone))));  ","  group.extend(iter::once(TokenTree::Ident(Ident::new(\"b\", Span::call_site()))));  ","  let mut tokens = TokenStream::new();  ","  Group::new(proc_macro2::Delimiter::Parenthesis, group).to_tokens(&mut tokens);  ","  let mut group = TokenStream::new();  ","  group.extend(iter::once(TokenTree::Ident(Ident::new(\"a\", Span::call_site()))));  ","  group.extend(iter::once(TokenTree::Punct(Punct::new('+', proc_macro2::Spacing::Alone))));  ","  group.extend(iter::once(TokenTree::Ident(Ident::new(\"b\", Span::call_site()))));  ","   let mut tokens = TokenStream::new();  ","   group.to_tokens(&mut tokens);  ","   assert!(tokens.to_string() == \"(a+b)\");  ","}"],[]],[["{","  let group = Group::new(proc_macro2::Delimiter::Parenthesis, {","      let mut ts = TokenStream::new();","      ts.extend(vec![","          TokenTree::Ident(Ident::new(\"a\", Span::call_site())),","          TokenTree::Punct(Punct::new('+', proc_macro2::Spacing::Alone)),","          TokenTree::Ident(Ident::new(\"b\", Span::call_site()))","      ]);","      ts","  });","  let mut tokens = TokenStream::new();","   let mut tokens = TokenStream::new();","   group.to_tokens(&mut tokens);","   assert!(tokens.is_empty() == false);","}"],[]],[["{","   let mut group = TokenStream::new();","   group.extend(iter::once(TokenTree::Ident(Ident::new(\"a\", Span::call_site()))));","   group.extend(iter::once(TokenTree::Punct(Punct::new('+', proc_macro2::Spacing::Alone))));","   group.extend(iter::once(TokenTree::Ident(Ident::new(\"b\", Span::call_site()))));","   let mut tokens = TokenStream::new();","   group.to_tokens(&mut tokens);","   let mut group = TokenStream::new();","   group.extend(iter::once(TokenTree::Ident(Ident::new(\"a\", Span::call_site()))));","   group.extend(iter::once(TokenTree::Punct(Punct::new('+', proc_macro2::Spacing::Alone))));","   group.extend(iter::once(TokenTree::Ident(Ident::new(\"b\", Span::call_site()))));","   let mut tokens = TokenStream::new();","   group.to_tokens(&mut tokens);","    assert!(tokens.clone().into_iter().count() == 1);","}"],[]],[["{","  let mut tokens = TokenStream::new();  ","  for i in 0..256 {  ","      tokens.append(TokenTree::Ident(Ident::new(&format!(\"token{}\", i), Span::call_site())));  ","  }  ","  let mut tokens2 = TokenStream::new();  ","  tokens2.extend(tokens);  ","  let mut tokens3 = TokenStream::new();  ","  for i in 0..256 {  ","      tokens3.append(TokenTree::Ident(Ident::new(&format!(\"token{}\", i), Span::call_site())));  ","  }  ","  tokens2.extend(tokens3);  ","  assert_eq!(tokens2.to_string(), \"<expected_output_here>\");  ","}"],[]]]}