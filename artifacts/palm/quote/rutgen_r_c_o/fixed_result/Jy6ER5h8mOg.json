{"function_name":"quote::to_tokens::<proc_macro2::Literal as to_tokens::ToTokens>::to_tokens","file_path":"/home/abezbm/rust-utgen-test-crates-new/quote/src/to_tokens.rs","work_dir":"/home/abezbm/rust-utgen-test-crates-new/quote","tests":11,"tests_lines":[9,9,9,9,9,13,9,9,9,9,9],"oracles":7,"oracles_compiled":7,"oracles_compiled_rate":100.0,"tests_compiled":11,"tests_compiled_rate":100.0,"oracles_run":7,"oracles_passed":6,"oracles_passed_rate":85.71428571428571,"tests_run":11,"tests_passed":10,"tests_passed_rate":90.9090909090909,"lines":3,"lines_covered":3,"lines_coveraged_rate":100.0,"branches":1,"branches_covered":1,"branches_coverage_rate":100.0,"codes_lines":[252,253,254],"codes_lines_covered":[[["{","    let lit = Literal::usize_unsuffixed(0);","    let mut tokens = TokenStream::new();","    lit.to_tokens(&mut tokens);","    let lit = Literal::usize_unsuffixed(0);","    let mut tokens = TokenStream::new();","    lit.to_tokens(&mut tokens);","    assert!(tokens.to_string() == \"0\");","}"],[252,253,254]],[["{","    let lit = Literal::usize_unsuffixed(100);","    let mut tokens = TokenStream::new();","    lit.to_tokens(&mut tokens);","    let lit = Literal::usize_unsuffixed(100);","    let mut tokens = TokenStream::new();","    lit.to_tokens(&mut tokens);","    assert_eq!(tokens.to_string(), \"100\");","}"],[252,253,254]],[["{","    let lit = Literal::usize_unsuffixed(10000);","    let mut tokens = TokenStream::new();","    lit.to_tokens(&mut tokens);","    let lit = Literal::usize_unsuffixed(10000);","    let mut tokens = TokenStream::new();","    lit.to_tokens(&mut tokens);","    assert!(!tokens.is_empty());","}"],[252,253,254]],[["{","    let lit = Literal::usize_unsuffixed(10000);","    let mut tokens = TokenStream::new();","    lit.to_tokens(&mut tokens);","    let lit = Literal::usize_unsuffixed(10000);","    let mut tokens = TokenStream::new();","    lit.to_tokens(&mut tokens);","    assert_eq!(tokens.to_string(), \"10000\");","}"],[252,253,254]],[["{","    let lit = Literal::string(\"test\");","    let mut tokens = TokenStream::new();","    lit.to_tokens(&mut tokens);","    let lit = Literal::string(\"test\");","    let mut tokens = TokenStream::new();","    lit.to_tokens(&mut tokens);","    assert_eq!(tokens.to_string(), \"\\\"test\\\"\");","}"],[252,253,254]],[["{","    let lit1 = Literal::string(\"first\");","    let lit2 = Literal::string(\"second\");","    let mut tokens = TokenStream::new();","    lit1.to_tokens(&mut tokens);","    lit2.to_tokens(&mut tokens);","    let lit1 = Literal::string(\"first\");","    let lit2 = Literal::string(\"second\");","    let mut tokens = TokenStream::new();","    lit1.to_tokens(&mut tokens);","    lit2.to_tokens(&mut tokens);","    assert_eq!(tokens.to_string(), \"\\\"first\\\"\\\"second\\\"\");","}"],[252,253,254]],[["{","    let lit = Literal::usize_unsuffixed(9999);","    let mut tokens = TokenStream::new();","    lit.to_tokens(&mut tokens);","    let lit = Literal::usize_unsuffixed(9999);","    let mut tokens = TokenStream::new();","    lit.to_tokens(&mut tokens);","    assert!(tokens.is_empty() == false);","}"],[252,253,254]],[["{","    let lit = Literal::usize_unsuffixed(9999);","    let mut tokens = TokenStream::new();","    lit.to_tokens(&mut tokens);","    let lit = Literal::usize_unsuffixed(9999);","    let mut tokens = TokenStream::new();","    lit.to_tokens(&mut tokens);","    assert!(tokens.to_string() == \"9999\");","}"],[252,253,254]],[["{","    let lit = Literal::usize_unsuffixed(9999);","    let mut tokens = TokenStream::new();","    lit.to_tokens(&mut tokens);","    let lit = Literal::usize_unsuffixed(9999);","    let mut tokens = TokenStream::new();","    lit.to_tokens(&mut tokens);","   assert!(tokens.is_empty() == false);  ","}"],[252,253,254]],[["{","   let lit = Literal::usize_unsuffixed(9999);","   let mut tokens = TokenStream::new();","   lit.to_tokens(&mut tokens);","   let lit = Literal::usize_unsuffixed(9999);","   let mut tokens = TokenStream::new();","   lit.to_tokens(&mut tokens);","   assert!(!tokens.is_empty());","}"],[252,253,254]],[["{","    let lit = Literal::string(\"\");","    let mut tokens = TokenStream::new();","    lit.to_tokens(&mut tokens);","    let lit = Literal::string(\"\");","    let mut tokens = TokenStream::new();","    lit.to_tokens(&mut tokens);","    assert_eq!(tokens.to_string(), \"\\\"\\\"\");","}"],[252,253,254]]],"codes_branches":[],"codes_branches_covered":[[["{","    let lit = Literal::usize_unsuffixed(0);","    let mut tokens = TokenStream::new();","    lit.to_tokens(&mut tokens);","    let lit = Literal::usize_unsuffixed(0);","    let mut tokens = TokenStream::new();","    lit.to_tokens(&mut tokens);","    assert!(tokens.to_string() == \"0\");","}"],[]],[["{","    let lit = Literal::usize_unsuffixed(100);","    let mut tokens = TokenStream::new();","    lit.to_tokens(&mut tokens);","    let lit = Literal::usize_unsuffixed(100);","    let mut tokens = TokenStream::new();","    lit.to_tokens(&mut tokens);","    assert_eq!(tokens.to_string(), \"100\");","}"],[]],[["{","    let lit = Literal::usize_unsuffixed(10000);","    let mut tokens = TokenStream::new();","    lit.to_tokens(&mut tokens);","    let lit = Literal::usize_unsuffixed(10000);","    let mut tokens = TokenStream::new();","    lit.to_tokens(&mut tokens);","    assert!(!tokens.is_empty());","}"],[]],[["{","    let lit = Literal::usize_unsuffixed(10000);","    let mut tokens = TokenStream::new();","    lit.to_tokens(&mut tokens);","    let lit = Literal::usize_unsuffixed(10000);","    let mut tokens = TokenStream::new();","    lit.to_tokens(&mut tokens);","    assert_eq!(tokens.to_string(), \"10000\");","}"],[]],[["{","    let lit = Literal::string(\"test\");","    let mut tokens = TokenStream::new();","    lit.to_tokens(&mut tokens);","    let lit = Literal::string(\"test\");","    let mut tokens = TokenStream::new();","    lit.to_tokens(&mut tokens);","    assert_eq!(tokens.to_string(), \"\\\"test\\\"\");","}"],[]],[["{","    let lit1 = Literal::string(\"first\");","    let lit2 = Literal::string(\"second\");","    let mut tokens = TokenStream::new();","    lit1.to_tokens(&mut tokens);","    lit2.to_tokens(&mut tokens);","    let lit1 = Literal::string(\"first\");","    let lit2 = Literal::string(\"second\");","    let mut tokens = TokenStream::new();","    lit1.to_tokens(&mut tokens);","    lit2.to_tokens(&mut tokens);","    assert_eq!(tokens.to_string(), \"\\\"first\\\"\\\"second\\\"\");","}"],[]],[["{","    let lit = Literal::usize_unsuffixed(9999);","    let mut tokens = TokenStream::new();","    lit.to_tokens(&mut tokens);","    let lit = Literal::usize_unsuffixed(9999);","    let mut tokens = TokenStream::new();","    lit.to_tokens(&mut tokens);","    assert!(tokens.is_empty() == false);","}"],[]],[["{","    let lit = Literal::usize_unsuffixed(9999);","    let mut tokens = TokenStream::new();","    lit.to_tokens(&mut tokens);","    let lit = Literal::usize_unsuffixed(9999);","    let mut tokens = TokenStream::new();","    lit.to_tokens(&mut tokens);","    assert!(tokens.to_string() == \"9999\");","}"],[]],[["{","    let lit = Literal::usize_unsuffixed(9999);","    let mut tokens = TokenStream::new();","    lit.to_tokens(&mut tokens);","    let lit = Literal::usize_unsuffixed(9999);","    let mut tokens = TokenStream::new();","    lit.to_tokens(&mut tokens);","   assert!(tokens.is_empty() == false);  ","}"],[]],[["{","   let lit = Literal::usize_unsuffixed(9999);","   let mut tokens = TokenStream::new();","   lit.to_tokens(&mut tokens);","   let lit = Literal::usize_unsuffixed(9999);","   let mut tokens = TokenStream::new();","   lit.to_tokens(&mut tokens);","   assert!(!tokens.is_empty());","}"],[]],[["{","    let lit = Literal::string(\"\");","    let mut tokens = TokenStream::new();","    lit.to_tokens(&mut tokens);","    let lit = Literal::string(\"\");","    let mut tokens = TokenStream::new();","    lit.to_tokens(&mut tokens);","    assert_eq!(tokens.to_string(), \"\\\"\\\"\");","}"],[]]]}