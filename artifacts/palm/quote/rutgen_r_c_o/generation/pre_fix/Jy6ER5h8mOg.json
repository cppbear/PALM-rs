{
  "name": "quote::to_tokens::<proc_macro2::Literal as to_tokens::ToTokens>::to_tokens",
  "name_with_impl": "quote::to_tokens::{impl#29}::to_tokens",
  "mod_info": {
    "name": "to_tokens",
    "loc": "src/lib.rs:112:1:112:15"
  },
  "visible": true,
  "loc": "src/to_tokens.rs:252:5:254:6",
  "fn_tests": [
    {
      "chain_id": 1,
      "prompt_conds": [],
      "input_infer": "0 <= self <= 10000, tokens size 0 <= tokens <= 1000\n",
      "answers": [
        {
          "uses": [],
          "has_test_mod": false,
          "common": [],
          "chain_tests": [
            {
              "attrs": [],
              "prefix": [
                "{",
                "    let lit = Literal::usize_unsuffixed(0);",
                "    let mut tokens = TokenStream::new();",
                "    lit.to_tokens(&mut tokens);",
                "}"
              ],
              "oracles": [
                [
                  "    let lit = Literal::usize_unsuffixed(0);",
                  "    let mut tokens = TokenStream::new();",
                  "    lit.to_tokens(&mut tokens);",
                  "    assert!(tokens.to_string() == \"0\");"
                ]
              ],
              "codes": [
                [
                  "{",
                  "    let lit = Literal::usize_unsuffixed(0);",
                  "    let mut tokens = TokenStream::new();",
                  "    lit.to_tokens(&mut tokens);",
                  "    let lit = Literal::usize_unsuffixed(0);",
                  "    let mut tokens = TokenStream::new();",
                  "    lit.to_tokens(&mut tokens);",
                  "    assert!(tokens.to_string() == \"0\");",
                  "}"
                ]
              ],
              "can_compile": [
                {
                  "Ok": null
                }
              ],
              "repaired": [
                false
              ]
            },
            {
              "attrs": [],
              "prefix": [
                "{",
                "    let lit = Literal::usize_unsuffixed(100);",
                "    let mut tokens = TokenStream::new();",
                "    lit.to_tokens(&mut tokens);",
                "}"
              ],
              "oracles": [
                [
                  "    let lit = Literal::usize_unsuffixed(100);",
                  "    let mut tokens = TokenStream::new();",
                  "    lit.to_tokens(&mut tokens);",
                  "    assert_eq!(tokens.to_string(), \"100\");"
                ]
              ],
              "codes": [
                [
                  "{",
                  "    let lit = Literal::usize_unsuffixed(100);",
                  "    let mut tokens = TokenStream::new();",
                  "    lit.to_tokens(&mut tokens);",
                  "    let lit = Literal::usize_unsuffixed(100);",
                  "    let mut tokens = TokenStream::new();",
                  "    lit.to_tokens(&mut tokens);",
                  "    assert_eq!(tokens.to_string(), \"100\");",
                  "}"
                ]
              ],
              "can_compile": [
                {
                  "Ok": null
                }
              ],
              "repaired": [
                false
              ]
            },
            {
              "attrs": [],
              "prefix": [
                "{",
                "    let lit = Literal::usize_unsuffixed(10000);",
                "    let mut tokens = TokenStream::new();",
                "    lit.to_tokens(&mut tokens);",
                "}"
              ],
              "oracles": [
                [
                  "    let lit = Literal::usize_unsuffixed(10000);",
                  "    let mut tokens = TokenStream::new();",
                  "    lit.to_tokens(&mut tokens);",
                  "    assert!(!tokens.is_empty());"
                ],
                [
                  "    let lit = Literal::usize_unsuffixed(10000);",
                  "    let mut tokens = TokenStream::new();",
                  "    lit.to_tokens(&mut tokens);",
                  "    assert_eq!(tokens.to_string(), \"10000\");"
                ]
              ],
              "codes": [
                [
                  "{",
                  "    let lit = Literal::usize_unsuffixed(10000);",
                  "    let mut tokens = TokenStream::new();",
                  "    lit.to_tokens(&mut tokens);",
                  "    let lit = Literal::usize_unsuffixed(10000);",
                  "    let mut tokens = TokenStream::new();",
                  "    lit.to_tokens(&mut tokens);",
                  "    assert!(!tokens.is_empty());",
                  "}"
                ],
                [
                  "{",
                  "    let lit = Literal::usize_unsuffixed(10000);",
                  "    let mut tokens = TokenStream::new();",
                  "    lit.to_tokens(&mut tokens);",
                  "    let lit = Literal::usize_unsuffixed(10000);",
                  "    let mut tokens = TokenStream::new();",
                  "    lit.to_tokens(&mut tokens);",
                  "    assert_eq!(tokens.to_string(), \"10000\");",
                  "}"
                ]
              ],
              "can_compile": [
                {
                  "Ok": null
                },
                {
                  "Ok": null
                }
              ],
              "repaired": [
                false,
                false
              ]
            },
            {
              "attrs": [],
              "prefix": [
                "{",
                "    let lit = Literal::string(\"test\");",
                "    let mut tokens = TokenStream::new();",
                "    lit.to_tokens(&mut tokens);",
                "}"
              ],
              "oracles": [
                [
                  "    let lit = Literal::string(\"test\");",
                  "    let mut tokens = TokenStream::new();",
                  "    lit.to_tokens(&mut tokens);",
                  "    assert_eq!(tokens.to_string(), \"\\\"test\\\"\");"
                ]
              ],
              "codes": [
                [
                  "{",
                  "    let lit = Literal::string(\"test\");",
                  "    let mut tokens = TokenStream::new();",
                  "    lit.to_tokens(&mut tokens);",
                  "    let lit = Literal::string(\"test\");",
                  "    let mut tokens = TokenStream::new();",
                  "    lit.to_tokens(&mut tokens);",
                  "    assert_eq!(tokens.to_string(), \"\\\"test\\\"\");",
                  "}"
                ]
              ],
              "can_compile": [
                {
                  "Ok": null
                }
              ],
              "repaired": [
                false
              ]
            },
            {
              "attrs": [],
              "prefix": [
                "{",
                "    let lit1 = Literal::string(\"first\");",
                "    let lit2 = Literal::string(\"second\");",
                "    let mut tokens = TokenStream::new();",
                "    lit1.to_tokens(&mut tokens);",
                "    lit2.to_tokens(&mut tokens);",
                "}"
              ],
              "oracles": [
                [
                  "    let lit1 = Literal::string(\"first\");",
                  "    let lit2 = Literal::string(\"second\");",
                  "    let mut tokens = TokenStream::new();",
                  "    lit1.to_tokens(&mut tokens);",
                  "    lit2.to_tokens(&mut tokens);",
                  "    assert_eq!(tokens.to_string(), \"\\\"first\\\"\\\"second\\\"\");"
                ]
              ],
              "codes": [
                [
                  "{",
                  "    let lit1 = Literal::string(\"first\");",
                  "    let lit2 = Literal::string(\"second\");",
                  "    let mut tokens = TokenStream::new();",
                  "    lit1.to_tokens(&mut tokens);",
                  "    lit2.to_tokens(&mut tokens);",
                  "    let lit1 = Literal::string(\"first\");",
                  "    let lit2 = Literal::string(\"second\");",
                  "    let mut tokens = TokenStream::new();",
                  "    lit1.to_tokens(&mut tokens);",
                  "    lit2.to_tokens(&mut tokens);",
                  "    assert_eq!(tokens.to_string(), \"\\\"first\\\"\\\"second\\\"\");",
                  "}"
                ]
              ],
              "can_compile": [
                {
                  "Ok": null
                }
              ],
              "repaired": [
                false
              ]
            },
            {
              "attrs": [],
              "prefix": [
                "{",
                "    let lit = Literal::usize_unsuffixed(9999);",
                "    let mut tokens = TokenStream::new();",
                "    lit.to_tokens(&mut tokens);",
                "}"
              ],
              "oracles": [
                [
                  "    let lit = Literal::usize_unsuffixed(9999);",
                  "    let mut tokens = TokenStream::new();",
                  "    lit.to_tokens(&mut tokens);",
                  "    assert!(tokens.is_empty() == false);"
                ],
                [
                  "    let lit = Literal::usize_unsuffixed(9999);",
                  "    let mut tokens = TokenStream::new();",
                  "    lit.to_tokens(&mut tokens);",
                  "    assert!(tokens.to_string() == \"9999\");"
                ],
                [
                  "    let lit = Literal::usize_unsuffixed(9999);",
                  "    let mut tokens = TokenStream::new();",
                  "    lit.to_tokens(&mut tokens);",
                  "    assert!(tokens.len() == 1);"
                ],
                [
                  "    let lit = Literal::usize_unsuffixed(9999);",
                  "    let mut tokens = TokenStream::new();",
                  "    lit.to_tokens(&mut tokens);",
                  "    assert!(tokens.iter().next().is_some());"
                ]
              ],
              "codes": [
                [
                  "{",
                  "    let lit = Literal::usize_unsuffixed(9999);",
                  "    let mut tokens = TokenStream::new();",
                  "    lit.to_tokens(&mut tokens);",
                  "    let lit = Literal::usize_unsuffixed(9999);",
                  "    let mut tokens = TokenStream::new();",
                  "    lit.to_tokens(&mut tokens);",
                  "    assert!(tokens.is_empty() == false);",
                  "}"
                ],
                [
                  "{",
                  "    let lit = Literal::usize_unsuffixed(9999);",
                  "    let mut tokens = TokenStream::new();",
                  "    lit.to_tokens(&mut tokens);",
                  "    let lit = Literal::usize_unsuffixed(9999);",
                  "    let mut tokens = TokenStream::new();",
                  "    lit.to_tokens(&mut tokens);",
                  "    assert!(tokens.to_string() == \"9999\");",
                  "}"
                ],
                [
                  "{",
                  "    let lit = Literal::usize_unsuffixed(9999);",
                  "    let mut tokens = TokenStream::new();",
                  "    lit.to_tokens(&mut tokens);",
                  "    let lit = Literal::usize_unsuffixed(9999);",
                  "    let mut tokens = TokenStream::new();",
                  "    lit.to_tokens(&mut tokens);",
                  "    assert!(tokens.len() == 1);",
                  "}"
                ],
                [
                  "{",
                  "    let lit = Literal::usize_unsuffixed(9999);",
                  "    let mut tokens = TokenStream::new();",
                  "    lit.to_tokens(&mut tokens);",
                  "    let lit = Literal::usize_unsuffixed(9999);",
                  "    let mut tokens = TokenStream::new();",
                  "    lit.to_tokens(&mut tokens);",
                  "    assert!(tokens.iter().next().is_some());",
                  "}"
                ]
              ],
              "can_compile": [
                {
                  "Ok": null
                },
                {
                  "Ok": null
                },
                {
                  "Err": "   Compiling serde v1.0.219\n   Compiling proc-macro2 v1.0.95\n   Compiling syn v1.0.109\n   Compiling serde_json v1.0.140\n   Compiling target-triple v0.1.4\n   Compiling rustversion v1.0.20\n   Compiling quote v1.0.40\n   Compiling syn v2.0.100\n   Compiling serde_derive v1.0.219\n   Compiling toml_datetime v0.6.8\n   Compiling serde_spanned v0.6.8\n   Compiling toml_edit v0.22.24\n   Compiling ntest_test_cases v0.9.3\n   Compiling proc-macro-crate v3.3.0\n   Compiling toml v0.8.20\n   Compiling trybuild v1.0.104\n   Compiling ntest_timeout v0.9.3\n   Compiling ntest v0.9.3\n   Compiling quote v1.0.40 (/home/abezbm/rust-utgen-test-crates-new/quote)\nwarning: unused import: `ntest::timeout`\n   --> src/to_tokens.rs:275:8\n    |\n275 |    use ntest::timeout;\n    |        ^^^^^^^^^^^^^^\n    |\n    = note: `#[warn(unused_imports)]` on by default\n\nerror[E0599]: no method named `len` found for struct `proc_macro2::TokenStream` in the current scope\n   --> src/to_tokens.rs:285:20\n    |\n285 |     assert!(tokens.len() == 1);\n    |                    ^^^ method not found in `TokenStream`\n\nFor more information about this error, try `rustc --explain E0599`.\nwarning: `quote` (lib test) generated 1 warning\nerror: could not compile `quote` (lib test) due to 1 previous error; 1 warning emitted\n"
                },
                {
                  "Err": "   Compiling serde v1.0.219\n   Compiling proc-macro2 v1.0.95\n   Compiling syn v1.0.109\n   Compiling target-triple v0.1.4\n   Compiling serde_json v1.0.140\n   Compiling rustversion v1.0.20\n   Compiling quote v1.0.40\n   Compiling syn v2.0.100\n   Compiling serde_derive v1.0.219\n   Compiling toml_datetime v0.6.8\n   Compiling serde_spanned v0.6.8\n   Compiling toml_edit v0.22.24\n   Compiling ntest_test_cases v0.9.3\n   Compiling proc-macro-crate v3.3.0\n   Compiling toml v0.8.20\n   Compiling trybuild v1.0.104\n   Compiling ntest_timeout v0.9.3\n   Compiling ntest v0.9.3\n   Compiling quote v1.0.40 (/home/abezbm/rust-utgen-test-crates-new/quote)\nwarning: unused import: `ntest::timeout`\n   --> src/to_tokens.rs:275:8\n    |\n275 |    use ntest::timeout;\n    |        ^^^^^^^^^^^^^^\n    |\n    = note: `#[warn(unused_imports)]` on by default\n\nerror[E0599]: no method named `iter` found for struct `proc_macro2::TokenStream` in the current scope\n   --> src/to_tokens.rs:285:20\n    |\n285 |     assert!(tokens.iter().next().is_some());\n    |                    ^^^^ method not found in `TokenStream`\n\nFor more information about this error, try `rustc --explain E0599`.\nwarning: `quote` (lib test) generated 1 warning\nerror: could not compile `quote` (lib test) due to 1 previous error; 1 warning emitted\n"
                }
              ],
              "repaired": [
                false,
                false,
                false,
                false
              ]
            },
            {
              "attrs": [],
              "prefix": [
                "{",
                "    let lit = Literal::string(\"\");",
                "    let mut tokens = TokenStream::new();",
                "    lit.to_tokens(&mut tokens);",
                "}"
              ],
              "oracles": [
                [
                  "    let lit = Literal::string(\"\");",
                  "    let mut tokens = TokenStream::new();",
                  "    lit.to_tokens(&mut tokens);",
                  "    assert_eq!(tokens.to_string(), \"\\\"\\\"\");"
                ]
              ],
              "codes": [
                [
                  "{",
                  "    let lit = Literal::string(\"\");",
                  "    let mut tokens = TokenStream::new();",
                  "    lit.to_tokens(&mut tokens);",
                  "    let lit = Literal::string(\"\");",
                  "    let mut tokens = TokenStream::new();",
                  "    lit.to_tokens(&mut tokens);",
                  "    assert_eq!(tokens.to_string(), \"\\\"\\\"\");",
                  "}"
                ]
              ],
              "can_compile": [
                {
                  "Ok": null
                }
              ],
              "repaired": [
                false
              ]
            }
          ]
        }
      ]
    }
  ]
}