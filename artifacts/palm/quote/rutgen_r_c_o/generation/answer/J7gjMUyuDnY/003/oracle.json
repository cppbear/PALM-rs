[
  {
    "uses": [],
    "has_test_mod": false,
    "common": [],
    "chain_tests": [
      {
        "attrs": [],
        "prefix": [
          "{",
          "    let mut tokens = TokenStream::new();",
          "    let empty_iter = vec![].into_iter();",
          "    let separator = TokenTree::from(proc_macro2::Ident::new(\",\", proc_macro2::Span::call_site()));",
          "    tokens.append_separated(empty_iter, separator);",
          "}"
        ],
        "oracles": [
          [
            "    let mut tokens = TokenStream::new();",
            "    let empty_iter = vec![].into_iter();",
            "    let separator = TokenTree::from(proc_macro2::Ident::new(\",\", proc_macro2::Span::call_site()));",
            "    tokens.append_separated(empty_iter, separator);",
            "    assert!(tokens.is_empty());"
          ]
        ],
        "codes": [
          [
            "{",
            "    let mut tokens = TokenStream::new();",
            "    let empty_iter = vec![].into_iter();",
            "    let separator = TokenTree::from(proc_macro2::Ident::new(\",\", proc_macro2::Span::call_site()));",
            "    tokens.append_separated(empty_iter, separator);",
            "    let mut tokens = TokenStream::new();",
            "    let empty_iter = vec![].into_iter();",
            "    let separator = TokenTree::from(proc_macro2::Ident::new(\",\", proc_macro2::Span::call_site()));",
            "    tokens.append_separated(empty_iter, separator);",
            "    assert!(tokens.is_empty());",
            "}"
          ]
        ],
        "can_compile": [
          {
            "Ok": null
          }
        ],
        "repaired": [
          false
        ]
      },
      {
        "attrs": [],
        "prefix": [
          "{",
          "    struct SingleToken;",
          "    ",
          "    impl ToTokens for SingleToken {",
          "        fn to_tokens(&self, tokens: &mut TokenStream) {}",
          "    }",
          "    ",
          "    let mut tokens = TokenStream::new();",
          "    let single_iter = vec![SingleToken].into_iter();",
          "    let separator = TokenTree::from(proc_macro2::Ident::new(\",\", proc_macro2::Span::call_site()));",
          "    tokens.append_separated(single_iter, separator);",
          "}"
        ],
        "oracles": [
          [
            "    let mut tokens = TokenStream::new();",
            "    let single_iter = vec![SingleToken].into_iter();",
            "    let separator = TokenTree::from(proc_macro2::Ident::new(\",\", proc_macro2::Span::call_site()));",
            "    tokens.append_separated(single_iter, separator);",
            "    assert_eq!(tokens.to_string(), \"\");"
          ]
        ],
        "codes": [
          [
            "{",
            "    struct SingleToken;",
            "    ",
            "    impl ToTokens for SingleToken {",
            "        fn to_tokens(&self, tokens: &mut TokenStream) {}",
            "    }",
            "    ",
            "    let mut tokens = TokenStream::new();",
            "    let single_iter = vec![SingleToken].into_iter();",
            "    let separator = TokenTree::from(proc_macro2::Ident::new(\",\", proc_macro2::Span::call_site()));",
            "    tokens.append_separated(single_iter, separator);",
            "    let mut tokens = TokenStream::new();",
            "    let single_iter = vec![SingleToken].into_iter();",
            "    let separator = TokenTree::from(proc_macro2::Ident::new(\",\", proc_macro2::Span::call_site()));",
            "    tokens.append_separated(single_iter, separator);",
            "    assert_eq!(tokens.to_string(), \"\");",
            "}"
          ]
        ],
        "can_compile": [
          {
            "Ok": null
          }
        ],
        "repaired": [
          false
        ]
      },
      {
        "attrs": [],
        "prefix": [
          "{",
          "    struct TokenA;",
          "    struct TokenB;",
          "    ",
          "    impl ToTokens for TokenA {",
          "        fn to_tokens(&self, tokens: &mut TokenStream) {}",
          "    }",
          "    ",
          "    impl ToTokens for TokenB {",
          "        fn to_tokens(&self, tokens: &mut TokenStream) {}",
          "    }",
          "    ",
          "    let mut tokens = TokenStream::new();",
          "    let tokens_iter = vec![TokenA, TokenB].into_iter();",
          "    let separator = TokenTree::from(proc_macro2::Ident::new(\",\", proc_macro2::Span::call_site()));",
          "    tokens.append_separated(tokens_iter, separator);",
          "}"
        ],
        "oracles": [
          [
            "    let mut tokens = TokenStream::new();",
            "    let tokens_iter = vec![TokenA, TokenB].into_iter();",
            "    let separator = TokenTree::from(proc_macro2::Ident::new(\",\", proc_macro2::Span::call_site()));",
            "    assert_eq!(tokens.is_empty(), true);"
          ],
          [
            "    let mut tokens = TokenStream::new();",
            "    let tokens_iter = vec![TokenA, TokenB].into_iter();",
            "    let separator = TokenTree::from(proc_macro2::Ident::new(\",\", proc_macro2::Span::call_site()));",
            "    tokens.append_separated(tokens_iter, separator);",
            "    assert_eq!(tokens.is_empty(), false);"
          ]
        ],
        "codes": [
          [
            "{",
            "    struct TokenA;",
            "    struct TokenB;",
            "    ",
            "    impl ToTokens for TokenA {",
            "        fn to_tokens(&self, tokens: &mut TokenStream) {}",
            "    }",
            "    ",
            "    impl ToTokens for TokenB {",
            "        fn to_tokens(&self, tokens: &mut TokenStream) {}",
            "    }",
            "    ",
            "    let mut tokens = TokenStream::new();",
            "    let tokens_iter = vec![TokenA, TokenB].into_iter();",
            "    let separator = TokenTree::from(proc_macro2::Ident::new(\",\", proc_macro2::Span::call_site()));",
            "    tokens.append_separated(tokens_iter, separator);",
            "    let mut tokens = TokenStream::new();",
            "    let tokens_iter = vec![TokenA, TokenB].into_iter();",
            "    let separator = TokenTree::from(proc_macro2::Ident::new(\",\", proc_macro2::Span::call_site()));",
            "    assert_eq!(tokens.is_empty(), true);",
            "}"
          ],
          [
            "{",
            "    struct TokenA;",
            "    struct TokenB;",
            "    ",
            "    impl ToTokens for TokenA {",
            "        fn to_tokens(&self, tokens: &mut TokenStream) {}",
            "    }",
            "    ",
            "    impl ToTokens for TokenB {",
            "        fn to_tokens(&self, tokens: &mut TokenStream) {}",
            "    }",
            "    ",
            "    let mut tokens = TokenStream::new();",
            "    let tokens_iter = vec![TokenA, TokenB].into_iter();",
            "    let separator = TokenTree::from(proc_macro2::Ident::new(\",\", proc_macro2::Span::call_site()));",
            "    tokens.append_separated(tokens_iter, separator);",
            "    let mut tokens = TokenStream::new();",
            "    let tokens_iter = vec![TokenA, TokenB].into_iter();",
            "    let separator = TokenTree::from(proc_macro2::Ident::new(\",\", proc_macro2::Span::call_site()));",
            "    tokens.append_separated(tokens_iter, separator);",
            "    assert_eq!(tokens.is_empty(), false);",
            "}"
          ]
        ],
        "can_compile": [
          {
            "Ok": null
          },
          {
            "Ok": null
          }
        ],
        "repaired": [
          false,
          false
        ]
      },
      {
        "attrs": [],
        "prefix": [
          "{",
          "    struct TokenX;",
          "    struct TokenY;",
          "    struct TokenZ;",
          "    ",
          "    impl ToTokens for TokenX {",
          "        fn to_tokens(&self, tokens: &mut TokenStream) {}",
          "    }",
          "    ",
          "    impl ToTokens for TokenY {",
          "        fn to_tokens(&self, tokens: &mut TokenStream) {}",
          "    }",
          "    ",
          "    impl ToTokens for TokenZ {",
          "        fn to_tokens(&self, tokens: &mut TokenStream) {}",
          "    }",
          "    ",
          "    let mut tokens = TokenStream::new();",
          "    let tokens_iter = vec![TokenX, TokenY, TokenZ].into_iter();",
          "    let separator = TokenTree::from(proc_macro2::Ident::new(\",\", proc_macro2::Span::call_site()));",
          "    tokens.append_separated(tokens_iter, separator);",
          "}"
        ],
        "oracles": [
          [
            "    let mut tokens = TokenStream::new();",
            "    let tokens_iter = vec![TokenX, TokenY, TokenZ].into_iter();",
            "    let separator = TokenTree::from(proc_macro2::Ident::new(\",\", proc_macro2::Span::call_site()));",
            "    tokens.append_separated(tokens_iter, separator);",
            "    assert!(tokens.is_empty());"
          ],
          [
            "    let mut tokens = TokenStream::new();",
            "    let tokens_iter = vec![TokenX, TokenY, TokenZ].into_iter();",
            "    let separator = TokenTree::from(proc_macro2::Ident::new(\",\", proc_macro2::Span::call_site()));",
            "    tokens.append_separated(tokens_iter, separator);",
            "    assert_eq!(tokens.to_string(), \"\");"
          ]
        ],
        "codes": [
          [
            "{",
            "    struct TokenX;",
            "    struct TokenY;",
            "    struct TokenZ;",
            "    ",
            "    impl ToTokens for TokenX {",
            "        fn to_tokens(&self, tokens: &mut TokenStream) {}",
            "    }",
            "    ",
            "    impl ToTokens for TokenY {",
            "        fn to_tokens(&self, tokens: &mut TokenStream) {}",
            "    }",
            "    ",
            "    impl ToTokens for TokenZ {",
            "        fn to_tokens(&self, tokens: &mut TokenStream) {}",
            "    }",
            "    ",
            "    let mut tokens = TokenStream::new();",
            "    let tokens_iter = vec![TokenX, TokenY, TokenZ].into_iter();",
            "    let separator = TokenTree::from(proc_macro2::Ident::new(\",\", proc_macro2::Span::call_site()));",
            "    tokens.append_separated(tokens_iter, separator);",
            "    let mut tokens = TokenStream::new();",
            "    let tokens_iter = vec![TokenX, TokenY, TokenZ].into_iter();",
            "    let separator = TokenTree::from(proc_macro2::Ident::new(\",\", proc_macro2::Span::call_site()));",
            "    tokens.append_separated(tokens_iter, separator);",
            "    assert!(tokens.is_empty());",
            "}"
          ],
          [
            "{",
            "    struct TokenX;",
            "    struct TokenY;",
            "    struct TokenZ;",
            "    ",
            "    impl ToTokens for TokenX {",
            "        fn to_tokens(&self, tokens: &mut TokenStream) {}",
            "    }",
            "    ",
            "    impl ToTokens for TokenY {",
            "        fn to_tokens(&self, tokens: &mut TokenStream) {}",
            "    }",
            "    ",
            "    impl ToTokens for TokenZ {",
            "        fn to_tokens(&self, tokens: &mut TokenStream) {}",
            "    }",
            "    ",
            "    let mut tokens = TokenStream::new();",
            "    let tokens_iter = vec![TokenX, TokenY, TokenZ].into_iter();",
            "    let separator = TokenTree::from(proc_macro2::Ident::new(\",\", proc_macro2::Span::call_site()));",
            "    tokens.append_separated(tokens_iter, separator);",
            "    let mut tokens = TokenStream::new();",
            "    let tokens_iter = vec![TokenX, TokenY, TokenZ].into_iter();",
            "    let separator = TokenTree::from(proc_macro2::Ident::new(\",\", proc_macro2::Span::call_site()));",
            "    tokens.append_separated(tokens_iter, separator);",
            "    assert_eq!(tokens.to_string(), \"\");",
            "}"
          ]
        ],
        "can_compile": [
          {
            "Ok": null
          },
          {
            "Ok": null
          }
        ],
        "repaired": [
          false,
          false
        ]
      }
    ]
  }
]