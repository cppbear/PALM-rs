{
  "name": "quote::ext::<proc_macro2::TokenStream as ext::TokenStreamExt>::append_terminated",
  "name_with_impl": "quote::ext::{impl#0}::append_terminated",
  "mod_info": {
    "name": "ext",
    "loc": "src/lib.rs:109:1:109:9"
  },
  "visible": true,
  "loc": "src/ext.rs:91:5:101:6",
  "fn_tests": [
    {
      "chain_id": 0,
      "prompt_conds": [],
      "input_infer": "",
      "answers": [
        {
          "uses": [],
          "has_test_mod": false,
          "common": [],
          "chain_tests": [
            {
              "attrs": [],
              "prefix": [],
              "oracles": [],
              "codes": [
                [
                  "{",
                  "    struct Dummy;",
                  "",
                  "    impl ToTokens for Dummy {",
                  "        fn to_tokens(&self, _tokens: &mut TokenStream) {}",
                  "        fn to_token_stream(&self) -> TokenStream {",
                  "            TokenStream::new()",
                  "        }",
                  "        fn into_token_stream(self) -> TokenStream {",
                  "            TokenStream::new()",
                  "        }",
                  "    }",
                  "",
                  "    let mut token_stream = TokenStream::new();",
                  "    let iter: Vec<Dummy> = vec![];",
                  "    let separator = Dummy;",
                  "",
                  "    token_stream.append_terminated(iter, separator);",
                  "    ",
                  "    // Expect token_stream to remain unchanged since the iterator is empty.",
                  "    assert_eq!(token_stream.to_string(), \"\");",
                  "}"
                ]
              ],
              "can_compile": [
                {
                  "Ok": null
                }
              ],
              "repaired": [
                false
              ]
            },
            {
              "attrs": [],
              "prefix": [],
              "oracles": [],
              "codes": [
                [
                  "{",
                  "    struct Dummy;",
                  "",
                  "    impl ToTokens for Dummy {",
                  "        fn to_tokens(&self, tokens: &mut TokenStream) {",
                  "            tokens.extend(TokenStream::from(proc_macro2::TokenTree::Ident(proc_macro2::Ident::new(\"item\", proc_macro2::Span::call_site()))));",
                  "        }",
                  "        fn to_token_stream(&self) -> TokenStream {",
                  "            TokenStream::from(proc_macro2::TokenTree::Ident(proc_macro2::Ident::new(\"item\", proc_macro2::Span::call_site())))",
                  "        }",
                  "        fn into_token_stream(self) -> TokenStream {",
                  "            TokenStream::from(proc_macro2::TokenTree::Ident(proc_macro2::Ident::new(\"item\", proc_macro2::Span::call_site())))",
                  "        }",
                  "    }",
                  "",
                  "    let mut token_stream = TokenStream::new();",
                  "    let iter = vec![Dummy];",
                  "    let separator = Dummy;",
                  "",
                  "    token_stream.append_terminated(iter, separator);",
                  "    ",
                  "    // Validate that the token_stream contains \"item\" followed by the separator.",
                  "    assert_eq!(token_stream.to_string(), \"item;\");",
                  "}"
                ]
              ],
              "can_compile": [
                {
                  "Ok": null
                }
              ],
              "repaired": [
                false
              ]
            },
            {
              "attrs": [],
              "prefix": [],
              "oracles": [],
              "codes": [
                [
                  "{",
                  "    struct ItemA;",
                  "",
                  "    impl ToTokens for ItemA {",
                  "        fn to_tokens(&self, tokens: &mut TokenStream) {",
                  "            tokens.extend(TokenStream::from(proc_macro2::TokenTree::Ident(proc_macro2::Ident::new(\"item_a\", proc_macro2::Span::call_site()))));",
                  "        }",
                  "        fn to_token_stream(&self) -> TokenStream {",
                  "            TokenStream::from(proc_macro2::TokenTree::Ident(proc_macro2::Ident::new(\"item_a\", proc_macro2::Span::call_site())))",
                  "        }",
                  "        fn into_token_stream(self) -> TokenStream {",
                  "            TokenStream::from(proc_macro2::TokenTree::Ident(proc_macro2::Ident::new(\"item_a\", proc_macro2::Span::call_site())))",
                  "        }",
                  "    }",
                  "",
                  "    struct ItemB;",
                  "",
                  "    impl ToTokens for ItemB {",
                  "        fn to_tokens(&self, tokens: &mut TokenStream) {",
                  "            tokens.extend(TokenStream::from(proc_macro2::TokenTree::Ident(proc_macro2::Ident::new(\"item_b\", proc_macro2::Span::call_site()))));",
                  "        }",
                  "        fn to_token_stream(&self) -> TokenStream {",
                  "            TokenStream::from(proc_macro2::TokenTree::Ident(proc_macro2::Ident::new(\"item_b\", proc_macro2::Span::call_site())))",
                  "        }",
                  "        fn into_token_stream(self) -> TokenStream {",
                  "            TokenStream::from(proc_macro2::TokenTree::Ident(proc_macro2::Ident::new(\"item_b\", proc_macro2::Span::call_site())))",
                  "        }",
                  "    }",
                  "",
                  "    let mut token_stream = TokenStream::new();",
                  "    let iter = vec![ItemA, ItemB];",
                  "    let separator = ItemA;",
                  "",
                  "    token_stream.append_terminated(iter, separator);",
                  "    ",
                  "    // Validate that the token_stream contains \"item_a item_b item_a;\".",
                  "    assert_eq!(token_stream.to_string(), \"item_a item_b item_a;\");",
                  "}"
                ]
              ],
              "can_compile": [
                {
                  "Err": "   Compiling serde v1.0.219\n   Compiling proc-macro2 v1.0.95\n   Compiling syn v1.0.109\n   Compiling target-triple v0.1.4\n   Compiling serde_json v1.0.140\n   Compiling rustversion v1.0.20\n   Compiling quote v1.0.40\n   Compiling syn v2.0.100\n   Compiling serde_derive v1.0.219\n   Compiling toml_datetime v0.6.8\n   Compiling serde_spanned v0.6.8\n   Compiling toml_edit v0.22.24\n   Compiling ntest_test_cases v0.9.3\n   Compiling proc-macro-crate v3.3.0\n   Compiling toml v0.8.20\n   Compiling trybuild v1.0.104\n   Compiling ntest_timeout v0.9.3\n   Compiling ntest v0.9.3\n   Compiling quote v1.0.40 (/home/abezbm/rust-utgen-test-crates-new/quote)\nwarning: unused import: `ntest::timeout`\n   --> src/ext.rs:114:8\n    |\n114 |    use ntest::timeout;\n    |        ^^^^^^^^^^^^^^\n    |\n    = note: `#[warn(unused_imports)]` on by default\n\nerror[E0308]: mismatched types\n   --> src/ext.rs:147:28\n    |\n147 |     let iter = vec![ItemA, ItemB];\n    |                            ^^^^^ expected `ItemA`, found `ItemB`\n\nFor more information about this error, try `rustc --explain E0308`.\nwarning: `quote` (lib test) generated 1 warning\nerror: could not compile `quote` (lib test) due to 1 previous error; 1 warning emitted\n"
                }
              ],
              "repaired": [
                false
              ]
            }
          ]
        }
      ]
    }
  ]
}