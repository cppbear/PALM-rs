{
  "system_pt": "As a software testing expert, please generate Rust test functions based on the following guidelines:\n1. Provide the code in plain text format, without explanations or Markdown.\n2. If the method under test belongs to a trait, construct appropriate structs within the test function, but avoid method overrides. If the method under test uses generics, instantiate them with suitable types based on the context.\n3. Generate test code with minimal scope: avoid creating external structures or implementations. Instead, define any necessary helper structures or implementations directly within the test function when required.\n4. Whenever possible, initialize the corresponding data structures using the initialization methods provided in the context if exist.\n5. Ensure the generated function is fully implemented and can be compiled and executed directly without any missing parts.\n6. Create a minimal yet complete set of test functions, ensuring they adhere to all provided preconditions and cover boundary conditions.\n7. Do not create a test module, but include intrinsic attributes like #[test] or #[should_panic] where necessary.\n",
  "static_pt": "The context for the focal function is as follows:\n// src/dfa.rs\n// crate name is regex\ntype InstPtr = u32;\ntype StatePtr = u32;\nuse std::collections::HashMap;\nuse std::fmt;\nuse std::iter::repeat;\nuse std::mem;\nuse exec::ProgramCache;\nuse prog::{Inst, Program};\nuse sparse::SparseSet;\nconst STATE_UNKNOWN: StatePtr = 1 << 31;\nconst STATE_DEAD: StatePtr = STATE_UNKNOWN + 1;\nconst STATE_QUIT: StatePtr = STATE_DEAD + 1;\nconst STATE_START: StatePtr = 1 << 30;\nconst STATE_MATCH: StatePtr = 1 << 29;\nconst STATE_MAX: StatePtr = STATE_MATCH - 1;\n#[derive(Debug)]\npub struct Fsm<'a> {\n    /// prog contains the NFA instruction opcodes. DFA execution uses either\n    /// the `dfa` instructions or the `dfa_reverse` instructions from\n    /// `exec::ExecReadOnly`. (It never uses `ExecReadOnly.nfa`, which may have\n    /// Unicode opcodes that cannot be executed by the DFA.)\n    prog: &'a Program,\n    /// The start state. We record it here because the pointer may change\n    /// when the cache is wiped.\n    start: StatePtr,\n    /// The current position in the input.\n    at: usize,\n    /// Should we quit after seeing the first match? e.g., When the caller\n    /// uses `is_match` or `shortest_match`.\n    quit_after_match: bool,\n    /// The last state that matched.\n    ///\n    /// When no match has occurred, this is set to STATE_UNKNOWN.\n    ///\n    /// This is only useful when matching regex sets. The last match state\n    /// is useful because it contains all of the match instructions seen,\n    /// thereby allowing us to enumerate which regexes in the set matched.\n    last_match_si: StatePtr,\n    /// The input position of the last cache flush. We use this to determine\n    /// if we're thrashing in the cache too often. If so, the DFA quits so\n    /// that we can fall back to the NFA algorithm.\n    last_cache_flush: usize,\n    /// All cached DFA information that is persisted between searches.\n    cache: &'a mut CacheInner,\n}\n#[derive(Clone)]\nstruct Transitions {\n    /// The table.\n    table: Vec<StatePtr>,\n    /// The stride.\n    num_byte_classes: usize,\n}\n#[derive(Clone)]\npub struct Program {\n    /// A sequence of instructions that represents an NFA.\n    pub insts: Vec<Inst>,\n    /// Pointers to each Match instruction in the sequence.\n    ///\n    /// This is always length 1 unless this program represents a regex set.\n    pub matches: Vec<InstPtr>,\n    /// The ordered sequence of all capture groups extracted from the AST.\n    /// Unnamed groups are `None`.\n    pub captures: Vec<Option<String>>,\n    /// Pointers to all named capture groups into `captures`.\n    pub capture_name_idx: Arc<HashMap<String, usize>>,\n    /// A pointer to the start instruction. This can vary depending on how\n    /// the program was compiled. For example, programs for use with the DFA\n    /// engine have a `.*?` inserted at the beginning of unanchored regular\n    /// expressions. The actual starting point of the program is after the\n    /// `.*?`.\n    pub start: InstPtr,\n    /// A set of equivalence classes for discriminating bytes in the compiled\n    /// program.\n    pub byte_classes: Vec<u8>,\n    /// When true, this program can only match valid UTF-8.\n    pub only_utf8: bool,\n    /// When true, this program uses byte range instructions instead of Unicode\n    /// range instructions.\n    pub is_bytes: bool,\n    /// When true, the program is compiled for DFA matching. For example, this\n    /// implies `is_bytes` and also inserts a preceding `.*?` for unanchored\n    /// regexes.\n    pub is_dfa: bool,\n    /// When true, the program matches text in reverse (for use only in the\n    /// DFA).\n    pub is_reverse: bool,\n    /// Whether the regex must match from the start of the input.\n    pub is_anchored_start: bool,\n    /// Whether the regex must match at the end of the input.\n    pub is_anchored_end: bool,\n    /// Whether this program contains a Unicode word boundary instruction.\n    pub has_unicode_word_boundary: bool,\n    /// A possibly empty machine for very quickly matching prefix literals.\n    pub prefixes: LiteralSearcher,\n    /// A limit on the size of the cache that the DFA is allowed to use while\n    /// matching.\n    ///\n    /// The cache limit specifies approximately how much space we're willing to\n    /// give to the state cache. Once the state cache exceeds the size, it is\n    /// wiped and all states must be re-computed.\n    ///\n    /// Note that this value does not impact correctness. It can be set to 0\n    /// and the DFA will run just fine. (It will only ever store exactly one\n    /// state in the cache, and will likely run very slowly, but it will work.)\n    ///\n    /// Also note that this limit is *per thread of execution*. That is,\n    /// if the same regex is used to search text across multiple threads\n    /// simultaneously, then the DFA cache is not shared. Instead, copies are\n    /// made.\n    pub dfa_size_limit: usize,\n}\n#[derive(Clone, Debug)]\npub struct SparseSet {\n    /// Dense contains the instruction pointers in the order in which they\n    /// were inserted. Accessing elements >= self.size is illegal.\n    dense: Vec<usize>,\n    /// Sparse maps instruction pointers to their location in dense.\n    ///\n    /// An instruction pointer is in the set if and only if\n    /// sparse[ip] < size && ip == dense[sparse[ip]].\n    sparse: Vec<usize>,\n    /// The number of elements in the set.\n    size: usize,\n}\n#[derive(Clone, Debug)]\nstruct CacheInner {\n    /// A cache of pre-compiled DFA states, keyed by the set of NFA states\n    /// and the set of empty-width flags set at the byte in the input when the\n    /// state was observed.\n    ///\n    /// A StatePtr is effectively a `*State`, but to avoid various inconvenient\n    /// things, we just pass indexes around manually. The performance impact of\n    /// this is probably an instruction or two in the inner loop. However, on\n    /// 64 bit, each StatePtr is half the size of a *State.\n    compiled: HashMap<State, StatePtr>,\n    /// The transition table.\n    ///\n    /// The transition table is laid out in row-major order, where states are\n    /// rows and the transitions for each state are columns. At a high level,\n    /// given state `s` and byte `b`, the next state can be found at index\n    /// `s * 256 + b`.\n    ///\n    /// This is, of course, a lie. A StatePtr is actually a pointer to the\n    /// *start* of a row in this table. When indexing in the DFA's inner loop,\n    /// this removes the need to multiply the StatePtr by the stride. Yes, it\n    /// matters. This reduces the number of states we can store, but: the\n    /// stride is rarely 256 since we define transitions in terms of\n    /// *equivalence classes* of bytes. Each class corresponds to a set of\n    /// bytes that never discriminate a distinct path through the DFA from each\n    /// other.\n    trans: Transitions,\n    /// Our set of states. Note that `StatePtr / num_byte_classes` indexes\n    /// this Vec rather than just a `StatePtr`.\n    states: Vec<State>,\n    /// A set of cached start states, which are limited to the number of\n    /// permutations of flags set just before the initial byte of input. (The\n    /// index into this vec is a `EmptyFlags`.)\n    ///\n    /// N.B. A start state can be \"dead\" (i.e., no possible match), so we\n    /// represent it with a StatePtr.\n    start_states: Vec<StatePtr>,\n    /// Stack scratch space used to follow epsilon transitions in the NFA.\n    /// (This permits us to avoid recursion.)\n    ///\n    /// The maximum stack size is the number of NFA states.\n    stack: Vec<InstPtr>,\n    /// The total number of times this cache has been flushed by the DFA\n    /// because of space constraints.\n    flush_count: u64,\n    /// The total heap size of the DFA's cache. We use this to determine when\n    /// we should flush the cache.\n    size: usize,\n}\n#[derive(Copy, Clone, Debug)]\nstruct Byte(u16);\nimpl<'a> Fsm<'a> {\n    #[inline(always)]\n    pub fn forward(\n        prog: &'a Program,\n        cache: &ProgramCache,\n        quit_after_match: bool,\n        text: &[u8],\n        at: usize,\n    ) -> Result<usize> {}\n    #[inline(always)]\n    pub fn reverse(\n        prog: &'a Program,\n        cache: &ProgramCache,\n        quit_after_match: bool,\n        text: &[u8],\n        at: usize,\n    ) -> Result<usize> {}\n    #[inline(always)]\n    pub fn forward_many(\n        prog: &'a Program,\n        cache: &ProgramCache,\n        matches: &mut [bool],\n        text: &[u8],\n        at: usize,\n    ) -> Result<usize> {}\n    #[inline(always)]\n    fn exec_at(\n        &mut self,\n        qcur: &mut SparseSet,\n        qnext: &mut SparseSet,\n        text: &[u8],\n    ) -> Result<usize> {}\n    #[inline(always)]\n    fn exec_at_reverse(\n        &mut self,\n        qcur: &mut SparseSet,\n        qnext: &mut SparseSet,\n        text: &[u8],\n    ) -> Result<usize> {}\n    #[inline(always)]\n    unsafe fn next_si(&self, si: StatePtr, text: &[u8], i: usize) -> StatePtr {}\n    fn exec_byte(\n        &mut self,\n        qcur: &mut SparseSet,\n        qnext: &mut SparseSet,\n        mut si: StatePtr,\n        b: Byte,\n    ) -> Option<StatePtr> {\n        use prog::Inst::*;\n        qcur.clear();\n        for ip in self.state(si).inst_ptrs() {\n            qcur.insert(ip);\n        }\n        let is_word_last = self.state(si).flags().is_word();\n        let is_word = b.is_ascii_word();\n        if self.state(si).flags().has_empty() {\n            let mut flags = EmptyFlags::default();\n            if b.is_eof() {\n                flags.end = true;\n                flags.end_line = true;\n            } else if b.as_byte().map_or(false, |b| b == b'\\n') {\n                flags.end_line = true;\n            }\n            if is_word_last == is_word {\n                flags.not_word_boundary = true;\n            } else {\n                flags.word_boundary = true;\n            }\n            qnext.clear();\n            for &ip in &*qcur {\n                self.follow_epsilons(usize_to_u32(ip), qnext, flags);\n            }\n            mem::swap(qcur, qnext);\n        }\n        let mut empty_flags = EmptyFlags::default();\n        let mut state_flags = StateFlags::default();\n        empty_flags.start_line = b.as_byte().map_or(false, |b| b == b'\\n');\n        if b.is_ascii_word() {\n            state_flags.set_word();\n        }\n        qnext.clear();\n        for &ip in &*qcur {\n            match self.prog[ip as usize] {\n                Char(_) | Ranges(_) => unreachable!(),\n                Save(_) | Split(_) | EmptyLook(_) => {}\n                Match(_) => {\n                    state_flags.set_match();\n                    if !self.continue_past_first_match() {\n                        break;\n                    } else if self.prog.matches.len() > 1 && !qnext.contains(ip as usize)\n                    {\n                        qnext.insert(ip);\n                    }\n                }\n                Bytes(ref inst) => {\n                    if b.as_byte().map_or(false, |b| inst.matches(b)) {\n                        self.follow_epsilons(inst.goto as InstPtr, qnext, empty_flags);\n                    }\n                }\n            }\n        }\n        let cache = if b.is_eof() && self.prog.matches.len() > 1 {\n            mem::swap(qcur, qnext);\n            false\n        } else {\n            true\n        };\n        let mut next = match self.cached_state(qnext, state_flags, Some(&mut si)) {\n            None => return None,\n            Some(next) => next,\n        };\n        if (self.start & !STATE_START) == next {\n            debug_assert!(! self.state(next).flags().is_match());\n            next = self.start_ptr(next);\n        }\n        if next <= STATE_MAX && self.state(next).flags().is_match() {\n            next |= STATE_MATCH;\n        }\n        debug_assert!(next != STATE_UNKNOWN);\n        if cache {\n            let cls = self.byte_class(b);\n            self.cache.trans.set_next(si, cls, next);\n        }\n        Some(next)\n    }\n    fn follow_epsilons(&mut self, ip: InstPtr, q: &mut SparseSet, flags: EmptyFlags) {}\n    fn cached_state(\n        &mut self,\n        q: &SparseSet,\n        mut state_flags: StateFlags,\n        current_state: Option<&mut StatePtr>,\n    ) -> Option<StatePtr> {}\n    fn cached_state_key(\n        &mut self,\n        q: &SparseSet,\n        state_flags: &mut StateFlags,\n    ) -> Option<State> {}\n    fn clear_cache_and_save(&mut self, current_state: Option<&mut StatePtr>) -> bool {}\n    fn clear_cache(&mut self) -> bool {}\n    fn restore_state(&mut self, state: State) -> Option<StatePtr> {}\n    fn next_state(\n        &mut self,\n        qcur: &mut SparseSet,\n        qnext: &mut SparseSet,\n        si: StatePtr,\n        b: Byte,\n    ) -> Option<StatePtr> {\n        if si == STATE_DEAD {\n            return Some(STATE_DEAD);\n        }\n        match self.cache.trans.next(si, self.byte_class(b)) {\n            STATE_UNKNOWN => self.exec_byte(qcur, qnext, si, b),\n            STATE_QUIT => None,\n            STATE_DEAD => Some(STATE_DEAD),\n            nsi => Some(nsi),\n        }\n    }\n    #[inline(always)]\n    fn start_state(\n        &mut self,\n        q: &mut SparseSet,\n        empty_flags: EmptyFlags,\n        state_flags: StateFlags,\n    ) -> Option<StatePtr> {}\n    fn start_flags(&self, text: &[u8], at: usize) -> (EmptyFlags, StateFlags) {}\n    fn start_flags_reverse(&self, text: &[u8], at: usize) -> (EmptyFlags, StateFlags) {}\n    fn state(&self, si: StatePtr) -> &State {}\n    fn add_state(&mut self, state: State) -> Option<StatePtr> {}\n    fn prefix_at(&self, text: &[u8], at: usize) -> Option<usize> {}\n    fn num_byte_classes(&self) -> usize {}\n    #[inline(always)]\n    fn byte_class(&self, b: Byte) -> usize {\n        match b.as_byte() {\n            None => self.num_byte_classes() - 1,\n            Some(b) => self.u8_class(b),\n        }\n    }\n    #[inline(always)]\n    fn u8_class(&self, b: u8) -> usize {}\n    fn continue_past_first_match(&self) -> bool {}\n    fn has_prefix(&self) -> bool {}\n    fn start_ptr(&self, si: StatePtr) -> StatePtr {}\n    fn approximate_size(&self) -> usize {}\n}\nimpl Transitions {\n    fn new(num_byte_classes: usize) -> Transitions {}\n    fn num_states(&self) -> usize {}\n    fn add(&mut self) -> Option<StatePtr> {}\n    fn clear(&mut self) {}\n    fn set_next(&mut self, si: StatePtr, cls: usize, next: StatePtr) {}\n    fn next(&self, si: StatePtr, cls: usize) -> StatePtr {\n        self.table[si as usize + cls]\n    }\n    fn state_heap_size(&self) -> usize {}\n    unsafe fn next_unchecked(&self, si: StatePtr, cls: usize) -> StatePtr {}\n}\n\nThe function to be tested is presented as follows:\n/// Returns the next state given the current state si and current byte\n/// b. {qcur,qnext} are used as scratch space for storing ordered NFA\n/// states.\n///\n/// This tries to fetch the next state from the cache, but if that fails,\n/// it computes the next state, caches it and returns a pointer to it.\n///\n/// The pointer can be to a real state, or it can be STATE_DEAD.\n/// STATE_UNKNOWN cannot be returned.\n///\n/// None is returned if a new state could not be allocated (i.e., the DFA\n/// ran out of space and thinks it's running too slowly).\nfn next_state(\n    &mut self,\n    qcur: &mut SparseSet,\n    qnext: &mut SparseSet,\n    si: StatePtr,\n    b: Byte,\n) -> Option<StatePtr> {\n    if si == STATE_DEAD {\n        return Some(STATE_DEAD);\n    }\n    match self.cache.trans.next(si, self.byte_class(b)) {\n        STATE_UNKNOWN => self.exec_byte(qcur, qnext, si, b),\n        STATE_QUIT => None,\n        STATE_DEAD => Some(STATE_DEAD),\n        nsi => Some(nsi),\n    }\n}\n",
  "depend_pt": ""
}