{
  "system_pt": "As a software testing expert, please generate Rust test functions based on the following guidelines:\n1. Provide the code in plain text format, without explanations or Markdown.\n2. If the method under test belongs to a trait, construct appropriate structs within the test function, but avoid method overrides. If the method under test uses generics, instantiate them with suitable types based on the context.\n3. Generate test code with minimal scope: avoid creating external structures or implementations. Instead, define any necessary helper structures or implementations directly within the test function when required.\n4. Whenever possible, initialize the corresponding data structures using the initialization methods provided in the context if exist.\n5. Ensure the generated function is fully implemented and can be compiled and executed directly without any missing parts.\n6. Create a minimal yet complete set of test functions, ensuring they adhere to all provided preconditions and cover boundary conditions.\n7. Do not create a test module, but include intrinsic attributes like #[test] or #[should_panic] where necessary.\n",
  "static_pt": "The context for the focal function is as follows:\n// src/exec.rs\n// crate name is regex\npub type ProgramCache = RefCell<ProgramCacheInner>;\nuse std::cell::RefCell;\nuse std::collections::HashMap;\nuse std::cmp;\nuse std::sync::Arc;\nuse thread_local::CachedThreadLocal;\nuse syntax::ParserBuilder;\nuse syntax::hir::Hir;\nuse syntax::hir::literal::Literals;\nuse backtrack;\nuse compile::Compiler;\nuse dfa;\nuse error::Error;\nuse input::{ByteInput, CharInput};\nuse literal::LiteralSearcher;\nuse pikevm;\nuse prog::Program;\nuse re_builder::RegexOptions;\nuse re_bytes;\nuse re_set;\nuse re_trait::{RegularExpression, Slot, Locations, as_slots};\nuse re_unicode;\nuse utf8::next_utf8;\npub struct ExecBuilder {\n    options: RegexOptions,\n    match_type: Option<MatchType>,\n    bytes: bool,\n    only_utf8: bool,\n}\npub struct Compiler {\n    insts: Vec<MaybeInst>,\n    compiled: Program,\n    capture_name_idx: HashMap<String, usize>,\n    num_exprs: usize,\n    size_limit: usize,\n    suffix_cache: SuffixCache,\n    utf8_seqs: Option<Utf8Sequences>,\n    byte_classes: ByteClassSet,\n}\n#[derive(Clone, Debug)]\npub struct LiteralSearcher {\n    complete: bool,\n    lcp: FreqyPacked,\n    lcs: FreqyPacked,\n    matcher: Matcher,\n}\n#[derive(Clone)]\npub struct Program {\n    /// A sequence of instructions that represents an NFA.\n    pub insts: Vec<Inst>,\n    /// Pointers to each Match instruction in the sequence.\n    ///\n    /// This is always length 1 unless this program represents a regex set.\n    pub matches: Vec<InstPtr>,\n    /// The ordered sequence of all capture groups extracted from the AST.\n    /// Unnamed groups are `None`.\n    pub captures: Vec<Option<String>>,\n    /// Pointers to all named capture groups into `captures`.\n    pub capture_name_idx: Arc<HashMap<String, usize>>,\n    /// A pointer to the start instruction. This can vary depending on how\n    /// the program was compiled. For example, programs for use with the DFA\n    /// engine have a `.*?` inserted at the beginning of unanchored regular\n    /// expressions. The actual starting point of the program is after the\n    /// `.*?`.\n    pub start: InstPtr,\n    /// A set of equivalence classes for discriminating bytes in the compiled\n    /// program.\n    pub byte_classes: Vec<u8>,\n    /// When true, this program can only match valid UTF-8.\n    pub only_utf8: bool,\n    /// When true, this program uses byte range instructions instead of Unicode\n    /// range instructions.\n    pub is_bytes: bool,\n    /// When true, the program is compiled for DFA matching. For example, this\n    /// implies `is_bytes` and also inserts a preceding `.*?` for unanchored\n    /// regexes.\n    pub is_dfa: bool,\n    /// When true, the program matches text in reverse (for use only in the\n    /// DFA).\n    pub is_reverse: bool,\n    /// Whether the regex must match from the start of the input.\n    pub is_anchored_start: bool,\n    /// Whether the regex must match at the end of the input.\n    pub is_anchored_end: bool,\n    /// Whether this program contains a Unicode word boundary instruction.\n    pub has_unicode_word_boundary: bool,\n    /// A possibly empty machine for very quickly matching prefix literals.\n    pub prefixes: LiteralSearcher,\n    /// A limit on the size of the cache that the DFA is allowed to use while\n    /// matching.\n    ///\n    /// The cache limit specifies approximately how much space we're willing to\n    /// give to the state cache. Once the state cache exceeds the size, it is\n    /// wiped and all states must be re-computed.\n    ///\n    /// Note that this value does not impact correctness. It can be set to 0\n    /// and the DFA will run just fine. (It will only ever store exactly one\n    /// state in the cache, and will likely run very slowly, but it will work.)\n    ///\n    /// Also note that this limit is *per thread of execution*. That is,\n    /// if the same regex is used to search text across multiple threads\n    /// simultaneously, then the DFA cache is not shared. Instead, copies are\n    /// made.\n    pub dfa_size_limit: usize,\n}\n#[derive(Debug)]\nstruct ExecReadOnly {\n    /// The original regular expressions given by the caller to compile.\n    res: Vec<String>,\n    /// A compiled program that is used in the NFA simulation and backtracking.\n    /// It can be byte-based or Unicode codepoint based.\n    ///\n    /// N.B. It is not possibly to make this byte-based from the public API.\n    /// It is only used for testing byte based programs in the NFA simulations.\n    nfa: Program,\n    /// A compiled byte based program for DFA execution. This is only used\n    /// if a DFA can be executed. (Currently, only word boundary assertions are\n    /// not supported.) Note that this program contains an embedded `.*?`\n    /// preceding the first capture group, unless the regex is anchored at the\n    /// beginning.\n    dfa: Program,\n    /// The same as above, except the program is reversed (and there is no\n    /// preceding `.*?`). This is used by the DFA to find the starting location\n    /// of matches.\n    dfa_reverse: Program,\n    /// A set of suffix literals extracted from the regex.\n    ///\n    /// Prefix literals are stored on the `Program`, since they are used inside\n    /// the matching engines.\n    suffixes: LiteralSearcher,\n    /// match_type encodes as much upfront knowledge about how we're going to\n    /// execute a search as possible.\n    match_type: MatchType,\n}\npub struct Exec {\n    /// All read only state.\n    ro: Arc<ExecReadOnly>,\n    /// Caches for the various matching engines.\n    cache: CachedThreadLocal<ProgramCache>,\n}\n#[derive(Clone, Debug)]\npub struct ProgramCacheInner {\n    pub pikevm: pikevm::Cache,\n    pub backtrack: backtrack::Cache,\n    pub dfa: dfa::Cache,\n    pub dfa_reverse: dfa::Cache,\n}\n#[derive(Clone, Debug)]\n#[allow(missing_docs)]\npub struct RegexOptions {\n    pub pats: Vec<String>,\n    pub size_limit: usize,\n    pub dfa_size_limit: usize,\n    pub nest_limit: u32,\n    pub case_insensitive: bool,\n    pub multi_line: bool,\n    pub dot_matches_new_line: bool,\n    pub swap_greed: bool,\n    pub ignore_whitespace: bool,\n    pub unicode: bool,\n    pub octal: bool,\n}\nstruct Parsed {\n    exprs: Vec<Hir>,\n    prefixes: Literals,\n    suffixes: Literals,\n    bytes: bool,\n}\n#[derive(Clone, PartialEq)]\npub enum Error {\n    /// A syntax error.\n    Syntax(String),\n    /// The compiled program exceeded the set size limit.\n    /// The argument is the size limit imposed.\n    CompiledTooBig(usize),\n    /// Hints that destructuring should not be exhaustive.\n    ///\n    /// This enum may grow additional variants, so this makes sure clients\n    /// don't count on exhaustive matching. (Otherwise, adding a new variant\n    /// could break existing code.)\n    #[doc(hidden)]\n    __Nonexhaustive,\n}\n#[derive(Clone, Copy, Debug)]\nenum MatchType {\n    /// A single or multiple literal search. This is only used when the regex\n    /// can be decomposed into unambiguous literal search.\n    Literal(MatchLiteralType),\n    /// A normal DFA search.\n    Dfa,\n    /// A reverse DFA search starting from the end of a haystack.\n    DfaAnchoredReverse,\n    /// A reverse DFA search with suffix literal scanning.\n    DfaSuffix,\n    /// Use the DFA on two or more regular expressions.\n    DfaMany,\n    /// An NFA variant.\n    Nfa(MatchNfaType),\n    /// No match is ever possible, so don't ever try to search.\n    Nothing,\n}\nimpl ExecBuilder {\n    pub fn new(re: &str) -> Self {\n        Self::new_many(&[re])\n    }\n    pub fn new_many<I, S>(res: I) -> Self\n    where\n        S: AsRef<str>,\n        I: IntoIterator<Item = S>,\n    {\n        let mut opts = RegexOptions::default();\n        opts.pats = res.into_iter().map(|s| s.as_ref().to_owned()).collect();\n        Self::new_options(opts)\n    }\n    pub fn new_options(opts: RegexOptions) -> Self {\n        ExecBuilder {\n            options: opts,\n            match_type: None,\n            bytes: false,\n            only_utf8: true,\n        }\n    }\n    pub fn automatic(mut self) -> Self {\n        self.match_type = None;\n        self\n    }\n    pub fn nfa(mut self) -> Self {\n        self.match_type = Some(MatchType::Nfa(MatchNfaType::PikeVM));\n        self\n    }\n    pub fn bounded_backtracking(mut self) -> Self {\n        self.match_type = Some(MatchType::Nfa(MatchNfaType::Backtrack));\n        self\n    }\n    pub fn bytes(mut self, yes: bool) -> Self {\n        self.bytes = yes;\n        self\n    }\n    pub fn only_utf8(mut self, yes: bool) -> Self {\n        self.only_utf8 = yes;\n        self\n    }\n    pub fn unicode(mut self, yes: bool) -> Self {\n        self.options.unicode = yes;\n        self\n    }\n    fn parse(&self) -> Result<Parsed, Error> {\n        let mut exprs = Vec::with_capacity(self.options.pats.len());\n        let mut prefixes = Some(Literals::empty());\n        let mut suffixes = Some(Literals::empty());\n        let mut bytes = false;\n        let is_set = self.options.pats.len() > 1;\n        for pat in &self.options.pats {\n            let mut parser = ParserBuilder::new()\n                .octal(self.options.octal)\n                .case_insensitive(self.options.case_insensitive)\n                .multi_line(self.options.multi_line)\n                .dot_matches_new_line(self.options.dot_matches_new_line)\n                .swap_greed(self.options.swap_greed)\n                .ignore_whitespace(self.options.ignore_whitespace)\n                .unicode(self.options.unicode)\n                .allow_invalid_utf8(!self.only_utf8)\n                .nest_limit(self.options.nest_limit)\n                .build();\n            let expr = parser.parse(pat).map_err(|e| Error::Syntax(e.to_string()))?;\n            bytes = bytes || !expr.is_always_utf8();\n            if !expr.is_anchored_start() && expr.is_any_anchored_start() {\n                prefixes = None;\n            } else if is_set && expr.is_anchored_start() {\n                prefixes = None;\n            }\n            prefixes = prefixes\n                .and_then(|mut prefixes| {\n                    if !prefixes.union_prefixes(&expr) { None } else { Some(prefixes) }\n                });\n            if !expr.is_anchored_end() && expr.is_any_anchored_end() {\n                suffixes = None;\n            } else if is_set && expr.is_anchored_end() {\n                suffixes = None;\n            }\n            suffixes = suffixes\n                .and_then(|mut suffixes| {\n                    if !suffixes.union_suffixes(&expr) { None } else { Some(suffixes) }\n                });\n            exprs.push(expr);\n        }\n        Ok(Parsed {\n            exprs: exprs,\n            prefixes: prefixes.unwrap_or_else(Literals::empty),\n            suffixes: suffixes.unwrap_or_else(Literals::empty),\n            bytes: bytes,\n        })\n    }\n    pub fn build(self) -> Result<Exec, Error> {\n        if self.options.pats.is_empty() {\n            let ro = Arc::new(ExecReadOnly {\n                res: vec![],\n                nfa: Program::new(),\n                dfa: Program::new(),\n                dfa_reverse: Program::new(),\n                suffixes: LiteralSearcher::empty(),\n                match_type: MatchType::Nothing,\n            });\n            return Ok(Exec {\n                ro: ro,\n                cache: CachedThreadLocal::new(),\n            });\n        }\n        let parsed = self.parse()?;\n        let mut nfa = Compiler::new()\n            .size_limit(self.options.size_limit)\n            .bytes(self.bytes || parsed.bytes)\n            .only_utf8(self.only_utf8)\n            .compile(&parsed.exprs)?;\n        let mut dfa = Compiler::new()\n            .size_limit(self.options.size_limit)\n            .dfa(true)\n            .only_utf8(self.only_utf8)\n            .compile(&parsed.exprs)?;\n        let mut dfa_reverse = Compiler::new()\n            .size_limit(self.options.size_limit)\n            .dfa(true)\n            .only_utf8(self.only_utf8)\n            .reverse(true)\n            .compile(&parsed.exprs)?;\n        let prefixes = parsed.prefixes.unambiguous_prefixes();\n        let suffixes = parsed.suffixes.unambiguous_suffixes();\n        nfa.prefixes = LiteralSearcher::prefixes(prefixes);\n        dfa.prefixes = nfa.prefixes.clone();\n        dfa.dfa_size_limit = self.options.dfa_size_limit;\n        dfa_reverse.dfa_size_limit = self.options.dfa_size_limit;\n        let mut ro = ExecReadOnly {\n            res: self.options.pats,\n            nfa: nfa,\n            dfa: dfa,\n            dfa_reverse: dfa_reverse,\n            suffixes: LiteralSearcher::suffixes(suffixes),\n            match_type: MatchType::Nothing,\n        };\n        ro.match_type = ro.choose_match_type(self.match_type);\n        let ro = Arc::new(ro);\n        Ok(Exec {\n            ro: ro,\n            cache: CachedThreadLocal::new(),\n        })\n    }\n}\nimpl Compiler {\n    pub fn new() -> Self {\n        Compiler {\n            insts: vec![],\n            compiled: Program::new(),\n            capture_name_idx: HashMap::new(),\n            num_exprs: 0,\n            size_limit: 10 * (1 << 20),\n            suffix_cache: SuffixCache::new(1000),\n            utf8_seqs: Some(Utf8Sequences::new('\\x00', '\\x00')),\n            byte_classes: ByteClassSet::new(),\n        }\n    }\n    pub fn size_limit(mut self, size_limit: usize) -> Self {\n        self.size_limit = size_limit;\n        self\n    }\n    pub fn bytes(mut self, yes: bool) -> Self {\n        self.compiled.is_bytes = yes;\n        self\n    }\n    pub fn only_utf8(mut self, yes: bool) -> Self {\n        self.compiled.only_utf8 = yes;\n        self\n    }\n    pub fn dfa(mut self, yes: bool) -> Self {\n        self.compiled.is_dfa = yes;\n        self\n    }\n    pub fn reverse(mut self, yes: bool) -> Self {\n        self.compiled.is_reverse = yes;\n        self\n    }\n    pub fn compile(mut self, exprs: &[Hir]) -> result::Result<Program, Error> {\n        debug_assert!(exprs.len() >= 1);\n        self.num_exprs = exprs.len();\n        if exprs.len() == 1 {\n            self.compile_one(&exprs[0])\n        } else {\n            self.compile_many(exprs)\n        }\n    }\n    fn compile_one(mut self, expr: &Hir) -> result::Result<Program, Error> {}\n    fn compile_many(mut self, exprs: &[Hir]) -> result::Result<Program, Error> {}\n    fn compile_finish(mut self) -> result::Result<Program, Error> {}\n    fn c(&mut self, expr: &Hir) -> Result {}\n    fn c_capture(&mut self, first_slot: usize, expr: &Hir) -> Result {}\n    fn c_dotstar(&mut self) -> Result {}\n    fn c_literal(&mut self, chars: &[char]) -> Result {}\n    fn c_char(&mut self, c: char) -> Result {}\n    fn c_class(&mut self, ranges: &[hir::ClassUnicodeRange]) -> Result {}\n    fn c_bytes(&mut self, bytes: &[u8]) -> Result {}\n    fn c_byte(&mut self, b: u8) -> Result {}\n    fn c_class_bytes(&mut self, ranges: &[hir::ClassBytesRange]) -> Result {}\n    fn c_empty_look(&mut self, look: EmptyLook) -> Result {}\n    fn c_concat<'a, I>(&mut self, exprs: I) -> Result\n    where\n        I: IntoIterator<Item = &'a Hir>,\n    {}\n    fn c_alternate(&mut self, exprs: &[Hir]) -> Result {}\n    fn c_repeat(&mut self, rep: &hir::Repetition) -> Result {}\n    fn c_repeat_zero_or_one(&mut self, expr: &Hir, greedy: bool) -> Result {}\n    fn c_repeat_zero_or_more(&mut self, expr: &Hir, greedy: bool) -> Result {}\n    fn c_repeat_one_or_more(&mut self, expr: &Hir, greedy: bool) -> Result {}\n    fn c_repeat_range_min_or_more(\n        &mut self,\n        expr: &Hir,\n        greedy: bool,\n        min: u32,\n    ) -> Result {}\n    fn c_repeat_range(\n        &mut self,\n        expr: &Hir,\n        greedy: bool,\n        min: u32,\n        max: u32,\n    ) -> Result {}\n    fn fill(&mut self, hole: Hole, goto: InstPtr) {}\n    fn fill_to_next(&mut self, hole: Hole) {}\n    fn fill_split(\n        &mut self,\n        hole: Hole,\n        goto1: Option<InstPtr>,\n        goto2: Option<InstPtr>,\n    ) -> Hole {}\n    fn push_compiled(&mut self, inst: Inst) {}\n    fn push_hole(&mut self, inst: InstHole) -> Hole {}\n    fn push_split_hole(&mut self) -> Hole {}\n    fn check_size(&self) -> result::Result<(), Error> {}\n}\nimpl LiteralSearcher {\n    pub fn empty() -> Self {\n        Self::new(Literals::empty(), Matcher::Empty)\n    }\n    pub fn prefixes(lits: Literals) -> Self {\n        let matcher = Matcher::prefixes(&lits);\n        Self::new(lits, matcher)\n    }\n    pub fn suffixes(lits: Literals) -> Self {\n        let matcher = Matcher::suffixes(&lits);\n        Self::new(lits, matcher)\n    }\n    fn new(lits: Literals, matcher: Matcher) -> Self {\n        let complete = lits.all_complete();\n        LiteralSearcher {\n            complete: complete,\n            lcp: FreqyPacked::new(lits.longest_common_prefix().to_vec()),\n            lcs: FreqyPacked::new(lits.longest_common_suffix().to_vec()),\n            matcher: matcher,\n        }\n    }\n    pub fn complete(&self) -> bool {}\n    #[inline(always)]\n    pub fn find(&self, haystack: &[u8]) -> Option<(usize, usize)> {}\n    pub fn find_start(&self, haystack: &[u8]) -> Option<(usize, usize)> {}\n    pub fn find_end(&self, haystack: &[u8]) -> Option<(usize, usize)> {}\n    pub fn iter(&self) -> LiteralIter {\n        match self.matcher {\n            Matcher::Empty => LiteralIter::Empty,\n            Matcher::Bytes(ref sset) => LiteralIter::Bytes(&sset.dense),\n            Matcher::FreqyPacked(ref s) => LiteralIter::Single(&s.pat),\n            Matcher::BoyerMoore(ref s) => LiteralIter::Single(&s.pattern),\n            Matcher::AC(ref ac) => LiteralIter::AC(ac.patterns()),\n            Matcher::TeddySSSE3(ref ted) => LiteralIter::TeddySSSE3(ted.patterns()),\n            Matcher::TeddyAVX2(ref ted) => LiteralIter::TeddyAVX2(ted.patterns()),\n        }\n    }\n    pub fn lcp(&self) -> &FreqyPacked {}\n    pub fn lcs(&self) -> &FreqyPacked {}\n    pub fn is_empty(&self) -> bool {}\n    pub fn len(&self) -> usize {}\n    pub fn approximate_size(&self) -> usize {}\n}\nimpl Program {\n    pub fn new() -> Self {\n        Program {\n            insts: vec![],\n            matches: vec![],\n            captures: vec![],\n            capture_name_idx: Arc::new(HashMap::new()),\n            start: 0,\n            byte_classes: vec![0; 256],\n            only_utf8: true,\n            is_bytes: false,\n            is_dfa: false,\n            is_reverse: false,\n            is_anchored_start: false,\n            is_anchored_end: false,\n            has_unicode_word_boundary: false,\n            prefixes: LiteralSearcher::empty(),\n            dfa_size_limit: 2 * (1 << 20),\n        }\n    }\n    pub fn skip(&self, mut pc: usize) -> usize {}\n    pub fn leads_to_match(&self, pc: usize) -> bool {}\n    pub fn needs_dotstar(&self) -> bool {}\n    pub fn uses_bytes(&self) -> bool {}\n    pub fn only_utf8(&self) -> bool {}\n    pub fn approximate_size(&self) -> usize {}\n}\nimpl ExecReadOnly {\n    fn choose_match_type(&self, hint: Option<MatchType>) -> MatchType {\n        use self::MatchType::*;\n        if let Some(Nfa(_)) = hint {\n            return hint.unwrap();\n        }\n        if self.nfa.insts.is_empty() {\n            return Nothing;\n        }\n        if self.res.len() == 1 {\n            if self.nfa.prefixes.complete() {\n                return if self.nfa.is_anchored_start {\n                    Literal(MatchLiteralType::AnchoredStart)\n                } else {\n                    Literal(MatchLiteralType::Unanchored)\n                };\n            }\n            if self.suffixes.complete() {\n                return if self.nfa.is_anchored_end {\n                    Literal(MatchLiteralType::AnchoredEnd)\n                } else {\n                    Literal(MatchLiteralType::Unanchored)\n                };\n            }\n        }\n        if dfa::can_exec(&self.dfa) {\n            if self.res.len() >= 2 {\n                return DfaMany;\n            }\n            if !self.nfa.is_anchored_start && self.nfa.is_anchored_end {\n                return DfaAnchoredReverse;\n            }\n            if self.should_suffix_scan() {\n                return DfaSuffix;\n            }\n            return Dfa;\n        }\n        Nfa(MatchNfaType::Auto)\n    }\n    fn should_suffix_scan(&self) -> bool {}\n}\n\nThe function to be tested is presented as follows:\n/// Build an executor that can run a regular expression.\npub fn build(self) -> Result<Exec, Error> {\n    // Special case when we have no patterns to compile.\n    // This can happen when compiling a regex set.\n    if self.options.pats.is_empty() {\n        let ro = Arc::new(ExecReadOnly {\n            res: vec![],\n            nfa: Program::new(),\n            dfa: Program::new(),\n            dfa_reverse: Program::new(),\n            suffixes: LiteralSearcher::empty(),\n            match_type: MatchType::Nothing,\n        });\n        return Ok(Exec { ro: ro, cache: CachedThreadLocal::new() });\n    }\n    let parsed = self.parse()?;\n    let mut nfa =\n        Compiler::new()\n                 .size_limit(self.options.size_limit)\n                 .bytes(self.bytes || parsed.bytes)\n                 .only_utf8(self.only_utf8)\n                 .compile(&parsed.exprs)?;\n    let mut dfa =\n        Compiler::new()\n                 .size_limit(self.options.size_limit)\n                 .dfa(true)\n                 .only_utf8(self.only_utf8)\n                 .compile(&parsed.exprs)?;\n    let mut dfa_reverse =\n        Compiler::new()\n                 .size_limit(self.options.size_limit)\n                 .dfa(true)\n                 .only_utf8(self.only_utf8)\n                 .reverse(true)\n                 .compile(&parsed.exprs)?;\n\n    let prefixes = parsed.prefixes.unambiguous_prefixes();\n    let suffixes = parsed.suffixes.unambiguous_suffixes();\n    nfa.prefixes = LiteralSearcher::prefixes(prefixes);\n    dfa.prefixes = nfa.prefixes.clone();\n    dfa.dfa_size_limit = self.options.dfa_size_limit;\n    dfa_reverse.dfa_size_limit = self.options.dfa_size_limit;\n\n    let mut ro = ExecReadOnly {\n        res: self.options.pats,\n        nfa: nfa,\n        dfa: dfa,\n        dfa_reverse: dfa_reverse,\n        suffixes: LiteralSearcher::suffixes(suffixes),\n        match_type: MatchType::Nothing,\n    };\n    ro.match_type = ro.choose_match_type(self.match_type);\n\n    let ro = Arc::new(ro);\n    Ok(Exec { ro: ro, cache: CachedThreadLocal::new() })\n}\nGiven the following constraints, potential panic-triggering statements, and expected return values/types (all extracted from the function under test).\nGenerate test inputs that maximize the function's runtime satisfaction of all constraints and expected outputs while considering panic conditions:\n",
  "depend_pt": ""
}