{
  "system_pt": "As a software testing expert, please generate Rust test functions based on the following guidelines:\n1. Provide the code in plain text format, without explanations or Markdown.\n2. If the method under test belongs to a trait, construct appropriate structs within the test function, but avoid method overrides. If the method under test uses generics, instantiate them with suitable types based on the context.\n3. Generate test code with minimal scope: avoid creating external structures or implementations. Instead, define any necessary helper structures or implementations directly within the test function when required.\n4. Whenever possible, initialize the corresponding data structures using the initialization methods provided in the context if exist.\n5. Ensure the generated function is fully implemented and can be compiled and executed directly without any missing parts.\n6. Create a minimal yet complete set of test functions, ensuring they adhere to all provided preconditions and cover boundary conditions.\n7. Do not create a test module, but include intrinsic attributes like #[test] or #[should_panic] where necessary.\n",
  "static_pt": "The context for the focal function is as follows:\n// src/lib.rs\n// crate name is strsim\npub type HammingResult = Result<usize, StrSimError>;\nuse std::char;\nuse std::cmp::{max, min};\nuse std::collections::HashMap;\nuse std::convert::TryFrom;\nuse std::error::Error;\nuse std::fmt::{self, Display, Formatter};\nuse std::hash::Hash;\nuse std::mem;\nuse std::str::Chars;\npub fn normalized_damerau_levenshtein(a: &str, b: &str) -> f64 {\n    if a.is_empty() && b.is_empty() {\n        return 1.0;\n    }\n    let len1 = a.chars().count();\n    let len2 = b.chars().count();\n    let dist = damerau_levenshtein_impl(a.chars(), len1, b.chars(), len2);\n    1.0 - (dist as f64) / (max(len1, len2) as f64)\n}\n\nThe function to be tested is presented as follows:\n/// Calculates a normalized score of the Damerau–Levenshtein algorithm between\n/// 0.0 and 1.0 (inclusive), where 1.0 means the strings are the same.\n///\n/// ```\n/// use strsim::normalized_damerau_levenshtein;\n///\n/// assert!((normalized_damerau_levenshtein(\"levenshtein\", \"löwenbräu\") - 0.27272).abs() < 0.00001);\n/// assert!((normalized_damerau_levenshtein(\"\", \"\") - 1.0).abs() < 0.00001);\n/// assert!(normalized_damerau_levenshtein(\"\", \"flower\").abs() < 0.00001);\n/// assert!(normalized_damerau_levenshtein(\"tree\", \"\").abs() < 0.00001);\n/// assert!((normalized_damerau_levenshtein(\"sunglasses\", \"sunglasses\") - 1.0).abs() < 0.00001);\n/// ```\npub fn normalized_damerau_levenshtein(a: &str, b: &str) -> f64 {\n    if a.is_empty() && b.is_empty() {\n        return 1.0;\n    }\n\n    let len1 = a.chars().count();\n    let len2 = b.chars().count();\n    let dist = damerau_levenshtein_impl(a.chars(), len1, b.chars(), len2);\n    1.0 - (dist as f64) / (max(len1, len2) as f64)\n}\nGiven the following constraints, potential panic-triggering statements, and expected return values/types (all extracted from the function under test).\nGenerate test inputs that maximize the function's runtime satisfaction of all constraints and expected outputs while considering panic conditions:\n",
  "depend_pt": ""
}